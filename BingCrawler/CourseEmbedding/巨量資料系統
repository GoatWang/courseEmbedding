



[評價] 102-1 廖世偉 巨量資料系統 - 看板 NTUcourse - 批踢踢實業坊


















批踢踢實業坊
›
看板 NTUcourse
關於我們
聯絡資訊




返回看板


分享







作者nkfly (遠足)看板NTUcourse標題[評價] 102-1 廖世偉 巨量資料系統時間Mon Jan 13 20:12:16 2014
※ 本文是否可提供臺大同學轉作其他非營利用途？（須保留原作者 ID）
         （是／否／其他條件）：
                是


      哪一學年度修課：
                102-1

      ψ 授課教師 (若為多人合授請寫開課教師，以方便收錄)
                廖世偉

      λ 開課系所與授課對象 (是否為必修或通識課 / 內容是否與某些背景相關) 
                資工所 網媒所 為選修

      δ 課程大概內容
                Big Data: Opportunities & Challenges
                Computation: MapReduce
                Hadoop
                In-Memory Computation : Spark
                Graph Computation: Pregel & HAMA
                Distributed Storage: GFS
                Distributed DB:Google's Big Table & HBase
                Distributed DB:Dynamo & Cassandra
                Data Warehouse: Hive & Shark
                Analytics: Google's Drmel & Drill
                Analytics: Big Explorer
                Tech Trend
                以上轉自ceiba上的課程大綱。
                就我自己上完的經驗，然後現在回想，
                除了作業中有碰過的MapReduce & HAMA外，
                其餘所有的東西都只剩下一些概念，然後知道這些名詞，
                我想以後真的需要用到時，才會再深入去研究。

      Ω 私心推薦指數(以五分計) ★★★★
                想從老師的Lecture中深入瞭解那些系統 (做不到)
                想從老師的Lecture中瞭解系統的概念 ★★★
                想認真做個final，並與老師深入交流 ★★★★★
                想隨便混學分 (學不到什麼)
                總結 ★★★★


      η 上課用書(影印講義或是指定教科書)
                上課用書，但推薦這本網路上的e-book
                Urs Holzle and Luiz Andre Barroso.
                The Datacenter as a Computer, Morgan & Claypool Publishers,2009

      μ 上課方式(投影片、團體討論、老師教學風格)
                投影片上課，老師會在臺上講解系統的設計的原理，
                然後常常會直接講code。
                老實說，大部分的時候我都聽不懂，老師在臺上講的東西不知所云。
                我想老師他是懂得其內涵的，但是可能沒有表達得讓學生可以懂。

      σ 評分方式(給分甜嗎？是紮實分？)
                Midterm: 30%
                Programming assignments & Hands-on: 35%
                Final project (proposal, oral presentation, report): 35%
                期中平均60，標準差很大

                分數還沒出來，不知道

      ρ 考題型式、作業方式
                考試  ：問答題、手寫程式題，好像是助教出的題目，
                所以非常的偏非常的細，例如要手寫spark版的Kmeans，
                然而對於spark，老師只有帶過spark官網的sample code，
                作業中也沒使用過；
                又或是會考到很細的什麼MapReduce的combinor，
                誰寫普通的MapReduce考慮過這個東西??
                我在上課方式那裡有講到，很多那麼細的東西，
                我上課的時候就沒有真正聽懂，所以當時在考期中的時候，
                就很憤憤，覺得為什麼要考這麼細，而不考一些大的架構。
                不過最後，助教改得還算寬鬆，我的分數也就還好。

                作業x2：程式作業，MapReduce & HAMA
                是用這兩種framework寫跟PageRank相關的演算法。
                環境必須自己架設，例如HAMA，
                不過MapReduce好像可以用停機很久的國網中心。

                作業差不多花我2天的空閒時間可以完成，
                從裝環境到跑sample code，到改code，debug。(我是資工系大四。)

                Final Presentation： 每組有12分鐘時間報告， 3分鐘Q&A。

      ω 其它(是否註重出席率？如果為外系選修，需先有什麼基礎較好嗎？老師個性？
加簽習慣？嚴禁遲到等…)

                基礎要會寫程式，最好是Java。

                因為我實際跟老師聊過，老師他是一個好人，
                會想認識學生並真正記得你是誰，
                他也會關心你的研究，並會給予一些方向上的建議。
                我覺得可以看出，老師是有料的，只是在臺上表現不出來，
                無法講得讓人聽得懂，然後閒話太多，但是實際跟老師單獨談話，
                卻不會覺得老師閒話很多，看老師的email也覺得老師是個有條理，
                邏輯清晰的人。
                所以，我覺得老師是個強者，也是個想認識學生的好老師，
                只是在臺上的時候表達不出來。

                第二次作業的時間差不多在期中考後2-3禮拜due，
                所以可以說留了相對充裕的時間來做Final Project，
                這點我覺得是相當不錯的，只要找到好隊友，
                並提早穩定開始做，最後出來的成果都不會太差。

                關於final project presentation，
                這個部分我要大大稱讚老師的厲害，
                老師從業界找了不少評審，大概有10個以上，
                使得場面變得相當正式與盛大，
                例如有些組別報告完他們自己設計的資料庫，
                就會有一些業界前輩很積極地過去交流，
                我覺得這基本上是挺好的一件事，
                各取所需，提供更多的機會等等。

                加簽都收。

                出席沒差。

      Ψ 總結
                這門課我不甚滿意的部分有，助教出題、
                沒有公用Hadoop Cluster可以讓學生用、老師講課讓人不太懂
                但是為什麼我仍會給予★★★★的評價，主要基於2點。
                1. 老師是個好人，私下與他接觸，可以學到很多，
                而且老師在final project presentation的時候找來了很多業界評審
                ，我覺得老師是真的有實力有料。
                2. 我自己這組的final project，很早就開始做，
                所以自己在這門課，也是有學到不少東西，
                寫了不少code，並把MapReduce應用在我們的project中，
                還是很有收穫。

                最後，老師下學期有要開，Android虛擬機及編譯器，
                老師是Android系統code的實際貢獻者，一定很強大。
                有興趣的同學可以考慮!



--
※ 發信站: 批踢踢實業坊(ptt.cc)
◆ From: 140.112.16.156
※ 編輯: nkfly           來自: 140.112.16.156       (01/13 20:14)
推 hsnuconan:哇!這麼好的課 我下學期一定要修Big Data應用 01/13 23:10
推 WCLab:樓上老師愛將 最喜歡跟老師一起沖鋒了 01/13 23:48
推 WCLab:走過路過千萬不要錯過喔 喜歡都可以試聽看看 01/13 23:52
推 Carlchen:\Big Data/ \Android/ 01/13 23:57
推 lsc36:下學期想修他的Andriod系統 XD 01/14 01:46
推 bowlbone:加簽有都收嗎？ 第一堂看到盛況後就退了...orz 01/14 07:31
→ KernelChen:樓上一堆亂推文 請不要誤導別人 01/14 10:38
→ KernelChen:然後原po也不是一路唸上來的 半路出家是能給什麼有用的 01/14 10:39
→ KernelChen:資訊? 01/14 10:39
推 QDR18:修課有一定風險 學分投資有過有當 選課前應詳閱公開說明書 01/14 15:38
推 deicide218:一到五樓都是他Lab的學生是嗎囧 01/14 23:48
推 samyyhh:一事歸一事 扯原PO半路出家也太過分了吧 01/15 01:32
推 drliao:有鼓勵有指教的評價，最真，才可幫台灣衝鋒BigData或Androi 01/15 10:25
→ drliao:我改進：去年在史丹佛教CS243時，每週有recitation hours幫 01/15 10:29
→ drliao:沒跟上的同學，所以沒收到有沒跟上的指教，下學期加這hours 01/15 10:31
→ drliao:請大家勿人肉搜索一到五樓，我不知。每個修課學生都是菩薩 01/15 10:37
→ drliao:不敢有“愛將”想法。謝謝。 01/15 10:38
推 ikeaven:這門課給我的感覺就像一家學習吃到飽的餐廳，提供豪華餐點 01/16 09:24
推 ikeaven:需要衝鋒挑戰的，有深度；需要認識業界技術的，有交流； 01/16 09:26
→ ikeaven:需要更多時間修其他課的，不點名；需要分數的，有空間 01/16 09:27
推 ikeaven:如果這不是值得選的一門課，那甚麼是值得選的課 ?? 01/16 09:39
→ chanhou:請問需要先修什麼課程嗎？本身修過C++可以嗎？ 01/27 13:55
→ drliao:Understanding of programming is necessary but not suffi 01/30 09:06
→ drliao:cient. Reviewing of my course slides on BigData Systems 01/30 09:06
→ drliao:is strongly recommended. Plus, read related course mate 01/30 09:07
→ drliao:rial in data mining, machine learning, information retr 01/30 09:08
→ drliao:ieval. Happy New Year and Happy reading during 寒假。 01/30 09:10















巨量資料與資料探勘 - 國立交通大學資訊工程學系 NCTU Department of Computer Science

































中文|English


最新消息

系所介紹 
系所簡介
歷史沿革
系所組織
研究所
系計中
軟硬體實驗室
地理位置
聯絡我們


系所成員

學術研究 
研究焦點
研究成果
研究計畫
研究中心


教學與課程資訊
榮譽事蹟
入學資訊
資工系友

相關連結 
表單下載
網路資源
程式檢定系統
英文檢定系統
Webmail
登入系統










巨量資料與資料探勘
 ＞ 
研究焦點
 ＞ 
學術研究
 ＞ 
首頁
 


回上層
演算法、計算機理論與科學計算
程式語言、編譯器與軟體工程
作業系統、分散式系統與即時系統
嵌入式 系統、晶片系統、計算機結構
電子設計自動化
人工智慧、機器學習、智慧型計算
物聯網通訊
無線網路
多媒體通訊
寬頻通訊
軟體定義網路
電腦視覺、影像處理、圖形辨識
多媒體資訊系統
生醫訊號與影像
人機互動、虛擬與擴增實境、穿戴式技術
圖學、動畫、遊戲、數位學習
智慧環境
雲端計算
巨量資料與資料探勘
資訊與網路安全



 
巨量資料與資料探勘 
Big Data and Data Mining
近年資訊科學領域已自傳統計算機科學與工程以及網路通訊發展出巨量資料領域。網際網路，電子商務，社群網站，乃至於物聯網，世界上所有物件可以像神經連在以起，也產生巨量的資料。現在大家面臨的問題是如何消化這些資料以產生有用的資訊。
目前巨量資料整理多起始於與應用相關，以領域知識為根據先清理資料。之後應用統計，最佳化，機器學習，資料探勘等技術從已有的資料中過濾出有用的資訊。我們應用的領域在電子商務及社群網站的推薦系統；在網路以及安全的系統，以及生物資訊病毒分類系統。巨量資料領域也將與物聯網技術結合，兩個結合領域將深入生活之中。
除了在應用領域，我們也探討巨量資料的理論部分。與巨量資料最相關的領域是統計以及高維度幾何。因為高維度幾何也使得計算成為問題；許多原本可以使用數位計算機藉覺得問題因為資料量過大而變得無法解。另外高維度已造成視覺化的問題。這些問題都有待理論以及系統實作有所突破。
在物聯網的時代，巨量資料成為資料流（stream）的問題，我們也將從理論以及系統實作探討資料流的取捨分析方法。
研究主軸
資料探勘、巨量資料處理、機器學習、社群資料處理與探勘、雲端運算、多媒體資料處理、行動資料處理、網際網路資料處理、資料庫系統 
研究人員
施仁忠、王國禎、胡毓志、蔡錫鈞、林文傑、蕭旭峰、易志偉、黃俊龍、袁賢銘、林甫俊、王協源、曾新穆、曹孝櫟 、李毅郎、彭文志、範倫達、彭文孝、荊宇泰、林一平、王昱舜、張明峰、莊榮宏、曾文貴、王豐堅、邵家健、林寶樹




























巨量資料的時代，用「大、快、雜、疑」四字箴言帶你認識大數據 - INSIDE 硬塞的網路趨勢觀察















































































INSIDE 硬塞的網路趨勢觀察

選單






新創


趨勢


娛樂


評論


焦點Hightlight

硬塞科技字典
物聯網






硬塞報童


主機與網站應用




訂閱


隨時關註最新創業、科技、網路、工作訊息。























趨勢

巨量資料的時代，用「大、快、雜、疑」四字箴言帶你認識大數據 


2015/2/6



Jewel 

大數據、網路


評論






評論





本文由 Yahoo 奇摩贊助。

你可能有註意到，「大數據（Big Data）」在我們的生活裡已經掀起滔天巨浪，繼雲端運算（Cloud Computing）之後，儼然成為學術界跟科技業中最熱門的潮字（Buzz Word），似乎每家公司都在進行有關的研究，三句不離大數據。究竟大數據是怎麼出現，又代表著什麼意思呢？
大數據（Big Data），資料爆炸的時代

大數據（Big Data）—— 或稱巨量資料 ，顧名思義，是指大量的資訊，當資料量龐大到資料庫系統無法在合理時間內進行儲存、運算、處理，分析成能解讀的資訊時，就稱為大數據。
“Big data is data that exceeds the processing capacity of conventional database systems.”
這些巨量資料中有著珍貴的訊息，像是相關性（Unknown Correlation）、未顯露的模式（Hidden Patterns）、市場趨勢（Market Trend），可能埋藏著前所未見的知識跟應用等著被我們挖掘發現；但由於資料量太龐大，流動速度太快，現今科技無法處理分析，促使我們不斷研發出新一代的資料儲存設備及科技，希望從大數據中萃取出那些有價值的資訊。
「Big Data」這個詞最早由 IBM 提出，2010 年才真正開始受到註目，並成為專業用語登上維基百科 1，算是「大數據」的正式問世。而在 2012 年時，《紐約時報》的專欄文章「The Age of Big Data2」更是宣告了「大數據時代」的來臨。值得一提的是，大數據並不是什麼新興的概念，事實上，歐洲粒子物理研究中心（CERN）的科學家已經面對巨量資料的問題好幾十年了，處理著每秒上看 PB（Peta Bytes，註：PB = 1,024 TB）的資料量 3。
TED-Ed 的影片講解 Big Data 概念，簡單又好懂：

一般來說，大數據涵蓋的範圍很廣，定義也各家歧異。最早由 Gartner 公司的分析師 Doug Laney 在 2001 年發表的「3D Data Management: Controlling Data Volume, Velocity, and Variety.」4 一文中挑明瞭資料處理的三個關鍵挑戰 –– 資料量、速度、多樣性，並在 2012 年 Doug Laney 給予大數據一個全新的定義 5：「大數據是大量、高速、及/或類型多變的資訊資產，它需要全新的處理方式，去促成更強的決策能力、洞察力與最佳化處理。」
"Big data is high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization."

於是大部份機構跟公司都將大數據的特性歸類為「3Vs」或「4Vs」–– 資料量 Volume、資料傳輸速度 Velocity、資料類型 Variety，以及後來提出的第四個 V —— 真實性 Veracity。以下整理了 4Vs 簡單的定義跟解釋，可以從這四點切入認識大數據。
Volume 資料量
Data volume: amount of data
以前人們「手動」在表格中記錄、累積出數據；現在數據是由機器、網路、人與人之間的社群互動來生成。你現在正在點擊的滑鼠、來電、簡訊、網路搜尋、線上交易... 都正在生成累積成龐大的數據，因此資料量很容易就能達到數 TB（Tera Bytes，兆位元組），甚至上看 PB（Peta Bytes，千兆位元組）或 EB（Exabytes，百萬兆位元組）的等級。
Velocity 資料輸入輸出速度
Data velocity: speed of data in and out
資料的傳輸流動（data streaming）是連續且快速的，隨著越來越多的機器、網路使用者，社群網站、搜尋結果每秒都在成長，每天都在輸出更多的內容。公司跟機構要處理龐大的資訊大潮向他們襲來，而回應、反應這些資料的速度也成為他們最大的挑戰，許多資料要能即時得到結果才能發揮最大的價值，因此也有人會將 Velocity 認為是「時效性」。
Variety 資料類型
Data variety: range of data types and sources
大數據的來源種類包羅萬象，十分多樣化，如果一定要把資料分類的話，最簡單的方法是分兩類，結構化與非結構化。早期的非結構化資料主要是文字，隨著網路的發展，又擴展到電子郵件、網頁、社交媒體、視訊，音樂、圖片等等，這些非結構化的資料造成儲存（storage）、探勘（mining）、分析（analyzing）上的困難。
Veracity 真實性
Data veracity: uncertainty of data
這個詞由在 Express Scripts 擔任首席數據官（Chief Data Officer, CDO）的 Inderpal Bhandar 在波士頓 大數據創新高峰會（Big Data Innovation Summit） 的演講中提出，認為大數據分析中應該加入這點做考慮，分析並過濾資料有偏差、偽造、異常的部分，防止這些「dirty data」損害到資料系統的完整跟正確性，進而影響決策。

大數據特性，謹記四字箴言：「大、快、雜、疑」
大數據資料量龐「大」（Volume）、變化飛「快」（Velocity），種類繁「雜」（Variety），以及真偽存「疑」（Veracity）。尤其在這資訊大爆炸時代，這些資料變得又多、又快、又雜、又真偽難分。
當然在「大數據」一詞像病毒一樣，侵入我們生活中的各個層面，也有越來越多人提出更多的「V」來解釋大數據，像是 Volatility、Validity、Value、Victory 等，這些分歧的意見在這就不多詳述，只要知道有這些說法、以後聽到別人說到「7Vs」時不要覺得驚訝就行啦！




Wikipedia: Big Data↩


紐約時報：The Age of Big Data↩


CERN experiments generating one petabyte of data every second↩


Laney, Douglas. “The Importance of ‘Big Data’: A Definition”. Gartner. Retrieved 21 June 2012.↩









分享文章或觀看評論

評論






Jewel

喜愛閱讀、學習新知及發掘新奇事物，對設計、創新及網路科技充滿熱情。自稱「崇簡一族」，視 “Simplicity is the ultimate sophistication” 為其生活宗旨，崇尚簡單設計，欣賞美麗事物。現居美國西雅圖，忠心耿耿的星巴克榮譽金卡會員。 


Facebook


Twitter


Mail














訂閱 INSIDE


隨時關註最新創業、科技、網路、工作訊息。






訂閱





相關文章





評論







知名廠商強力徵才中






Android Engineer (APP, SDK) *赴日工作* 

XFLAG (Mixi旗下遊戲公司) 




創業夥伴- 資料分析工程師 

旅型資訊股份有限公司 




Ruby on Rails Full stack developer 

Zooe Inc. 




測試工程師 Test Engineer 

LINEFukuoka [Momozono代徵] 











新創


踏出「休閒運動的一小步」，Reebok 這款鞋將要登上外太空！



2017/7/20



【合作媒體】iFanr愛範兒 

reebok、太空鞋



台灣新創 Pointimize 獨霸亞洲簡報大賽 挺進歐洲科技盛會



2017/7/14



INSIDE 硬塞的網路趨勢觀察 

Pointimize、RISE、歐洲科技盛會



用電商賣吐司　冷凍包子王轉型豪賭！



2017/7/14



商業周刊 

B2C、烘焙、電商



目標時速 1126 公里，「超級高鐵」Hyperloop One 真空試跑成功！



2017/7/13



Chris 

Hyperloop、超級高鐵



創業不再孤獨，SLP Taipei 創業培訓課程即將開跑！



2017/7/4



INSIDE 硬塞的網路趨勢觀察 

SLP、創業、新創


趨勢


Facebook 註冊專利，投入研發 Google 放棄的模組化手機



2017/7/21



Mashdigi 

Building 8、Facebook、專利、手機、模組化



鮮京電信、NVIDIA 合作，取得南韓自駕車路測許可



2017/7/21



MoneyDJ理財網 

南韓、自動駕駛、電信



是預言家日報嗎？哈利波特 20 年，找亞馬遜推出「會動的」電子版



2017/7/21



【合作媒體】iFanr愛範兒 

互動、亞馬遜、動態、哈利波特、電子書



遠程控制「捕魚機器人」，讓你邊玩抓魚遊戲邊賣魚賺錢！



2017/7/21



【合作媒體】iFanr愛範兒 

機器人、海洋生態



Google 街景無極限，前進國際太空站！



2017/7/21



騰訊科技 

Google、太空、街景


娛樂


是預言家日報嗎？哈利波特 20 年，找亞馬遜推出「會動的」電子版



2017/7/21



【合作媒體】iFanr愛範兒 

互動、亞馬遜、動態、哈利波特、電子書



【Cheng lap 的資訊通鑑】打電話玩 RPG：勇者鬥惡婆、修羅戰記與七座金城



2017/7/20



Chenglap 

BBS、RPG、修羅戰記、撥號、遊戲



花錢當課長 SSR 老抽不到？立委籲修法，明示手遊抽獎機率！



2017/7/20



Chris 

SSR、手遊、課金



《冰與火之歌》第七季熱燒，能為 HBO 在網路趕上 Netflix 車尾燈嗎？



2017/7/19



Chris 

HBO、streaming、冰與火之歌



華文首部 VR 電影怎麼拍？蔡明亮說沒有構圖、特寫，要當劇場去規劃



2017/7/18



Chris 

VR、蔡明亮


評論


兩週募破千萬，達成率 1300%！ALPHA Camp 和慕課專案要培養「國際級全端工程師」



2017/7/20



Mia 

ALPHA Camp、全端工程師、募資、慕課、課程



oBike 來台引爭議，問題到底出在哪？



2017/7/20



Mashdigi 

oBike、共享單車、市容問題



在萬物聯網的新時代下，區塊鏈才是撐起一切的安全關鍵！



2017/7/20



精選轉貼 

區塊鏈、萬物聯網



從 Google 出走的這五家「創業車隊」，其命運各自為何？



2017/7/19



【合作媒體】36kr 

Google、無人車創業



Google「你畫我猜」數據分析：你畫圈是順時針還是逆時針？台、日和其他國家大不同



2017/7/18



Mia 

Google、文化、文字、畫圈、畫圓









訂閱 INSIDE


隨時關註最新創業、科技、網路、工作訊息。






訂閱





關於 INSIDE


聯絡我們


隱私權聲明


著作權聲明



© 2009-2017 INSIDE 硬塞的網路趨勢觀察 



























 | Видео на Запорожском портале








 
























Пятница, 21 Июль, 2017г.

Сделать стартовой | 
				Добавить в избранное | 



 



Поиск в разделе Видео





пример:   запорожские мосты




 
			Погода в Запорожье: +22°, ясно  
			







Мой аккаунтрегистрация



E-mail
Пароль
Забыли пароль? 



 
Реклама





 









Главная



Знакомства

Видео

Игры

09

Карта

Такси

Погода








		 
		






























У вас не установлен Flash Player



 



 
 



Теги: 資策會 | III | 前瞻所 | 智慧系統服務 | 鉅量資料 | ARI | 巨量資料 | 智慧健康 | 智慧觀光 | 智慧綠建築 | 智慧社區 | 智慧媒體 | smart | big-data | system | research | 




Комментарии




Комментарии для сайта Cackle


Facebook ()




















 

























 

 


			PortAll.zp.ua - Запорожский городской портал 























 | Видео на Запорожском портале








 
























Пятница, 21 Июль, 2017г.

Сделать стартовой | 
				Добавить в избранное | 



 



Поиск в разделе Видео





пример:   запорожские мосты




 
			Погода в Запорожье: +22°, ясно  
			







Мой аккаунтрегистрация



E-mail
Пароль
Забыли пароль? 



 
Реклама





 









Главная



Знакомства

Видео

Игры

09

Карта

Такси

Погода








		 
		






























У вас не установлен Flash Player



 



 
 



Теги: 資策會 | III | 前瞻所 | 智慧系統服務 | 鉅量資料 | ARI | 巨量資料 | 智慧健康 | 智慧觀光 | 智慧綠建築 | 智慧社區 | 智慧媒體 | smart | big-data | system | research | 




Комментарии




Комментарии для сайта Cackle


Facebook ()




















 

























 

 


			PortAll.zp.ua - Запорожский городской портал 




































巨量資料來襲 | iThome





















移至主內容















































 










技術文章


 

巨量資料來襲
 eBAY每天資料增加50TB、中華電信每月累積4TB紀錄、義大醫院醫療資料7年成長60倍，越來越多企業面臨PB級規模的巨量資料挑戰，你的企業準備好了嗎？

 






 
按讚加入iThome粉絲團









 




 
文/iThome
|
2011-06-24發表
  

 









 撰文☉王宏仁、辜雅蕾 攝影☉辜雅蕾巨量資料的超級挑戰來臨了eBay的資料庫每天增加50TB、中華電信每個月累積3～4TB記錄、義大醫院醫療資料7年成長60倍，越來越多企業面臨PB級規模的巨量資料挑戰分析師：複雜又巨量的資料為資料倉儲系統帶來新挑戰Gartner認為，資料倉儲的角色在2011年將面臨非常明顯的改變，來因應巨量、複雜、更多不同資料形式資料的挑戰，未來邏輯資料庫的概念也會逐漸浮現eBay如何分析巨量資料 用Hadoop分析巨量非結構性資料eBay在4年前就關註半結構性的資料分析，並打造專屬軟硬體平臺，藉由壓縮技術與Hadoop技術分析巨量的半結構資料中華電信如何分析巨量資料 組合168臺伺服器建立巨量資料運算平臺中華電信研究所去年1月完成名為「大資料運算平臺」的建置後，利用平臺測試大量非結構性資料如訊務資料與MOD收視率分析，進行加值應用Teradata的巨量資料對策：Aster Data 用結合SQL和MapReduce平臺處理Teradata以具有SQL-MapReduce技術的Aster Data平臺，處理非結構性資料。同時藉由含SSD的資料倉儲硬體，加快回應速度IBM的巨量資料對策：InfoSphere Big Insights 以多層次架構分析巨量非結構資料IBM透過另建平臺搜尋檔案系統資料，將檔案轉為資料庫格式後，由資料倉儲系統分析Oracle的巨量資料對策：Exadata v2 用儲存層工具過濾資料減少存取瓶頸Exadata v2在儲存硬碟系統中安裝儲存層工具軟體，預先過濾資料欄位，減少資料存取數EMC的巨量資料對策：Greenplum Greenplum可同時支援兩種技術Greenplum的資料庫引擎同時支援SQL與MapReduce，可直接讀取非結構性資料，將其當作外部資料表來進行分析巨量資料的超級挑戰來臨了
在eBay上，每天有上百萬件商品在線上交易，8,800萬名使用者平均每天查詢商品數百萬次，eBay資料庫系統每天會增加上1.5兆筆新記錄，合計每天增加的資料量超過50TB。為了提供各種交易媒合以及使用者行為分析，eBay的系統還得每天處理超過50PB的資料量，來進行5千多項商業分析，這正是eBay分析平臺高級總監Oliver Ratzesberger所面臨的挑戰，一個巨量資料（Big Data）的超級挑戰。巨量資料的挑戰並非只有規模如eBay般的企業才會面臨的問題。在臺灣，中華電信每個月保留的資料如用戶網頁瀏覽記錄等，大約有3～4TB的資料量，若要分析這些原始資料，過程中必須對資料進行多種複製和轉換，系統要處理的資料量還會再增加2倍以上，但中華電信現有資料倉儲設備僅能負荷6～9月所保存的資料量，若直接使用原始資料和傳統資料庫技術，難以進行長期或深入性的分析，來找出關鍵的用戶特性進行客製化行銷。如何分析龐大資料，是中華電信越來越嚴峻的挑戰。不只員工人數上萬人的中華電信，就連人數不到20人的臺灣社群遊戲廠商力可科技，也遇到資料暴增的難題，力可科技今年新推出的Facebook社群遊戲越來越受歡迎，記錄遊戲資訊的資料庫容量也快速暴增。數千名使用者在一天內產生的遊戲資訊高達2GB，1個月就會增加60GB的資料量，按照這個增長速度，不用幾個月，就會用完資料庫伺服器上的硬碟，力可科技總經理馮彥文既興奮又擔心。像社交遊戲這類的社交型網站，資料成長速度飛快，你可以想像假設一個社交網站隨時上線的使用者有1萬人，若這些人每天和10位朋友打招呼，一天就會產生10萬筆資料。若是Facebook，每天有5百萬名臺灣用戶上線，光是臺灣地區產生的資料量，每天至少有5千萬筆。就連醫院也有資料暴增的隱憂，例如義大醫院2004年4月成立後採取全面無紙化的策略，所有醫療影像，包括X光照片、斷層掃描等資料，甚至在導入電子病歷和心血管系統後，7年資料量增加了60倍，從2TB暴增到120TB，義大醫院預估，再過5年，資料量甚至會達到PB等級。 全球資料量2010年成長70億 GB麥肯錫全球研究中心今年5月發表了一份全球巨量資料研究報告，報告中指出，全球資料量光是在2010年就增加了70億GB，相當於4千座美國國會圖書館典藏資料的總和。巨量資料並非是新的議題，過去大多只有科學研究時，會遇到這類巨量資料的挑戰，例如高能物理分析、氣象預測、基因分析、生物研究、財務或商業資訊分析等，學者為了進行複雜現象的模擬和預測，經常利用平行運算或分散式運算技術來處理這樣大量的資料分析工作。 但現在，面臨資料暴增挑戰的企業陸續出現，也有越來越多的企業，擔心自己不久之後會面臨同樣的情況。現在很多提供全球性服務的網路業者如Google的搜尋服務、Flickr的圖片服務、Facebook的各種社交服務等，也都用巨量資料來描述他們所遭遇到的挑戰，再加上行動裝置普及後，光是2010年全球使用中的手機就有50億隻，許多新型態的資料蒐集工具也產生了大量資料，例如相機、麥克風、RFID讀取裝置、無線網路感應等，使用這些裝置提供服務的業者也同樣面臨了巨量資料的處理挑戰。這樣數10TB甚至是PB等級的資料量無法一次儲存在單一硬碟上，必須分散儲存，一般程式常用的關聯式資料庫架構處理這樣龐大資料時的效率不佳，遠超過傳統常見的資料庫管理工具所能處理的資料量。因為資料規模龐大也連到造成了後續進行資料擷取、保存、使用、分享以及分析時的處理難度。目前常見的巨量資料例如像網站Log記錄、RFID資訊、感測器網路資訊、社交網路的互動資料、網際網路上的文件、影音圖片、網路搜尋索引、客服中心呼叫記錄、天文資料、大氣科學分析、基因資料、生化分析、複雜或跨學科的科學分析、醫學記錄，甚至是生產線機臺設備產生的Log記錄。這些大多是非結構性資料，不容易以傳統關聯式資料庫的作法，透過固定資料欄位架構，將資料儲存到關聯式資料庫中來進行處理。除了巨量的挑戰以外，還有資料結構複雜化的挑戰。巨量資料衝擊資料倉儲技術升級這些巨量資料的挑戰帶來IT技術和商用軟體的變革，首當其衝的當然是資料庫和資料倉儲業者，Gartner副總裁Donald Feinberg表示，資料倉儲的角色在2011年時將面臨非常明顯的改變，來因應巨量、複雜、更多不同資料形式的挑戰。Donald Feinberg認為，資料倉儲的角色之所以會有所轉變，其中一項因素就是資料不僅在數量上變多，而且日益複雜，對於5到10年前所設計出來的資料倉儲系統來說，還必須能處理資訊的多樣性、複雜性、巨大的容量而且系統反應速度要即時等特性。而他認為，雖然巨量資料對不同產業都有不同的意義，但基本上，巨量資料代表的就是大量、複雜和非結構化的資料。巨量資料影響層面之廣，IDC軟體市場分析師鍾翠玲表示，巨量資料對於各方廠商都是新的戰場，但她認為，資料倉儲會是因應巨量資料的主力。一直以來，資料倉儲系統大多運用在OLAP（On-Line Analytical Processing）領域，著重在資料採礦、深度分析的功能。在過去，深度資料採礦與建模的工作並沒有立即性的需求，因此，相對於以交易為基礎的OLTP（On-Line Transaction Processing）領域，對時間與立即性的要求沒有那麼高。不過，隨著巨量資料時代來臨，資料量不僅大幅成長，資料的種類與態樣也越來越複雜，企業對於大量訊息快速分析後要立即給予反應的要求也越來越高。這些對專營OLAP資料倉儲的廠商來說，就帶來了效能與分析多樣性資料的能力都必須提升的挑戰。於是，舉凡壓縮技術、SSD硬碟等都紛紛出籠。而各家廠商面對巨量資料的因應策略也有所不同。Donald Feinberg表示，現今大多數廠商都在談巨量資料，並試著將此納入資料倉儲管理的環境中。他分析的幾個資料倉儲廠商分別是甲骨文、微軟、IBM、SAP/Sybase、Teradata、EMC的Greenplum等。他表示，甲骨文與微軟都處於剛開始談論巨量資料的階段，IBM則是靠著Big Insights進入巨量資料領域，Teradata收購的Aster Data被Donald Feinberg歸納為處理多樣性、複雜性資料的領導廠商，因此，他表示，該併購也讓Teradata一舉成為處理巨量資料的領導廠商之一。另外，儲存廠商EMC所併購的Greenplum也將MapReduce納入資料倉儲中，成為另一個處理巨量資料領導廠商。事實上，隨著資料量增加，已有OLTP領域的廠商推出軟硬體整合的產品跨足進資料倉儲的世界。3年多前甲骨文將自己最擅長的OLTP資料庫搭上昇陽的硬體，推出了一款資料倉儲產品Exadata，並且在第二版的儲存硬碟上加裝了儲存伺服器軟體，讓資料採礦計分的功能直接在儲存硬碟上進行，降低資料庫引擎的負擔。面對巨量資料的挑戰，甲骨文大中華區臺灣技術諮詢部資深諮詢經理黃久安表示，原先資料庫軟體其實就能處理許多複雜的資料來源，包括文本檔案，甲骨文推出軟硬體搭配的資料倉儲產品，就是因為企業資料量逐漸增加，必須藉由硬體去剋服為了分析所帶來的巨量資料。不過，雖然甲骨文的資料庫引擎可以做到半結構性資料的分析，並宣稱自己的資料倉儲系統可以同時提供OLAP與OLTP的功能，但是，這代表所有的資料都必須儲存在資料倉儲系統中才能分析，若以資料量計價的話，恐怕沒有很經濟。　
  

     ▲中華電信資訊處第四科科長楊秀一點出巨量資料對企業的真正挑戰是「最大的問題是沒有便宜的儲存方式。」所以，中華電信用Hadoop預先處理來減量資料，降低資料倉儲的負擔。　
中華電信資訊處第四科科長楊秀一就指出巨量資料對企業真正的難題是，「最大的問題在於沒有便宜的儲存方式。」他說。這使得Teradata與IBM Netezza都用另一個平臺先處理大量非結構或是半結構性的資料來達到減量效果。Teradata專門用於儲存分析巨量資料的平臺是併購來的Aster Data，IBM則是採用自家開發的InfoSphere來儲存與分析巨量資料。資料倉儲結合Hadoop運算技術 
 Hadoop是目前最受歡迎的高擴充雲端運算技術，不論企業或IT廠商都使用Hadoop來處理巨量資料，圖為Hadoop提供的網頁管理介面，可以監控每一個運算節點的執行情形。
這些平臺的特色都是採用了Hadoop開源雲端運算平臺的MapReduce處理技術，來解決關連式資料庫無法分析非結構性資料的困境。像是Aster Data就能同時支援使用者透過標準SQL來進行MapReduce的處理，可先透過MapReduce找出非結構性資料中的有用的結構性資料，減少資料量後，再由傳統資料倉儲接手分析。MapReduce是Google用來分析龐大網路服務資料的關鍵技術，在2005年釋出後，開源社群改用Java實作出MapReduce技術的開發平臺Hadoop。MapReduce的基本概念其實不難懂，用一個真實的數錢幣故事來解釋。有位企業主為了刁難銀行，用50元硬幣和10元硬幣償還316萬元的貸款，數萬枚硬幣重達1公噸，還得找來弔車才能送到銀行，幾位行員七手八腳花了好幾個小時才清點完畢。銀行只要不斷加派人手，就能縮短清點時間，例如能立即找到100個人手，10分鐘內就能完成，不會影響到正常銀行運作。就像這個不斷加派人手來清點錢幣的做法一樣，MapReduce可以不斷增加更多伺服器來提高運算能力，增加可承載的運算量。透過Map程式將資料切割成不相關的區塊，分配給大量電腦處理，再透過Reduce程式將結果彙整，輸出開發者需要的結果。資料倉儲業者正是利用Hadoop的高擴充分散式運算技術，來解決巨大資料的難題。不過，另外建置一個平臺，除了增加建置成本之外，當然也就多一道資料存取的工作，資料的正確性也就成了另一個風險。以單純軟體起家的Greenplum雖可同時支援SQL與MapReduce，直接讀取企業存取資料的儲存設備中的資料，並且在計價時只計算保留在資料倉儲空間中的資料量。過去Greenplum一直都是以販售軟體為主，讓企業自行搭配硬體。去年第三季他們也推出了軟硬體整合的產品。就目前而言，各家廠商認為臺灣企業對於分析結構性資料的需求仍舊大於非結構性資料，而龐大資料的產生，則是正在發生中的事情，多數企業開始面對巨量資料的問題，都是在為了未來而打算，而不是現在就面臨的困難。低成本的NoSQL資料庫技術倒是網路業者更快面臨了巨量資料，例如先前提到的力可科技，或像eBay、Facebook、Google等，他們為瞭解決PB等級的資料儲存和擴充問題，也開始研發建置成本較低的分散式開源資料庫，也就是所謂的NoSQL資料庫。這類技術可使用個人電腦等級的伺服器，以較低的成本，但大量的設備來撐起巨量資料需要的儲存規模和分析處理能力。像是Google自行研發的BigTable就是最好的例子。其他如Amazon、Yahoo、Facebook、Twitter也都投入這類NoSQL資料庫的研發。甚至連微軟Azure雲端平臺也使用了NoSQL技術來存取資料。而像Facebook也開發了一套NoSQL資料庫Cassandra，在600多個運算核心的叢集系統上，儲存了超過120TB的站內郵件資料。 目前主要有4種NoSQL資料，包括Key-Value資料庫，記憶體資料庫（In-memory Database）、圖學資料庫（Graph Database）以及文件資料庫（Document Database）。Key-Value資料庫是NoSQL資料庫中最大宗的類型，這類資料最大的特色就是採用Key-Value資料架構，最簡單的Key分析師：複雜又巨量的資料為資料倉儲系統帶來新挑戰
分析機構Gartner副總裁Donald Feinberg表示，資料倉儲的角色之所以會有所轉變，其中一項因素就是資料不僅在數量上變多，而且日益複雜，對於5到10年前所設計出來的資料倉儲系統來說，就必須要能處理資訊的多樣性、複雜性、巨大的容量而且系統反應速度要即時等特性。而他認為，雖然巨量資料對不同產業都有不同的意義，但基本上，巨量資料代表的就是大量、複雜和非結構化的資料。但是，對於擅長處理結構化資料的關聯式資料庫管理系統來說，是很難去處理巨量資料的。因此，Donald Feinberg表示，目前大部分的企業會特別打造一個空間或是平臺來存放非結構化資料或是巨量資料。因應巨量資料的來臨，Donald Feinberg表示，未來邏輯資料倉儲的概念將會浮現，也就是將不同性質的資料存放在不同的資料庫中，就可以用適當的工具來獲取正確的資訊，同時，邏輯資料倉儲會利用適當的後設資料連結所有資料倉儲系統中不同的資料。Donald Feinberg也表示，有許多工具都是用來處理巨量而非結構化的資料，但是，將有很多應用程式是使用MapReduce技術開發。資料倉儲廠商面臨必須快速回應查詢的挑戰巨量資料影響層面之廣，IDC軟體市場分析師鍾翠玲表示，巨量資料對於各方廠商都是新的戰場，其中也包含了儲存廠商，像是EMC買下資料倉儲軟體業者Greenplum就是一例。原因正是，她認為，資料倉儲的確是可因應巨量資料的主力。不過，對資料倉儲廠商來說，還是有不少挑戰存在，首當其衝的是，他們必須要強化關聯式資料庫的效能，增加資料管理和資料壓縮的功能。因為過往關聯性資料庫產品處理大量資料時的運作速度都不快，需要引進新技術來加速資料查詢的功能。另外，資料倉儲的廠商也開始嘗試不只採用傳統硬碟來儲存資料，像是使用快閃記憶體的資料庫、記憶體式資料庫等，都逐漸產生。另一個挑戰就是傳統關聯性資料庫無法分析非結構化資料，因此，併購具有分析非結構化資料的廠商以及資料管理廠商，是目前資料倉儲大廠擴增實力的方向。資料管理的影響主要是資訊安全的考量。IDC軟體市場分析師吳乃沛表示，巨量資料對於儲存技術與資訊安全也都會產生衝擊。首先，快照、重覆資料刪除等技術在巨量資料時代都很重要，就衍生了資料擷取權限的管理。舉例來說，現在企業後端與前端所看到的資料模式並不一樣，當企業要處理非結構化資料時，就必須界定出是IT部門還是業務單位才是資料管理者。而吳乃沛表示，由於這牽涉的不僅是技術問題，還有公司政策的制定，因此界定出資料管理者是臺灣企業目前最頭痛的問題。文⊙辜雅蕾eBay如何分析巨量資料 用Hadoop分析巨量非結構性資料
對於臺灣企業來說，巨量資料的分析與應用大多採取較為保守的態度，即便看到巨量資料的來臨，還是著重於結構性資料的應用。這可能是受臺灣的市場規模所限，相對來說，國外的許多大型企業則是已經看到不少巨量資料的挑戰，並且試著用更好的效能或是管理來解決。比如以麥當勞來說，他們因為近年來在世界各地越來越多產品品項，每一個品項在各地的銷售狀況，都會再傳回美國母公司的資料庫進行分析，為了優化資料庫的效能，藉由管理工作負載的軟體來改善資料回應的速度。但對擁有全世界最大資料倉儲系統的eBay來說，挑戰不僅於此。eBay近年來數據成長的腳步相當驚人。他們現在每天有50PB的新增資料，使用者平均每天對5萬種商品進行數百萬次的網上查詢。除此之外，eBay還有7,000多個商業用戶和分析人員，為了分析，每8秒鐘會產生1TB的資料量。這些加起來，eBay每天要處理的資料量高達100PB。巨量資料最大的挑戰是要同時處理結構與非結構性資料這麼驚人的數字對eBay 來說並不只是量的增加而已。eBay分析平臺高級總監Oliver Ratzesberger認為，近年來在分析資料領域最大的挑戰就是要同時處理結構化與非結構化的資料。eBay的非結構化資料主要是來自行為分析的數據、以及網站點擊率的分析。Ratzesberger表示，這些資料都比過去還要複雜、多變許多。就拿追蹤點擊率來說，近年來大部分的網頁都是動態網頁，過去只要透過網址就能知道使用者正在看什麼網頁，但是現在一個網頁上的內容變多了，而且每一秒都在變化，這對於分析使用者行為來說，難度也就更高。Ratzesberger認為，目前關聯式資料庫已經能夠將結構性資料處理的非常好，不過，在半結構性資料或非結構性資料的處理能力還不行，而這些點擊率資訊就是這一類的資料。運用Hadoop技術將大塊資料打散，可讓資料模型更小因此，eBay在4年多前另外建立了一個軟硬體整合的平臺Singularity，在這個平臺上他們開始開發壓縮技術與解決結構、半結構資料的技術。2年多前這個平臺上加入了Hadoop的技術，專門處理半結構與非結構性的資料。Ratzesberger表示，現在eBay在這個平臺上處理的結構與非結構性資料已經達到40PB。這個平臺除了可以儲存大量的結構與非結構性資料外，藉由Hadoop 的技術處理大塊的非結構性資料，當資料庫引擎出現大量的請求與查詢時，就不需要將整個資料放到資料模型中，因此讓資料模型變得較小。在eBay的作法上，他們先為點擊率中的共同特性設定欄位，像是IP位址、時間、URL、使用者所使用的瀏覽器等，再進行交叉分析。這些欄位仍舊保留，其他較複雜的非結構化訊息則集中在另一個欄位中，一旦出現查詢需求時，就可以經過相對應數值的匹配，找到符合的概念與資料，再應用到資料模型中。而這些資料都會放在同一個資料表中。eBay充分運用所能蒐集到的資料加以分析，並不是IT技術上的變革而已，這些工作，也確實對eBay產生了不少正面的影響。比如說，頂級賣家的銷售額占所有賣家銷售額的百分比從2009年10月的22％，到2010年4月時成長為32％，一共上升了10個百分點。Ratzesberger表示，從分析使用者行為中得出來的介面設計經驗，也優化了網頁結構，提高銷售額。應用虛擬化的資料超市來減少重覆複製資料其實分析本身就是資料量不斷增加的一個重要因素。每進行一次分析，用於分析的資料就會再被複製一次，使得資料量不斷成長。但是，企業也必須使用資料倉儲進行深度分析，惟有深度分析才能創造出與其他企業區隔的獨特之處。為了減少資料不斷複製的情況，Ratzesberger就提出了分析作為服務（Analytics as a Service）的觀念。作法是提供虛擬化的資料架構，也就是將資料超市（Data Mart）虛擬化，這些資料超市就像是一種資料次集合。當eBay旗下各單位有資料分析需求時，可以用自助服務申請專屬的資料次集合。Ratzesberger表示，過去當業務單位需要分析資料時，這些資料可能來自於不同的資料庫，而這些資料庫也不能共享，資料產出的分析會存在一個資料庫中，當另一個單位需要分析時，就要將類似的資料再複製一次，導致許多資料為了不同的分析目的而被一再地複製。資料架構虛擬化之後所有的資料都儲存在統一的資料倉儲中，當任何單位有需要分析服務時，這些資料超市都是共享同一個資料倉儲中的資料，而不需要複製，只有特別具有保存價值的分析結果資料，才另外進行儲存。這樣做也可以解決資料庫使用效率不彰的問題。Ratzesberger表示，過去不同部門的資料超市都各自儲存，使得有些資料庫的效能浪費掉，有的資料庫效能又不敷使用。「在資料架構虛擬化之前，資料庫有一半以上的性能都浪費掉了。」他說。舉例來說，在早上9點時，是行銷與IT部門的使用率最高，10點時，又變成行銷、財務、搜尋的使用率最高，到了下午1點，詐欺跟客戶服務的使用率變得最高。利用資料架構虛擬化的作法，就能在不同時間彈性調配不同的資料庫運算資源給不同單位使用。現在eBay還讓企業內部的員工可以自助服務，申請自己需要的資料超市。這個虛擬的資料超市可以隨時調配需求，也具有簡單的管理功能。未來，eBay也關註於社群網站的言論分析，配合行動裝置銷售版圖的擴展進行更多行動應用的優化，像是藉由行動裝置拍攝逛街看到的衣服照片，就可以立刻搜尋拍賣網站是否有相同物件等功能。因此，從今年開始，eBay還要進一步把Hadoop的技術整合進資料倉儲中，協助分析大量的資料，以因應未來持續增加、越來越複雜的資料量，以及更即時的回應。文⊙辜雅蕾 
     eBay將資料庫中的資料架構虛擬化，讓資料庫資源可彈性配置，也減少因分析造成的大量資料複製的資料量，各單位也可以透過自助服務申請所需要使用的資料超市（Data     Mart）。
中華電信如何分析巨量資料 組合168臺伺服器建立巨量資料運算平臺
雖然對很多臺灣企業來說，巨量資料仍被視為未來才會逐漸發生的事情，但實際上，臺灣電信業者確實已開始發展處理巨量資料的方法。企業分析巨量資料的目的，多半是為了分析客戶行為，並針對這些行為給予主動行銷。以過去常運用資料倉儲分析資料的金融業來說，現在有更多即時性的資料出現，若能結合歷史性跟即時性的資料進行綜合分析，就能讓應用資料的效益更高。現在臺灣也有電信業將巨量資料的分析結果應用在預測駭客攻擊的領域。由於一般駭客在正式攻擊之前，會先嘗試攻擊不同的伺服器，這些攻擊都會在系統的Log中留下軌跡。在Log會有一段敘述，用來描述錯誤訊息，電信業者就藉由可同時處理結構與非結構性資料的資料倉儲系統來處理這些半結構性資料，利用這些錯誤訊息建立模式，進而預測駭客攻擊提早加以預防。顯見得巨量資料在應用領域上已經逐漸多元化。為瞭解決這些巨量又大型的非結構性資料，各個企業作法並不同，但Gartner副總裁Donald Feinber表示，大部分的企業會特別打造一個空間或是平臺來存放並分析這些非結構化資料或是巨量資料。中華電信的作法也是如此。中華電信研究所為了配合中華電信的需求，在2010年1月建置了一個以Hadoop技術為核心的平臺，稱為「大資料運算平臺」，用來分析一些訊務資料、MOD每日收視率分析等。中華電信研究所寬網室研究員蕭毅表示，目前這個平臺仍在研發階段，會針對中華電信內部的需求來開發平臺功能，接下來，將進一步對內實際提供加值應用，未來也打算將技術包裝後，對外提供巨量資料平臺運算的服務。開發巨量資料元件庫，即使不會Hadoop技術也能使用平臺資料
中華電信「大資料運算平臺」組成要素
1. 168臺伺服器叢集，容量600TB。    2. Hadoop雲端運算技術為核心。    3. 平臺使用度模組化工具，如分散式資料庫系統、工作排程、流程管理、資料庫介接工具。    4. 平臺維護效率模組化工具，如效能監測、告警通知、組態管理等。    5. 「大資料元件庫」提供API，簡化開發。
這個「大資料運算平臺」目前是由168臺伺服器所組成，資料容量是600TB，以Hadoop雲端運算技術為核心架構。在底層核心架構上，中華電信研究所再利用開放原始碼各種技術開發了其他模組，像是分散式資料庫系統、工作排程、流程管理、資料庫介接工具等來提高平臺的可使用度。同時，為了提升平臺的維運效率，中華電信研究所開發了管理模組、效能監測、告警通報、組態管理等一般網管所具有的機制。另外，中華電信研究所也開發了一個「大資料元件庫」。蕭毅表示，元件庫就如同中介軟體，藉由這些元件庫的API，開發人員不一定要學會用Hadoop技術來寫程式，就能使用平臺上的資料分析功能。目前這個元件庫底下約有6種元件庫，包括MOD元件庫、影音搜尋元件庫、影像辨識元件庫等。蕭毅表示，當巨量資料平臺所群組起來的伺服器越多時，就表示要處理資料量越大，相對來說，管理能力就一定要增強，而目前中華電信研究所開發的「大資料運算平臺」程式功能已具有管理200臺伺服器的能力，未來若要商用化，這些能力都會持續擴增，讓可運算的資料量達到PB等級。開發介面程式可相互轉換結構與非結構性資料，讓資料的分析更具有彈性中華電信研究所會想要開發這個巨量資料運算平臺，有一個原因就是想要利用Hadoop來處理過去關聯性資料庫不容易處理的大量非結構化資料。非結構化資料通常都呈現非常大型的狀態，就好像是一整篇文章，而不是經過篩選的資料欄位，蕭毅稱為「一尾式」的資料。蕭毅表示，這種「一尾式」的資料，如果要變成結構性資料，第一個問題是由於資料太過龐大，讓資料庫的費用大幅增加。第二個問題是，在資料量太大的時候，傳統資料庫難以連接不同的資料表。因此，「一尾型的資料因為傳統資料庫無法運算，就改放入Hadoop平臺運算，若原本是簡化過的結構性資料，才放進原來的資料庫分析。」他說。像之前中華電信研究所曾經利用傳統資料庫來計算MOD每日收視率分析，結果由於資料量過大而無法分析，建構了「大資料運算平臺」以後，運用Hadoop 技術只需1個小時就能計算出結果。蕭毅認為，如果硬體的數量再增加，分析所需要的時間甚至可以在幾分鐘內完成。雖然巨量資料運算平臺可以解決關聯性資料庫無法分析非結構性資料的難題，但蕭毅認為，只要是200TB以內的資料量都還是可以靠傳統資料庫分析，但超過PB等級資料量的話，傳統的資料庫恐怕就無法負荷。因此，中華電信研究所也在這個平臺上開發了介面程式來轉換結構與非結構性資料，可以將非結構性資料轉成結構性資料分析，也可以把原先結構性資料打散變成非結構性資料，再讓Hadoop技術做倒立式的搜尋。建立培訓機制協助技術人員學習Hadoop技術雖然開發這個平臺為中華電信研究所帶來許多嶄新的測試經驗，但在開發過程中，他們遇到最大的困難就是嚴重的技術瓶頸。蕭毅表示，最大的挑戰在於NoSQL與Hadoop等巨量資料技術與傳統資料的設計觀念完全不一樣，必須訓練資訊人員接受新方法，而難題就在於說服資深的技術人員學習新技術。「一旦採用Hadoop技術，原始程式和應用系統功能都要修改，要讓技術人員重新學習，這就是我們的困難。」他說。中華電信要自己開發元件庫也是為瞭解決這個難題。不過，在這個元件庫下還是得開發不同專業領域元件庫，這時候需要該領域的專家以及能用Hadoop技術開發程式的技術人員共同合作才能完成。就算可以使用元件庫來簡化開發，對於技術人員來說，要從本來傳統資料庫的元件庫轉換，也會出現轉換障礙。而且，蕭毅表示，即使可以利用元件庫，技術人員還是直接用Java寫MapReduce的分析程式，在運作效能與速度都會比較好，技術人員還是得熟悉Hadoop技術。因此，中華電信研究所建立了巨量資料技術的專長培訓機制，來協助技術人員的轉換技能，也為了訓練各應用領域的系統設計人員，建立新的巨量資料架構觀念擁有自行評估設計、規畫、開發的技術能力。文⊙辜雅蕾
Hadoop技術的優缺點比較
    中華電信研究所從2010年1月建置好「大資料運算平臺」後，陸陸續續在這個平臺上測試了不少工作，包含訊務的分析以及MOD收視率分析等。    綜合這1年半來運用Hadoop技術的經驗，中華電信研究所認為，Hadoop技術各有幾項優缺點。    第一個優點是，運用Hadoop技術可以節省成本。中華電信研究所寬網室研究員蕭毅表示，開發巨量資料運算平臺的硬體很便宜，軟體也是免費的，如果要計算一樣的資料量來說，只需要支付用傳統資料庫計算時價格的10分之1。        第二個優點是，減輕程式維護人力。蕭毅表示，過去企業要維護一個傳統資料庫，需要大量的專業人力，尤其是要計算PB等級的資料量時，資料庫會變得更加複雜，加上備份的機制，對於程式維護來說是很大的負擔。但利用Hadoop技術，由於每一筆資料體積龐大，只要利用類似使用搜尋引擎的功能就可以找到資料，而且Hadoop也會自動備份3次，大大減低程式維護的人力。        另外，中華電信研究所也看好Hadoop技術將成為Java程式語言主流架構，可以同時支援開發單機版，或是多機版。    同時，他們也提出幾項目前採用Hadoop技術的缺點，其中有一些也是正在解決的問題。        第一個缺點是，安全性不足的問題。蕭毅解釋，中華電信研究所未來想要讓這個「大資料運算平臺」上擁有多租戶的功能，但是如果要將這些用戶隔開，就必須自行開發程式或使用不同的硬體來區分不同的用戶，不過，他認為，這對於單一企業應用此技術開發單一平臺來說，就不會有這個問題。        第二個缺點是程式開發人員必須要學習MapReduce架構才能在Hadoop平臺開發程式，而且沒有針對各行各業需求打造的元件庫。    第三個缺點則是各版本功能的差異較大，容易造成應用程式相容性的問題。蕭毅表示，為瞭解決這個問題，在開發的過程中就必須加進許多管控機制才能讓程式運作更順暢。        第四個缺點則是管理機制大多為指令介面，缺乏友善的圖像管理介面。事實上，蕭毅認為，對專業的開發人員來說，指令介面並沒有什麼問題，不過對於一般的人來說，容易產生距離感。文⊙辜雅蕾
Teradata的巨量資料對策：Aster Data 用結合SQL和MapReduce平臺處理
專註在OLAP領域的資料倉儲廠商Teradata，一直以來都是以MPP（Massive Parallel Processing）技術分析結構性資料，但巨量資料中混合存在的結構與非結構資料，使得資料的管理分析困難度便高，難以用原先的技術進行分析。為了藉由第三方工具協助，他們在去年12月買下行銷軟體公司Aprimo，用來分析及管理來自網站、客服中心、郵寄廣告或社交網路等不同管道的資料，強化行銷業務領域的分析能力，又在今年買下了Aster Data強化分析非結構性資料的能力。面對巨量資料中的非結構性資料，由於Teradata的資料庫引擎仍沒有處理非結構性資料的能力，在Teradata買下Aster Data以後，資料處理的架構則是將結構性資料與非結構性資料先儲存在Aster Data的平臺上，再藉由Aster Data來支援關連性資料庫SQL語法，以及可處理非結構性資料的MapReduce函式庫，將非結構性資料中可利用的訊息，轉變成結構性資料，進一步分析並建立資料模組，再交由Teradata資料倉儲系統進行關聯式分析。Teradata大中華區專業服務副總經理張錦滄表示，目前Aster Data已預先提供了80個分析模組，針對多種資料源，包括圖形檔、臉書上的文字和感應器收集來的資料，企業不需要自行開發全部的分析模組。同時，該平臺也與Teradata資料庫完成初步整合，藉由開放API，Teradata資料庫可直接用SQL指令呼叫Aster Data平臺分析所產生的資料集（Dataset），並進行分析；在Aster Data平臺上也可取出Teradata資料庫的資料進行分析整合。另外在資料處理的效能強化上，Teradata也在今年4月底推出全新Active EDW 6 系列的SSD與硬碟混合型的資料倉儲來提高資料處理的速度，解決巨量資料需要更即時反應查詢。這種混合型的資料倉儲系統，主要是藉由Teradata的虛擬存儲軟體（TVS）依照企業內部資料使用的頻率來自動分配，讓較常用的的資料置於SSD中處理，較少用的資料則放在一般硬碟中處理，讓平常越常使用資料，能獲得更快的資料處理效能。Active EDW 6680搭配300GB到600GB的硬碟，加上300GB的SSD，資料量可從7TB擴充到36PB。Active EDW 6650則是搭配300GB到450GB的硬碟，企業可自行選擇是否升級到SSD，資料量可從7.5TB擴充到92PB。文⊙辜雅蕾IBM的巨量資料對策：InfoSphere Big Insights 以多層次架構分析巨量非結構資料
面對巨量資料，IBM是以去年併購的資料倉儲廠商Netezza的資料倉儲產品TwinFin應戰。IBM軟體事業處資訊工程顧問莊惟欽表示，專責OLAP的資料倉儲與專責OLTP的資料庫，其應用與強項各有不同，但近年來，單純記錄交易資料已經無法區隔出企業的競爭力，因此，資料倉儲就成為企業發揮獨特優勢的工具。IBM針對巨量資料共有3種產品線，第一種是針對傳統關聯性有結構的資料，像是企業內部一般的ERP、CRM、採購等所產生的資料，第二種則是非傳統、非關聯的資料源，比如智能電網、股票交易等，都是在短時間內產生大量數據的系統，其中也包含了影像。第三種則是巨量資料，這種資料來源通常是非結構性以及半結構性，資料的格式也很多元，像是個人部落格、文件檔案等。在資料處理的架構上，第一種資料則是藉由資料庫或是資料倉儲系統處理。第二種資料則是會藉由InfoSphere Streams處理感應器接收的資料，並不以儲存為目的，而是要快速回應，盡快提供分析結果。第三種資料，則是透過InfoSphere Big Insights平臺當作搜尋引擎，搜尋分析時所需要的文本資料。InfoSphere Big Insights平臺可作為資料的存放空間，運用Hadoop中MapReduce的技術，搜尋存放在該平臺內部的檔案資料，但該平臺僅能進行簡單分析，例如文字敘述中的偏好等，企業若要進一步與歷史資料比對交叉分析的話，還是要靠底層資料庫架構將資料轉換成資料庫格式，再放到資料倉儲中運算。莊惟欽表示，MapReduce可以搜尋影音、文件、語音等檔案，但是在應用上，仍還是以文件為主。TwinFin為了快速回應查詢，搭配了FPGA硬體分析伺服器，來負責大量資料解壓縮、欄位縮減過濾等動作，如同在硬碟與主機資料庫中加裝了加速卡，解決巨量資料從磁碟取出放入主機伺服器記憶體中分析的效能瓶頸，也讓資料存取的速度變快。另外，莊維欽還強調TwinFin可將進階分析軟體如SAS、SPSS直接內建在資料倉儲的系統中，並支援平行處理進階分析軟體。文⊙辜雅蕾Oracle的巨量資料對策：Exadata v2 用儲存層工具過濾資料減少存取瓶頸
甲骨文Exadata v2是整合了昇陽的硬體與甲骨文資料庫的資料倉儲系統。Exadata v2的特色是在儲存層就安裝了可過濾資料的儲存伺服器軟體（Oracle Exadata Storage Server Software），讓儲存伺服器可以先處理部分資料，壓縮後傳給資料庫伺服器，減少往來傳輸的資料量，降低處理器的負擔。另外，壓縮技術使得系統可儲存的資料量更大，加上以快閃記憶體做為快取（cache），提高了系統的效能。甲骨文大中華區臺灣技術諮詢部資深諮詢經理黃久安表示，不同於其他資料倉儲是將全部的資料都傳到資料庫引擎中運算，甲骨文的資料倉儲系統的特色就是在儲存系統中加裝了可過濾資料的儲存伺服器軟體，而這套軟體最大的功能就是過濾資料欄位，減少資料存取時的瓶頸。簡單來說，就是Exadata v2運用儲存系統上的軟體先過濾出部分資料，產生一部份的資料超市（Data Mart）後，資料庫引擎就只需要進行統合的工作，也大大減少了資料庫主機伺服器的工作。另外，藉由Exadata v2採用自家資料庫軟體來處理半結構性資料或是非結構性資料，直接利用甲骨文資料庫中的XML DB產品，把文件檔案當作一種XML網頁的格式，只要在文件內容貼上索引用的標籤，資料庫就可以全文檢索，並能傳到資料庫進行分析。黃久安表示，傳統資料庫軟體比起原本資料倉儲系統更擅長處理半結構性資料，不需要多層次處理。不過，若要處理的資料來源是企業外部的資料，就得利用甲骨文的企業搜尋軟體Secure Enterprise Search來進行搜尋。但只要是企業想分析的資料都得放進資料倉儲的儲存空間中，才能進行分析，成本難免增加。黃久安表示，目前臺灣已有4家企業採用Exadata資料倉儲系統，其中一家高科技製造業已經上線，而他認為，甲骨文的資料倉儲系統可同時執行OLTP與OLAP，當巨大資料不斷產生時，許多資料其實是混合型產生的，比較符合企業的實際狀況。舉例來說，臺灣的高科技製造業導入Exadata資料倉儲系統，主要是用來分析生產線上的狀況，然而，生產線上的資訊大多屬於OLTP，快速運算之後，再經由OLAP分析處理，一旦發現任何問題，如良率下降時，就能立即停止線上的生產，再進行調整。文⊙辜雅蕾EMC的巨量資料對策：Greenplum Greenplum可同時支援兩種技術
資料倉儲軟體Greenplum去年被儲存大廠EMC併購，原先僅有軟體產品，併購後旋即推出軟硬體整合的機櫃式產品，其中的DCA-1000，每個全櫃機櫃內含2臺主機伺服器，16個節點，搭配壓縮技術可達144TB的容量，最大可擴充到24個機櫃。同時，資料計價方式也從過去按照使用人數計算軟體授權費用，改由以資料倉儲系統中的資料量計費。EMC業務協理楊傑儂表示，Greenplum最大的優勢在於它是一個可以同時支援SQL跟MapReduce語法的資料庫引擎。因此，在處理非結構性資料時，Greenplum並不需要再另外建一個分析平臺，而是可以直接讀取存在企業內部儲存系統中的非結構資料，並進行分析。大量的非結構性資料無論儲存在企業的SAN架構或是NAS架構，Greenplum會將這些文件當作是外部資料表（External Table），利用在資料倉儲系統上開發的MapReduce程式分析這些資料表。楊傑儂表示，不過，僅需進一步利用的非結構性資料才儲存在資料倉儲系統中，計價時，也只計算這部分的資料量，能解決儲存非結構性資料成本高昂的問題。為了強化系統效能，Greenplum採用MPP（Massive Parallel Processing）架構，由2臺Master主機，和最多可擴充到上千臺的Segment主機，中間以網路連接。Master主機負責建立用戶端的連接和管理、SQL的解析與形成執行計畫、分發Segment執行計畫與收集結果等工作。資料的儲存、存取和SQL查詢的執行則由各個Segment負責。每個Segment都使用一般PC等級伺服器，上面會搭載Greenplum的資料庫軟體，各自擁有獨立的儲存硬碟、記憶體、CPU等。當執行查詢工作時，則是切分給各個Segment去執行，提高效能。楊傑儂認為，隨著企業有越來越多分析需求，資料查詢的工作越來越複雜，資料存取的速度就很重要。因此，Greenplum將用來選擇、萃取資料的ETL（Extract-Transform-Load）伺服器獨立出來，連接內部網路，這個ETL伺服器會自動將資料分散到讓每一個Segment來進行分析，加快資料存取的速度。文⊙辜雅蕾
 


































 




 







 Advertisement


 

 

更多 iThome相關內容


  
 新一代主流2路伺服器規格大更新 

 Intel推出首款採用Broadwell架構的Xeon處理器，內建10Gb網路晶片 

 活用混合雲策略，重新定義IT服務 

 當代企業IT新顯學：混合雲應用 

 新世代入門級NAS進軍企業應用需求 

 Avago展出100GbE、PCIe I/O整合技術，引領資料中心網路新方向 
 
 






 







 

熱門新聞






 


英國Wi-Fi業者使壞，讓2.2萬名用戶無意中同意去掃流動廁所

2017-07-18
 
 






 


Google 兩步驟驗證將以手機提示取代簡訊

2017-07-17
 
 






 


【AI關鍵技術】三大熱門深度學習框架新進展

2017-07-19
 
 






 


硬體不相容，部份英特爾Atom裝置無法升級Windows 10 Creators Update

2017-07-18
 
 






 


災難！CoinDash首度發行貨幣當天就被駭，損失近700萬美元

2017-07-18
 
 






 


微軟亞洲研究院院長洪小文：越複雜越不管用，AI最適合封閉型的高重複性任務

2017-07-17
 
 






 


安撫使用者不滿情緒，Skype聯絡人狀態顯示功能回來了!

2017-07-17
 
 






 


南韓代管業者Nayana遭勒索軟體攻擊，與駭客達成協議將支付110萬美元贖金

2017-06-21
 
 






 


2017年AI開始普及化，技術競賽白熱化

2017-07-15
 
 






 


國際警方聯手關閉暗網市集AlphaBay

2017-07-17
 
 



 

專題報導




企業行動化管理解決方案採購大特輯 


AI 100（上） 


公有雲儲存服務大盤點 


富士通AI新戰略 


企業身分驗證雲端服務採購特輯 

更多專題報導
 

 


















	關於我們 - 巨量資訊科技中心 - 單位介紹 - 工研院中文版
























        您的瀏覽器不支援JavaScript語法,但是並不影響您獲取本網站的內容。
    



















:::
工業技術研究院

迴首頁網站導覽菁英招募出版品服務據點公告電子報專業連結FBYouTubei創科技EN










關於工研院

工研院簡介

董監事會

經營團隊介紹

工研院院士

綠色低碳院區

社會公益

獲獎榮耀

工研院院友會

安衛品質環境能源政策



創新應用

簡介

智慧生活

健康樂活

永續環境



產業服務

技術移轉

檢測服務

創業育成中心

開放實驗室

產業趨勢諮詢

產業學習服務

業界合作



新聞室

新聞資料庫

新聞連絡

精彩影音



單位介紹

總覽

南分院

中分院

生醫與醫材研究所

綠能與環境研究所

材料與化工研究所

機械與機電系統研究所

資訊與通訊研究所

電子與光電系統研究所

量測技術發展中心

影像顯示科技中心

服務系統科技中心

產業經濟與趨勢研究中心

巨量資訊科技中心

智慧機械科技中心

智慧微系統科技中心

雷射與積層製造科技中心

產業學院

技術移轉與法律中心

產業服務中心

國際中心













:::

首頁
單位介紹巨量資訊科技中心


關於我們






                    關於我們


字級：
小字級
中字級
大字級

若您無法使用字級縮放功能，請改用鍵盤"Ctrl"+"加號鍵"或"Ctrl"+"減號鍵"，來放大或縮小字級

巨量資訊科技中心


面對全球巨量資料（Big Data）時代的來臨，工研院成立「巨量資訊科技中心」，為國內第一個以推動巨量資料技術與產業為任務的科技研發中心。在工研院強化系統、軟體與服務研發之宏觀策略之下，期許巨量資訊科技中心成為台灣發展巨量資料技術與分析的研究重鎮，並藉由產業應用之方式，將研究成果技轉至國內廠商，積極促成新創事業，以提升產業加值競爭力。 巨量資料已成為全球資訊及服務的新趨勢，資產價值從過去有形轉變至無形，「資料」儼然成為企業最重要的資產之一，「資料」將成為資訊經濟時代的新石油。面對全球化的國際競爭，巨量資料分析將對未來我國產業產生優化，台灣長期以硬體組裝與生產為主，巨量資料分析技術將可強化我國在製造業，以及服務業的競爭力。  巨量資訊科技中心的成立任務有二，其一是建立智慧分析技術，協助資訊軟體業建立知識經濟核心能力；其二，是切入智慧分析應用，協助相關產業提昇生產力、創造新商機。巨量資訊科技中心執行的策略將是善用工研院跨領域整合之優勢，選擇台灣具獨特優勢之應用領域切入；並結合Social, Local, Mobile（SoLoMo）、智慧聯網（Internet of Things；IOT）、人工智慧（Artificial Intelligent）、開放源碼（Open Source）、開放資料（Open Data）等重要趨勢，與國內外產學研合作，加速帶動技術與產業的發展。 巨量資訊科技中心技術核心能量將涵蓋跨領域的需求，提供產業所需的智慧分析與機器學習演算法等核心技術，建構巨量資料及開放資料分析應用所需之運算平臺，以巨量資料之創新應用情境來進行服務設計與商業模式，提供全方位的巨量資料解決方案。



           
    











友善列印


若您無法使用字級縮放功能，請改用鍵盤"Ctrl"+"加號鍵"或"Ctrl"+"減號鍵"，來放大或縮小字級

分享：
Share to Twitter
Share to Plurk
Share to Facebook
Share to Google Plus


                                當SCRIPT關閉時,請點選以下連結.
                                Facebook
plurk
twitter
google plus





TOP



:::
:::

巨量資訊科技中心

關於我們

研究與發展
智慧製造巨量資料分析智慧商務巨量資料分析智慧健康巨量資料分析巨量資料平臺人工智慧自然語言處理智慧視訊監控
可移轉技術

聯絡我們












關於工研院

工研院簡介

董監事會

經營團隊介紹

工研院院士

綠色低碳院區

社會公益

獲獎榮耀

工研院院友會

安衛品質環境能源政策



創新應用

簡介

智慧生活

健康樂活

永續環境



產業服務

技術移轉

檢測服務

創業育成中心

開放實驗室

產業趨勢諮詢

產業學習服務

業界合作



新聞室

新聞資料庫

新聞連絡

精彩影音



單位介紹

總覽

南分院

中分院

生醫與醫材研究所

綠能與環境研究所

材料與化工研究所

機械與機電系統研究所

資訊與通訊研究所

電子與光電系統研究所

量測技術發展中心

影像顯示科技中心

服務系統科技中心

產業經濟與趨勢研究中心

巨量資訊科技中心

智慧機械科技中心

智慧微系統科技中心

雷射與積層製造科技中心

產業學院

技術移轉與法律中心

產業服務中心

國際中心









法律聲明智財聲明工研院圖書館服務專線 / 信箱採購資訊問答集本網站已通過A+等級無障礙網頁檢測

版權所有© 2014工業技術研究院 ∣ 新竹縣竹東鎮中興路四段195號  (地圖) ∣ 總機：+886-3-582-0100 ∣ 客服專線：0800-45-8899 














巨量資料 | NEC















This is the top of the page.
Jump to main content.
Please note that JavaScript and style sheet are used in this website,Due to unadaptability of the style sheet with the browser used in your computer, pages may not look as original.Even in such a case, however, the contents can be used safely.




Site menu starts here.
Skip site menu.




End of site menu.













Displaying present location in the site.
首頁系統解決方案巨量資料解決方案
Main content starts here.









巨量資料解決方案巨量資料處理技術的活用可疑人物監控安全解決方案活用臉部辨識技術之行銷服務巨量資料處理技術之相關產品與服務NEC的巨量資料透過巨量資料解決社會課題創造價值解決方案支援巨量資料的先進技術顧客特性推斷技術











巨量資料解決方案






















有效地利用資訊、促進社會進步
目前全球人口70億人預估到2050年將成長到90億人，再再顯示全球對於能源、水資源、天然氣、糧食等之需求將大幅提升；另一方面從資訊科技的發展來看，近10年來中央處理器 (CPU)運算速度的進步超過百倍，通訊網路傳輸速度的進步超過千倍，資料量迅速地成長，從原來每人每天772KB到今天的20.5GB。在資訊爆炸的現今，要如何妥善、有效地分析這些資訊並活用到個人、企業、政府，以增進社會的進步呢？

NEC CONNEXIVE與巨量資料雲端處理分析平臺
提供最佳解決方案，M2M建立了一個完整的即時資訊收集平臺

NEC CONNEXIVE提供具效率的全面性M2M (Machine to Machine)巨量化資訊收集平臺，連結各式各樣的裝置與感測儀器，包括如家用電子設備、汽車、自動販賣機、攝影機、工業儀器、環境感測等等，透過無論是家用網際網路、有線網路、無線網路或電信業所提供的3G/4G行動數據網路，以接近即時 (Near Real-time)的方式收集所要的資訊，並儲存於雲端巨量資料中心，供進一步的處理、分析與應用。就整體解決方案從收集 (Gather)、分析 (Analysis) 到創建價值 (Create Value) 來看，M2M建立了一個完整的即時資訊收集平臺，並且可透過各種不同的網路通訊方式來收集巨量資料。

創造資訊分析的價值
以資訊處理分析的角度來看，資訊可簡易地區分為原始資料 (Explicit Information or Raw Data) 與隱含資訊 (Implicit Information)，而資訊分析之價值也就是在快速收集的巨量資料中找出背後的意義，進而推展出對人類社會或企業運行上有價值的產出。

長期並即時的資訊收集，更能建立有效的分析與應用
掌握目前促銷活動的成效
以百貨賣場舉例，收集來訪客戶的資訊如：人數、性別與年齡層，並配合實際天氣狀態、交通與特賣商品等資訊，經過分析後便能掌握目前的促銷活動是否具成效。

購買行為分析作為未來商品促銷活動依據
透過分析購買商品的客戶年齡與性別之原始資料，進而達成使用者購買行為分析，能夠作為未來商品促銷活動設計的依據，來創造企業價值。
除此之外，在農業、交通、犯罪調查等，都可以利用此平臺進行資訊收集、分析，以創造新的價值。

將在全球建立CONNEXIVE M2M平臺並推出各類型應用實例
NEC將致力於五種巨量資料分析引擎 (Analysis Engines) ，來創造隱藏在原始資料背後的應用價值，分別為「Invariant Analysis」、「Heterogeneous mixture learning」、「Facial Recognition」、「Action Analysis」以及「Text Matching」。在實際應用的場景下，多種分析引擎將被同時使用，以達到資訊相互之關聯度、長期資訊之樣式 (Pattern)，並利用智慧自我學習的能力來進行預測。
NEC也將在全球從大中華區、亞太區、歐洲、北美到中南美建立CONNEXIVE M2M平臺，並計畫在農業、交通、物流、遠端監視/看護、環境、能源、防災等領域推出相關之分析應用實例，以實現『關懷人類與地球的資訊社會』之願景。

新聞焦點
2014年7月29日　NEC強化「異種混合機械學習」 發現巨量資料中的複數規則
2014年7月14日　NEC臉部辨識技術 連續3次榮獲NIST評比全球第一
2014年6月11日　日本島根核能發電廠採用NEC「故障預兆監視系統」
2013年12月17日　NEC迎接巨量資料時代的挑戰
2012年12月10日　NEC強化巨量資料事業 推出三項搭載自有尖端科技的分析型雲端服務
2012年10月11日　NEC巨量資料處理技術
Contact
聯繫我們>
Top of this page




Share:Tweet




相關連結全球首創「群眾行為解析技術」！在群眾影像中偵測擁擠狀況及異常情況

















































巨量資料分析-使用RHadoop




















 資策會 數位教育研究所 科技化服務訓練中心 


【資策會臺北課程】Big Data、商業智慧、SAP系列課程
【Big Data課程】Big Data之處理與分析實務班
【Big Data課程】Big Data之處理與分析進階班
【Big Data課程】巨量資料分析-使用RHadoop
【Big Data課程】資料分析首部曲-R軟體實作班
【Big Data課程】資料分析二部曲-R軟體與資料探勘
【Big Data課程】資料分析三部曲-R軟體與資料視覺化
【雲端運算課程】Cloud Computing 雲端運算國際認證班
【雲端運算課程】CompTIA CEP 雲端運算國際認證班
【雲端運算課程】雲端資訊安全實務
【雲端運算課程】CompTIA Security + 國際網路資安認證班
【雲端運算課程】雲端SLA服務水準協定實務
【商業智慧課程】整合Big Data與BI實戰班
【商業智慧課程】Big Data資料倉儲應用實務班
【SAP ERP課程】SAP TERP國際認證班
【SAP ERP課程】SAP顧問認證班
【SAP ERP課程】SAP五大模組入門課程

							【主題館】資料科學家主題館

							【主題館】雲端運算課程主題館

							【主題館】服務科學主題館

 















 


　


《歡迎企業包班，洽詢電話 (02)6631-6533， 
								黃小姐》






「資料科學家」系列課程，同步招生中！





 ◆ 課程介紹









												　　 
												當Hadoop技術問世後，巨量資料儲存及處理的問題便獲得瞭解答，不過與其單純處理資料，企業還是希望能從資料中獲取關鍵資訊，因此必須藉由資料探勘及機器學習等分析技術，從巨量資料中掏金。雖然統計語言R本身已經提供了許多資料分析與圖形化的套件，卻缺乏有效分散處理巨量資料的特性，因此透過RHadoop：結合R語言易於分析資料的特性與Hadoop的分散式運算及儲存能力， 
												便能有效的解決巨量資料中的分析問題。　　 
												為了滿足業界需求，資策會特規劃「巨量資料分析－使用RHadoop」課程，本課程學員將學習到如何使用RHadoop 
												分析巨量資料及架設分析應用等關鍵技術，學習該如何結合R 與Hadoop 
												Eco 
												System，打造巨量資料分析系統，藉由實作分析應用，讓學員更加瞭解如何透過RHadoop進行大量資料的處理、分析與應用。







◆ 課程目標









 
												　　本課程學員將學習如何使用RHadoop架構資料分析平臺等關鍵技術：包含學習到該如何使用Ｒ進行資料探索與分析、如何透過Hadoop 
												Eco System 建立分析應用流程，及學習如何使用RHadoop實際建構分析與應用平臺。 







◆ 課程特色









　　
												本課程旨在建立巨量(Big 
												Data)分析、應用的根基，讓參訓學員瞭解巨量資料分析的觀念與方法， 
												課程重點在於透過採體驗式教學方式的實作，經由指令剪貼方式來體驗實際的操作方式，以從體驗中驗證課程所學。







◆ 招生對象










● 
												企業資料分析部門主管及相關人員

● 
												專案經理、系統架構師或系統網路管理人員

● 
												對於巨量資料(Big 
												Data)處理、分析、應用有興趣者 








◆ 預備知識








　　建議要有使用過Hadoop 
												的經驗、或正在導入Hadoop 
												者，及些許程式設計基礎為佳。 







◆ 課程大綱











 課程單元 
課程內容




													巨量資料分析基礎

◇
 什麼是巨量資料?
◇

													 資料科學家應扮演的角色
◇  資料分析的案例 




													Hadoop Eco System簡介

◇  使用HDFS分散式儲存資料
◇  使用MapReduce
													進行平行運算
◇  使用Sqoop
													與Flume
													擷取資料
◇  使用Oozie
													管理工作 




													R 

													資料分析

◇  為什麼使用R語言?
◇  R語言基礎
◇  使用Plyr
													套件完成簡單資料分析
◇  使用R完成資料探索





													RHadoop 

													元件簡介

◇  RHadoop
													

													簡介
◇  資料序列化與資料交換-
													使用ravro
◇  操作 
													HDFS –
													使用RHDFS
◇  操作HBase 
													– 使用RHBase
◇  操作 
													MapReduce – 使用rmr2




													R MapReduce 

													簡介與實作

◇  Hello 
													World- 

													使用rmr2
													撰寫MapReduce
													版的Word 
													Count
◇  使用rmr2
													實做巨量資料統計
◇  使用rmr2
													實作表格連結 
													(table join)




													RHadoop 

													與巨量資料分析

◇  使用plyrmr
													實作資料分析
◇  使用rmr2
													實作迴歸分析
◇  使用rmr2
													實作分群演算法
◇  使用rmr2
													實作分類演算法




													推薦系統實作

◇  簡介推薦演算法 
													
													Collaborative Filtering
◇  使用R
													實作推薦演算法
◇  使用RHadoop
													實作推薦演算法
◇  串接Hadoop 
													Eco System 元件與RHadoop
													建構及時推薦系統


* 課程執行單位保留調整課程內容與講師之權利　　 








◆ 課程日期








本課程目前僅提供企業包班，時間可依客戶需求做彈性調整
												。








◆ 課程時數









本課程時數為二天、14 小時。







◆ 上課地點









資策會數位教育研究所教室 或 客戶指定場地。 
                  本所教室地址：臺北市信義路三段153號10樓 （捷運大安站1號出口）。 







◆ 
									課程費用










請來電洽詢。洽詢電話：(02)6631-6533，黃小姐。








◆ 
										相關課程推薦









 

Big Data之處理與分析(Hadoop)實務班

Big Data之處理與分析(Hadoop)進階班

Big Data資料分析首部曲-R軟體實作

Big Data資料分析二部曲-R軟體與資料探勘

Big Data資料分析三部曲-R軟體與資料視覺化

R軟體與網頁資料擷取應用

R軟體與財金資料分析

Python資料探勘實作

巨量資料分析-使用RHadoop

Elasticsearch分散式系統實務班

Spark巨量資料分析實務班

Spark Streaming巨量資料串流分析實務班

文字資料探勘實作班















 資訊工業策進會數位教育研究所  版權所有，禁止侵害，違者必究。
Copyright (c) 2013 III Digital Education Institute. All Rights
      Reserved








產業學院~巨量資料資料分析自動化設計







 






日期
課程名稱
課程大綱


03/07
              ~
03/08
巨量資料資料分析自動化設計-NoSQL
              資料庫系列

在巨量資料的領域中，我們極其渴望擁有創新技術，用以簡化巨量資料分析的基礎建設，Cassandra並非高速的in-memory資料庫，但的確可以很快地把資料寫到傳統磁碟中。和大部分NoSQL資料庫一樣，Cassandra也很簡單，企業部署它會比關聯式資料庫還快，因為它幾乎不用耗費建資料模型的工。擴充性與彈性是NoSQL資料庫的兩大特色，也是它們變成巨量資料(Big   Data)專案最愛的原因。


03/23
              ~
              03/24

AIX大數據分析

大數據分析形塑企業策略已成趨勢，AIX 用戶不需去疊床架屋，定時搬動大量資料至其他大數據環境，直接就在資料源 AIX 環境中實現數據分析自動化工作，同時解放POWER 運算能力，簡化資料分析系統架構與資料同步作業之複雜性。



04/13
              ~
              04/14

巨量資料資料分析自動化設計-R實務應用進階課程

因應巨量資料時代來臨，績優企業紛紛嘗試從蒐集內部「企業資源規劃」 (ERP) 系統與外部網路資源，想要建置類似「市場動態情報儀表板」系統，協助經營層決策分析與方案制定。Linux 作業系統是驅動開源軟體發展與育成平臺，從風潮蔚起的科技研發開始，到今天有愈來愈多商用資料分析系統、程式庫，與相關應用系統，亦使用 Linux 作為原生發展平臺，利用開放核心與作業系統設計優勢，完全釋放硬體運算能力。



04/17
              ~
              04/18
雲端物聯網行動
              運算設計密技班

隨著網際網路和行動裝置的便利與發達，雲端議題與物聯網被視為未來重要的產業趨勢與發展商機，本課程主要是透過服務設計模式帶領學員瞭解從前端聯網技術或感測設備與網際網路怎做連接。


05/11
              ~
              05/12
巨量資料資料分析自動化設計-製造業專題系列

因應巨量資料時代來臨，績優企業紛紛嘗試從蒐集內部「企業資源規劃」 (ERP) 系統與外部網路資源，想要建置類似「生產排程分析動態平臺」系統，協助經營層決策分析與方案制定。製造業所面臨的「微利時代」將是未來的常態，在市場規模有限的情況下，有效的成本控制仍是製造商最重要的手段。


05/16
              ~
              05/17
巨量資料之智慧金融服務設計與分析

在網路科技與行動商務普及下，金融服務亦以全新服務模式與經營樣貌躍躍欲試，如何能掌握金融服務產業變化，以「設計思考」(Design Thinking)，探索潛在服務商機與應用模式，如何為智慧企業爭取競爭優勢與先機是當務之急。


06/05
              ~
              06/06
巨量資料資料分析自動化設計-Python系列

Linux 作業系統是驅動開源軟體發展與育成平臺，從風潮蔚起的科技研發開始，到今天有愈來愈多商用資料分析系統、程式庫，與相關應用系統，亦使用 Linux 作為原生發展平臺，利用開放核心與作業系統設計優勢，完全釋放硬體運算能力。在資料分析自動化設計上，Python 以物件導向程式語言簡潔語法。






【   講 師 簡 介 】

-李智老師-

                【經歷】IBM資深策略暨技術顧問
工研院產業學院產業分析暨產業導顧問講師
國立清華大學 服務科學研究所 兼任助理教授
【專長】從事資訊科技暨管理相關工作多年，專解系統整體架構設計，與企業作業管理改造等。
【精通】軟體工程問題與解決因應之道。
系統整合 (EAI) ，平行運算，與雲端運算相關技術。
多種作業系統，多種類型電腦語言，與多種資料庫。

                【熟悉】服務科學 企業架構 策略地圖 系統動力等企業轉型管理方法與實踐。
製造業 流動業 金融保險業 運輸業 供應鏈 等服務創新與與設計。
企業資源規畫 (ERP) 導入，整體服務資訊系統規劃。
智能分析 (Business Analytics)，巨量資料 (Big Data)，及其相關應用。
企業轉型改造，提供企業診斷與諮詢建議。







【   開 課 資 訊 】

主辦單位：財團法人工業技術研究院   臺北學習中心

協辦單位：聚碩科技股份有限公司

上課地點：聚碩科技(臺北市內湖路一段516號10樓，捷運港墘站)，實際地點依上課通知為準!
全程於電腦教室上課，學員可再自行攜帶筆電

註意事項：
1. 為確保您的上課權益，報名後若未收到任何回覆，敬請來電洽詢方完成報名。
2. 因課前教材、講義及餐點之準備及需為您進行退款相關事宜，若您不克前來
                    請於開課三日前告知，以利行政作業進行並共同愛護資源。
3. 若原報名者因故不克參加，但欲更換他人參加，敬請於開課前二日通知。

課程承辦 :    02-2370-1111#319 顏小姐





 






版權所有 c 2017 工業技術研究院
工研院產業學院．價值創造










產業策略評析：巨量資料之商業模式















■本網站改版測試中，歡迎舊雨新知來試用。網址：http://iknow.stpi.org.tw





│本室簡介│重大產業政策│產業新聞│市場報導│產業策略評析│專利情報│技術情報│


本站檢索：













│熱點專題│調查報告 │關鍵圖表│訂電子報│服務內容│STPI首頁│


 











■ 巨量資料之商業模式


巨量資料（Big Data）是一新興技術，這新興技術要能形成產業（emerging technology industrialization）關鍵在於未來商業模式（business model）與創新商業模式（innovative business model）有沒有被發展出來，而商業模式的發展首重價值鏈之重新定位，對巨量資料所衍生之產品（product）或產業（industry）亦是如此。而引導巨量資料商業模式發展的核心概念，正是決策支援系統（decision supporting system）。
圖一巨量資料價值鏈架構
 
決策支援系統包括軟硬體架構及對應人力組織編制
首先，巨量資料體系所要支援的客戶包括內部與外部，內部主要是總經理或是需要擬定各項計畫之功能部門，例如行銷與業務單位、製造與生產單位、研究與發展單位及內部流程管控單位等。
外部包括事業客戶（Business to Business）與消費者（Business to Consumer），其相關功能亦包括行銷與業務、製造與生產、研究與發展與內部流程管控。而消費者即是利用巨量資料分析結果之終端顧客，例如購買線上書籍時，網站對於你的其他書籍推薦，或是其他針對其他需求所產生之精準行銷與廣告。
其次，巨量資料體系屬於系統整合工作，因此可視為解決方案供應商（solution provider）。解決方案供應商透過自行建置基本資料、軟硬體工具與研擬有價值之資訊，提供給內部與外部客戶能夠支援其決策之情報。
第三為基本資料供應商（data or raw data），這些公司提供自己資料（own data），或整合其他企業之資料（other data）或整合政府公部門之資料（open data），其關鍵在於資料之取得與整合。資料供應商如同天然礦場的擁有者，具取得龐大資料（Volume）、提供快速資料（Velocity），並具有整合種類繁多雜資料（Variety）之供應商將成為贏家。
關於基本資料供應商，日本野村總研諮詢顧問城田真琴在《大數據的獲利模式》一書中[1]，根據核心資料與非核心資料、內部資料與外部資料之二維矩陣，區別出四類基本資料內容與運用策略，如圖二與圖三所示。基本上，如何掌握與控管內部核心資料，並善用外部或政府部門之公開資料（open data），是基本資料供應商營運關鍵。
圖二、巨量資料之資料運作分類
 
資料來源：城田真琴(2013)
圖三、巨量資料之資料運作策略
 
資料來源：城田真琴(2013)
第四為巨量資料之軟硬體系統供應商，即提供資料儲存、處理、分析之資訊（information technology）軟硬體公司，包括IBM、Oracle、SAP與HP等。其中不同類型之軟體工具開發商將引導此產業之發展。當然已趨成熟之雲端運算（cloud computing）之儲存與運算工具亦屬其中，而支援這些軟硬體工具後面的電腦代工廠商，例如廣達與鴻海等，當然也可視為此產業鏈之相關成員。
最後，為決策情報服務公司，包括發展具有獨特演算技術之新興服務公司，能夠從不同屬性資料中萃取出（整合出）具有情報價值的公司。一般來說，相關決策支援模式包括整合與診斷資料、找出規律行為、預測未來可能模式並提供改善之建議等。
在決策情報服務公司運作模式中，城田真琴在《大數據的獲利模式》一書中亦提出以「批次處理型」、「即時資訊型」及「個別優化」、「全體優化」提出決策情報服務公司之四類商業模式，有興趣的讀者可以進一步瀏覽。
最後，從新興技術之商品化與產業化來說，較佳之運作流程應為「5.內外部客戶→ 4.系統整合（巨量資料）→ 3.決策情報→2.軟硬工具→1.基本資料」。如何從需求端引導服務，並進一步整合軟硬體的發展，將是未來巨量資料產業的發展主軸。當然，產業發展過程中，在「內外部客戶」、「系統整合（巨量資料）」、「決策情報」、「軟硬工具」與「基本資料」等個別流程的運作與優化，也是想要投入此領域新興企業可思考之營運重點。(1186字；圖3)
參考資料：

城田真琴 (2013), Big Data大數據的獲利模式：圖解．案例．策略．實戰, 經濟新潮社出版社

 
關鍵字：Big Data大數據；獲利模式
(科技產業資訊室-- David撰稿，2013/10/29)
 



前期資料：


 企業的經濟護城河
2013/10/24


 王道思想與永續經營
2013/10/24


 DIKW金字塔與情報應用
2013/10/17


 專案管理的第十大知識領域--利益關係人管理
2013/10/17


科技服務化，鴻海結構轉型再上路
2013/06/06


... more 


 

 















財團法人國家實驗研究院科技政策研究與資訊中心   資訊服務處　科技產業資訊室 2003-2009 All Rights Reserved.


臺北市106-36 和平東路二段106號14樓（科技大樓14樓）/ TEL: (02)2737-7660 / FAX: (02)2737-7837 / Email: stmember@stpi.narl.org.tw 






版本建議MSIE 8.0以上　最佳解析度1024x768以上 │ Visitors:  Since 2003/03/10 | 網頁更新：2013/10/29



 












	科技大觀園 -- 大數據與巨量資料分析


















































:::
						｜
						網站導覽
						｜
						科國司
						｜
						科技部
						｜
						行動版


一般大眾 
						|
						國中小生





























  單元  



新知報
新知專欄 (956)電磁波知多少 (5)科技新知 (999)專題報導 (541)人物專訪 (86)科普點子王 (33)行動與無線通..(3)產學小聯盟 (32)科普人談科普 (32)創業第一桶金 (16)


文章
科普知識 (793)精選專題 (1121)文章導覽 (9)突破的故事 (94)女科技人 (28)獎聲響起 (82)台灣新發現 (274)科技與社會 (114)科技瞭望 (67)


演講
「展望」系列..(182)「週日閱讀科..(167)「週末 Le..(146)「FUN科學..(58)經典譯註『人..(24)人文大師下午..(2)「網際網路素..(53)健康與醫藥科..(27)科學講古 (74)週末學術科普..(34)生活化與科技..(16)中研院「知識..(20)其它演講 (195)


影視
來點ㄦ科學 (100)牛頓馬戲團 (80)科學大解碼 (201)科技萬花筒 (34)發現 (129)神秘的史前踏..(5)科學再發現 (113)流言真與假 (118)有趣化學實驗..(38)百秒說科學 (23)二分鐘發現科..(37)ㄐㄧㄤˋ吃就..(26)科普一傳十 (40)其它影視 (2)


廣播
科學180 (67)生活才科學 (112)來自海洋的聲..(103)今天科學了沒..(50)科學三分鐘 (148)啟動科學腦 (52)似是而非 (54)




  訊息  

佈告欄 (16)電子報 (51)演講活動 (466)科普活動 (372)

  認證  

公務人員學習教師研習

  科學迴廊    資源  

活動成果 (45)假日科學廣場 (45)科普資源資料庫 (11720)國研院年度成果 (1)全國科學探究競賽－這樣教我就懂 (2)

  出版品  

科學發展 (67)東亞科技與社會國際期刊 (13)



























:::
首頁 > 
			單元 > 文章 > 科普知識 > 大數據與巨量資料分析



				科普知識
			





	
		 
		
    


















大數據與巨量資料分析
 


2016/08/05
曾龍 | 崑山科技大學資訊工程系／雲端大數據分析暨資通安全研發中心
















 

在2012年10月發行的《哈佛商業評論》中，戴文波特‧湯姆斯（Thomas H. Davenport）及帕蒂爾（D.J. Patil）發表了一篇文章，描述「21世紀最性感的職業—資料科學家（Data Scientist: The Sexiest Job of the 21st Century）」。同年美國歐巴馬政府更投資了近兩億美元推行「大數據的研究與發展計畫（The Big Data Research and Development Initiative）」，希望藉著提升從大型複雜的資料中提取知識的能力，能加快科學和工程的開發並保障國家安全。

2015年2月19日，白宮正式任命帕蒂爾為首位首席資料科學家。當天他在聖荷西（San Jose）的Strata + Hadoop 2015會議做了一場主題演講，講題是「資料科學：我們將邁向何方？（Data Science: Where are We Going）」，美國總統歐巴馬還特地錄製短片祝賀大會順利舉行。影片中歐巴馬呼籲：「我們需要你—資料科學家—來幫助國民建立更好的數位服務，幫助我們揭開更新的創意……幫助我們改善這個國家和全世界。」

資料科學與大數據

在這個大數據時代，資料科學的狂潮不斷地推動著這個世界。2015年4月，美國國家標準技術研究所（National Institute of Standards and Technology, NIST）發表了共包括7冊資料的「大數據互用性架構草案」。在第一冊定義篇中，資料科學被譽為新興的第四個科學典範（理論科學、實驗科學、計算科學與資料科學）：「資料科學是一透過完整資料生命周期流程，所產生的自原始資料到具行動力的知識的實驗性綜合體。」

資料科學，這第四個科學典範是2007年由格雷‧吉姆（Jim Gray）所命名，它代表直接由資料本身所產生的知識。NIST所定義的資料科學典範是「直接由資料，並透過一系列發現、假設與假設檢定的流程，萃取出具行動力的知識」。

所謂「Big Data」坊間有許多翻譯，包括大數據、巨量資料、海量資料等。NIST則定義為：由具有龐大資料量、高速度、多樣性（多重異質資料格式）、變異性等特徵的資料集所組成，它需要可擴延的架構來進行有效儲存、處理與分析。

巨量資料的特徵

今日可說是個大數據的時代！自從進入21世紀後，全球資料量呈現大爆炸式的增長，資料量從PB級躍升至ZB級。根據國際資料公司（IDC）發布的2012年研究報告，從2011年全球創建和複製的資料總量是1.8 ZB，並以每兩年增加一倍的速度快速增長。預計到2020年，全球產生的資料總量將超過 40 ZB，這是地球上所有海灘上沙粒數量的57倍。

谷歌（Google）公司每天處理超過24 PB的資料，每個月則超過400 PB。淘寶網有5億多名會員，線上商品超過10億件，每天交易平均金額高達新台幣6億元以上，每日所產生的資料量也超過 50 TB以上，然而這只是全球資料量的一小部分。

大數據時代產生的資料有許多特徵，這些特徵也引領資料科學在這些新興資料型態的分析上有著重大發展。巨量資料的最大特徵當然就是龐大的資料量，如一般桌上型電腦的記憶體是以GB為計量單位，硬碟的容量則是以TB為主。電腦運算須把資料載入到記憶體上，因此要處理龐大的PB或EB資料，就必須有新的儲存模式及計算模式，這也是資料科學的重要研發領域。

巨量資料的第二大特徵就是速度。高速有兩層涵義，第一層是資料產生的速度，每天社交網路Facebook、Twitter及通訊軟體Line所產生的資料就是一例。IDC指出，到2020年，全球所有資訊部門擁有伺服器的總量將較目前多出10倍，管理的資料也比現在多出50倍，全球將總共有35ZB的資料量。另一層則是處理的速度要求，以中國大陸淘寶網在每年11月11日光棍節的電子商務活動為例，淘寶網須針對交易資料即時呈現活動的交易現況，這是巨量資料分析的一大挑戰。

巨量資料通常有時效性，一旦傳送到運算伺服器，就要能即時取得分析結果才能發揮其最大價值。巨量資料的即時分析需要飛秒級的速度，甚至1秒內完成億萬級資料的處理和分析，這也是巨量資料分析的挑戰課題。

資料多樣性是巨量資料的第三大特徵。一般商業交易所使用的資料大抵是以結構化資料為主，透過預先定義好的資料欄位進行儲存與運算。但除了結構化資料外，巨量資料還包含許多半結構化或非結構化資料。這些資料包括各類型生產機台所產生的日誌檔案、各式網路設備與伺服器產生的網路日誌檔、聲音、影片、圖片、地理位置資訊等，這類型資料的儲存與運算都需要新的運算架構。

上述所指的巨量資料主要以龐大的資料量（volume）、速度（velocity）與資料多樣性（variety）三大特徵為主，這就是大數據所謂的3V特徵。後續也有許多學研單位指出其他特徵包括真實性、價值與視覺化，這也凸顯了巨量資料的多面向觀點。

挑戰性課題與解決方案

龐大、高度異質性與非結構化資料的第一個挑戰就是資料儲存架構。現今資料庫技術主要是1970年卡德（E.F. Codd）所提出的關聯式資料庫，不管是開放原始碼的Postgresql、MySQL或商業版的Oracle、IBM DB2與微軟MSSQL資料庫，都是以關聯式資料庫的理論架構為主。這些資料庫在面對新興的高度異質性與非結構化資料都面臨了極大的挑戰，因此有許多新興的資料庫技術被提出，這些不同的資料庫技術都通稱為NoSQL（Not Only SQL）。

NoSQL與傳統式資料庫有相當多的不同，後者以定義良好的資料庫綱要來組織與儲存資料，並利用高階的SQL查詢語法存取資料。但前者無固定綱要模式，且NoSQL也不使用一般認知的SQL查詢語法。這些不同資料庫設計都有其目的與使用場景，最主要的設計考量包括可擴展性資料儲存功能的需求。

NoSQL資料庫是現今資料庫技術研發的重要領域之一。在超過上百個NoSQL資料庫中，大致可區分為五大類型，分別是鍵—值儲存資料庫、圖形資料庫、文件儲存資料庫、記憶體資料庫與欄儲存資料庫。這些針對資料多樣性與可擴展性所設計的資料庫技術，是資訊領域必須掌握的新技術。

針對龐大資料量進行運算，最常見與直覺的做法便是利用多台電腦（電腦叢集）來運算，這是分散式運算著重的主題。要進行電腦叢集的運算，通常需要有分散式檔案系統來儲存計算過程中的資料，以方便不同電腦快速且一致地存取資料。另外，不同台電腦運算所得的結果可能出錯，部分電腦也有當機的風險，因此要讓計算結果無誤，便需要新的容錯架構來處理。巨量資料的資料匯入、資料預先處理、資料分析與資料探勘都是巨量資料分析平臺必須深入考量的課題。

面對龐大資料量的分析，必須特別註重穩定性與系統平臺的可擴延性。現今巨量資料分析有許多架構，從最早廣受喜愛的Hadoop生態體繫到新進的Apache Spark、Storm都有不同的擁護者。Hadoop是Apache軟體基金會眾多開放原始碼的專案之一，也是現今使用度最高的巨量資料分析平臺，它主要特色在於分散式運算和分散式檔案系統，整合了許多軟體及元件共同組成了一個Hadoop生態體系，具有高可用性、高擴充性、高效率、高容錯性等優點，因此廣受喜愛。

2003年當谷歌發表GFS分散式檔案系統的核心技術論文後，次年卡丁‧道格（Doug Cutting）根據這理論撰寫出HDFS分散式檔案系統，同年谷歌再發表Map Reduce核心運算模式，而卡丁‧道格與同事也立即實作出運算架構。

由於卡丁等人曾聽見小孩為小象玩具取名為Hadoop，索性就把Hadoop做為專案名稱。Hadoop在2008年成為Apache頂級專案，這專案主要核心技術可分為3個子項目，即Hadoop Distributed File System（HDFS）分散式檔案系統和MapReduce分散式運算架構及資源調度子模組Yet Another Resource Negotiator（YARN）。

HDFS分散式檔案系統把分散的儲存資源整合成一個具有高容錯性、高擴充性、高吞吐率等優點，且允許使用者把Hadoop建置在低廉的硬體上的檔案系統。HDFS是主從架構，它由兩種角色組成：命名節點及資料節點。命名節點負責檔案系統中各個檔案屬性權限等資訊的管理及儲存，資料節點則擔任運算的任務。

一個龐大的資料檔案會被切割成數個較小的區塊，儲存在不同的資料節點上，每一個區塊還會有數份副本存放在不同節點，因此當其中一個節點損壞時，檔案系統中的資料還能保存無缺。命名節點還需要記錄每一份檔案存放的位置，當有存取檔案的需求時，要協調資料節點來負責回應。當有節點損壞時，命名節點也會自動進行資料的搬遷和複製。

Hadoop的分散式運算是建立在MapReduce計算模式，其主架構是把龐大資料切割成許多部分資料，然後交給多台電腦先進行Map運算後，再做Reduce運算來進行巨量資料的平行化快速處理。在Hadoop中是以Java編寫程式，其以Java開發的MapReduce模式稱為native mode（原生模式），若要以不同程式如Python或R進行分析，也可利用Hadoop Streaming模式開發。

Hadoop隨著發展推出第2代的Yarn資源調度與管理的新框架。Yarn把負責運算工作分配與追蹤的任務分開來，它使用資源管理者負責管理分配全局資源，並使用應用程式主導者負責管理任務的整個生命周期內的所有事宜，任務執行的追蹤與管理則使用節點管理者。整體運作架構是由應用程式主導者與資源管理者溝通協商如何分配資源，和節點管理者協同執行並監測應用程式的執行情況。

Hadoop生態體系除了上述三大核心外，也包括了下列子平臺。其中HBase是用於Hadoop檔案系統上的資料庫系統，採取Column-Oriented 資料庫設計。Hive則是建置在HDFS上的一套分散式資料倉儲系統，可用SQL語法存取Hadoop資料，另可讓使用者以慣用的SQL語法存取Hadoop檔案中的大型資料集。

ZooKeeper則是監控和協調Hadoop分散式運作的集中式服務，可提供各個伺服器的配置和運作狀態資訊，用於提供不同Hadoop系統角色之間的工作協調。Pig則利用更接近使用者的介面，封裝了HDFS和MapReduce中低層的程式設計介面，使用者使用一些敘述就能完成工作，而不需撰寫較為複雜的Map Reduce框架程式，這就降低了使用者開發的難度，也為系統自動進行最佳化。

Sqoop主要是協助傳統關聯式資料庫與 Hadoop之間進行高效率的大規模資料交換，透過 Sqoop可以輕鬆地在指令模式下把資料導入到Hadoop與其相關系統（如HBase、Hive）。Mahout則提供具高度可擴充性的機器學習演算法，它包括群集、分類，以及協同過濾的核心演算法。

近年興起的Storm是Twitter公司在2011年7月收購的BackType社交媒體資料分析公司，其首席工程師馬茲‧內森（Nathan Marz）與其團隊於同年9月17日推出的第一個作品Storm，是一個分散式串流資料處理系統，其強大的分散式管理、可靠性高、高容錯保障，在性能和功能方面大幅彌補Hadoop所欠缺的即時運算需求，使得很多公司紛紛加入使用。

Clojure是Storm主要的開發語言，它是基於Lisp所設計的函數型語言，並且增加了多執行緒等特性，使得Storm在底層有著高效率的通信和非同步處理能力。另一個著名的巨量資料分析平臺是Spark，2009年由扎哈里亞‧馬泰（Matei Zaharia）在加州大學柏克萊分校AMP Lab所開發，2010年以Scala語言開發完成，並於同年透過BSD授權條款開源釋出。2013年該專案捐贈給Apache軟體基金會，並切換授權條款至Apache2.0。

2014年2月Cloudera宣稱加入Spark，2014年4月MapR也投入Spark陣營。另Apache Mahout也放棄MapReduce模式，將改用Spark為計算引擎。2014年11月Databricks團隊使用Spark刷新資料排序的世界紀錄而引起全球註目。

Spark使用了記憶體內運算技術，能在資料尚未寫入硬碟時，就在記憶體內分析運算，甚至透過Spark的串流處理套件即時處理串流資料。根據Apache Spark官方的說明，Spark在記憶體內執行程式的運算速度，可以比Hadoop MapReduce的運算速度還快上100倍，即便是在硬碟執行時，Spark也有達到10倍的速度。

面對巨量資料時代的作為

我國及全球已經有許多巨量資料分析的應用領域與成功案例。以半導體產業為例，各種先進製程控制的資料分析至為關鍵，一旦製程良率出問題，如何在最短的時間內找出所有相關因素，甚至事先就能預知並且杜絕問題發生，一直是高科技製造業最大的挑戰。面對各種機台產生的大數據，巨量資料分析就扮演著重要角色。

另外在全球興起的物聯網、車聯網及智慧城市，再加上各國政府力推的開放政府與開放資料，都會產生許多龐大的資料，這些資料如何產生有價值的訊息、如何有效管理與利用，更是現今資料治理的重大議題。

各行各業對於大數據的濃厚興趣，也直接反映在大數據人才的豐厚薪資中。McKinsey Global Institute在 2013 年的報告指出，僅美國而言，到 2018 年就缺少 14 萬到 19 萬名的大數據分析師。在美國芝加哥獵人頭公司Linda Burtch 2014年的薪資報告中，也發現資料科學家的平均年薪資已優於醫師和律師，而美國人力資源網站 SimplyHires.com與Linkedin上則約有 24,000～36,000個資料科學職務求才名額。這些報導都不斷強調嚴重欠缺的資料科學家或大數據資料分析師將是各國爭相搶奪的人才。

資料科學家或大數據資料分析師都是近三年才冒出頭的職務，學術界尚未培育出足夠業界所需的人力，因此現在大多是以其他領域的人來從事資料分析工作。譬如雅虎的資料分析工作是由天體物理學、應用數學背景的人擔任；行動付款公司Square則僱用認知心理學家來研究消費者的付款行為模式。

大數據時代的到來及巨量資料分析的龐大需求，不管是大資料城市治理，還是智慧聯網的各種應用，都宣示著需要更多的人才投入。這也是現今台灣朝向加值創新智慧島之路邁進時，須及早準備的議題。
 瀏覽人次：6,077    大數據(29)  來源：《科學發展》2016年8月，524期，66 ~ 71頁 




已有 1 個人按~讚~


 

熱門標籤  

 


物種滅絕(13)電洞(21)聖嬰現象(14)擴增實境(19)輻射(27)基因工程(6)電波(41)臺灣山毛櫸(3)災害(42)3D列印(29)枯草桿菌(4)再生能源(27)稀有物種滅絕(2)肥胖(48)大數據(29)機器人(51)衛星遙測(32)演化(85)穿戴裝置(7)地震(106)


 


 返回列表 


 





需要開刀　該如何選醫師...
大數據的行動網路商機
資料科學的第一堂課：心...
物聯網產業現況與大數據...
畢業季到 多目標的決策...





















單元
新知報
文章
演講
影視
廣播


訊息
佈告欄
電子報
演講活動
科普活動


認證
公務人員學習
教師研習


科學迴廊


資源
活動成果
假日科學廣場
科普資源資料庫
國研院年度成果
全國科學探究競賽－這樣教我就懂


出版品
科學發展
東亞科技與社會國際期刊














關於我們 | 著作權聲明 | 隱私權及資訊安全宣告 | 服務條款 | 聯絡我們

				瀏覽本站建議使用 IE10 以上、MS Edge、Firefox、Chrome 或 Safari 等瀏覽器，1,280 x 720 以上解析度  
				    
				網站瀏覽人次：15,184,158
			

















[評價] 103-2 李宏毅 機器學習及其深層與結構化 - 看板 NTUcourse - 批踢踢實業坊


















批踢踢實業坊
›
看板 NTUcourse
關於我們
聯絡資訊




返回看板


分享







作者ittfie (kevin)看板NTUcourse標題[評價] 103-2 李宏毅 機器學習及其深層與結構化時間Fri Aug  7 15:24:57 2015
※ 本文是否可提供臺大同學轉作其他非營利用途？（須保留原作者 ID）
         （是／否／其他條件）： 是


      哪一學年度修課： 103

      ψ 授課教師 (若為多人合授請寫開課教師，以方便收錄)

         李宏毅

      λ 開課系所與授課對象 (是否為必修或通識課 / 內容是否與某些背景相關) 

         電機工程研究所

      δ 課程大概內容

         主要就是講Deep Learning和Structured Learning，不過由於這門課是完全

         由作業決定成績，且到後來的內容就越來越和作業沒有關係，我也就不常去

         上課了...。老師的網站上寫得很清楚，有興趣可以自己去看，而雖然我沒

         修過林軒田的機器學習，不過老師表示他會在內容上盡量和林軒田老師的課

         錯開來，所以應該不用怕學不到新東西。

      Ω 私心推薦指數(以五分計)
★★★★★
η 上課用書(影印講義或是指定教科書)

         無

      μ 上課方式(投影片、團體討論、老師教學風格)

         投影片上課，不過由於這門課修的人實在太多，老師有開隔壁教室做同步，

         老師把投影片和課程錄影錄影公開在課程網頁上，所以我覺得如果只是要聽

         老師講機器學習的話，不一定要修課。老師上課常會用很多動漫哏，尤其是

         涼宮春日，喜歡的人應該會覺得滿有趣的。另外老師很喜歡大家問問題，有

         人舉手就會很激動的停下來給發問的人講，然後幾乎都會說「我覺得這個問

         題問得非常好」，才繼續回答。偶爾也會請專家來演講，像是請NVIDIA的人

         來講GPU在機器學習的應用，還有請徐宏民教授講 convolutional neural

         network，Final Stage(等下說明)時也有請聯發科的人講機器學習有用在手

         機的什麼什麼功能。


      ρ 考題型式、作業方式

         因為作業就佔了全部所以這裡我會講詳細一點，我儘量用比較淺顯的方式說

         明每個作業在做什麼。其實作業做的都是語音處理，只是這門課不需要相關

         基礎也能做。而作業基本上都是分組進行，一組兩到四人，這次大概有五十

         組左右。


         作業一：手刻DNN(Deep Neural Network)

         目標是把一句不知內容為何語音轉成「phone」，phone可以就想做音標，像

         是apple 是由 ae p el 三個音標組成的。每一個聲音片段都會對到一個音標

         ，所以我們要做的就是把聲音片段的音標找出來，我們拿到每個聲音片段都

         是用一個向量表示，所以DNN的輸入就是一個向量，輸出就是它的音標，當然

         助教會給有標記的資料讓我們train。會講手刻是因為助教幾乎禁止所有機器

         學習的Library，除了計算需要的GPU加速的套件以外。


         作業二：Structure Learning

         作業二是直接承襲作業一的，雖然現在一句話對應到的 phone sequence

         已經決定，但是如果考量每個phone的前後出現機率的話，可以讓結果更好

         。這個步驟就是這個作業的目的，而助教是希望我們用 Structured SVM的

         Library，搭配Viterbi演算法完成。


         作業三：手刻 RNN(Recurrent Neural Network)

         RNN和一般NN不同的是它有記憶性，而做的事和作業一類似，只是這次輸入

         是有挖空並附選項的福爾摩斯小說的句子，而我們要利用RNN找出正確的選

         項。train的資料是助教給的十九世紀小說集(只能用這個train)。助教有

         另外同意讓我們用google word2vec，只是RNN基本上還是要自己寫。


         Final Project：實際完成一個ASR(Automatic Speech Recognition system)

         其實前幾次作業都是在做語音辨識系統的一部分，Final Project就是希望

         我們把它全部合起來，流程大概是這樣：


               hw1           hw2                   WFST          hw3
      一堆向量----->一串音標----->一串修正過的音標----->一串單字----->一句話


          WFST是助教會提供的，把phone轉成單字的程式，當然你要自己寫也是可以

          ，和之前不一樣的是這次開放使用任何Library(不過當然不行直接把音檔丟

          google 的語音辨識)，不用交程式碼(前幾次都要)，只看你上傳的句子的正

          確性與繳交的書面報告。最後上傳分數前十組的可以參加 Final Stage，每

          組報告十分鐘，有修課的同學都可以來聽，並可參與投票，不過只有最後得

          票最高前三組有獎，並有額外的加分(非常多)。

      σ 評分方式(給分甜嗎？是紮實分？)

         三次作業各20%，Final Project 40%

         作業主要依據報告，上傳分數，和繳交的程式碼(Final Project不用)

         我的感覺是給分非常甜，雖然不知道最後等第是怎麼打的，不過單次破百似

         乎是很正常的。

      ω 其它(是否註重出席率？如果為外系選修，需先有什麼基礎較好嗎？老師個性？
加簽習慣？嚴禁遲到等…)

         可能第一次開，加上這主題最近很夯，非常多人想修這個課，應該不太好簽

         因為我是一開始就選上所以忘記怎麼簽了...，不過要註意這門課真的很累。

         基礎的話我只有上計概知道有NN這個東西而已...，我們這一組也都沒學過

         相關的機器學習的知識，第一次作業就比較辛苦，而且有些進階的技巧像是

         Maxout, Dropout 之類的老師那時還沒教所以也沒用進去，分數就差了點，

         後面幾次就比較沒有這個問題，但還是花很多時間在寫程式和弄懂問題上面

         。我是覺得整體來說：程式基礎>機器學習基礎>語音辨識基礎，這門課是希

         望你除了會機器學習的方法外，更期待你可以完整的把它實作出來 。另外

         這門課不會限制語言，不過大部份人用的不外乎Python,C++或MATLAB，不過

         比較麻煩的是這門課很吃計算資源，所以用C/C++可能算較快外，如果組員

         有人有好的GPU應該有幫助，好像也是有人花錢買AWS來算就是...

      Ψ 總結

         其實滿推薦這門課的，不過要有花非常多時間的準備，最好找好組員再來修，

         能有這個機會可以一起合作寫這些很重的作業也是滿難得的。收穫的部分我

         個人是：程式 > 機器學習 > 用Toolkit 的技巧。程式不用說，一直寫，尤

         是檔案輸入輸出變得很熟，機器學習部分我覺得有些可惜，因為作業實在太

         重，就沒放太多心思在老師上課的內容上。而我們這組到最後幾乎還是什麼

         東西都是自己刻，像是Kaldi 之類的工具不是沒試著去學怎麼用，但後來都

         因為太複雜弄不懂而放棄，這部分也滿可惜的。不過有時候也很奇怪，一些

         步驟用正規toolkit上傳的分數也不見得較自己亂試的方法高。


         論整體的收穫，雖然其實我們這組最後成績非常好，但我還是覺得有點浪費

         教授細心準備這門好課的感覺，因為沒學到很多機器學習的東西。結論每一

         次的作業都滿複雜的，我想助教很難仔細瞭解你們到底做了什麼，所以成績

         也很難反應你的收穫，且因為自由度很大，絕對有可能可以找一些偷吃步的

         方法，因此收穫真的很看個人。



--
※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 1.172.236.170
※ 文章網址: https://www.ptt.cc/bbs/NTUcourse/M.1438932299.A.017.html
※ 編輯: ittfie (1.172.236.170), 08/07/2015 15:32:55
推 hei566: 能請春日創造一個永無止盡的八月嗎 08/07 20:02
推 felgher: 看到這ID必推強者我同學XDDD 08/07 23:04
推 fantasywater: 感謝分享 08/09 06:30
推 st890609: 感謝您的分享，請問各位大大這門課104-2不開是真的嗎? 08/10 00:50
→ energyaup6: 104-1好像有開 08/10 09:52
推 hahaha222: 感謝分享。另外，目前 104-2 應該沒有開課的計畫 08/10 23:14
推 kriswu8021: 強者我同學 11/08 18:49











臺大課程地圖






















首頁
共同必修課程

國文
外文
體育
服務學習
進階英語


通識課程

文學與藝術領域
歷史思維領域
世界文明領域
哲學與道德思考領域
公民意識與社會分析領域
量化分析與數學素養領域
物質科學領域
生命科學領域


院系所課程

文學院
理學院
社會科學院
醫學院
工學院
生物資源暨農學院
管理學院
公共衛生學院
電機資訊學院
法律學院
生命科學院
牙醫專業學院
獸醫專業學院
其他教學單位


其他全校性課程

軍訓
共同選修
新生專題
寫作教學
基本能力課程


English．英文版



課程名稱：【機器學習及其深層與結構化】


當學期所開設課程



課號
班次
課名
學分數
全半年
授課教師
時間(教室)


CommE5045

機器學習及其深層與結構化 
3.0
2
李宏毅
五789 (電二143) 


CommE5045

機器學習及其深層與結構化 
3.0
2
李宏毅
五789 (電二143) 



往年所開設課程



開課年度
課號
班次
課名
學分數
全半年
授課教師
時間(教室)


106-1
CommE5045

機器學習及其深層與結構化
3.0
2
李宏毅
四234 (電二106) 


104-1
CommE5045

機器學習及其深層與結構化
3
2
李宏毅
五789 (明達205) 


104-1
CommE5045

機器學習及其深層與結構化
3
2
李宏毅
五789 (明達205) 


103-2
CommE5045

機器學習及其深層與結構化
3
2
李宏毅
五678 (明達231) 


103-2
CommE5045

機器學習及其深層與結構化
3
2
李宏毅
五678 (明達231) 










Copyright 2008 臺灣大學 National Taiwan University
10617 臺北市羅斯福路四段一號　No. 1, Sec. 4, Roosevelt Road, Taipei, 10617 Taiwan(R.O.C)
電話 (Phone)：+886-2-3366-2388轉308,607　　傳真號碼 (Fax)：+886-2-2362-6282


















        機器學習及其深層與結構化(李宏毅教授) 的一則課程評價 - CourseUnion：分享 x 學習 | 大學的課程社群































Toggle navigation





                          CourseUnion
                        








                                        註冊
                                    



                                        登入
                                    


































評價
 機器學習及其深層與結構化 






wulala

2016年7月11日





103-2 &nbsp
                            甜 5
                            扎實 5
                            清晰 5
                            難 5
                            整體 5



# 課程大概內容從基本的機器學習概念開始講起，介紹機器學習使用者都應該知道的基本機器學習理論、方法和工具，並講授機器學習如何應用在語音處理、影像處理、自然語言處理等領域。除了基本的機器學習概念和方法之外，本課程還會涵蓋下麵兩個機器學習中較為進階的主題： 一、深層機器學習：在分類問題中，例如：判斷一帳相片有人臉或是沒有人臉，輸入的物件(如：相片)和其類別(如：有、無人臉)之間的對應關係有時可能非常複雜，簡單的模型可能難以描述這類複雜的關係，所以需要以深層類神經網路(Deep Neural Network, DNN)等較複雜的模型來處理這類問題。 二、結構化機器學習：在真實世界的應用中，機器常常需要學習去處理遠比分類更複雜的問題，例如： 1.當我們對語音辨識系統說一段話，機器必須根據從訓練資料學習的結果找出聲音訊號對應的字串。2.當我們在Google上輸入關鍵字時，Google透過機器學習的技術知道如何產生搜尋結果。 結構性機器學習和預測便是一系列處理上面這類複雜問題的機器學習方法。 具體每週上課內容Deep Neural Network -> Training Deep Neural Network -> Structured Learning for Sequence Labeling -> Structured SVM -> Real Implementation Issue -> Recurrent Neural Network -> Structured SVM with Hidden Variables -> GPU (Guest Lecture), Graphical Model, Gibbs Sampling -> Restricted Boltzmann Machine and Autoencoder -> Deep Learning for Spoken Language Technology -> Markov Logic Network (課程大綱)# 上課用書(影印講義或是指定教科書)沒有課本, 使用老師做的精美投影片# 上課方式(投影片、團體討論、老師教學風格)投影片+Guest 演講老師是新教授, 非常年輕有活力, 但會在投影片放一些宅宅梗, 比方說以動漫人物(ex: 涼宮春日) 當作教學例子XDD# 評分方式分組作業 60%  期末分組專題 40% 2~4人一組# 考題型式、作業方式總共三次作業, 都是程式苦工, 第一個作業就直接要硬幹一個DNN出來, 之後的作業會愈來愈應用, 最後的final project與作業一脈相承, based on之前的作業做出語音辨識的模型, 然後有個score board讓大家上傳預測結果, 很刺激的阿, 可是對於沒有GPU的人(例如我們) 用CPU真的跑得好累阿orz...建議能弄到一張厲害的GPU再來修比較不那麼痛苦..# 總結老師上課很認真! 而且每次上課會投影片錄影錄音(沿襲李琳山模式), 不管是不想去上課自己在家裡看(誤)或是上課聽不太懂之後可以複習都超好用的, 而且給分好甜阿~雖然score board排名不是很前面還是拿到了A+
                    











 1 







永久連結







































×















×Close



立即註冊，加入你/妳的大學課程社群 !
瞭解更多

 Facebook 註冊
         





&nbsp男
                    &nbsp&nbsp&nbsp&nbsp
                    &nbsp女










Email有點問題...
- 目前僅開放台灣大學 -





帳號特殊字元只能含 .&nbsp- _










您輸入的密碼不一致!







            已經有帳號了
        









































臺大李宏毅最新深度學習課程：機器學習及其深層與結構化（347PPT） - GOOREAD
















 








GOOREAD



熱點
旅遊
科技
搞笑
生活
星座
美食
歷史
人文
健康
軍事
遊戲
情感
親子















 臺大李宏毅最新深度學習課程：機器學習及其深層與結構化（347PPT） 

科技 
2017-04-10 16:06:19 
 

 
 




　　新智元介紹　　來源: NTU　　介紹：劉小芹 胡祥傑 張易　　【新智元導讀】臺大李宏毅老師的深度學習課程以其深入淺出和全面性而受到大家的歡迎。是不可多得的、較為全面的系統的深度學習中文教材。目前，他們在網上貼出了2017年的最新課程《機器學習及其深層與結構化》，包括TensorFlow介紹、深度學習模型的基礎架構、用於反向傳播的計算圖、深度學習語言模型、深度學習晶片等等。我們第一時間帶來課程設置和相關資源。　　在新智元微信公眾後台回複170410下載全部課程資料（含347PPT 、資料庫、視頻地址）　　2017年臺大李宏毅中文深度學習課程來了。課程名稱是“機器學習及其深層與結構化（NTUEE Machine Learning and having it Deep and Structured）”。我們先來看一下李老師對於課程名稱的解釋。　　可以看出，其中的“深度”描述了機器學習的方法，也就是說本門課程主要內容是關於深度學習的，而“結構化”則是深度學習的任務。　　課程目錄　　課程介紹　　作業0　　TensorFlow介紹　　例1- Word2vector模型　　例2-捲積神經網路（CNN）　　深度學習模型的基礎架構　　用於反向傳播的計算圖　　深度學習語言模型　　作業1-語言模型　　特殊的深度學習架構　　RNN條件生成　　作業2　　自然語言對話的深度學習　　深度學習和晶片　　評分　　視頻地址：　　https://www.youtube.com/playlist?list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9　　李宏毅老師簡介　　李宏毅老師於2012年從臺北National Taiwan University (NTU) 博士畢業。2012年9月—2013年8月，在 Sinica Academia 的 Research Center for Information Technology Innovation 做博士後。2013年9月—2014年7月，在 MIT Computer Science and ArtificialIntelligence Laboratory (CSAIL) 的Spoken Language Systems Group 做訪問學者。現任Department of Electrical Engineering of National TaiwanUniversity 副教授。主要研究領域為機器學習（特別是深度學習）、口語語義理解和語音識別。　　第一章 課程介紹　　結構化的（輸出）學習；　　機器學習就是去尋找一個函數 f　　回歸　　分類　　機構化學習　　輸出序列:以語音到文本的轉換為例　　輸出矩陣：以映像到映像、文字到映像的轉換為例　　結構化輸出的挑戰：　　輸出空間是非常稀疏的　　因為輸出組件有依存性，應該對他們進行全局考慮　　第二章 TensorFlow介紹　　流程結構　　總原則　　導入模組　　Session1　　Session2　　變數和範圍1　　變數和範圍2　　變數和範圍3　　變數和範圍4　　變數和範圍5　　佔位符1　　佔位符2　　定義添加層　　第三章 深度學習模型的基礎架構　　深度學習三步走：神經網路--成本函數--優化　　完整的連接層　　不同層輸出之間的的關係　　遞歸神經網路　　深度RNN　　三角RNN　　Naive RNN　　LSTM　　堆疊RNN　　第四章 用於反向傳播的計算圖 　　　　反向傳播：一種計算梯度的高效方法　　通過計算圖（computational graph）理解反向傳播：Tensorflow, Theano, CNTK, etc.　　計算圖：一種描述函數的“語言”　　節點：變數（標量、向量、張量……）　　邊線：操作（簡單函數）　　參數共用：相同的參數出現在不同的節點　　前饋網路計算圖　　前饋網路的損失函數　　損失函數的梯度　　計算梯度需要：計算偏導數，使用反向模式→輸出總是一個標量（scalar）　　遞歸網路計算圖　　參考資料　　第五章 語言建模 　　語言模型：預估單詞序列的機率　　應用：語音識別（不同的單詞序列可能發音相同）；句子生成　　N-gram　　　　怎樣預估P(w?, w? , w?, …., wn)　　收集大量文本數據作為訓練數據（但單詞序列 w?，w?，…，wn可能沒有出現在訓練數據中）　　N-gram 語言模型： P(w?, w?, w?, …., wn ) = P(w? |START)P(w? |w? ) …... P(wn |wn-? ) ←這是 2-gram　　　　3-gram, 4-gram …… 也很容易生成　　NN -based LM　　RNN-based LM：為長期資訊建模　　也可以用深度 RNN 或 LSTM　　N-gram 的挑戰：估計的機率不一定準確（尤其當 n-gram 中 n 的數值非常大時）　　原因是數據稀疏性：大的模型，不充分的數據　　這叫做“語言模型平滑”（language model smoothing）　　語言模型的神經圖靈機　　更多參考資料　　　　第六章 特殊深度學習結構  　　Spatial Transformer Layer　　　　映像轉換　　　　　　遞歸結構　　應用：情感分析　　迴圈結構：是遞歸結構的特殊形式　　遞歸結構：如何堆棧函數 f 是已經確定的　　遞歸模型　　　　遞歸神經張量網路　　　　實驗：5-class 情感分類 ( -- , - , 0 , + , ++ )　　矩陣-向量遞歸網路　　Tree LSTM　　　　第七章 RNN 條件生成  　　生成　　　　句子由字元/單片語成　　利用 RNN，每次生成一個字元/單詞　　映像由像素組成　　利用 RNN，每次生成一個像素　　條件生成　　我們不希望只是簡單生成一些隨機的句子，希望根據當前條件生成句子。　　應用：生成圖說；聊天機器人　　註意力：動態條件生成　　機器翻譯：基於註意力的模型　　語音識別　　　　映像說明生成　　課程地址：http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS17.html　　3月27日，新智元開源·生態AI技術峰會暨新智元2017創業大賽頒獎盛典隆重召開，包括“BAT”在內的中國主流 AI 公司、600多名行業精英齊聚，共同為2017中國人工智慧的發展畫上了濃墨重彩的一筆。　　點擊閱讀原文，查閱文字版大會實錄　　訪問以下連結，回顧大會盛況：　　阿裡雲棲社區：http://yq.aliyun.com/webinar/play/199　　愛奇藝：http://www.iqiyi.com/l_19rrfgal1z.html　　騰訊科技：http://v.qq.com/live/p/topic/26417/preview.html　　讚賞
 喜歡這篇文章嗎？立刻分享出去讓更多人知道～





BY : 新智元



相關文章

























您可能感興趣






最佳機器學習深度學習課程Top 7，第三名年薪已過12萬美元 






IBM發布PowerAI深度學習軟體，訓練速度提升100倍_億歐_產業創新服務平臺 






嚴格的評選，造就了這張分享量過千的線上機器學習課程榜單 






人工智慧與自然語言處理概述：AI三大階段、NLP關鍵應用 






【280頁JP摩根報告】大數據和 AI 策略——面向投資的機器學習和另類數據方法 






【薦書】5 本深度學習和 10 本機器學習書籍（下載） 






機器學習小課堂 Machine Learning at UC Berkeley｜RobotX Workshop NO.30 






J.P.摩根：大數據和 AI 策略--面向投資的機器學習和另類數據方法（附280頁報告） 


這可能是2017年最好的AI技術大禮 DGX-1技術大拆解及應用揭秘 






關於Python機器學習的疑問，相信這個視頻能幫你解答 














© 2016 華語熱聞 
       		| 聯絡我們
       		| 最新文章













[問題] 李宏毅 機器學習及其深層與結構化 | PTT 好讀


























首頁
Ntucourse












[問題] 李宏毅  機器學習及其深層與結構化
作者 fantasywater
看板 Ntucourse
時間
            
                2015-08-03 04:48:33
            
        
https://www.ptt.cc/bbs/NTUcourse/M.1438548516.A.479.html
下學期認真的考慮想要修這門課程，

不知道修過的同學可否提供評價供我做個參考，

包含作業以及考試..等相關資訊，非常感謝幫忙!!

--
※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 140.112.107.144
※ PTT 文章網址: https://www.ptt.cc/bbs/NTUcourse/M.1438548516.A.479.html






1F→ykes60513:很難就是 最好先找好同學 然後要有點基礎 08/03 08:47
2F→energyaup6:首先，你要先找到夠強的GPU 08/03 09:41
3F推kmchao33:\Deep learning/ 08/03 12:41
4F推coldplay5566:李宏毅幾班～ 08/03 17:09
5F推howardkuo725:daikin 08/03 17:37
6F推kchiazo:推，也想知道 08/03 20:34
7F推mkym:超吃程式能力跟數學能力...然後有無止盡的功課ㄏㄏ 08/04 00:49
8F→mkym:應該說功課全部連在一起 喘息時間是每個中間一小時XDDDD 08/04 00:49
9F推sunprinceS:沒有考試，但作業很重(有兩次作業需要手刻NN...) 08/04 11:05
10F→sunprinceS:如果你有聽過電機系的DSnP，我覺得不相上下...:P 08/04 11:06
11F推b29308188:你需要雄厚的基礎，過人的學習力，以及神一般的隊友 08/04 11:49
12F推bibo9901:三次作業的份量 都可以當作final project來做 08/04 22:29
13F推shaform:強者我朋友都 A+ 08/06 10:48
14F推st890609:各位大大，聽說104-2老師不會開課，請問是真的嗎? 08/09 00:43

































Re: [情報] 幻滅時刻預覽





[新聞] 劉在錫樸明洙等再入軍營 拍攝《無挑》版





[新聞] 被說大嬸很受傷 Yura在意顴骨想整形





[新聞] 《大力女》在台首播破《太陽》紀錄





[新聞] 乾淨街道不見了！中國人住進日本社區變這





[分享] 圖畫出差廣州的生活紀錄





[閒聊] Jayson Tatum 的身高有 6'9"  傑倫也長高





[新聞] 向華強夫婦待蕭敬騰如自家人　蕭駕千萬名





[新聞] 反年改群眾包圍立院爆發衝突 1員警送醫





[新聞] 實測OPPO R11 自拍超清晰





[情報] 爆料大神們討論的Galaxy Note8情報





[新聞] 防彈少年團與川普並列 《時代》前25名最





[問題] 為什麼高位的討論相比低位少很多





[新聞] 伊賀跟甲賀大和解 握手言和












[新聞] 4歲孩亂畫菜單被店員斥 老主顧：嚇到不敢





[新聞] 一蘭第二間分店要開在哪？ 他點名竹科：





[情報] TWICE JAPAN DEBUT BEST ALBUM『#TWICE』





[新聞]  回歸中國20年 香港人熱衷移民台灣





[新聞]2千字心路歷程！Dinter發聲明上大師仍是





Re: [新聞] 建中生問蔣介石銅像 柯文哲直呼：你的題





[0629] 聖獸覺醒.星寶 / 關銀屏.輝夜姬.始龍女.時龍契





[情報] iPhone 8 dummy機上手影片





[LIVE] 170629 日本デビュー記念 スペシャル生配





[新聞] 結婚6月生3500克寶寶 優格姐姐挨轟說謊





[新聞] 美軍艦停靠台灣港口 國防部：樂觀其成





Re: [新聞] 結婚6月生3500克寶寶 優格姐姐挨轟說謊





[歐洲] 七月置底曬卡區





[情報] Red Velvet 7/9回歸 更新WENDY





[新聞] Red Velvet發布充滿水果氣息的回歸照片





[新聞] 「秋天就想到台灣」樸信惠笑容美炸：想多





[情報] 170630 WINGS TOUR日本札幌場 南俊不參與舞蹈部分演出





Re: [問卦] 為什麼共產主義在舊俄失敗，在中國成功





[新聞] 葉毓蘭：向元首丟鞋法院認可無罪 勿侵害





[新聞] 防彈Rap Monster受傷了！　「腳指甲掀起





Re: [新聞] 南市「瘦身」大減逾100里 最快9月底定





七月置底





[問卦] 今年師大錄取分數會降嘛?





[ＣＧ]7/3是依田芳乃的生日でしてー





[閒聊] METHOD過了化身了





Fw: [新聞] 直行遭救護車撞！　駕駛求260萬國賠敗訴





Fw: [新聞] 烈陽無處躲 高市擬增設機車停等遮陽棚





[新聞] 微博名「今天宋仲基宋慧喬結婚了嗎」每





[新聞]警員托腮慢慢來 單親媽下跪救不回愛女外孫





[創作] SKT板繪





[新聞] 悚！胡志強一夕蒼老嘴歪 出院逞強開直播





Re: [新聞] 免簽國167個勝中國　馬英九歸功台人行善





[新聞] 悲！準新娘搭直升機給驚喜..竟婚禮成葬禮







































臺大李宏毅347頁PPT乾貨，機器學習及其深層與結構化 - 閱讀屋



















 










閱讀屋



健康
養生
時尚
娛樂
家居
汽車
科技
科學
財經
體育
旅遊
社會
時政
人文
熱門













臺大李宏毅347頁PPT乾貨，機器學習及其深層與結構化


科技 
2017-04-11





臺達李宏毅教授的機器學習教程因系統化和深入淺出的特點，受到了廣大網友的歡迎。之前給大家分享了李教授的深度學習教程：286頁PPT純乾貨，一天入門深度學習（公眾號後臺回覆“DL”下載）。李宏毅教授 2017 年的最新教程《機器學習及其深層與結構化》目前已經放出，包括 TensorFlow 介紹、深度學習模型的基礎架構、用於反向傳播的計算圖、深度學習語言模型等等。

《機器學習及其深層與結構化》系統介紹頁面






課程目錄










第一章：課程介紹






結構化的（輸出）學習；
機器學習就是去尋找一個函數 f 
迴歸
分類
機構化學習

輸出序列:以語音到文字的轉換為例

輸出矩陣：以影象到影象、文字到影象的轉換為例ADVERTISEMENT

結構化輸出的挑戰：
輸出空間是非常稀疏的
因為輸出元件有依存性，應該對他們進行全局考慮





第二章：TensorFlow介紹






流程結構

總原則

匯入模組

Session1 

Session2

變數和範圍1

變數和範圍2

變數和範圍3

變數和範圍4

變數和範圍5

佔位符 1

佔位符 2

定義新增層
例1- Word2vector模型









第三章：深度學習模型的基礎架構






深度學習三步走：神經網路--成本函數--優化

完整的連線層

不同層輸出之間的的關係

遞迴神經網路

深度RNN


Naive RNN



反向傳播：一種計算梯度的高效方法ADVERTISEMENT
通過計算圖（computational graph）理解反向傳播：Tensorflow, Theano, CNTK, etc.


計算圖：一種描述函數的“語言”

節點：變數（標量、向量、張量……）
邊線：操作（簡單函數）


參數共享：相同的參數出現在不同的節點
前饋網路計算圖

前饋網路的損失函數

損失函數的梯度

計算梯度需要：計算偏導數，使用反向模式→輸出總是一個標量（scalar）
遞迴網路計算圖 




參考資料






第五章：語言建模






語言模型：預估單詞序列的概率
應用：語音識別（不同的單詞序列可能發音相同）；句子生成
N-gram

怎樣預估P(w₁, w₂ , w₃, …., wn) 
收集大量文字資料作為訓練資料（但單詞序列 w₁，w₂，…，wn可能沒有出現在訓練資料中）ADVERTISEMENT
N-gram 語言模型： P(w₁, w₂ , w₃, …., wn ) = P(w₁ |START)P(w₂ |w₁ ) …... P(wn |wn-₁ ) ← 這是 2-gram
 3-gram, 4-gram …… 也很容易生成
NN -based LM 


RNN-based LM：為長期資訊建模


也可以用深度 RNN 或 LSTM
N-gram 的挑戰：估計的概率不一定準確（尤其當 n-gram 中 n 的數值非常大時）
原因是資料稀疏性：大的模型，不充分的資料
這叫做“語言模型平滑”（language model smoothing）
語言模型的神經圖靈機








第六章：特殊深度學習結構





Spatial Transformer Layer



影象轉換


遞迴結構

應用：情感分析

迴圈結構：是遞迴結構的特殊形式
遞迴結構：如何堆棧函數 f 是已經確定的

遞迴模型

遞迴神經張量網路



實驗：5-class 情感分類 ( -- , - , 0 , + , ++ )
矩陣-向量遞迴網路

Tree LSTM

生成

句子由字元/單片語成
利用 RNN，每次生成一個字元/單詞


影象由畫素組成
利用 RNN，每次生成一個畫素
條件生成

我們不希望只是簡單生成一些隨機的句子，希望根據當前條件生成句子。
應用：生成圖說；聊天機器人
註意力：動態條件生成


機器翻譯：基於註意力的模型


語音識別

影象說明生成





李宏毅機器學習教程
- DataCastle -




科技 教育 

 » DataCastle
 喜歡這篇文章嗎？立刻分享出去讓更多人知道～







相關文章
2017-04-10臺大李宏毅最新深度學習課程：機器學習及其深層與結構化（347PPT） 
2017-07-12谷歌要構建10 億+ 級別的超大資料集，這樣能取代機器學習演算法嗎？ 
2017-04-14杉數科技CTO王子卓：4大案例告訴你，如何用機器學習玩轉企業大資料 | 硬創公開課 
2016-10-30這五大因素讓多倫多成為機器學習的溫床？ 
2017-03-22數博前沿丨谷歌大規模機器學習：模型訓練、特徵工程和演算法選擇 (32頁PPT乾貨) 
2017-03-2032頁ppt乾貨｜谷歌大規模機器學習：模型訓練、特徵工程和演算法選擇 
2017-03-03乾貨！32頁PPT,讀懂基礎機器學習演算法 
2017-02-06華為為什麼這麼牛？（70頁PPT乾貨分享） 
2017-01-09深度盤點國內四大機器學習開源平臺：PaddlePaddle,Angel 









您可能感興趣




特斯拉屢遭“被建廠” 專家稱騰訊入股致傳聞發酵 


投資風向標：任澤平稱股市和房地產投資樂觀 現金為王是個坑 




大資料商業智慧的十大戒律 




美聯航CEO聲稱：支援一線員工處理方法 




警示與反思丨華為打贏了！三星侵權成立需賠8000萬元 




【報名】資料科學研究院&IE商學院邀你來戰：大資料挑戰日 


村幹部貪汙：別人拼命撈錢 自己不撈是犯傻 




章魚藐視遺傳“中心法則” 




河北邢臺拆除燃煤鍋爐為藍天“減負” 




不用爭家裡誰是老大了，Google Home將支援多使用者切換 


















© 2017 閱讀屋 ReadHouse.Net 聯絡我們







404 Not Found

404 Not Found
nginx



臺大李宏毅最新深度學習課程：機器學習及其深層與結構化（347PPT） - 每日頭條每日頭條臺大李宏毅最新深度學習課程：機器學習及其深層與結構化（347PPT）2017-04-10 由 新智元 發表於 教育...
新智元介紹
在新智元微信公眾後台回復170410下載全部課程資料（含347PPT 、資料庫、視頻地址）
...
2017年臺大李宏毅中文深度學習課程來了。課程名稱是「機器學習及其深層與結構化（NTUEE Machine Learning and having it Deep and Structured）」。我們先來看一下李老師對於課程名稱的解釋。
...ADVERTISEMENT
可以看出，其中的「深度」描述了機器學習的方法，也就是說本門課程主要內容是關於深度學習的，而「結構化」則是深度學習的任務。
課程目錄


課程介紹


作業0


TensorFlow 介紹
例1- Word2vector模型
例2-捲積神經網絡（CNN）


深度學習模型的基礎架構


用於反向傳播的計算圖


深度學習語言模型


作業1-語言模型




特殊的深度學習架構


RNN條件生成


作業2


自然語言對話的深度學習


深度學習和晶片


評分


在新智元微信公眾後台回復170410下載全部課程資料（含347PPT 、資料庫、視頻地址）
視頻地址：
https://www.youtube.com/playlist?list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9
李宏毅老師簡介
李宏毅老師於2012年從臺北 National Taiwan University (NTU) 博士畢業。2012年9月—2013年8月，在 Sinica Academia 的 Research Center for Information Technology Innovation 做博士後。2013年9月—2014年7月，在 MIT Computer Science and
ArtificialIntelligence Laboratory (CSAIL) 的 Spoken Language Systems Group 做訪問學者。現任 Department of Electrical Engineering of National TaiwanUniversity 副教授。主要研究領域為機器學習（特別是深度學習）、口語語義理解和語音識別。ADVERTISEMENT
第一章 課程介紹
...
結構化的（輸出）學習；
機器學習就是去尋找一個函數 f
回歸
分類
機構化學習
...
輸出序列:以語音到文本的轉換為例
...
輸出矩陣：以圖像到圖像、文字到圖像的轉換為例ADVERTISEMENT
...
結構化輸出的挑戰：
輸出空間是非常稀疏的
因為輸出組件有依存性，應該對他們進行全局考慮
第二章 TensorFlow介紹
...
流程結構
...
總原則
...ADVERTISEMENT
導入模塊
...
Session1
...
Session2
...
變量和範圍1
...
變量和範圍2
...
變量和範圍3
...
變量和範圍4
...
變量和範圍5
...
占位符 1
...
占位符 2
...
定義添加層
例1- Word2vector模型
...
...
...
例2-捲積神經網絡（CNN）
...
第三章 深度學習模型的基礎架構
...
深度學習三步走：神經網絡--成本函數--優化
...
完整的連接層
...
不同層輸出之間的的關係
...
遞歸神經網絡
...
深度RNN
...
三角RNN
...
Naive RNN
...
LSTM
...
堆疊RNN
第四章 用於反向傳播的計算圖
...
反向傳播：一種計算梯度的高效方法
通過計算圖（computational graph）理解反向傳播：Tensorflow, Theano, CNTK, etc.
...
...
計算圖：一種描述函數的「語言」


節點：變量（標量、向量、張量……）


邊線：操作（簡單函數）


...
參數共享：相同的參數出現在不同的節點
前饋網絡計算圖
...
前饋網絡的損失函數
...
損失函數的梯度
...
計算梯度需要：計算偏導數，使用反向模式→輸出總是一個標量（scalar）
遞歸網絡計算圖
...
...
...
...
參考資料
...
第五章 語言建模
...
語言模型：預估單詞序列的機率
應用：語音識別（不同的單詞序列可能發音相同）；句子生成
N-gram
怎樣預估P(w₁, w₂ , w₃, …., wn)
收集大量文本數據作為訓練數據（但單詞序列 w₁，w₂，…，wn可能沒有出現在訓練數據中）
N-gram 語言模型： P(w₁, w₂ , w₃, …., wn ) = P(w₁ |START)P(w₂ |w₁ ) …... P(wn |wn-₁ ) ← 這是 2-gram
3-gram, 4-gram …… 也很容易生成
NN -based LM
RNN-based LM：為長期信息建模
...
...
也可以用深度 RNN 或 LSTM
N-gram 的挑戰：估計的機率不一定準確（尤其當 n-gram 中 n 的數值非常大時）
原因是數據稀疏性：大的模型，不充分的數據
這叫做「語言模型平滑」（language model smoothing）
語言模型的神經圖靈機
更多參考資料
第六章 特殊深度學習結構
Spatial Transformer Layer
圖像轉換
遞歸結構
應用：情感分析


循環結構：是遞歸結構的特殊形式


遞歸結構：如何堆棧函數 f 是已經確定的


遞歸模型
遞歸神經張量網絡
實驗：5-class 情感分類 ( -- , - , 0 , + , ++ )
矩陣-向量遞歸網絡
Tree LSTM
第七章 RNN 條件生成
生成
句子由字符/單詞組成
利用 RNN，每次生成一個字符/單詞
圖像由像素組成
利用 RNN，每次生成一個像素
條件生成
我們不希望只是簡單生成一些隨機的句子，希望根據當前條件生成句子。
應用：生成圖說；聊天機器人
註意力：動態條件生成
機器翻譯：基於註意力的模型
語音識別
圖像說明生成
課程地址：http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS17.html
...
3月27日，新智元開源·生態AI技術峰會暨新智元2017創業大賽頒獎盛典隆重召開，包括「BAT」在內的中國主流 AI 公司、600多名行業精英齊聚，共同為2017中國人工智慧的發展畫上了濃墨重彩的一筆。
點擊閱讀原文，查閱文字版大會實錄
訪問以下連結，回顧大會盛況：


阿裡雲棲社區：http://yq.aliyun.com/webinar/play/199


愛奇藝：http://www.iqiyi.com/l_19rrfgal1z.html


騰訊科技：http://v.qq.com/live/p/topic/26417/preview.html


相關文章淺析自然語言理解之統計語言模型2016-10-10本文由Emotibot出品，作者為技術專家王海波。Emotibot致力於打造中國首款人工智慧伴侶，以情感計算研究為核心，深度學習等尖端技術為基礎，滿足廣大用戶的日常生活和工作所需。如需轉載，請聯繫Emotibot情感機器人微信公眾號（Emotibot_tech），並註明出處。從圖像到知識：深度神經網絡實現圖像理解的原理解析2016-07-11摘要：本文將詳細解析深度神經網絡識別圖形圖像的基本原理。能模仿韓寒小四寫作的神奇遞歸神經網絡（附代碼）2016-04-27大數據文摘作品，轉載需授權作者|寒小陽 && 龍心塵鳴謝|Owen 對Recurrent Neural Networks Tutorial part1一文的翻譯和部分內容提供出處|http://blog.csdn.Yoshua Bengio最新演講：Attention 讓深度學習取得巨大成功（46ppt）2016-05-16C新智元編譯 Yoshua Bengio，電腦科學家，畢業於麥吉爾大學，在MIT和AT&T貝爾實驗室做過博士後研究員，自1993年之後就在蒙特婁大學任教，與 Yann LeCun、 Geoffrey Hinton並稱為「深度學習三巨頭」，也是神經網絡復興的主要的三個發起人之一，神經網絡學習筆記-03-循環神經網絡-反向傳播計算公式的證明2017-02-16本文是根據WildML的Recurrent Neural Networks Tutorial寫的學習筆記。原文的例子原文中計劃實現一個循環神經網絡，用於發現自然語言句子中單詞出現的模式，最終可以生成一些合理的句子。數據來源 原文中，從網上下載了很多條句子（英文的）。納米神經網絡 NanoNet：數據有限，照樣玩轉深度學習2017-02-141 新智元編譯 近來深度學習大受歡迎，在諸如語言翻譯、玩策略遊戲和自動駕駛汽車方面都達到了非常高的水平。使用深度學習的一大常見的壁壘是訓練模型所需的數據。由於機器需要學習的模型含有大量的參數，所需要的訓練數據也因此驟增。斯坦福深度學習課程第三彈：神經網絡與反向傳播2016-06-20像追美劇一樣追課程！大數據文摘已獲史丹福大學深度學習課程CS224d翻譯授權，重磅啟動「斯坦福深度學習課程CS224d」的翻譯工程，所有譯文將會免費發布，計劃每周發布1篇。期待你的加入，加入要求見文末報名請點擊文末「閱讀原文」。Facebook通過10億單詞構建有效的神經網絡語言模型2016-11-28由於在語言識別、機器翻譯和語言建模等領域表現出了優異的性能，為序列預測而設計的神經網絡最近再次引起了人們的興趣，但是這些模型都是計算密集型的，成本非常高。CVPR演講LeCun 談深度學習技術局限及發展（157PPT）2016-07-031新智元編譯 進入新智元公眾號，直接回復「0703」下載PPT全文深度捲積網絡和深度學習的動機：端到端的學習一些老方法：步長內核，非共享的本地連接，度量學習，全捲積訓練深度學習缺少什麼？Hinton 谷歌大腦最新研究：1370 億參數超大規模神經網絡2017-01-251新智元編譯 超大規模神經網絡：稀疏門控混合專家層摘要神經網絡吸收信息的能力受其參數數量的限制。有人在理論上提出了條件計算（conditional computation）的概念，作為大幅提升模型容量而不會大幅增加計算力需求的一種方法。 Copyright © 2017 / 服務條款 / DMCA / 聯絡我們AlphaGo 可以開無人車嗎？AI 其實需要訓練師｜數位時代About us廣告刊登商店場地租借EN 新聞
新聞分類最新新聞科技物聯網人工智慧機器人金融科技虛擬實境大數據交通運輸電信通訊資訊安全實驗室裡的科技企業阿裡巴巴Amazon蘋果FacebookGoogleIBM微軟Yahoo商業產業創新策略IPO併購合作創業新創團隊募資創業活動創投創業人物新創管理行銷流量數據廣告創意品牌經營內容行銷社群行銷技能職場未來工作數位工作術產品開發開發者電子商務數位內容新聞媒體遊戲電子書音樂影視人物產品觀點專題PX酷品 活動
活動未來商務展Meet Taipei社群活動雜誌創業小聚數位行銷學院人工智慧機器人交通運輸 AlphaGo 可以開無人車嗎？AI 其實需要訓練師
 by
 李宏毅
2016.10.17分享Google分享 很多企業已迫不及待想要應用AI技術來改變世界，但想要成功的運用AI技術，需要AI訓練師。跟使用一般機器不同，人類員工並不是一聘請來就什麼都會，需要提供充分而合適的訓練才能勝任工作，「AI系統」也是一樣。
隨著2016年3月 Alpha Go 以四比一擊敗李世乭， 人工智慧（AI）的熱潮於全球興起，AI背後所需要的機器學習技術受到各方關註，而 Alpha Go 背後所用到的深度學習技術（機器學習的其中一種方法）更是成為眾所矚目的焦點。今日機器在學習時並非是死背人類提供的訓練資料，而是具備抽象化問題的能力（甚至可以誇張地說機器具備某種程度的理解能力）。Alpha Go 以四比一擊敗李世乭，讓全球興起人工智慧（AI）的熱潮。Google例如：當機器在做人臉辨識時，它並非將資料庫中人臉的影像死記下來，然後將輸入的影像和資料庫中的影像一一比對，現在機器有能力自動根據資料庫中人臉的影像，瞭解人臉由眼、鼻、口等所構成，而眼、鼻、口又由基本的幾何圖形所構成（例如：眼是一個深色的圓圈外圍套一個白色圓圈）。因此，就算是機器沒有見過的人臉，透過抽象化問題的能力，機器也可以正確辨認出來。很多企業已迫不及待想要應用AI技術來改變世界，但想要成功的運用AI技術需要什麼樣的人才呢？AI技術買來就可以直接用嗎？有些人相信只要請 Google 授權 Alpha Go或請 IBM 授權 Watson，就可以把工廠瞬間變成智慧工廠，汽車瞬間變成智慧型無人車。如此一來，哪還需要什麼人才？但真實的情況並非如此，現在以深度學習技術為基礎的AI，在成功應用前，需要經過三個階段：模型設計、設定目標、學習。模型設計，就是選定AI的天賦，不同的模型將使得AI適合做不同的事，如果想讓機器下圍棋，卻選擇適合開無人車的天賦，則AI將怎麼學也學不好。不同的模型讓AI各有所長，如果想讓機器下圍棋，卻選擇適合開無人車的天賦，則AI將怎麼學也學不好。Google官網選定天賦後，需要人類給予AI學習目標，例如：想要讓AI學會下圍棋，必須有人告訴AI贏棋是好的，並告訴AI什麼樣的情況叫做「贏」。接下來，雖然AI在理論上可以根據人類設定的目標自動去學習，但需要人類幫AI選擇學習方式，不同的模型和學習目標適合不同的學習方式，若是沒有選擇恰當的學習方式，AI也無法成功達成人類給予的學習目標。也就是說，跟 Google 拿到 Alpha Go全套的程式碼和模型參數，等於是聘請了一位超強的棋士，但它也只會下圍棋而已。如果你想要讓它做其它事情，必須重新訓練，而這個轉換過程絕對少不了人類專家的介入。因此，有了Alpha Go 和 Watson，並非已經解決所有的問題，現階段它們只是解決了某一個非常特定的問題，想要把它們的技術用在其他應用上，還是需要下一番非常大的工夫才行。AI系統像員工一樣，必須訓練！要使用AI技術，必須具有和使用一般機器不同的思維。 人們習慣機器買回來就可以立即使用，例如買一個馬達，插上電源後就可以運作，但是AI 系統並不相同，AI系統更像是名員工。人類員工並不是一聘請來就什麼都會，需要提供充分而合適的訓練才能勝任工作，「AI系統」也是一樣。但要如何根據AI所要執行的任務，選擇合適的天賦、合適的目標、合適的學習方式呢？這些就需要靠人類專家了，因此這些專家可以說是「AI訓練師（AI Mentor）」。如何選擇合適的天賦、目標、學習方式，目前還沒有一以貫之的理論，但厲害的AI訓練師可以用較少的錯誤嘗試，有效率地訓練出厲害的AI。而正是因為理論的缺乏，AI訓練師不是看某一本教科書、修某一門課就可以練成的，AI訓練師的養成最需要的是實戰經驗，而對主管來說，想讓培養工程師變成AI訓練師，需要的是提供足夠的練習機會和時間並鼓勵嘗試錯誤。因著科技進步，現在只要幾台伺服器插幾張顯卡，然後在開源框架（framework）下寫幾行程式碼，馬上就可以開始開發以深度學習為基石的AI技術。但AI技術是否像一個訓練優良的員工有戰力，關鍵在於AI訓練師能否給予妥當的訓練。在台灣應該找尋及培育一個有實戰經驗的AI訓練師，讓人才在關鍵的技術上做出突破，才能讓台灣產業抓緊在人工智慧時代，自主研發技術的機會。系列文章：台灣如何在人工智慧彎道超車？得培養高級AI人才《數位時代》長期徵稿，針對時事科技議題，需要您的獨特觀點，歡迎各類專業人士來稿一起交流。投稿請寄edit@bnext.com.tw，文長800至1000字，兩天內會回覆是否採用，文章會經編輯潤飾，如需改標會與您討論。延伸閱讀AlphaGo推手黃士傑現身說法：台灣人才不輸國際，我們要有信心走出去！台灣如何在人工智慧彎道超車？得培養高級AI人才數說新語NextPedia深度學習Deep Learning 「深度學習」是機器學習的分支，源於類神經網絡，簡單來說，即是大量的訓練樣本、龐大的計算能力、靈巧的神經網路結構設計三者結合，目前深度學習已深入應運於語音辨識、影像辨識，Google AlphaGo也是奠基於深度學習，而能掌握抽象概念。讓電腦進行深度學習主要有三個步驟：設定好類神經網路架構、訂出學習目標、開始學習。
(來源：
數位時代 、
台灣資料科學年會 
)
#人工智慧#無人車#AI#機器學習#AlphaGo分享李宏毅 臺大電機系助理教授
研究方向以機器學習技術讓機器辨識並理解語音訊號的內容，致力於語音數位內容搜尋、語音數位內容之自動化組織、語音數位內容擷取關鍵資訊、人機互動、問答系統、智慧型線上教學平臺等。曾在臺大開設「機器學習及其深層與結構化」。熱門文章1 台灣的軟體工程師都跑哪裡去了？
by 林宜敬2017-07-192 董事會成員只剩CEO！曾獲比爾蓋茲、李嘉誠投資的「植物蛋」新創陷困局
by 愛範兒 ifanr20 小時前3 BNB Air #9——吳柏蒼X張鐵志：《誰把音樂變免費》一個原本賣不掉的發明，摧毀了整個產業
by 數位時代16 小時前4 本週第二起！以太坊錢包Parity遭駭，損失金額高達3千萬美元
by 張庭瑜14 小時前5 當宮廟遇上科技──PTT最紅求籤「七王爺線上靈籤」的誕生之路
by 顏理謙2017-07-196 挑戰蘋果、Fitbit失敗，傳Intel已裁撤整個健康穿戴式裝置部門
by 張庭瑜19 小時前追蹤我們
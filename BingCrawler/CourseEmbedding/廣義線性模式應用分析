


線性回歸 - 維基百科，自由的百科全書































 







線性回歸

維基百科，自由的百科全書


					前往：					導覽，					搜尋







本條目存在以下問題，請協助改善本條目或在討論頁針對議題發表看法。






本條目部分連結不符合格式手冊規範。跨語言連結及章節標題等處的連結可能需要清理。（2015年12月12日） 
請協助改善此條目。參見WP:LINKSTYLE、WP:MOSIW以瞭解細節。突出顯示跨語言連結可以便於檢查。 







本條目包含過多行話或專業術語，可能需要簡化或提出進一步解釋。（2013年10月5日） 
請在討論頁中發表對於本議題的看法，並移除或解釋本條目中的行話。 







本條目翻譯品質不佳。 
翻譯者可能不熟悉中文或原文語言，也可能使用了機器翻譯，請協助翻譯本條目或重新編寫。明顯拙劣的機器翻譯請改掛{{Delete|G13}}提交刪除。 














統計學系列條目


迴歸分析





模型




線性回歸
簡單回歸（英語：Simple linear regression）
普通最小平方法（英語：Ordinary least squares）
多項式回歸（英語：Polynomial regression）
一般線性模型






廣義線性模式
離散選擇（英語：Discrete choice）
邏輯迴歸
多項羅吉特（英語：Multinomial logit）
混合羅吉特
波比（英語：Probit model）
多項式波比（英語：Multinomial probit）
排序性模型（英語：Ordered logit）
有序波比（英語：Ordered probit）
泊松回歸






等級線性模型
固定效應（英語：Fixed effects model）
隨機效應（英語：Random effects model）
混合模型（英語：Mixed model）






非線性回歸（英語：Nonlinear regression）
非參數（英語：Nonparametric regression）
半參數（英語：Semiparametric regression）
穩健（英語：Robust regression）
分位數迴歸
保序回歸
主成分（英語：Principal component regression）
最小角
局部（英語：Local regression）
分段（英語：Segmented regression）






含誤差變量（英語：Errors-in-variables models）




估計




最小平方法
普通最小平方法（英語：Ordinary least squares）
線性
偏最小平方回歸
總體（英語：Total least squares）
廣義（英語：Generalized least squares）
加權
非線性（英語：Non-linear least squares）
非負（英語：Non-negative least squares）
重複再加權（英語：Iteratively reweighted least squares）
嶺回歸（英語：Tikhonov regularization）
LASSO






最小絕對值導數法（英語：Least absolute deviations）
貝葉斯（英語：Bayesian linear regression）
貝葉斯多元（英語：Bayesian multivariate linear regression）




背景




回歸模型檢驗（英語：Regression model validation）
平均響應和預測響應（英語：Mean and predicted response）
誤差和殘差
擬合優度（英語：Goodness of fit）
學生化殘差（英語：Studentized residual）
高斯－馬可夫定理






 機率與統計主題







閱
論
編





在統計學中，線性回歸（Linear regression）是利用稱為線性回歸方程的最小平方函數對一個或多個自變量和因變量之間關係進行建模的一種回歸分析。這種函數是一個或多個稱為回歸係數的模型參數的線性組合。只有一個自變量的情況稱為簡單回歸，大於一個自變量情況的叫做多元回歸。（這反過來又應當由多個相關的因變量預測的多元線性回歸區別[來源請求]，而不是一個單一的純量變量。）
在線性回歸中，數據使用線性預測函數來建模，並且未知的模型參數也是通過數據來估計。這些模型被叫做線性模型。最常用的線性回歸建模是給定X值的y的條件均值是X的仿射函數。不太一般的情況，線性回歸模型可以是一個中位數或一些其他的給定X的條件下y的條件分佈的分位數作為X的線性函數表示。像所有形式的回歸分析一樣，線性回歸也把焦點放在給定X值的y的條件機率分佈，而不是X和y的聯合機率分佈（多元分析領域）。
線性回歸是回歸分析中第一種經過嚴格研究並在實際應用中廣泛使用的類型。這是因為線性依賴於其未知參數的模型比非線性依賴於其位置參數的模型更容易擬合，而且產生的估計的統計特性也更容易確定。
線性回歸有很多實際用途。分為以下兩大類：

如果目標是預測或者映射，線性回歸可以用來對觀測數據集的和X的值擬合出一個預測模型。當完成這樣一個模型以後，對於一個新增的X值，在沒有給定與它相配對的y的情況下，可以用這個擬合過的模型預測出一個y值。
給定一個變量y和一些變量X1,...,Xp，這些變量有可能與y相關，線性回歸分析可以用來量化y與Xj之間相關性的強度，評估出與y不相關的Xj，並識別出哪些Xj的子集包含了關於y的冗餘信息。

線性回歸模型經常用最小平方逼近來擬合，但他們也可能用別的方法來擬合，比如用最小化「擬合缺陷」在一些其他規範里（比如最小絕對誤差回歸），或者在橋回歸中最小化最小平方損失函數的懲罰。相反，最小平方逼近可以用來擬合那些非線性的模型。因此，儘管「最小平方法」和「線性模型」是緊密相連的，但他們是不能劃等號的。



目錄


1 簡介

1.1 理論模型
1.2 數據和估計
1.3 古典假設


2 最小平方法分析

2.1 最小平方法估計
2.2 回歸推論

2.2.1 單變量線性回歸


2.3 變異數分析


3 其他方法

3.1 廣義最小平方法
3.2 總體最小平方法
3.3 廣義線性模式
3.4 穩健回歸


4 線性回歸的應用

4.1 趨勢線
4.2 流行病學
4.3 金融
4.4 經濟學


5 參考文獻

5.1 引用
5.2 來源


6 延伸閱讀
7 參見



簡介[編輯]




帶有一個自變量的線性回歸


理論模型[編輯]
給一個隨機樣本



(

Y

i


,

X

i
1


,
…
,

X

i
p


)
,

i
=
1
,
…
,
n


{\displaystyle (Y_{i},X_{i1},\ldots ,X_{ip}),\,i=1,\ldots ,n}

，一個線性回歸模型假設回歸子




Y

i




{\displaystyle Y_{i}}

和回歸量




X

i
1


,
…
,

X

i
p




{\displaystyle X_{i1},\ldots ,X_{ip}}

之間的關係是除了X的影響以外，還有其他的變數存在。我們加入一個誤差項




ε

i




{\displaystyle \varepsilon _{i}}

（也是一個隨機變量）來捕獲除了




X

i
1


,
…
,

X

i
p




{\displaystyle X_{i1},\ldots ,X_{ip}}

之外任何對




Y

i




{\displaystyle Y_{i}}

的影響。所以一個多變量線性回歸模型表示為以下的形式：






Y

i


=

β

0


+

β

1



X

i
1


+

β

2



X

i
2


+
…
+

β

p



X

i
p


+

ε

i


,

i
=
1
,
…
,
n


{\displaystyle Y_{i}=\beta _{0}+\beta _{1}X_{i1}+\beta _{2}X_{i2}+\ldots +\beta _{p}X_{ip}+\varepsilon _{i},\qquad i=1,\ldots ,n}



其他的模型可能被認定成非線性模型。一個線性回歸模型不需要是自變量的線性函數。線性在這裡表示




Y

i




{\displaystyle Y_{i}}

的條件均值在參數



β


{\displaystyle \beta }

裡是線性的。例如：模型




Y

i


=

β

1



X

i


+

β

2



X

i


2


+

ε

i




{\displaystyle Y_{i}=\beta _{1}X_{i}+\beta _{2}X_{i}^{2}+\varepsilon _{i}}

在




β

1




{\displaystyle \beta _{1}}

和




β

2




{\displaystyle \beta _{2}}

裡是線性的，但在




X

i


2




{\displaystyle X_{i}^{2}}

裡是非線性的，它是




X

i




{\displaystyle X_{i}}

的非線性函數。
數據和估計[編輯]
區分隨機變量和這些變量的觀測值是很重要的。通常來說，觀測值或數據（以小寫字母表記）包括了n個值 



(

y

i


,

x

i
1


,
…
,

x

i
p


)
,

i
=
1
,
…
,
n


{\displaystyle (y_{i},x_{i1},\ldots ,x_{ip}),\,i=1,\ldots ,n}

.
我們有



p
+
1


{\displaystyle p+1}

個參數




β

0


,
…
,

β

p




{\displaystyle \beta _{0},\ldots ,\beta _{p}}

需要決定，為了估計這些參數，使用矩陣表記是很有用的。





Y
=
X
β
+
ε



{\displaystyle Y=X\beta +\varepsilon \,}



其中Y是一個包括了觀測值




Y

1


,
…
,

Y

n




{\displaystyle Y_{1},\ldots ,Y_{n}}

的列向量，



ε


{\displaystyle \varepsilon }

包括了未觀測的隨機成份




ε

1


,
…
,

ε

n




{\displaystyle \varepsilon _{1},\ldots ,\varepsilon _{n}}

以及回歸量的觀測值矩陣



X


{\displaystyle X}

：





X
=


(



1



x

11




⋯



x

1
p






1



x

21




⋯



x

2
p






⋮


⋮


⋱


⋮




1



x

n
1




⋯



x

n
p





)




{\displaystyle X={\begin{pmatrix}1&x_{11}&\cdots &x_{1p}\\1&x_{21}&\cdots &x_{2p}\\\vdots &\vdots &\ddots &\vdots \\1&x_{n1}&\cdots &x_{np}\end{pmatrix}}}



X通常包括一個常數項。
如果X列之間存在線性相依，那麽參數向量



β


{\displaystyle \beta }

就不能以最小平方法估計除非



β


{\displaystyle \beta }

被限制，比如要求它的一些元素之和為0。
古典假設[編輯]

樣本是在母體之中隨機抽取出來的。
因變量Y在實直線上是連續的，
殘差項是獨立且相同分佈的(iid)，也就是說，殘差是獨立隨機的，且服從高斯分佈。

這些假設意味著殘差項不依賴自變量的值，所以




ε

i




{\displaystyle \varepsilon _{i}}

和自變量X（預測變量）之間是相互獨立的。
在這些假設下，建立一個顯示線性回歸作為條件預期模型的簡單線性回歸，可以表示為：






E

(

Y

i


∣

X

i


=

x

i


)
=
α
+
β

x

i





{\displaystyle {\mbox{E}}(Y_{i}\mid X_{i}=x_{i})=\alpha +\beta x_{i}\,}



最小平方法分析[編輯]
主條目：最小平方法
最小平方法估計[編輯]
回歸分析的最初目的是估計模型的參數以便達到對數據的最佳擬合。在決定一個最佳擬合的不同標準之中，最小平方法是非常優越的。這種估計可以表示為：








β
^



=
(

X

T


X

)

−
1



X

T


y



{\displaystyle {\hat {\beta }}=(X^{T}X)^{-1}X^{T}y\,}



回歸推論[編輯]
對於每一個



i
=
1
,
…
,
n


{\displaystyle i=1,\ldots ,n}

，我們用




σ

2




{\displaystyle \sigma ^{2}}

代表誤差項



ε


{\displaystyle \varepsilon }

的變異數。一個無偏誤的估計是：









σ
^




2


=


S

n
−
p



,


{\displaystyle {\hat {\sigma }}^{2}={\frac {S}{n-p}},}



其中



S
:=

∑

i
=
1


n






ε
^




i


2




{\displaystyle S:=\sum _{i=1}^{n}{\hat {\varepsilon }}_{i}^{2}}

是誤差平方和（殘差平方和）。估計值和實際值之間的關係是：









σ
^




2


⋅



n
−
p


σ

2




∼

χ

n
−
p


2




{\displaystyle {\hat {\sigma }}^{2}\cdot {\frac {n-p}{\sigma ^{2}}}\sim \chi _{n-p}^{2}}



其中




χ

n
−
p


2




{\displaystyle \chi _{n-p}^{2}}

服從卡方分佈，自由度是



n
−
p


{\displaystyle n-p}


對普通方程的解可以冩為：








β
^



=
(


X

T


X

)

−
1



X

T


y

.


{\displaystyle {\hat {\boldsymbol {\beta }}}=(\mathbf {X^{T}X)^{-1}X^{T}y} .}



這表示估計項是因變量的線性組合。進一步地說，如果所觀察的誤差服從正態分佈。參數的估計值將服從聯合正態分佈。在當前的假設之下，估計的參數向量是精確分佈的。








β
^



∼
N
(
β
,

σ

2


(

X

T


X

)

−
1


)


{\displaystyle {\hat {\beta }}\sim N(\beta ,\sigma ^{2}(X^{T}X)^{-1})}



其中



N
(
⋅
)


{\displaystyle N(\cdot )}

表示多變量正態分佈。
參數估計值的標準差是：









σ
^




j


=




S

n
−
p





[


(

X

T


X
)


−
1


]


j
j




.


{\displaystyle {\hat {\sigma }}_{j}={\sqrt {{\frac {S}{n-p}}\left[\mathbf {(X^{T}X)} ^{-1}\right]_{jj}}}.}



參數




β

j




{\displaystyle \beta _{j}}

的



100
(
1
−
α
)
%


{\displaystyle 100(1-\alpha )\%}

置信區間可以用以下式子來計算：









β
^




j


±

t



α
2


,
n
−
p






σ
^




j


.


{\displaystyle {\hat {\beta }}_{j}\pm t_{{\frac {\alpha }{2}},n-p}{\hat {\sigma }}_{j}.}



誤差項可以表示為：









r
^



=
y
−
X



β
^



=
y
−
X
(

X

T


X

)

−
1



X

T


y

.



{\displaystyle \mathbf {{\hat {r}}=y-X{\hat {\boldsymbol {\beta }}}=y-X(X^{T}X)^{-1}X^{T}y} .\,}



單變量線性回歸[編輯]
單變量線性回歸，又稱簡單線性回歸（simple linear regression, SLR），是最簡單但用途很廣的回歸模型。其回歸式為：





Y
=
α
+
β
X
+
ε


{\displaystyle Y=\alpha +\beta X+\varepsilon }



為了從一組樣本



(

y

i


,

x

i


)


{\displaystyle (y_{i},x_{i})}

（其中



i
=
1
,
 
2
,
…
,
n


{\displaystyle i=1,\ 2,\ldots ,n}

）之中估計最合適（誤差最小）的



α


{\displaystyle \alpha }

和



β


{\displaystyle \beta }

，通常採用最小平方法，其計算目標為最小化殘差平方和：






∑

i
=
1


n



ε

i


2


=

∑

i
=
1


n


(

y

i


−
α
−
β

x

i



)

2




{\displaystyle \sum _{i=1}^{n}\varepsilon _{i}^{2}=\sum _{i=1}^{n}(y_{i}-\alpha -\beta x_{i})^{2}}



使用微分法求極值：將上式分別對



α


{\displaystyle \alpha }

和



β


{\displaystyle \beta }

做一階偏微分，並令其等於0：






{




n
 
α
+

∑

i
=
1


n



x

i


 
β
=

∑

i
=
1


n



y

i







∑

i
=
1


n



x

i


 
α
+

∑

i
=
1


n



x

i


2


 
β
=

∑

i
=
1


n



x

i



y

i










{\displaystyle \left\{{\begin{array}{lcl}n\ \alpha +\sum \limits _{i=1}^{n}x_{i}\ \beta =\sum \limits _{i=1}^{n}y_{i}\\\sum \limits _{i=1}^{n}x_{i}\ \alpha +\sum \limits _{i=1}^{n}x_{i}^{2}\ \beta =\sum \limits _{i=1}^{n}x_{i}y_{i}\end{array}}\right.}



此二元一次線性方程組可用克萊姆法則求解，得解






α
^



,
 



β
^





{\displaystyle {\hat {\alpha }},\ {\hat {\beta }}}

：








β
^



=



n

∑

i
=
1


n



x

i



y

i


−

∑

i
=
1


n



x

i



∑

i
=
1


n



y

i




n

∑

i
=
1


n



x

i


2


−


(

∑

i
=
1


n



x

i


)


2





=




∑

i
=
1


n


(

x

i


−



x
¯



)
(

y

i


−



y
¯



)



∑

i
=
1


n


(

x

i


−



x
¯




)

2








{\displaystyle {\hat {\beta }}={\frac {n\sum \limits _{i=1}^{n}x_{i}y_{i}-\sum \limits _{i=1}^{n}x_{i}\sum \limits _{i=1}^{n}y_{i}}{n\sum \limits _{i=1}^{n}x_{i}^{2}-\left(\sum \limits _{i=1}^{n}x_{i}\right)^{2}}}={\frac {\sum \limits _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{\sum \limits _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}\,}











α
^



=




∑

i
=
1


n



x

i


2



∑

i
=
1


n



y

i


−

∑

i
=
1


n



x

i



∑

i
=
1


n



x

i



y

i




n

∑

i
=
1


n



x

i


2


−


(

∑

i
=
1


n



x

i


)


2





=



y
¯



−



x
¯






β
^





{\displaystyle {\hat {\alpha }}={\frac {\sum \limits _{i=1}^{n}x_{i}^{2}\sum \limits _{i=1}^{n}y_{i}-\sum \limits _{i=1}^{n}x_{i}\sum \limits _{i=1}^{n}x_{i}y_{i}}{n\sum \limits _{i=1}^{n}x_{i}^{2}-\left(\sum \limits _{i=1}^{n}x_{i}\right)^{2}}}={\bar {y}}-{\bar {x}}{\hat {\beta }}}








S
=

∑

i
=
1


n


(

y

i


−




y
^




i



)

2


=

∑

i
=
1


n



y

i


2


−



n
(

∑

i
=
1


n



x

i



y

i



)

2


+
(

∑

i
=
1


n



y

i



)

2



∑

i
=
1


n



x

i


2


−
2

∑

i
=
1


n



x

i



∑

i
=
1


n



y

i



∑

i
=
1


n



x

i



y

i




n

∑

i
=
1


n



x

i


2


−


(

∑

i
=
1


n



x

i


)


2







{\displaystyle S=\sum \limits _{i=1}^{n}(y_{i}-{\hat {y}}_{i})^{2}=\sum \limits _{i=1}^{n}y_{i}^{2}-{\frac {n(\sum \limits _{i=1}^{n}x_{i}y_{i})^{2}+(\sum \limits _{i=1}^{n}y_{i})^{2}\sum \limits _{i=1}^{n}x_{i}^{2}-2\sum \limits _{i=1}^{n}x_{i}\sum \limits _{i=1}^{n}y_{i}\sum \limits _{i=1}^{n}x_{i}y_{i}}{n\sum \limits _{i=1}^{n}x_{i}^{2}-\left(\sum \limits _{i=1}^{n}x_{i}\right)^{2}}}}












σ
^




2


=


S

n
−
2



.


{\displaystyle {\hat {\sigma }}^{2}={\frac {S}{n-2}}.}



協變異數矩陣是：







1

n

∑

i
=
1


n



x

i


2


−


(

∑

i
=
1


n



x

i


)


2







(



∑

x

i


2




−
∑

x

i






−
∑

x

i




n



)




{\displaystyle {\frac {1}{n\sum _{i=1}^{n}x_{i}^{2}-\left(\sum _{i=1}^{n}x_{i}\right)^{2}}}{\begin{pmatrix}\sum x_{i}^{2}&-\sum x_{i}\\-\sum x_{i}&n\end{pmatrix}}}



平均響應置信區間為：






y

d


=
(
α
+



β
^




x

d


)
±

t



α
2


,
n
−
2





σ
^







1
n


+



(

x

d


−



x
¯




)

2




∑
(

x

i


−



x
¯




)

2









{\displaystyle y_{d}=(\alpha +{\hat {\beta }}x_{d})\pm t_{{\frac {\alpha }{2}},n-2}{\hat {\sigma }}{\sqrt {{\frac {1}{n}}+{\frac {(x_{d}-{\bar {x}})^{2}}{\sum (x_{i}-{\bar {x}})^{2}}}}}}



預報響應置信區間為：






y

d


=
(
α
+



β
^




x

d


)
±

t



α
2


,
n
−
2





σ
^





1
+


1
n


+



(

x

d


−



x
¯




)

2




∑
(

x

i


−



x
¯




)

2









{\displaystyle y_{d}=(\alpha +{\hat {\beta }}x_{d})\pm t_{{\frac {\alpha }{2}},n-2}{\hat {\sigma }}{\sqrt {1+{\frac {1}{n}}+{\frac {(x_{d}-{\bar {x}})^{2}}{\sum (x_{i}-{\bar {x}})^{2}}}}}}



變異數分析[編輯]
在變異數分析（ANOVA）中，總平方和分解為兩個或更多部分。
總平方和SST (sum of squares for total) 是：






SST

=

∑

i
=
1


n


(

y

i


−



y
¯




)

2




{\displaystyle {\text{SST}}=\sum _{i=1}^{n}(y_{i}-{\bar {y}})^{2}}

　，其中：　






y
¯



=


1
n



∑

i



y

i




{\displaystyle {\bar {y}}={\frac {1}{n}}\sum _{i}y_{i}}



同等地：






SST

=

∑

i
=
1


n



y

i


2


−


1
n




(

∑

i



y

i


)


2




{\displaystyle {\text{SST}}=\sum _{i=1}^{n}y_{i}^{2}-{\frac {1}{n}}\left(\sum _{i}y_{i}\right)^{2}}



回歸平方和SSReg (sum of squares for regression。也可寫做模型平方和，SSM，sum of squares for model) 是：






SSReg

=
∑


(




y
^




i


−



y
¯



)


2


=




β
^




T




X


T



y

−


1
n



(


y

T


u

u

T


y

)

,


{\displaystyle {\text{SSReg}}=\sum \left({\hat {y}}_{i}-{\bar {y}}\right)^{2}={\hat {\boldsymbol {\beta }}}^{T}\mathbf {X} ^{T}\mathbf {y} -{\frac {1}{n}}\left(\mathbf {y^{T}uu^{T}y} \right),}



殘差平方和SSE (sum of squares for error) 是：






SSE

=

∑

i





(


y

i


−




y
^




i



)


2



=


y

T


y
−




β
^




T



X

T


y

.


{\displaystyle {\text{SSE}}=\sum _{i}{\left({y_{i}-{\hat {y}}_{i}}\right)^{2}}=\mathbf {y^{T}y-{\hat {\boldsymbol {\beta }}}^{T}X^{T}y} .}



總平方和SST又可寫做SSReg和SSE的和：






SST

=

∑

i




(

y

i


−



y
¯



)


2


=


y

T


y

−


1
n



(


y

T


u

u

T


y

)

=

SSReg

+

SSE

.


{\displaystyle {\text{SST}}=\sum _{i}\left(y_{i}-{\bar {y}}\right)^{2}=\mathbf {y^{T}y} -{\frac {1}{n}}\left(\mathbf {y^{T}uu^{T}y} \right)={\text{SSReg}}+{\text{SSE}}.}



回歸係數R2是：






R

2


=


SSReg
SST


=
1
−


SSE
SST


.


{\displaystyle R^{2}={\frac {\text{SSReg}}{\text{SST}}}=1-{\frac {\text{SSE}}{\text{SST}}}.}



其他方法[編輯]
廣義最小平方法[編輯]
廣義最小平方法可以用在當觀測誤差具有異變異數或者自相關的情況下。
總體最小平方法[編輯]
總體最小平方法用於當自變量有誤時。
廣義線性模式[編輯]
廣義線性模式應用在當誤差分佈函數不是正態分佈時。比如指數分佈，伽瑪分佈，逆高斯分佈，泊松分佈，二項式分佈等。
穩健回歸[編輯]
將平均絕對誤差最小化，不同於在線性回歸中是將均方誤差最小化。
線性回歸的應用[編輯]
趨勢線[編輯]
一條趨勢線代表著時間序列數據的長期走勢。它告訴我們一組特定數據（如GDP、石油價格和股票價格）是否在一段時期內增長或下降。雖然我們可以用肉眼觀察數據點在坐標系的位置大體畫出趨勢線，更恰當的方法是利用線性回歸計算出趨勢線的位置和斜率。
流行病學[編輯]
有關吸菸對死亡率和發病率影響的早期證據來自採用了回歸分析的觀察性研究。為了在分析觀測數據時減少偽相關，除最感興趣的變量之外,通常研究人員還會在他們的回歸模型里包括一些額外變量。例如，假設我們有一個回歸模型，在這個回歸模型中吸菸行為是我們最感興趣的獨立變量，其相關變量是經數年觀察得到的吸菸者壽命。研究人員可能將社會經濟地位當成一個額外的獨立變量，已確保任何經觀察所得的吸菸對壽命的影響不是由於教育或收入差異引起的。然而，我們不可能把所有可能混淆結果的變量都加入到實證分析中。例如，某種不存在的基因可能會增加人死亡的幾率，還會讓人的吸菸量增加。因此，比起採用觀察數據的回歸分析得出的結論，隨機對照試驗常能產生更令人信服的因果關係證據。當可控實驗不可行時，回歸分析的衍生，如工具變量回歸，可嘗試用來估計觀測數據的因果關係。
金融[編輯]
資本資產定價模型利用線性回歸以及Beta係數的概念分析和計算投資的系統風險。這是從聯系投資回報和所有風險性資產回報的模型Beta係數直接得出的。
經濟學[編輯]
線性回歸是經濟學的主要實證工具。例如，它是用來預測消費支出，固定投資支出，存貨投資，一國出口產品的購買，進口支出，要求持有流動性資產，勞動力需求、勞動力供給。
參考文獻[編輯]
引用[編輯]

來源[編輯]

書籍


Cohen, J., Cohen P., West, S.G., & Aiken, L.S. Applied multiple regression/correlation analysis for the behavioral sciences. Hillsdale, NJ: Lawrence Erlbaum Associates. 2003. 
Draper, N.R. and Smith, H. Applied Regression Analysis. Wiley Series in Probability and Statistics. 1998. 
Robert S. Pindyck and Daniel L. Rubinfeld. Chapter One. Econometric Models and Economic Forecasts. 1998. 
Charles Darwin. The Variation of Animals and Plants under Domestication. (1868) (Chapter XIII describes what was known about reversion in Galton's time. Darwin uses the term "reversion".)


刊物文章


Galton, Francis. Regression Towards Mediocrity in Hereditary Stature (PDF). Journal of the Anthropological Institute. 1886, 15: 246–263 [2008-12-30]. 

延伸閱讀[編輯]

Pedhazur, Elazar J. Multiple regression in behavioral research: Explanation and prediction 2nd. New York: Holt, Rinehart and Winston. 1982. ISBN 0-03-041760-0. 
Barlow, Jesse L. Chapter 9: Numerical aspects of Solving Linear Least Squares Problems. (編) Rao, C.R. Computational Statistics. Handbook of Statistics 9. North-Holland. 1993. ISBN 0-444-88096-8 
Björck, Åke. Numerical methods for least squares problems. Philadelphia: SIAM. 1996. ISBN 0-89871-360-9. 
Goodall, Colin R. Chapter 13: Computation using the QR decomposition. (編) Rao, C.R. Computational Statistics. Handbook of Statistics 9. North-Holland. 1993. ISBN 0-444-88096-8 
National Physical Laboratory. Chapter 1: Linear Equations and Matrices: Direct Methods. Modern Computing Methods. Notes on Applied Science 16 2nd. Her Majesty's Stationery Office. 1961 

參見[編輯]


變異數分析
安斯庫姆四重奏
橫截面回歸
曲線擬合
經驗貝葉斯方法
邏輯斯蒂回歸
M估計
非線性回歸
非參數回歸
多元自適應回歸樣條
Lack-of-fit sum of squares
截斷回歸模型
刪失回歸模型
簡單線性回歸
分段線性回歸











閱
論
編


試驗設計






科學方法



科學實驗
統計設計
控制
內部效度 & 外部效度
Experimental unit
雙盲實驗


Optimal design: Bayesian
Random assignment
Randomization
Restricted randomization
Replication versus subsampling
Sample size








實驗
& 阻塞



Treatment
效應值
Contrast
Interaction
Confounding
正交
Blocking
Covariate
Nuisance variable








機率模型
& 推論統計學



線性回歸
Ordinary least squares
Bayesian


Random effect
Mixed model
等級線性模型: 貝氏網路


ANOVA
Cochran's theorem
Manova (multivariate)
Ancova (covariance)


Compare means
Multiple comparison








試驗設計:

完全隨機設計



Factorial
Fractional factorial
Plackett-Burman
田口方法


反應曲面法
Polynomial & rational modeling
Box-Behnken
Central composite


Block
Generalized randomized block design (GRBD)
拉丁方陣
希臘拉丁方陣
Orthogonal array
Latin hypercube
Repeated measures design
Crossover study


隨機對照試驗
Sequential analysis
Sequential probability ratio test











Glossary
實驗設計分類
機率與統計
Statistical outline
Statistical topics
















閱
論
編


統計學






描述統計學





連續變數機率分佈






集中趨勢


平均數（平方 · 算術 · 幾何 · 調和 · 算術-幾何 · 幾何-調和 · 希羅|平均數不等式） · 中位數 · 眾數







離散程度


全距 · 標準差 · 變異係數 · 百分位數 · 四分差 · 四分位數 · 變異數 · 標準分數 · 切比雪夫不等式







分佈形態（英語：Shape of the distribution）


偏態 · 峰態










離散變數機率分佈


次數（英語：Count data） · 列聯表（英語：Contingency table）












推論統計學
和 假設檢定





推論統計學


置信區間 · 區間估計（英語：Interval estimation） · 顯著性差異 · 元分析 · 貝氏推論







實驗設計


統計總量 · 抽樣 · 重複（英語：Replication (statistics)） · 阻礙 · 特敏度 · 區集（英語：Blocking (statistics)）







樣本量（英語：Sample size）


統計功效 · 效應值 · 標準誤 · 虛無假設 · 對立假設（英語：Alternative hypothesis） · 第一型和第二型誤差 · 統計檢定力







常規估計


貝葉斯推論 · 區間估計（英語：Interval estimation） · 最大似然估計 · 最小距離估計（英語：Minimum distance estimation） · 矩量法 · 最大間距







特效檢驗


Z檢驗 · 學生t檢驗 · F檢驗 · 卡方檢驗 · Wald檢驗（英語：Wald test） · 曼-惠特尼檢驗（英語：Mann–Whitney U test） · 秩和檢驗







生存分析


生存函數 · 乘積極限估計量 · 對數秩和檢定 · 失效率 · 危險比例模式









相關及
回歸分析





相關性


混淆變項（英語：Confounding） · 皮爾森積差相關係數 · 等級相關（英語：Rank correlation） (史匹曼等級相關係數 · 肯德等級相關係數（英語：Kendall tau rank correlation coefficient）)







線性回歸


線性模式（英語：Linear model） · 一般線性模式 · 廣義線性模式 · 變異數分析 · 協變異數分析（英語：Analysis of covariance）







非線性回歸（英語：Nonlinear regression）


非參數回歸模型（英語：Nonparametric regression） · 半參數回歸模型（英語：Semiparametric regression） · Logit模型









統計圖形

圓餅圖 · 長條圖 · 雙標圖 · 箱形圖 · 管制圖 · 森林圖（英語：Forest plot） · 直方圖 · QQ圖 · 趨勢圖 · 散佈圖（英語：Scatter plot） · 莖葉圖（英語：Stem-and-leaf display） · 雷達圖（英語：Radar chart） · 示意地圖









分類
主題
共享資源
專題












 
						取自 "https://zh.wikipedia.org/w/index.php?title=線性回歸&oldid=44541537"					
2 個分類：回歸分析估計理論隱藏分類：自2015年12月連結格式不正確的條目自2013年10月包含過多行話或專業術語的條目粗劣翻譯含有多個問題的條目有未列明來源語句的條目參考文獻格式不符的條目 



導覽選單


個人工具

沒有登入對話貢獻建立帳號登入 



命名空間

條目
討論




台灣正體



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






查看

閱讀
編輯
檢視歷史



更多







搜尋



 







導航


首頁分類索引特色內容新聞動態近期變更隨機條目 



說明


說明維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



其他專案


維基共享資源 



列印/匯出


下載成 PDF 



工具


連結至此的頁面相關變更上傳檔案特殊頁面可列印版靜態連結頁面資訊維基數據 項目引用此頁面 



其他語言


العربيةCatalàČeštinaDeutschΕλληνικάEnglishEspañolEuskaraفارسیFrançaisGalegoעבריתHrvatskiMagyarItaliano日本語한국어МакедонскиNorsk bokmålPolskiPortuguêsРусскийSimple EnglishSlovenščinaSvenskaУкраїнськаTiếng Việt 
編輯連結 





 本頁面最後修訂於2017年5月28日 (週日) 21:26。
本站的全部文字在創用CC 姓名標示-相同方式分享 3.0 協議之條款下提供，附加條款亦可能應用（請參閱使用條款）。
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發人員
Cookie 聲明
手機版檢視



 

 








廣義線性模式Generalized Linear Model - 統計學習網站





























				Home
			



				About
			



				課程 Course
			





			迴歸分析 Regression Analysis
		>






			作業
		





			投影片
		





			統計表
		








			統計學 Statistics
		>






			統計學一 Statistics I
		>






			作業
		





			MOOCs
		>






			教學影片單元1-10
		





			教學影片單元11-20
		





			教學影片單元21-30
		





			教學影片單元31-40
		





			教學影片單元41-50
		








			教學影片
		>






			教學影片單元1-10
		





			教學影片單元11-20
		





			教學影片單元21-30
		





			教學影片單元31-40
		





			教學影片單元41-50
		











			統計學二 Statistics II
		>






			MOOCs
		>






			教學影片單元1-10
		





			教學影片單元11-20
		





			教學影片單元21-30
		





			教學影片單元31-41
		











			SPSS教學影片
		








			研究方法 Research Methodology
		





			市場調查與分析 Marketing Survey and Analysis
		>






			投影片
		





			SPSS教學影片
		








			商用軟體應用 Commercial Software Application
		





			類別資料分析 Categorical Data Analysis
		>






			課程投影片
		





			SPSS教學影片
		








			數理統計(一) Mathematical Statistics I
		





			數理統計(二) Mathematical Statistics II
		





			應用多變量分析Applied Multivariate Analysis
		>






			教學影片
		








			廣義線性模式Generalized Linear Model
		>






			教學影片
		








			Big Data
		>






			區別分析
		





			迴歸與分類樹
		





			集群分析
		








			R 語言與資料分析 R Language and Data Analysis
		>






			R 教學影片
		





			R 講義
		





			R 實例練習
		





			R 作業
		








			R 書籍, 文獻與網站
		





			Weebly 教學
		







				Links
			



				 研討會
			



				Contact
			



				問捲
			



				R 教學影片
			




























廣義線性模式 Generalized linear Model

教課書A Introduction to Generalized Linear Models (3rd Edition), 2008, by Annette J. Dobson and Adrian Barnett.課程大綱/uploads/3/1/3/6/31364275/103下_廣義線性模式_課程大綱.doc



教學影片


課本pdf檔(2nd edition).

 an_introduction_to_generalized_linear_models,_annette_j._dobson.pdfFile Size:  1527 kbFile Type:   pdfDownload File










作業

 glm_hw1.docxFile Size:  13 kbFile Type:   docxDownload File



 glm_hw2.docxFile Size:  11 kbFile Type:   docxDownload File



 glm_hw3.docxFile Size:  11 kbFile Type:   docxDownload File


 
電腦講義一

 lab1.pdfFile Size:  12 kbFile Type:   pdfDownload File



 lab1.rnwFile Size:  1 kbFile Type:   rnwDownload File


 







 第四章羅吉斯迴歸6-15.pdfFile Size:  663 kbFile Type:   pdfDownload File









Create a free website

			Powered by 























✕







廣義線性模型 - 維基百科，自由的百科全書































 







廣義線性模型

維基百科，自由的百科全書
(已重新導向自 廣義線性模式)

					前往：					導覽，					搜尋






本條目部分連結不符合格式手冊規範。跨語言連結及章節標題等處的連結可能需要清理。（2015年12月11日） 
請協助改善此條目。參見WP:LINKSTYLE、WP:MOSIW以瞭解細節。突出顯示跨語言連結可以便於檢查。 









統計學系列條目


迴歸分析





模型




線性回歸
簡單回歸（英語：Simple linear regression）
普通最小平方法（英語：Ordinary least squares）
多項式回歸（英語：Polynomial regression）
一般線性模型






廣義線性模式
離散選擇（英語：Discrete choice）
邏輯迴歸
多項羅吉特（英語：Multinomial logit）
混合羅吉特
波比（英語：Probit model）
多項式波比（英語：Multinomial probit）
排序性模型（英語：Ordered logit）
有序波比（英語：Ordered probit）
泊松回歸






等級線性模型
固定效應（英語：Fixed effects model）
隨機效應（英語：Random effects model）
混合模型（英語：Mixed model）






非線性回歸（英語：Nonlinear regression）
非參數（英語：Nonparametric regression）
半參數（英語：Semiparametric regression）
穩健（英語：Robust regression）
分位數迴歸
保序回歸
主成分（英語：Principal component regression）
最小角
局部（英語：Local regression）
分段（英語：Segmented regression）






含誤差變量（英語：Errors-in-variables models）




估計




最小平方法
普通最小平方法（英語：Ordinary least squares）
線性
偏最小平方回歸
總體（英語：Total least squares）
廣義（英語：Generalized least squares）
加權
非線性（英語：Non-linear least squares）
非負（英語：Non-negative least squares）
重複再加權（英語：Iteratively reweighted least squares）
嶺回歸（英語：Tikhonov regularization）
LASSO






最小絕對值導數法（英語：Least absolute deviations）
貝葉斯（英語：Bayesian linear regression）
貝葉斯多元（英語：Bayesian multivariate linear regression）




背景




回歸模型檢驗（英語：Regression model validation）
平均響應和預測響應（英語：Mean and predicted response）
誤差和殘差
擬合優度（英語：Goodness of fit）
學生化殘差（英語：Studentized residual）
高斯－馬可夫定理






 機率與統計主題







閱
論
編





在統計學上， 廣義線性模型 (Generalized linear model) 是一種受到廣泛應用的線性迴歸模式。此模式假設實驗者所量測的隨機變數的分佈函數與實驗中系統性效應(即非隨機的效應)可經由一鏈結函數(link function)建立起可資解釋其相關性的函數。
John Nelder與Peter McCullagh在1989年出版，被視為廣義線性模式的代表性文獻中提綱挈領地說明瞭廣義線性模式的原理、計算(如最大概似估計量)及其實務應用。



目錄


1 概說
2 模式組成

2.1 指數族
2.2 線性預測子
2.3 鏈結函數


3 範例

3.1 一般線性模式
3.2 線性迴歸
3.3 二元資料
3.4 計次資料


4 參考文獻



概說[編輯]
廣義線性模型（generalized linear model, GLM)是簡單最小平方回歸（OLS)的擴展,在廣義線性模式中，假設每個資料的觀測值




Y



{\displaystyle \mathbf {Y} }

來自某個指數族分佈。 該分佈的平均數 




μ



{\displaystyle {\boldsymbol {\mu }}}

 可由與該點獨立的X解釋：





E
⁡
(

y

)
=

μ

=

g

−
1


(

X


β

)


{\displaystyle \operatorname {E} ({\boldsymbol {y}})={\boldsymbol {\mu }}=g^{-1}(\mathbf {X} {\boldsymbol {\beta }})}



其中



E
(

y

)


{\displaystyle E({\boldsymbol {y}})}

為




y



{\displaystyle {\boldsymbol {y}}}

的期望值，




X


β



{\displaystyle \mathbf {X} {\boldsymbol {\beta }}}

是由未知待估計參數




β



{\displaystyle {\boldsymbol {\beta }}}

與已知變數




X



{\displaystyle \mathbf {X} }

構成的線性估計式，



g


{\displaystyle g}

則為鏈結函數。
在此模式下，




y



{\displaystyle {\boldsymbol {y}}}

的變異數



V


{\displaystyle V}

可表示為：





Var
⁡
(

y

)
=
V
⁡
(

μ

)
=
V
⁡
(

g

−
1


(

X


β

)
)
.


{\displaystyle \operatorname {Var} ({\boldsymbol {y}})=\operatorname {V} ({\boldsymbol {\mu }})=\operatorname {V} (g^{-1}(\mathbf {X} {\boldsymbol {\beta }})).}



一般假設



V


{\displaystyle V}

可視為一指數族隨機變數的函數。
未知參數




β



{\displaystyle {\boldsymbol {\beta }}}

通常會以最大概似估計量, 殆最大概似估計量, 或以貝氏方法來估計。
模式組成[編輯]
廣義線性模式包含了以下主要部份：

1. 來自指數族的分佈函數



f


{\displaystyle f}

。
2. 線性預測子 




η

=

X


β



{\displaystyle {\boldsymbol {\eta }}=\mathbf {X} {\boldsymbol {\beta }}}

。
3. 鏈結函數



g


{\displaystyle g}

使得 



E
(

y

)
=

μ

=

g

−
1


(

η

)


{\displaystyle E({\boldsymbol {y}})={\boldsymbol {\mu }}=g^{-1}({\boldsymbol {\eta }})}

。

指數族[編輯]
指數族隨機變數意指其具參數θ與τ的機率密度函數, f (在論離散型隨機變數時，則為機率質量函數)可表為：






f

Y


(
y
;
θ
,
τ
)
=
exp
⁡


(



a
(
y
)
b
(
θ
)
+
c
(
θ
)


h
(
τ
)



+
d
(
y
,
τ
)
)


.




{\displaystyle f_{Y}(y;\theta ,\tau )=\exp {\left({\frac {a(y)b(\theta )+c(\theta )}{h(\tau )}}+d(y,\tau )\right)}.\,\!}



τ稱之為變異參數，通常用以解釋變異數。函數a、b、c、d 及h為已知。許多（不包含全部）型態的隨機變數可歸類為指數族
θ與該隨機變數的期望值有關。若a為恆等函數，則稱該分佈屬於 正則型式。 另外，若b為恆等而τ已知，則θ稱為正則參數，其與期望值的關係可表為：





μ
=
E
⁡
(
Y
)
=
−

c
′

(
θ
)
.




{\displaystyle \mu =\operatorname {E} (Y)=-c'(\theta ).\,\!}



一般情形下，該分佈的變異數可表為：





Var
⁡
(
Y
)
=
−

c
″

(
θ
)
h
(
τ
)
.




{\displaystyle \operatorname {Var} (Y)=-c''(\theta )h(\tau ).\,\!}



線性預測子[編輯]
線性預測子是用將獨立變數經由線性組合來尋模式所能提供之資訊的計量變數。符號η (希臘字母 "Η")通常用來表示線性預測子。它與資料的期望值的鏈結函數值有關(故稱"預測子")。
η表為未知參數β的線性組合(故為"線性")。X則為獨立變數所組合而成的觀測矩陣。如此一來，η可表示為





η
=

X


β

.



{\displaystyle \eta =\mathbf {X} {\boldsymbol {\beta }}.\,}



X的元素通常為模式設計時可觀測的資料或為實驗時所得的數據。
鏈結函數[編輯]
鏈結函數解釋了線性預測子與分佈期望值的關係。鏈結函數的選擇可視情形而定。通常只要符合鏈結函數的值域有包含分佈期望值的條件即可。
當使用具正則參數θ的分佈時，鏈結函數需符合XTY 為β的充份統計量此一條件。這在θ與線性預測子的鏈結函數值相等時方成立。下麵列出若干指數族分佈的典則鏈結函數及其反函數(有時稱為均值函數)：

典則鏈結函數

Y的分佈
名稱
鏈結函數
均值函數


正態
恆等





X


β

=
μ




{\displaystyle \mathbf {X} {\boldsymbol {\beta }}=\mu \,\!}






μ
=

X


β





{\displaystyle \mu =\mathbf {X} {\boldsymbol {\beta }}\,\!}




指數
倒數





X


β

=

μ

−
1






{\displaystyle \mathbf {X} {\boldsymbol {\beta }}=\mu ^{-1}\,\!}






μ
=
(

X


β


)

−
1






{\displaystyle \mu =(\mathbf {X} {\boldsymbol {\beta }})^{-1}\,\!}




Gamma


逆高斯
二次倒數





X


β

=

μ

−
2






{\displaystyle \mathbf {X} {\boldsymbol {\beta }}=\mu ^{-2}\,\!}






μ
=
(

X


β


)

−
1

/

2






{\displaystyle \mu =(\mathbf {X} {\boldsymbol {\beta }})^{-1/2}\,\!}




卜瓦松
自然對數





X


β

=
ln
⁡

(
μ
)





{\displaystyle \mathbf {X} {\boldsymbol {\beta }}=\ln {(\mu )}\,\!}






μ
=
exp
⁡

(

X


β

)





{\displaystyle \mu =\exp {(\mathbf {X} {\boldsymbol {\beta }})}\,\!}




二項式
Logit





X


β

=
ln
⁡


(


μ

1
−
μ



)






{\displaystyle \mathbf {X} {\boldsymbol {\beta }}=\ln {\left({\frac {\mu }{1-\mu }}\right)}\,\!}






μ
=



exp
⁡

(

X


β

)



1
+
exp
⁡

(

X


β

)








{\displaystyle \mu ={\frac {\exp {(\mathbf {X} {\boldsymbol {\beta }})}}{1+\exp {(\mathbf {X} {\boldsymbol {\beta }})}}}\,\!}




多項式


在指數分佈與Gamma分佈中，其典則鏈結函數的值域並不包含分佈均值，另外其線性預測子亦可能出現負值，此兩種分佈絕無均值為負的可能。當進行極大似然估計進行計算時需避免上述情形出現，這時便需要使用到非典則鏈結函數。
範例[編輯]
一般線性模式[編輯]
有些人可能會把一般線性模式和廣義線性模式給弄混了。一般線性模式可視為廣義線性模式的一個鏈結函數為恆等的特例。一般線性模式有著悠長的發展歷史。廣義線性模式具非恆等鏈結函數者有著漸近一致的結果。
線性迴歸[編輯]
廣義線性模式最簡單的例子便是線性迴歸。此例中分佈函數為常態分佈而鏈結函數為恆等函數在變異數已知的條件下並符合正規式。 這個例子具有廣義線性模式罕有的最大概似估計量的解析解
二元資料[編輯]
在討論二元反應結果(如有跟沒有)時，通常以二項式分佈建模。其期望值'μi通常解釋為樣本Yi發生事件的機率p
二項式分佈有許多常用的鏈結函數，最常用的鏈結函數是logit：





g
(
p
)
=
ln
⁡

(


p

1
−
p



)

.


{\displaystyle g(p)=\ln \left({p \over 1-p}\right).}



以此建模的廣義線性模式通常稱為logistic迴歸模式。
另外，任何連續型機率分配累積函數(CDF)的反函數皆可使用此模式，因為其值域為[0,1]，包含了二項式分佈期望值的可能值域。常態機率分配累積函數



Φ


{\displaystyle \Phi }

是一個廣受應用於probit模式的選擇。其鏈結函數為





g
(
p
)
=

Φ

−
1


(
p
)
.




{\displaystyle g(p)=\Phi ^{-1}(p).\,\!}



有時恆等函數也會被用為二項式分佈的鏈結函數，其缺點為預測值可能超出合理範圍。經過若干修正可以避免上述問題，但會在解釋上造成困難。此模式通常適用於p接近0.5的情形。 此種建模很接近logit及probit的線性轉換，有時計量經濟學家會稱其為Harvard模式。
二元資料的廣義線性模式變異函數可寫為





Var
⁡
(

Y

i


)
=
τ

μ

i


(
1
−

μ

i


)




{\displaystyle \operatorname {Var} (Y_{i})=\tau \mu _{i}(1-\mu _{i})\,\!}



其中變異參數



τ


{\displaystyle \tau }

通常等於1，若非，則該模式稱為溢變異或殆二元。
計次資料[編輯]
另一個常用的例子為用於計次的卜瓦松分佈。此例的鏈結函數為自然對數，為正規鏈結。 變異數函數與均值成等比





var
⁡
(

Y

i


)
=
τ

μ

i


,



{\displaystyle \operatorname {var} (Y_{i})=\tau \mu _{i},\,}



其中變異參數



τ


{\displaystyle \tau }

通常為1。 若非，此模式通常稱為溢變異或似卜瓦松。
參考文獻[編輯]

McCullagh, Peter; John Nelder. Generalized Linear Models. London: Chapman and Hall. 1989. ISBN 0-412-31760-5.  引文使用過時參數coauthors (幫助)


Dobson, A.J. Introduction to Generalized Linear Models, Second Edition. London: Chapman and Hall/CRC. 2001. 


Hardin, James; Joseph Hilbe. Generalized Linear Models and Extensions. College Station: Stata Press. 2001, 2007.  引文使用過時參數coauthors (幫助); 請檢查|date=中的日期值 (幫助)










閱
論
編


統計學






描述統計學





連續變數機率分佈






集中趨勢


平均數（平方 · 算術 · 幾何 · 調和 · 算術-幾何 · 幾何-調和 · 希羅|平均數不等式） · 中位數 · 眾數







離散程度


全距 · 標準差 · 變異係數 · 百分位數 · 四分差 · 四分位數 · 變異數 · 標準分數 · 切比雪夫不等式







分佈形態（英語：Shape of the distribution）


偏態 · 峰態










離散變數機率分佈


次數（英語：Count data） · 列聯表（英語：Contingency table）












推論統計學
和 假設檢定





推論統計學


置信區間 · 區間估計（英語：Interval estimation） · 顯著性差異 · 元分析 · 貝氏推論







實驗設計


統計總量 · 抽樣 · 重複（英語：Replication (statistics)） · 阻礙 · 特敏度 · 區集（英語：Blocking (statistics)）







樣本量（英語：Sample size）


統計功效 · 效應值 · 標準誤 · 虛無假設 · 對立假設（英語：Alternative hypothesis） · 第一型和第二型誤差 · 統計檢定力







常規估計


貝葉斯推論 · 區間估計（英語：Interval estimation） · 最大似然估計 · 最小距離估計（英語：Minimum distance estimation） · 矩量法 · 最大間距







特效檢驗


Z檢驗 · 學生t檢驗 · F檢驗 · 卡方檢驗 · Wald檢驗（英語：Wald test） · 曼-惠特尼檢驗（英語：Mann–Whitney U test） · 秩和檢驗







生存分析


生存函數 · 乘積極限估計量 · 對數秩和檢定 · 失效率 · 危險比例模式









相關及
回歸分析





相關性


混淆變項（英語：Confounding） · 皮爾森積差相關係數 · 等級相關（英語：Rank correlation） (史匹曼等級相關係數 · 肯德等級相關係數（英語：Kendall tau rank correlation coefficient）)







線性回歸


線性模式（英語：Linear model） · 一般線性模式 · 廣義線性模式 · 變異數分析 · 協變異數分析（英語：Analysis of covariance）







非線性回歸（英語：Nonlinear regression）


非參數回歸模型（英語：Nonparametric regression） · 半參數回歸模型（英語：Semiparametric regression） · Logit模型









統計圖形

圓餅圖 · 長條圖 · 雙標圖 · 箱形圖 · 管制圖 · 森林圖（英語：Forest plot） · 直方圖 · QQ圖 · 趨勢圖 · 散佈圖（英語：Scatter plot） · 莖葉圖（英語：Stem-and-leaf display） · 雷達圖（英語：Radar chart） · 示意地圖









分類
主題
共享資源
專題












 
						取自 "https://zh.wikipedia.org/w/index.php?title=廣義線性模型&oldid=45235051"					
2 個分類：統計學回歸分析隱藏分類：自2015年12月連結格式不正確的條目含有過時參數的引用的頁面引文格式1錯誤：日期 



導覽選單


個人工具

沒有登入對話貢獻建立帳號登入 



命名空間

條目
討論




台灣正體



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






查看

閱讀
編輯
檢視歷史



更多







搜尋



 







導航


首頁分類索引特色內容新聞動態近期變更隨機條目 



說明


說明維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



列印/匯出


下載成 PDF 



工具


連結至此的頁面相關變更上傳檔案特殊頁面可列印版靜態連結頁面資訊維基數據 項目引用此頁面 



其他語言


العربيةDeutschEnglishEspañolفارسیSuomiFrançaisItaliano日本語Português 
編輯連結 





 本頁面最後修訂於2017年7月17日 (週一) 05:13。
本站的全部文字在創用CC 姓名標示-相同方式分享 3.0 協議之條款下提供，附加條款亦可能應用（請參閱使用條款）。
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發人員
Cookie 聲明
手機版檢視



 

 









臺大課程地圖






















首頁
共同必修課程

國文
外文
體育
服務學習
進階英語


通識課程

文學與藝術領域
歷史思維領域
世界文明領域
哲學與道德思考領域
公民意識與社會分析領域
量化分析與數學素養領域
物質科學領域
生命科學領域


院系所課程

文學院
理學院
社會科學院
醫學院
工學院
生物資源暨農學院
管理學院
公共衛生學院
電機資訊學院
法律學院
生命科學院
牙醫專業學院
獸醫專業學院
其他教學單位


其他全校性課程

軍訓
共同選修
新生專題
寫作教學
基本能力課程


English．英文版



課程名稱：【廣義線性模式應用分析】


當學期所開設課程



課號
班次
課名
學分數
全半年
授課教師
時間(教室)


MPH5002

廣義線性模式應用分析 
2.0
2
洪  弘
三34 (公衛213) 


MPH5002

廣義線性模式應用分析 
2.0
2
洪  弘
三34 (公衛213) 


MPH5002

廣義線性模式應用分析 
2.0
2
洪  弘
三34 (公衛213) 



往年所開設課程



開課年度
課號
班次
課名
學分數
全半年
授課教師
時間(教室)


99-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
四56 (公衛212) 


99-1
MPH5002

廣義線性模式應用分析
2
2
陳佩君
一56 (公衛211) 


104-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


104-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


104-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


104-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


103-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


103-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


103-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


103-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


102-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


102-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛213) 


101-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛505) 


101-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
三34 (公衛505) 


100-2
MPH5002

廣義線性模式應用分析
2
2
洪  弘
四56 (公衛505) 










Copyright 2008 臺灣大學 National Taiwan University
10617 臺北市羅斯福路四段一號　No. 1, Sec. 4, Roosevelt Road, Taipei, 10617 Taiwan(R.O.C)
電話 (Phone)：+886-2-3366-2388轉308,607　　傳真號碼 (Fax)：+886-2-2362-6282











SPSS 廣義線性模型篇：線性與指數分析的整合工具 統雄-統計神掌 Statistics/SPSS Canon: Generalized Linear Model, GLM/GLZ_An Integrated Modeling Tool for Linear and Exponential Analysis, By Sean TX Wu


































統雄-統計神掌 廣義線性模型篇


線性與指數模型的整合工具
Generalized Linear Model, GLM/GLZ
















研究方法講義目錄
資訊管理講義目錄
數位文創/數位內容講義目錄
數位音樂講義目錄
產學合作-就業進修講義目錄
人文素養-人與社會講義目錄 
人類行為+資訊管理研究目錄
網路使用/電子商務研究目錄
網路教育研究目錄
數位音樂作品目錄







An Integrated Modeling Tool for 
Linear and Exponential Analysis

神掌打通任督二脈‧易筋經以簡馭繁

多變項-多因子分析常用模型簡介

廣義線性模型特色

廣義線性模型與一般線性模型比較

統計模型的發展與統計史觀的分界

統計模型的重要發展點



廣義線性模型特色

廣義線性模式
(generalized 

linear model)，縮寫早期同樣是GLM，這個術語，是統計史上最容易混淆的案例之一，所以，近來已有將縮寫改為GLZ的趨勢。

廣義線性模型的定義，簡單說：
範圍比一般線性模型更大，可包括指數、與對數迴歸，處理更多元的機率分配問題。

廣義線性模型與一般線性模型比較 
GLM vs. GLZ




 



General linear model



Generalized linear model





Typical estimation method



Least squares, best linear unbiased prediction



Maximum likelihood or Bayesian





Special cases



ANOVA, ANCOVA, MANOVA, MANCOVA, ordinary linear regression, mixed model, 
t-test, F-test



linear regression, logistic regression, Poisson regression





統計模型的發展與統計史觀的分界


GLZ是由Nelder & Wedderburn (1972)所提出的，名稱還叫做線性模型，但已經能夠處理非線性的問題了；同時，(Nelder, 
1966)也提出了Gamma 分配，以整合卡方分配、與F分配…等，在知識論上，提供了更整合性基礎（脫離原始框架）的觀照。

（其實，一般線性模型也能處理二次曲線，此細節在此不論。）

統雄老師-似乎零星西文文獻也有此議-感到，似可作為畫分「古典統計」與當代統計的界限。

同時，統雄老師也認為非線性分析，才是人類行為研究計量法的方向，不過，與GLZ 
在基礎思想上又大不相同了。

統計模型的重要發展點

以下是由Lindsey, McCullagh, Nelder, Stiegler所建議的統計模型的重要發展點：

‧Multiple linear regression — normal distribution & identity
link (Legendre, Guass: early 19th century).
‧ANOVA — normal distribution & identity link (Fisher: 1920』s
– 1935).
‧Likelihood function — a general approach to inference about
any statistical model (Fisher, 1922).
‧Dilution assays — a binomial distribution with
complementary log-log link (Fisher, 1922).
‧Exponential family — class of distributions with sufficient
statistics for parameters (Fisher, 1934).
‧Probit analysis — binomial distribution & probit link (Bliss,
1935).
‧Logit for proportions — binomial distribution & logit link
(Berkson, 1944; Dyke & Patterson, 1952)
Item analysis — Bernoulli distribution & logit link (Rasch,
1960).
‧Log linear models for counts — Poisson distribution & log
link (Birch, 1963).
‧Regressions for survival data — exponential distribution &
reciprocal or log link (Feigl & Zelen, 1965; Zippin & Armitage,
1966; Glasser, 1967).
‧Inverse polynomials — Gamma distribution & reciprocal link
(Nelder, 1966).
‧Nelder & Wedderburn (1972): provided unification. They
showed "All the previously mentioned models are special cases of
a general model, 「Generalized Linear Models」 The MLE for all these models could be obtained using
same algorithm.
‧All of the models listed have distributions in the
"Exponential Dispersion Family」




管理研究統計課程-問捲












		
		 


統雄數學神掌系列目錄

分享意見反映
統計教學的內涵與取向
高考統計考題的解析
微積分精華篇
微積分思想篇
微積分進階精華篇
統計/數學符號與其英語讀法
資料型態與視覺呈現
敘述統計
機率論與機率分配
推論統計學精華篇
t分配與 t檢定
推論統計‧理論建構
資料分析程序與SPSS基礎
SPSS 資料清理

SPSS 轉換:Recode 重新編碼

SPSS 轉換:Compute 建構新變項
SPSS 選擇觀察值_SPSS 
資料庫管理

樣本代表性檢定
單變項:類別_二元資料/詮釋
單變項:類別_二元資料/應用
單變項分析:連續資料

單變項連續資料視覺檢視與清理
卡方分析（雙向）
多向卡方分析
單向卡方分析
變異數分析（單因子）：詮釋
變異數分析（單因子）：應用
簡單迴歸/相關分析：詮釋
簡單迴歸/相關分析：應用
對數/邏輯相關分析

測量工具信度/效度分析

量表信度 檢定
量表效標關聯效度 檢定

探索式因素分析 (EFA)：詮釋與實作
探索式因素分析 (EFA)：應用進階

因素效度分析_CFA：詮釋

因素效度分析_CFA：應用
多變項分析精華篇
多元迴歸分析：詮釋
多元迴歸分析：應用
一般線性模型精華篇
廣義線性模型

雙因子/多因子變異數分析
調節模型與交互作用詮釋
調節模型分析與建構
SPSS 統計圖應用:調節模型檢定
共變數分析/詮釋
共變模型建構/應用
因果模型與因果邏輯
中介模型分析

因徑/SEM:模型詮釋與因果邏輯

因徑/SEM:探索式因徑模型建構

因徑/SEM:驗證式結構方程解析

多變項分析實例SEM篇

多變項分析實例SEM+調節篇

因徑/結構方程SEM：反省
無母數統計
統計研討篇
專題-卜豐投針實驗
專題-機率與統計悖論
第1類知識計量工具
第2類知識計量工具
第3類知識計量工具

非等機率知識體系建構
TX空時座標建構
一般取用測量
信仰取用測量

研究方法/民調市調系列















TX取用行為一般模式篇

TX取用行為進階模式篇
人類取用行為模式 應用系列
調查知識管理系統 應用系列
資訊系統與資訊管理 系列

多元學習‧獨立好問
教改與快樂學習
自主式學習成就評鑑方案
核心理念-全人教育
網路無邊界教室
國際化雙語互動
人格與群己教育
虛擬平等校園
孔子的杏壇六藝
亞理斯多德的學園漫步
腦半球的偽科學與真知識
教育與社經地位
知識創新與知識光譜
接龍實驗：創新就是與眾不同
Google排行榜實驗：科學創新就是一再與眾不同
學習的金字塔












  
  
 

 








 










	 中文圖書

















































   線上目錄





















.訂閱電子報.





















   首頁













   關於雙葉










  雙葉歷史  









  服務處  




















   中文圖書










  管理  









  財金  









  經濟  









  統計  









  心理教育  









  社會社工  









  觀光  









  傳播  









  哲學  









  其他  




















   英文圖書










  管理  









  財金  









  經濟  









  統計  









  心理教育  









  社會社工  









  觀光  









  傳播  









  哲學  









  其他  









  GIS  

















  Management, Organization, Business  









  Marketing & Consumer Behavior  









  Management Science, Operations Research  

















  Finance, Investment & Insurance  









  Accounting & Auditing  

















  Economics  

















  Statistics  









  Mathematics  

















  Psychology & Education  

















  Sociology, Social Work, Research Method  









  Quantitative Applications in Social Science  









  Applied Social Research Methods Series  









  Qualitative Research Methods  

















  Hospitality, Tourism  

















  Arts, T.V., Media  

















  Philosophy, Logic  

















  Dictionary & Reference  









  Literature & Critical Theory  









  Potery & Prose  









  Drama  









  Fiction  









  Cliffs Notes  









  Book of China  









  Modern Masters Series  









  Library  









  Languages  









  French  









  German  









  Spanish, Latin, Italian & Greek  









  Russian  









  Religion  









  Political Science  









  History  









  Civil Physics Computer Electronic Mechanics  









  Modern Library College Editions Series  




















   題庫










  製作考題  









  相關訊息  









  個人基本資料  









  變更密碼  









  登出  




















   訂購資訊










  書店購書  









  團體購書  









  網路購書  










































  管理財金經濟統計心理教育社會社工觀光傳播哲學其他 























  首頁  >>  中文圖書  . 資料首頁  
















階層線性模式:原理.方法與應用 第一版 2006年 (HIERARCHICAL LINEAR MODELING)作/ 譯者：溫福星 著ISBN：9867433505年份：2006書號：00105963開數：18K頁數：680定價：550元 教師教學配件：溫福星

現職 
東吳大學國際貿易學系助理教授，兼任輔仁大學心理所與交通大學管科所線性結構模型分析課程。


學歷 
國立政治大學企業管理博士（2002），主修財務管理、副修國際企業，擁有國際財務風險管理師(FRM)證照。


經歷 
聯合報民意調查中心、奧美廣告、奧美直效行銷公司


研究領域 
心理計量、財務風險管理、財務數學與時間數列議題


◆介紹HLM的原理與方法論。
◆說明何時要採用HLM和忽略HLM時可能遭遇的問題。
◆對HLM所用的參數估計與檢定方法有扼要的推導過程。
◆對非連續變數依變項的分析做簡單的介紹。
◆除了橫斷面分析的HLM，對縱貫面資料的線性成長模型也有所涉獵。
◆對當代有關HLM的重大議題進行詳實探討。
◆以實例對各種HLM的模型進行範例說明與結果報表的解讀，並對HLM與SPSS軟體有關階層線性   模式的操作介面、功能與繪圖做一有系統的介紹。
第零章   前言
第一章   迴歸模式與階層線性模式
1.1 迴歸模式
1.2 階層線性模式的方法論
1.3 參考文獻與進階閱讀文章

第二章   階層線性模式的原理與各種模型
2.1 階層線性模式概念
2.2 階層線性模式原理
2.3 階層線性模式的主要模型
2.4 階層線性模式的另外一種分類方法
2.5 階層線性模式的一般式
2.6 參考文獻與進階閱讀文章

第三章   階層線性模式的參數估計(I) 
3.1 簡單迴歸分析的參數估計
3.2 多元迴歸分析的參數估計
3.3 階層線性模式的參數估計
3.4 參考文獻與進階閱讀文章

第四章   階層線性模式的參數估計(II) 
4.1 具隨機效果的單因子變異數分析τ00 與σ2 的估計
4.2 具隨機效果的單因子共變數分析τ00 與σ2 的估計
4.3 隨機係數迴歸模型的參數估計（ IGLS 技術）
4.4 階層線性模式一般式的IGLS
4.5 最大概似估計法
4.6 EM 演算法. 
4.7 其他演算法
4.8 參考文獻與進階閱讀文章

第五章   階層線性模式的參數檢定
5.1 簡單迴歸分析的迴歸係數檢定
5.2 階層線性模式的參數假設檢定類型
5.3 階層線性模式的參數檢定
5.4 模式擬合度的概似比檢定
5.5 強韌標準誤
5.6 參考文獻與進階閱讀文章

第六章   廣義階層線性模式
6.1 廣義線性模式介紹
6.2 邏吉斯迴歸與機率迴歸
6.3 多項邏吉斯迴歸或多項邏輯模型
6.4 次序機率迴歸分析或累積邏吉斯迴歸
6.5 布拉松迴歸
6.6 廣義線性階層模式
6.7 參考文獻與進階閱讀文章

第七章   縱貫面資料分析
7.1 縱貫面資料的類型
7.2 橫斷面與縱貫面資料的關係
7.3 線性成長模式
7.4 第一層解釋變項的中心化問題
7.5 誤差項的假設
7.6 混合模型
7.7 參考文獻與進階閱讀文章

第八章   階層線性模式假設與一些重要議題
8.1 HLM 的基本假設
8.2 中心化議題
8.3 固定效果與隨機效果的選擇
8.4 樣本大小的決定
8.5 殘差分析
8.6 決定係數的計算
8.7 縮動與信度的意義
8.8 參考文獻與進階閱讀文章

第九章   階層線性模式的應用實例
9.1 基本資料概述
9.2 零模型（具隨機效果的單因子變異數分析）
9.3 具隨機效果的單因子共變數分析
9.4 隨機迴歸係數模型
9.5 以平均數為結果變項模型
9.6 脈絡模型
9.7 完整模型
9.8 參考文獻與進階閱讀文章

第十章   階層線性模式的軟體操作介紹
10.1 HLM6.02 的操作
10.2 SPSS 的Mixed 模組
10.3 SPSS Mixed 語法
























































Copyright ©2007 雙葉書廊.All Right Reserved.地址: 臺北市羅斯福路三段269巷12號1樓TEL: 02-2368-4198 02-2368-7084 FAX: 02-2365-7990 e-mail : service.yeh@yehyeh.com.tw






























廣義線性模型觀點：統計迴歸分析(Regression)的基本原理與結構 – 服務科學的分子廚房 Molecular Service Science















































						服務科學的分子廚房 Molecular Service Science					

一整桌跨領域學術與實務的美味融合









廣義線性模型觀點：統計迴歸分析(Regression)的基本原理與結構

九月 12, 2012Wendell.Huang
 6 Comments



差不多 2 月左右，衝假的緣故休得特別多，又正好碰到統計上無法解決的問題，於是本人也很有野心的列了一張清單，幾月的時候要看完哪些書目、做點小研究、整理一些心得什麼的，不過就像許多人每年的「夢想板」，寫爽的成分比較多…，趁著空檔，終於趕在開工前夕把 ptt 上也常有推薦的經典譯作， Neter 原著的「應用線性迴歸模型」掃完，再加上看了一部分的「類別資料分析導論」，穿插著幾本統計小書，一時恐怕是整理不完了。
我們準備來談談「迴歸分析的本質」以及它的歷史軼事，但無論如何，一窺迴歸分析的堂奧之前，還是有些觀念需要先建立起來。
為何這麼麻煩？把方法完整巡遊一遍後，回頭探討基本結構是很有好處的，像是出國旅行，人生地不熟的時候，常常只能跟著人潮與旅行團規劃走，但熟練的旅行者，會鑽進街巷之中，尋找連結著城市各處的最短途徑以及稍縱即逝的美麗風景。
首先，故事從這裡開始：迴歸是什麼？
統計迴歸模型( Regression )的起源：天才可以無限制地被遺傳下去嗎？
時空來到好久好久以前，英國的達爾文(對，就是那個達爾文)有個謠傳智商高達 200 的天才表弟叫 Galton ， Galton 是個驚人的另類科學家，雖不是正統的學院學者，卻出版了數以百計的書籍與論文，領域之廣幾乎無所不包，被尊稱為「 Victorian Polymath 」。
Galton 身為偉大的達爾文的表弟，不意外地，他對遺傳學也很有心得，並首創了優生學( Eugenics )用詞。由於出身銀行業兼軍火商的家族， Galton 幸運地得以任意從事他喜愛的探險與科學活動，在 1880 中期到 1890 年代這段時間， Galton 找來了一群人做了各種人體特徵的紀錄，他得到兩個心得：
第一，有兩隨機變數 X 、 Y ，當其中一者的改變多少受到另一方的影響時，必然存在同時作用於此二者的因素，將這種關係定義為「有相關」，反之則為獨立。
第二，當時人類遺傳學開始相信優勢是可以遺傳給後代的，但是會不會持續下去則是未證實的疑問，譬如身高都很高的夫妻，是否會生下更高的兒女？

Galton 發現，父母特徵的確會遺傳給後代，但是並不會產生極端身高的族群。當父母的身高已經遠離平均身高時，生下的兒女身高並沒有持續「遠離」平均，而會稍微「靠近」平均，也就是相對矮了一點；反之父母身高很矮的後代，身高會相對其父母「靠近」平均一點。
當然雙親身高都很高的後代，比起雙親身高都很矮的後代，還是相對較高的，不過差距並未一直增加，反而會持續減少。
Galton 把這個「極端」往「平均」移動的現象稱為「 regression to the mean 」。用東方人的說法，就是「物極必反」，至於「極物」將「反向」何方？
Galton 說，這個答案就叫「平均數」。
Galton 的第一項發現「相關係數 r 」，後來由另一位在統計史上名氣鼎盛的 Karl Pearson 推導出線性通則，該式又名「 Pearson 積差相關係數」。
晚年的 Galton 與 Pearson 及 Weldon 關係相當好，不僅是研究夥伴，也資助二人創辦了至今影響力仍鉅的生物統計期刊《 Biometrika 》，在 Galton 的支持下，早期的《 Biometrika 》皆以超水準的規格發行，讓該刊知名度大開， Galton 過世以後也是由 Pearson 親自為其整理傳記。
Pearson 的介紹，可參閱《 卡方檢定 ON THE CROSS：PEARSON, YATES AND FISHER 》。

迴歸分析概念的視覺化
Galton 的迴歸概念，被逐漸補充、擴大，變得越來越完整，現在迴歸已是一個意義廣泛的用詞，更好的說法是「迴歸模型」，在這個模型底下包含了許多用以解釋、判斷、修正的諸多內容，若要產生一個「真正正確而有用」的模型所需的知識量，只看入門教科書絕對是不夠的。
從模型整合的角度出發，所有迴歸都具有三個基本要件：
1. 系統成分( Systematic Component )
2. 隨機成分( Random Component )
3. 連結函數( Link Function )
系統成分是給定的迴歸中，用來解釋研究現象的元素，隨機成分則是研究希望討論的「未知」的現象。而「連結」就是描述系統成分與隨機成分兩者之間關係的函數。
從文字定義似乎不易理解「迴歸」是什麼，由圖入手或許清楚得多，以下利用某地區房屋「坪數 X 」對應「房價(單位:千萬) Y 」的簡迴歸 ( Simple Regression ) 範例說明之：

圖中的圓點，是抽樣的資料點，貫穿其中的直線，則是「迴歸直線」，迴歸直線的意義即是 Galton 所謂的「平均」。殘差 e31 、 e33 分別表示第 31 、 33 個資料點與平均線的差異，其餘以此類推。其中，「坪數 X 」就是系統成分，而「房價 Y 」則是隨機成分，對一個簡單直線迴歸，連結函數就是線性方程式。
由於「迴歸到平均」的性質，觀察迴歸直線與資料點的距離，即可推估該資料的一些特性，掌握這些數學特性，可以幫助我們做幾件事：
1.可推估某資料點是否為「離群的極端值」。
2.可計算自變數 X 與應變數 Y 的相關性。
3.根據上述的相關性，可描述資料集的發展趨勢。
4.拓展到擁有多個預測變數 X 的「複迴歸」，可分析多個自變數與應變數的互動。
5.可大膽預測「資料集之外(括號外的部份)」的資訊，對應變數的可能影響。
例圖用的是「線性迴歸」，然而迴歸用以描述自變數與應變數關係的函數不只有直線而已，二次或三次以上曲線、指數、對數、分段都是可行的方式，這也衍生出各種迴歸問題。
迴歸分析的公式化與殘差 
以最普遍的直線迴歸為例，典型的線性迴歸式如下：

此式稱為「母體迴歸直線」，是描述「真實未知情況」的完美配適。但是因為完整、正確的普查在多數情況下幾乎是不可行的，因此沒人知道「真實情況」究竟是如何，退而求其次，統計學容忍些許錯誤的可能性，改以抽樣資料推算真實的大概樣貌。
樣本迴歸直線因此誕生：

迴歸式中的「殘差( Residual )」描述「觀察資料 Yi 」與「配適結果 Yi-hat 」的差異，殘差越小，代表模型的配適越接近觀察資料，假如可證明觀察資料之於真實情況具有代表性，就可利用配適結果對真實情況的良好描述進行有用的統計推論。
可以想像，對一個良好模型，其模型殘差的期望值 E( ei )應該要等於 0 。
殘差的實際用法，改天再討論，本文僅著重於殘差與模型的關係描述。
在一般的直線迴歸中，殘差的假設為：

註意，其中殘差的常態假設並非必要，雖然假設殘差服從常態分配對很多人而言可能是理所當然的…，一些作者直接就把它寫成基本假設，卻沒交代清楚，稍後會談到殘差的假設分配對模型的影響。
先來看看為何殘差不必要是常態分配？
根據高斯-馬可夫定理( Gauss-Markov Theorem )，以「最小平方法( Least Squares Method )」計算線性迴歸參數 b0 、 bi 將有「最佳線性不偏估計量( BLUE ，  Best Linear Unbiased Estimator )」性質的前提，要求殘差符合以下條件：
1. 殘差期望值為 0 。
2. 殘差具有同質變異，變異數為一固定常數。
3. 殘差間沒有自相關( Autocorrelation )。
4. 自變數與殘差無關，即「正交性( Orthogonality )」。
發現了嗎？最小平方法下的殘差其實是不需要常態假設的。關於迴歸係數的最小平方估計，可參閱《一場關於猜的魔術：統計估計的形成》。

統計迴歸分析與常態分配的關係
回到迴歸分析的主題上，針對殘差假設為常態分配的意義有三：
第一，迴歸是需要相對大樣本才較有意義的方法，特別是多元變數的複迴歸，對樣本的需求量很大，很自然會符合中央極限定理。實務上，筆者會建議 300-500 個樣本或是更多時才適用。
第二，統計推論常見的 Z 、 T 、 Chi-squared 、F 基本上都是跟常態的機率分佈性質( Normal Distribution )有關，光是有殘差，要是無法對殘差進行推論也是不夠力的。
第三，係數檢定用的 T 分配及類  T  統計量都是對偏離常態不太敏感的統計量，因為它們本身就是常態 Z 統計量的近似，因此近似又近似的結果就是，除非是殘差真實分配遠離常態，不然影響非常有限。在稍大的樣本條件下更是如此(理由同第一點)。
那有沒有殘差不為常態的迴歸模型範例？
有的，像 Logistic 迴歸式就沒有殘差的假設，因為「根本沒有殘差」，那是因為推導中代換掉的關係，有機會再來談。
回到殘差的分配對模型的影響上，記得常態分配具有「水平位移」的特性嗎？
對模型：

由此可知，當假定殘差服從常態分配時，其實也就等於假定Y將服從常態分配，期望值 E( Y )= b0 + biX +… bkX ，變異數與殘差相同。
應該有人看過教科書這麼說：對 Y 而言，假設其為常態分配…，理由可以從這裡找到。
在迴歸裡，殘差變異數的估計量數是 MSE ( Mean Squared Error )，因此迴歸線的變異數也等於 MSE ，記得以前做專題還看過一個很爛的翻譯叫做「均方差」…，天啊，什麼東西？
假如你也被書中一下子說殘差變異數、一下子說模型變異數、一下子均方差搞得糊裡糊塗，那麼現在應該鬆一口氣了，因為都是同一件事。
所以一般說的直線迴歸究竟是不是常態的方法？
某個程度上視你從什麼角度切入。基本上，迴歸的分配取決於殘差的假設，而 XY 對應關係則決定迴歸的函數形式。在上述的直線模型中，假如只有一個自變項，通常稱為簡迴歸或簡單直線迴歸( Simple Regression )，同時存在多個自變項的情形，稱為複迴歸或多元迴歸( Multiple Regression )，兩者在許多基本性質上可以直接推廣，不過在複迴歸，容易產生因多元變數而起的模型問題，是以在統計教學中通常會將兩者分開討論。
簡迴歸的式子其實就是國中學過的 Y = a*X + b ，但在統計上描述得更實務、更精細，直線迴歸基本特性，可由符號下標看出來：
第一，每一組樣本 Xi1~Xik 對應到一個應變數 Yi (函數基本定義)。
第二，截距項與斜率項在迴歸配適完成之後就固定住了，因此可以任意代入想觀察的自變數組合，或者稍作修正，做資料集外的「預測」，做討論比較時也很方便…，總之這種一目瞭然的形式深受分析人員喜愛。
接著來談談迴歸函數的形式吧。
廣義線性模型的變化與結構：直線、曲線與非線
如果從自變數「 X 」與應變數「 Y 」的函數反應形狀來決定迴歸的「線性」，那麼我們基本上可以得到三個種類：直線、曲線與非線。
但是！對於這幾種對應關係的迴歸稱呼，似乎沒有一致的標準。
舉個例子來說好了，某些作者會用「線性」來表示「直線 + 曲線」，但問題是曲線在沒有充分指定的情況下是非常任意的，也就是所有的對應關係都是廣義的曲線，其實直線本身也不過曲率= 0 的曲線特例罷了。
另一些作者，用「線性」代表「直線」，非線性代表「廣義的曲線」，這個分法本身就有誤導之嫌，畢竟線性不等於直線，在書目之前來來去去很容易混為一談。
至於直線與非直線的區別，曾看過這樣的分法：直線迴歸永遠是「一階式」，只要是「二階」以上式子基本上就是非直線。但是這個有點可議…，等一下的例子告訴你為什麼。

剛開始很令人納悶，明明就可以清清楚楚劃分成三種情形，統計學家何苦老愛用個意義不定的「線性」一詞來描述迴歸…？不過這是有原因的。
到目前為止，本文使用的範例都是「直線」。
不如來看看「非直線」的迴歸能不能給我們一些線索：

拋物線迴歸不難懂，是很常見的曲線，但是多項式迴歸就很複雜了，隨著次方項增高，結果可能是一平面、曲面或者無法圖像化，總之，對應關係根本就不是線型。你可能會有點意外的是，其實，這兩個式子，「曲線」與「不是線」的迴歸，都是「線性」迴歸。
關鍵在於變數轉換！
用拋物線迴歸的例子，只要設新變數 X’ = X^2 ，再換入原先的公式，不就令「二階式」變為「一階式」了嗎？有樣學樣，交互作用以及更高階項次也都能比照辦理。
總之只要迴歸式表示成「相加式」，不管是怎樣的對應關係，曲線或者非線都可以透過代入新變數轉成直線。
至於「相乘式」的迴歸…，沒錯，還是線性迴歸。不過轉換的方式不一樣。
我們曾在《 Data Transformation的一些探討 》中看過這個公式：


是的，該式加入殘差項就成為「相乘式」的迴歸，轉換後的 e’ = log( e ) 。
在前面提到的《 Data Transformation的一些探討 》一文中，筆者沒有特意以「迴歸模型」為例的原因是，這個資料變造手法即使在非模型分析，也可能產生不錯的作用，當然了，資料轉換在迴歸中是很重要的技巧。
再換個例子，以經濟學柯布-道格拉斯生產函數( Cobb-Douglas Production Function ) 為例並加入殘差項如下：

其中 Q 代表產出， L 代表勞動力投入， K 代表資本投入。
轉換的方式同上，取對數轉換：

這正是一個標準的線性迴歸式。
看完「曲線」與「非線」轉換成「直線」的過程，相信你也不難理解為何眾多統計學家都愛用「線性迴歸」的名稱，因為不管是怎樣的函數形式，在統計學家的巧手下，都有辦法合理地轉成線性關係！
雖然變數轉換好不好用有時候見仁見智，但是理論上提供的彈性確實非常強大。
線性這種極強的相容性，提供了一個「超級模型」所需要的基礎，你一定在想，有沒有可能利用這種性質把各種不同類型的迴歸模型全都包在同一個理論下來解讀呢？
事實上，此模型就名為「廣義線性模型( GLM ， Generalized Linear Model )」，廣泛包納了 ANOVA 、直線迴歸、多項式迴歸、 Poisson迴歸 、 Logistic 迴歸等等模型，不光反應變數是連續型的迴歸，反應變數是類別變數的模型也可以用它來解釋。
還記得前面提過所有迴歸的共同組成嗎？一個迴歸模型包含了三個基本元素：
1. 系統成分( Systematic Component )
2. 隨機成分( Random Component )
3. 連結函數( Link Function )
這三個元素，就是廣義線性模型的結構定義！
廣義線性模型從兩個方向將常態線性模型擴充到其他模型：
第一，隨機成分假設為非常態的其他分配；
第二，將連結函數從直線方程式改為其他函數。
當隨機成分 Y 不限於常態，那麼以類別變數為反應變數的模型就能用同一套概念運作，譬如 Y 服從二項分配，那麼 Y 取値就成為非 0 即 1 ，而非常態分配的範圍負無限大到正無限大之間。甚至計數資料也可以應用上來，譬如 Poisson 分配。
連結函數的彈性，則允許 GLM 納入各種不同的對應關係，並利用前述的資料轉換技巧，將曲線與非線案例變為直線函數，成為名符其實的「 廣義線性模型 」。
廣義線性模型的常見應用：直線迴歸、 ANOVA 與卡方檢定 
對社會科學領域的學生來說，它們三個可能是最廣泛學習的方法了，但在我的學習印象中，也是最傻傻搞不清楚的方法。
ANOVA 與卡方，在大學的時候許多老師都會要求學生手動計算，主要的方法就是開表格，對 ANOVA 開二維表，對卡方也是開二維表，瞎的地方則是統計量算著算著，怎麼兩個方法好像都差不多！
後來敎迴歸，才終於導入模型化的概念，但是這下可慘了，因為已經把卡方檢定跟 ANOVA 混在一起，我實在無法理解為什麼 ANOVA =直線迴歸？
事後想想，這個疑惑某個程度上可歸因為沒有細分「變數類型」的關係。
統計的資料維度，概分四類：
1. 名目變數或類別變數( Nominal Variable 、 Categorical Variable )
2. 順序變數( Ordinal Variable )
3. 區間變數( Interval Variable )
4. 比例變數( Proportional Variable )
其中 1 、 2 合稱「質」變數； 3 、4 稱為「量」變數。
對於具有絕對原點的比例資料相信多數人都不陌生，統計上較容易產生問題的是前面三種，譬如順序變數，喜好分數從 1~3 ， 1 為最喜歡， 3 為最不喜歡，看起來好像可以直接做加減運算，不過這樣會有個隱藏的問題，因為你不曉得分數 1 與分數 2 的差距是不是等於分數 2 到分數 3 的差距。
假如不是這樣的話，那麼運算結果就失真了。若是單位「等距」，順序變數就會變成「區間變數」。詳細內容可參考 UCLA Academic Technology Services 的網站，此處有相關說明。
在二維卡方檢定當中，行列代表的兩個變數都是「類別變數」，內容是運用各類別的次數，檢定機率的「獨立性」與比例的「同質性」，但對 ANOVA 而言，比較的是各組的「平均數」差異，也就是說「組別是類別變數」，但平均數卻是「連續變數」。
而直線迴歸，稍早之前已經解釋過，應變數 Y 受到殘差的影響，服從「常態分配」， Y 是理所當然的「連續變數」，至於 X 的變數類型…，前面沒提，因為類別變數或順序變數都適用，比例變數更是不在話下，可說「沒什麼限制」。
數學裡，無限制的狀況是很難得的，理由可以從前面「水平位移」與「轉直線」的過程找到一點線索。
因為對迴歸線而言， X 不影響迴歸的分配誰屬，由於有了轉直線的方法， X 對 Y 的真實函數對應也不太重要了，因此 X 只要不與殘差有相關，能符合高斯-馬可夫定理，除此之外則是很自由的。
如此說來，直線迴歸與 ANOVA 的關係就清楚多了，對僅有 1 個預測變數 X ，且是「屬質」變數的直線迴歸，根本就是 ANOVA 。
從這層關係來看，迴歸分析的檢定報表使用 ANOVA Table 實在是再合理不過了。
順道一提， X 為「屬質」變數的迴歸，將會用到「虛擬變數( Dummy Variable )」的變數轉換，質對量的分析，不論用 ANOVA 計算或者跑 Dummy 迴歸，結果會一模一樣，對於 GLM 將 ANOVA 納入廣義線性的家族之中，現在你應該一點都不意外了。
另外要提醒，在其他的迴歸當中，是有以「類別變數」為應變數 Y 的模型，所以這裡特別指出「直線迴歸」。
最後就以一張簡化的圖示，來說明三者的差異，但是下圖的對應式並不保證 XY 具有因果關係，這又是另一個大主題了，我們改天再深入討論。

閱讀一分鐘，臺下十年功！精選文章推薦：
＊ DATA TRANSFORMATION的一些探討
＊ 維度縮減DIMENSION REDUCTION，通往線性代數的聖母峰 : 特徵值分解(EIGENVALUE DECOMPOSITION)、奇異值分解(SINGULAR VALUE DECOMPOSITION) 與主成份分析(PRINCIPAL COMPONENT ANALYSIS)
＊ 隨機性、大數法則與中央極限定理
＊ 統計R語言實作筆記系列 – 資料尺度與變數類型
＊ 統計R語言實作筆記系列 – 2D視覺化進階 GGPLOT()的基本架構(一)
＊ 數大有時不美的統計性質
 
(Visited 18,991 times, 43 visits today) 





Wendell.Huang
科技公司嫌棄太活潑,消費品牌挑剔太沉悶..., 經常必須解釋自己在學什麼, 不小心就摔破對方眼鏡的跨領域玩家｡

更多該作者文章
LinkedIn






			6 Comments		



			Pingback: 服務科學課程回顧: 應用商業分析(Applied Business Analytics) | 服務科學的分子廚房 Molecular Service Science 



			Pingback: Data Transformation的一些探討 – 服務科學的分子廚房 Molecular Service Science 



			Pingback: 隨機性、大數法則與中央極限定理 – 服務科學的分子廚房 Molecular Service Science 



			Pingback: 服務科學課程回顧: 應用商業分析(Applied Business Analytics) – 服務科學的分子廚房 Molecular Service Science 



			Pingback: 數大有時不美的統計性質 – 服務科學的分子廚房 Molecular Service Science 



			Pingback: Excel 交互參照必學神器， 用 lookup 系列函數一鍵搞定資料比對 : vlookup篇 – 服務科學的分子廚房 Molecular Service Science 



發表迴響 取消回覆

你的電子郵件位址並不會被公開。 必要欄位標記為 * 名稱 * 
電子郵件 * 
個人網站 
迴響 
 



Currently you have JavaScript disabled. In order to post comments, please make sure JavaScript and Cookies are enabled, and reload the page. Click here for instructions on how to enable JavaScript in your browser.
 







Search for:




  近期文章 

《合伙人：如何發掘高潛力人才》的企業人員聘用秘訣


《從 0 到 1》的 3 個創業關鍵學習


初心者也會用的 R 語言讀取 XML 資料分析實戰教學！(三)


初心者也會用的 R 語言讀取 XML 資料分析實戰教學！(二)


初心者也會用的 R 語言讀取 XML 資料分析實戰教學！(一)


重讀《經理人的一天》，與我在高階主管們身邊的日子(二)


重讀《經理人的一天》，與我在高階主管們身邊的日子(一)


統計R語言實作筆記系列 – 用 Shiny 套件極速打造你的商業智慧分析網站！


SEO 老兵不死的 Meta Tag 美學


資料玩家人人必備！ 5 分鐘快速部署你的第一支 R Shiny 互動式圖表網頁APP






大腦USB


標籤4P
ABC Model
ANOVA
ATCC
ATCC 心得
Attitude
Big 5
Big Five
BPMN
Breslow-Day-Test
Chi-squared-Test
CMH檢定
Cochran-Mantel-Haenszel Test
Contingency table
Data Mining
Data Transformation
Data Visualization
Design Thinking
DHL
Excel
Excel VBA
Factor Analysis
Fisher's exact test
Gamma
Generalized Linear Model
ggplot
GLM
How the mighty fall
Html
Just Noticeable Difference
Kano Model
Karl Pearson
KPI
Machine Learning
Mantel-Haenszel-Test
MBO
MBTI
MH檢定
Myers-Briggs Type Indicator
Normal Distribution
Peter Thiel
Positioning
Principal Component Analysis
P value
PZB Model
R. A. Fisher
reBuzz專欄
Regression
regular-expression
R語言
R軟體
Self-efficacy
Self-esteem
SEO
Service Oriented Architecture
Service Profit Chain
SERVQUAL
Shiny
SOA
Special Purpose Vehicle
STP
Succession Planning
text-analysis
TPB Model
TRA Model
Weber-Fechner Law
Wilcoxon Signed-Rank Test
XML
X理論
Yates Continuity Correction
Y理論
Zero to One
三維列聯表
三維表
中央極限定理
主成分分析
二維列聯表
二維表
人力資源
人格測驗
佛洛伊德
使用者研究
健保
共同勝算比
判定係數
創業
創業計畫書
動差估計法
勝算比
區間估計
卡方檢定
品牌命名
品茶實驗
品質缺口模式
哲學
商業計畫書
因素分析
塑化劑
大數法則
奇異值分解
定位
寡占
差異門檻
巴塞爾協定
常態分配
康德
廣義線性模型
從0到1
德州儀器
心理學
心理定錨
心理測驗
態度三元論
接班人計畫
搜尋引擎優化
文字分析
旺中事件
智財
最大概似估計法
最小平方法
服務人文體驗營
服務利潤鏈
服務創新
服務導向資訊系統架構
服務業
服務科學
服務藍圖
服務行銷
服務行銷與管理
服務設計
杜拉克
案例討論
條件勝算比
榮格
樣本數
機器學習
流程再造
流程管理
消費者行為
無母數統計
營運計畫書
特徵值
獨占
產業分析
百工的一天
目標管理
相關分析
知識工作者
符號等級檢定
管理學
精實創業
精神分析
系統動力學
絕對門檻
統計估計
統計學
經濟學
經理人的一天
綠色經濟
網路行銷
線性代數
總統大選
職場
自尊
自我感覺良好
自我效能
葉氏連續性校正
薪資
行銷3.0
行銷學
行銷組合
行銷賽局
衍生性金融商品
製造業
證所稅
變異數分析
貨幣乘數
費雪精確檢定
資料分析
資料探勘
資料處理
資料視覺化
資料轉換
資本適足率
賽局理論
超幾何分配
軟體開發
迴歸分析
邊際勝算比
金融海嘯
門檻心理學
隻字片語
雜學心得
面試
食品安全
點估計
 






Apache Tomcat (TomEE)/8.5.6 (7.0.2) - Error report HTTP Status 404 - /SPSS/IBMSPSSAdvancedStatistics.asptype Status reportmessage /SPSS/IBMSPSSAdvancedStatistics.aspdescription The requested resource is not available.Apache Tomcat (TomEE)/8.5.6 (7.0.2)
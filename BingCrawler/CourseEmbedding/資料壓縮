


資料壓縮 - 維基百科，自由的百科全書






























 







資料壓縮

維基百科，自由的百科全書


					前往：					導覽，					搜尋















在電腦科學和資訊理論中，資料壓縮或者源編碼是按照特定的編碼機制用比未經編碼少的資料位元（或者其它資訊相關的單位）表示資訊的過程。例如，如果我們將「compression」編碼為「comp」那麼這篇文章可以用較少的資料位表示。常見的例子是ZIP檔案格式，此格式不僅僅提供壓縮功能，還可作為歸檔工具（Archiver），能夠將許多檔案儲存到同一個檔案中。



目錄


1 概要
2 應用
3 理論
4 參見

4.1 資料壓縮專題
4.2 壓縮演算法

4.2.1 非破壞性資料壓縮
4.2.2 破壞性資料壓縮
4.2.3 實現例項




5 外部連結



概要[編輯]
對於任何形式的通訊來說，只有當資訊的傳送方和接受方都能夠理解編碼機制的時候壓縮資料通訊才能夠工作。例如，只有當接受方知道這篇文章需要用漢語字元解釋的時候這篇文章才有意義。同樣，只有當接受方知道編碼方法的時候他才能夠理解壓縮資料。
資料壓縮能夠實現是因為多數現實世界的資料都有統計冗餘。例如，字母「e」在英語中比字母「z」更加常用，字母「q」後面是「z」的可能性非常小。非破壞性資料壓縮通常利用了統計冗餘，這樣就能更加簡練地、但仍然是完整地表示傳送方的資料。
如果允許一定程度的保真度損失，那麼還可以實現進一步的壓縮。例如，人們看圖畫或者電視畫面的時候可能並不會註意到一些細節並不完善。同樣，兩個音訊錄音採樣序列可能聽起來一樣，但實際上並不完全一樣。破壞性資料壓縮在帶來微小差別的情況下使用較少的位數表示圖像、影片或者音訊。
然而，經常有一些檔案不能被破壞性資料壓縮壓縮，實際上對於不含可以辨別樣式的資料任何壓縮演算法都不能壓縮。另外，試圖壓縮已經經過壓縮的資料通常得到的結果實際上是增加資料。
實際上，破壞性資料壓縮也會最終達到不能工作的地步。例如一個極端的例子：壓縮演算法每次去掉檔案最後一個位元組，那麼經過這個演算法不斷的壓縮直至檔案變空，壓縮演算法將不能繼續工作。
由於可以幫助減少如硬碟空間與連線頻寬這樣的昂貴資源的消耗，所以壓縮非常重要，然而壓縮需要消耗資訊處理資源，這也可能是費用昂貴的。所以資料壓縮機制的設計需要在壓縮能力、失真度、所需計算資源以及其它需要考慮的不同因素之間進行折衷。
應用[編輯]
一種非常簡單的壓縮方法是行程長度編碼，這種方法使用資料及資料長度這樣簡單的編碼代替同樣的連續資料，這是非破壞性資料壓縮的一個例項。這種方法經常用於辦公電腦以更好地利用磁碟空間、或者更好地利用電腦網路中的頻寬。對於電子表格、文字、執行檔等這樣的符號資料來說，非破壞性是一個非常關鍵的要求，因為除了一些有限的情況，大多數情況下即使是一個資料位的變化都是無法接受的。
對於影片和音訊資料，只要不損失資料的重要部分一定程度的品質下降是可以接受的。通過利用人類感知系統的局限，能夠大幅度的節約儲存空間並且得到的結果品質與原始資料品質相比並沒有明顯的差別。這些破壞性資料壓縮方法通常需要在壓縮速度、壓縮資料大小以及品質損失這三者之間進行折衷。
破壞性圖像壓縮用於數位相機中，大幅度地提高了儲存能力，同時圖像品質幾乎沒有降低。用於DVD的破壞性MPEG-2編解碼影片壓縮也實現了類似的功能。
在破壞性音訊壓縮中，心理聲學的方法用來去除訊號中聽不見或者很難聽見的成分。人類語音的壓縮經常使用更加專業的技術，因此人們有時也將「語音壓縮」或者「語音編碼」作為一個獨立的研究領域與「音訊壓縮」區分開來。不同的音訊和語音壓縮標準都屬於音訊編解碼範疇。例如語音壓縮用於網際網路電話，而音訊壓縮被用於CD翻錄並且使用MP3播放器解碼。
理論[編輯]
壓縮的理論（它與演算法資訊理論密切相關）以及率失真理論，這個領域的研究工作主要是由美國學者克勞德·香農（Claude Elwood Shannon）奠定的，他在二十世紀四十年代末期及五十年代早期發表了這方面的基礎性的論文。Doyle和Carlson在2000年寫到資料壓縮「是所有的工程領域最簡單、最優美的設計理論之一」。密碼學與編碼理論也是密切相關的學科，資料壓縮的思想與統計推斷也有很深的淵源。
許多非破壞性資料壓縮系統都可以看作是四步模型，破壞性資料壓縮系統通常包含更多的步驟，例如它包括預測、頻率變換以及量化。
Lempel-Ziv（LZ）壓縮方法是最流行的非破壞性儲存演算法之一。DEFLATE是LZ的一個變體，它針對解壓速度與壓縮率進行了最佳化，雖然它的壓縮速度可能非常緩慢，PKZIP、gzip以及PNG都在使用DEFLATE。LZW（Lempel-Ziv-Welch）是Unisys的專利，直到2003年6月專利到期限，這種方法用於GIF圖像。另外值得一提的是LZR (LZ-Renau） 方法，它是Zip方法的基礎。LZ方法使用基於表格的壓縮模型，其中表格中的條目用重複的資料串替換。對於大多數的LZ方法來說，這個表格是從最初的輸入資料動態生成的。這個表格經常採用霍夫曼編碼維護（例如SHRI、LZX）。 目前一個效能良好基於LZ的編碼機制是LZX，它用於微軟公司的CAB格式。
最好的壓縮工具將機率模型預測結果用於算術編碼。算術編碼由芬蘭資訊理論學家Jorma Rissanen發明，並且由Witten、Neal以及Cleary將它轉變成一個實用的方法。這種方法能夠實現比眾人皆知的哈夫曼演算法更好的壓縮，並且它本身非常適合於自適應資料壓縮，自適應資料壓縮的預測與上下文密切相關。算術編碼已經用於二值圖像壓縮標準JBIG、文件壓縮標準DejaVu。文字輸入系統Dasher是一個逆算術編碼器。
參見[編輯]
資料壓縮專題[編輯]

柯氏複雜性
資訊熵
自解壓縮檔
圖像壓縮
語音壓縮
影片壓縮
多媒體壓縮
最小描述長度
最小訊息長度（two-part lossless compression designed for inference）

壓縮演算法[編輯]
非破壞性資料壓縮[編輯]

行程長度編碼
字典編碼

LZ77與LZ78
LZW


局部符合預測（也稱為PPM）
熵編碼

哈夫曼編碼：簡單的熵編碼，通常用於壓縮的最後一步
自適應哈夫曼編碼
算術編碼

區間編碼：與算術編碼一樣，但是用一種少許不同的方法工作


T-code：哈夫曼編碼的變體
Golomb coding：用於幾何分佈的無限輸入資料的簡單熵編碼


Slepian-Wolf編碼：非破壞性的分散式信源編碼

破壞性資料壓縮[編輯]

離散餘弦變換
分形壓縮（fractal compression）

分形變換（fractal transform）


小波壓縮
向量量化（vector quantization）
線性預測編碼
Wyner-Ziv編碼（破壞性的分散式信源編碼）

實現例項[編輯]

DEFLATE（LZ77與哈夫曼編碼的組合）– ZIP、gzip、zlib與PN]檔案在使用
LZMA：7-Zip與StuffitX使用
LZO（非常快速的LZ變體，針對速度要求）
Unix compress工具（.Z檔案格式）、以及GIF使用LZW
bzip2（Burrows-Wheeler變換與哈夫曼編碼的組合）
PAQ（一種基於context mixing的超高壓縮率的演算法，但是極度緩慢，是最高壓縮比競爭中的佼佼者。）


JPEG（使用離散餘弦變換、量化、哈夫曼編碼的圖像壓縮）
MPEG（廣泛使用的音訊及影片壓縮標準族，影片壓縮使用離散餘弦變換以及運動補償預測）
MP3（MPEG-1標準中用於聲音及音樂壓縮的部分，使用子帶、MDCT、感知模型、量化以及哈夫曼編碼）
WMA（WMV音訊編碼規範中的一部分，使用MDCT、感知模型、低位元率量化、量化以及哈夫曼編碼）
Vorbis（類似於AAC的基於DCT的音訊編解碼，為了避免專利問題而設計）
JPEG 2000（使用小波、量化、熵編碼的圖像壓縮）
TTA（使用線性預測編碼，用於非破壞性音訊壓縮）
FLAC（用於非破壞性音訊壓縮的線性預測編碼）

外部連結[編輯]

Data Compression Benchmarks and Tests
Data Compression - Systematisation by T.Strutz
Public domain article on data compression
How Compression Works
Ultimate Command Line Compressors
Compression Resources catalog（currently the biggest）
The Data Compression News Blog
Practical Compressor Test（Compares speed and efficiency for commonly used compression programs）
The Monthly Data Compression Newsletter
Compressed File Types and File Extensions
Compressed File Types and File Extensions









閱
論
編


資料壓縮方法






非破壞性資料壓縮





理論




熵
複雜性
資訊冗餘
破壞性資料壓縮









熵編碼法




香農-範諾編碼
Shannon–Fano–Elias
霍夫曼編碼（適應性霍夫曼編碼
範式霍夫曼編碼
改良型霍夫曼編碼）
算術編碼
區間編碼 · 格倫布編碼
指數格倫布編碼
統一編碼（以利亞伽瑪編碼
斐波那契編碼）









字典編碼




DEFLATE
LZ77 / LZ78（LZJB（英語：LZJB）
LZMA
LZO
LZSS
LZW
LZWL（英語：LZWL）
LZX
LZ4） · Snappy









其他




BWT
CTW（英語：CTW）
DMC
MTF
PAQ（英語：PAQ）
PPM（英語：Prediction_by_partial_matching）
RLE











音訊





理論




捲積
採樣
採樣定理









音訊編解碼器




LPC
WLPC（英語：WLPC）
CELP
ACELP（英語：ACELP）
A-law（英語：A-law）
μ-law（英語：μ-law）
MDCT
傅立葉變換
音響心理學









其他




動態範圍壓縮
語音編碼
子帶編碼











影像





理論




位元率
色彩空間
像素
色度抽樣
標準測試圖像
峰值信噪比
壓縮失真









方法




RLE
分形壓縮
小波壓縮
SPIHT（英語：Set partitioning in hierarchical trees）
DCT
K-L 轉換











視訊





理論




視訊特性
Frame（英語：Film frame）
視訊類型
視訊質量









視訊編解碼器




運動補償
DCT
量化









其他




率失真理論（CBR
ABR
VBR）












另見壓縮格式和資料壓縮軟體實作











權威控制



NDL: 00942229












 
						取自 "https://zh.wikipedia.org/w/index.php?title=數據壓縮&oldid=44122933"					
分類：數據壓縮 



導覽選單


個人工具

沒有登入對話貢獻建立帳號登入 



命名空間

條目
討論




台灣正體



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






查看

閱讀
編輯
檢視歷史



更多







搜尋



 







導航


首頁分類索引特色內容新聞動態近期變更隨機條目 



說明


說明維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



其他專案


維基共享資源 



列印/匯出


下載成 PDF 



工具


連結至此的頁面相關變更上傳檔案特殊頁面可列印版靜態連結頁面資訊維基數據 項目引用此頁面 



其他語言


AlemannischالعربيةAzərbaycancaБеларуская (тарашкевіца)‎БългарскиBosanskiCatalàکوردیČeštinaDanskDeutschΕλληνικάEnglishEspañolEestiEuskaraفارسیSuomiFrançaisGaeilgeעבריתहिन्दीHrvatskiMagyarՀայերենBahasa IndonesiaItaliano日本語Қазақша한국어КыргызчаLatinaLietuviųLatviešuBahasa MelayuNederlandsNorsk nynorskNorsk bokmålPolskiPortuguêsRomânăРусскийScotsSrpskohrvatski / српскохрватскиSimple EnglishSlovenčinaSvenskaไทยTürkçeУкраїнськаاردوTiếng Việt 
編輯連結 





 本頁面最後修訂於2017年4月25日 (週二) 06:15。
本站的全部文字在創用CC 姓名標示-相同方式分享 3.0 協議之條款下提供，附加條款亦可能應用（請參閱使用條款）。
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發人員
Cookie 聲明
手機版檢視



 

 






資料壓縮 data compression









資料來源: http://oz.nthu.edu.tw/~u911803/projectdata.htm
資料壓縮 data 
compression
　
Abstract
Introduction
Chapter 
one  The design procedure of Compression Methods
Chapter  
tow  modeling  &  coding
Chapter 
Three  The technology of lossless Compression － 
Quantization
Chapter 
four  影像壓縮格式概述
Chapter 
 five  視訊數位壓縮標準－MPEG家族
Reference
　
 

　
Abstract
    本文將對資料壓縮做一深入淺出的介紹，有關資料壓縮的用處及應用層面，並對時壓縮編碼的原理做簡單的認識。而對於目前各層面主流的壓縮規格，也將做全面性的介紹，內容將包括其規格及應用操作。
Introduction：
    科技資訊的發展將電腦帶入家庭，成為人類生活中視聽娛樂的一部份。但目前軟體設計的發展，一套比一套複雜，所需硬碟空間也越來越大，再加上影像(image)、視訊(Video)、聲音(audio)等資料的儲存需求也日益提升，在龐大的硬碟空間也有不敷使用的一天。再者，隨著數位科技的進步與網際網路的蓬勃發展，各種包含影像、聲音與視訊的多媒體應用技術不斷推陳出新。而由於多媒體資料的龐大，資料壓縮就顯得重要且無法避免。
    資料壓縮在提升傳輸效率的效果顯得格外顯著，譬如說，一張解析度為400×400 的彩色影像而言，其影像含有400×400 = 160K個像素(pixel)，每個像素由R(紅色)、G(綠色)和B(藍色)三個顏色所組成，而每一個顏色一般而言需要1byte(8個位元)來表示256種不同的色階，所以這張影像共需要400×400×8×3 = 
0.48Mega bytes的資料量。若以56Kbit/Sec的窄頻數據機傳輸約需70 秒左右。再者，如果要在網路上傳輸視訊資料其資料量就更為龐大了。一秒的視訊約包含30張連續的影像畫面，也就是說一秒需要0.48×30 = 14.4Mega bytes的資料量，就算以今日的寬頻傳輸也顯吃力。在資料壓縮後，不僅減少儲存空間，傳輸時間也是大大縮短。
    而在資料傳輸安全方面，由於資料完成壓縮後，已經經過運算處理，資料並非單純為原本的格式，必須經由解壓縮的操作才能復原，大大增加資訊的安全性。
GO 
BACK
Chapter 
one  The design procedure of Compression Methods：
    本章將讓讀者對於壓縮方法有個基本的概念，並將說明失真與無失真壓縮的異同；再來則描述實現資料壓縮的兩個主要步驟：模式化與編碼。
  資料壓縮系統：
    為達到資料壓縮的目的，通常我們必須找出存在原始資料間的相關特性，也就是存在原始資料間的資料累贅(data redundancy)。如果我們能找出這些累贅（或稱多餘資料），減少且移除這些累贅，就能達到資料壓縮的目的。
    一個壓縮方法的編碼效率(coding 
rate)或稱壓縮效率(compression ratio or rate, Cr)通常使用下列方式來評估：
Cr= (原始資料的大小 – 壓縮後的資料大小 / 原始資料大小) × 100 %
    而一般資料壓縮系統(data compression 
system)包含兩大部分：壓縮器(compressor)及解壓縮器(decompressor)。壓縮器主要的工作包含：(1)找出帶壓縮資料（或稱做原始資料或資料原，source 
data or original data）中存在的資料累贅(data 
redundancy)。(2)移除這些累贅。(3)將剩餘的必要資料編碼並送出編碼結果（或稱壓縮結果，compressed data）等動作。相反的，解壓縮器的主要工作則是將讀入的編碼結果依據既定的步驟解碼並送出解碼結果（或稱坐重建結果，decompressed data or reconstructed data）。
    圖一為一個資料壓縮系統的是意圖。壓縮器主要功能在於壓縮編碼，故有時也稱為編碼器(encoder)，壓縮過程也可稱為編碼(encoding or 
coding)；同樣的，解壓所器也稱做解碼器(decoder)，其過程亦可稱做解碼過程(decoding)過程。
　
圖一 
(1)
  
無失真與失真壓縮：
    
無失真壓縮( lossless 
compression)又稱做無損壓縮或是可逆壓縮(reversal compression)，由於重建結果和壓縮前的資料源完全相同，一般用於文字檔、執行檔、醫學影像和重要資料的壓縮上。為確保無失真，此類壓縮通常無法得到很好的壓縮率。設計一無失真的壓縮需考慮下列三因素：編碼效率（coding efficiency）、編碼延遲（coding 
delay）與編碼器複雜度（coder complexity）。編碼效率指的是壓縮效率，編碼延遲是指資料壓縮編碼所花費的時間，而編碼器複雜度則是指實現壓縮編碼演算法所需運算的複雜程度。當我們要求壓縮效率好一點時，通常編碼器複雜度與編碼延遲都會增加；相對的，如果希望編碼延遲端一點，通常效率會降低。如何在三者間找出一平衡點，而設計出一適合的要求的壓縮方法，是需要思考的。
    
失真壓縮又稱為有損壓縮或是不可逆壓縮（irreversal compression），即重建結果和壓縮前的資料源不完全相同（也就說會發生資料短少的現象）。當然，重建結果雖和原始資料不同，但原始資料的大部分資訊與特色仍包含在重建的結果當中。由於失真壓縮的壓縮效率遠高於無失真壓縮，故常用於需要高壓縮比且允許部分失真的影像壓縮（如JPEG和MPEG）與聲音壓縮(如MP3) 
，這部分後面將會有更為詳細的述說。當設計一個失真壓縮方法時，序要在下列四個因素中取得平衡：編碼效率、編碼延遲、編碼器複雜度與重建資料的品質(quality)。
  
資料壓縮過程：
    
一般而言，資料是由許多連續的符號(symbols)所組成而成，通常這些符號間必存在著某種關連性，也就是說存在許多所謂的資料累贅（data redundancy）。如果我們能找出這些累贅，解少且移除這些累贅，就能達到資料壓縮的目的。
    
資料壓縮的過程，主要包含兩步驟：編碼(coding)及模式化(modeling)。所謂模式化是指萃取出(extract)資料中的累贅，並且選擇一個適當的模式來描述這些累贅的動作過程。而編碼則是將所選擇的模式之描述(model description)及資料與模式間的差異（或稱誤差），加以編碼（通常編成二進制碼）的動作過程。這兩個步驟的好壞，影響整個系統的壓縮效率，換句話說，選擇好的模式與好的編碼法可確保高效率的壓縮。因此，要設計一個實用且高效率的資料壓縮方法，必須妥善選擇所採用的編碼及模式。下麵將對編碼及模式化做較詳細的介紹。
GO 
BACK
　
Chapter  
tow  modeling  &  coding：
    
所謂編碼，是指將資料中所有的字母或是符號一一編成相對應且唯一的二進位序列（binary sequences）。一般而言，編碼可區分成兩類：固定長度碼(fixed-length code)，如：ASCII碼；與變動長度碼（variable-length 
code），如：摩斯碼(Morse)與霍夫曼編碼 （Huffman coding）等。固定長度編碼雖可完整的代表每一個符號，但是通常沒有壓縮的功能。相反地，變動長度編碼通常會使用比固定長度編碼更少的位元數來代表整個資料，因此具有壓縮效果。
  
固定長度碼：
    
為了編碼個人電腦所需要的文數資料，一般採用美國國家標準資訊交換碼(American Standard Code for Information Interchange , 
ADCII)來表示資料。每個符號的ASCII碼都由七個位元組合而成，由於每個位元可為1或0，故可用來表示128種不同的符號字元。由於每一個符號資料都使用固定長度的字碼來表示，此種編碼方式稱為固定長度邊碼(fixed-length code)。舉例說明，A∼F以ASCII來表示如下：





符號

ASCII字碼 (7 
  bits)


A

1000001(65)


B

1000010(66)


C

1000011(67)


D

1000100(68)


E

1000101(69)


F

1000110(70)
 
  變動長度碼：
    如果有一種編碼方式是用不同長度的字碼來編碼符號資料，就稱為變動長度編碼（variable-length coding, VLD）。有一些常用的變動長度編碼方法是將資料中出線機率較低之符號以較長位元的自碼來編碼；而出線機率較高之符號則是用較短位元的自碼來編碼，藉由這樣的編碼方式，可在編碼的同時也達到資料壓縮的目的。
    一般編碼系統的基本要求必須符合所謂的「單一可解碼」(uniquely decodable code)，也就是解碼端把收到的壓縮結果分析後，只會有唯一的一種解釋，即為一的解碼結果。從下麵的範例種可以明顯區分其中的差別。
    
現在有一串序列其內容為：wxxyz，試考慮不同的編碼方式將此序列編碼：
  編碼方式A（code 
- A）：




符號(symbol)

w

x

y

z


字碼(codeword)

1

0

1

01
    根據Code-A 的編碼方式，此序列wxxyz被編碼成100101，只需要6個位元，但是這種編碼方式有一嚴重的缺點，因為w與y的編碼字碼完全相同，所以解碼端無法判定何者才是正確的輸入資列。解碼端收到100101後，可解碼成wxxyz，也可解碼成yxxyz，甚至解碼成wxxwz，根本無法確定何者為正確且唯一的答案，所以Code-A不為唯一可解碼。
  編碼方式B（Code 
- B）：




符號(symbol)

w

x

y

z


字碼(codeword)

01

0

001

000
    根據Code-B的編碼方式，此序列wxxyz被編碼成0111001000，共需要十個位元。明顯的，這種編碼方式以解決上述的問題，因為解碼端收到0111001000後，只能解碼成唯一的答案wxxyz，所以Code-B為唯一可解碼。
  編碼方式C（Code-C）：




符號(symbol)

w

x

y

z


字碼(codeword)

10

1

100

1000
    根據Code-C 的編碼，此序列wxxyz被編碼成10111001000，需要11個位元。這種編碼方式在解碼端收到編碼後，一開始收到前2個位元10仍無法決定是w、y或是z，必須再多看一個位元，發現下一個位元是1，此時才能確定前面解出的是w，同樣地，之後的編碼也需向下多看一個位元才可以確定解碼結果。雖然此種解碼結果可解出唯一的答案wxxyz，但它在解碼時常需要向下多看一個或數個位元，故此種編碼方式稱做非及時可解碼方式。而相對地，Code-B的解碼過程是一種即時可解碼（instantaneous 
decodable code）。
    一個編碼系統一定要符合唯一可解碼的特性，不然編碼後無法解回，讓資料流失。至於即時可解碼的特性，則就不一定需要。
 
    
模式可視為是「一個用來代表資料符號間相關聯性（即資料累贅）的表示式」。一個好的模式比一個不好的模式更能貼切的表示出資料間的關係，因此資料原與好的模式間的差異就會較小，模式化後緊接的編碼動作就能達到較好的編碼壓縮效率。下麵的範例將詳細說明模式好壞對壓縮效率的影響。
假設有一串序列「s1、s2、s3、…….、s12」如下所示
6 8 8 8 10 12 12 13 15 16 
17 18 現在常適用二進制編碼此序列
    
此序列最大樣本值為18，因此若使用固定長度編碼，我們必須以5個位元來編碼每一輸入樣本（5個位元可以表示的值從0到31），故共需使用60bits來編碼此含有12個樣本的序列。
    
然而，若要加入壓縮概念，我們則分別實現模式化與編碼兩動作。
  Modeling：
    
假設我們選用如下的A模式來表示此序列資料：
  n= 1,2,3,4,…,12
    
則可以得初以此A模式所建立的序列如下：
6 7 8 9 10 11 12 13 14 15 16 17
    而模式A與原始序列間的誤差序列（）為：
0 1 0 -1 0 1 0 0 1 1 1 1 
    由於誤差序列的值只有「-1,0,1」三種可能，我們只需要2bits就可以編碼此誤差序列。
  Coding：
    
編碼是把模式的描述及待壓縮資料與模式間的差異加以編碼的過程，因此編碼次序列後所產生的資料量就包含表示A模式所需參數的位元數及待表誤差序列的2×12=24個位元。
    
然而，假設我們選用如下的模式B來表示此序列資料：
  n=1,2,3,…,12
    
其中Integer(x)代表取x的整數值。則可得出以此B模式所建立的序列如下：
7 8 9 9 10 11 11 12 13 13 14 15
    
而B模式與原序列的誤差序列為：-1 0 -1 -1 0 1 1 
1 2 3 3 3
    
由於此誤差序列的值有「-1,0,1,2,3」五種可能，我們需要3bits來編碼此誤差序列，因此B模式的壓縮效率會比A模式差（因為要表示B模式誤差序列所需的位元數較多）。也就是說，模式比B模式更適合來代表此範例的輸入序列，故採用A模式設計出的壓縮方法壓縮效率較好。
    
為建立好的模式以提高壓縮效率，我們必須找出存在於待處理資料間的一些數學關係，再將這些數學特性以一個適當的數學模式來表示，下麵是幾個建立數學模式的方法：
  
實質模式
    
如果我們知道那些資料或是事件的物理實質特性（physics，即是資料間真正的關聯性）時，就可以依據獲得的特性資訊來建立一個正確的模式，稱為實質模式（physical model）。例如，當我們瞭解語音產生的物理特性時，就可以建構一個適當的數學模式來對語音作取樣並進行編碼。而大部分資料間的物理特性相當複雜，我們幾乎不可能它們研究清楚而以數學式子明確而完整的表示。而遇到如此複雜的問題時，我們只能憑藉經驗去觀察懂記資料藉以建構最合適的模式。
  
機率模式：
  
  最簡單的機率模式(probability model)是假設帶處理資料中的每個字母是獨立出現（任何字母出現和其他字母無關），而且每個字母出線的機率是一樣的。但由於這種機率模式的假設通常和現實經驗中不合，因此甚少被採用。
    
最常被使用的機率模式是假設待處理資料中的每個字母是獨立出現，但是每個字母出現的機率是不一樣的，是依據該字母在資料中出現的機率來決定的。當決定好使用的機率模式後，我們可選擇適當的編碼方法來編碼輸入資料。
    
然而，若是待壓縮資料間存在某種相關聯性，及字母間是有某種相依關係（dependent），而非彼此獨力出現的，則可以使用下麵介紹的馬卡夫模式(Markov Models)來得到更好的機率估計。
  
馬可夫模式(Markov 
Models)
    
馬可夫模式一般是應用於資料間存在有關聯性的時候，我們藉由分析前面出現過的資料來獲取一些資訊，這些資訊可用來幫助我們瞭解將來資料可能具備的特興。當此模式應用在壓縮技術時，通常使用一種稱為離散時間馬可夫鏈(discrete time Markov chain)的模式。在說明前，在此先定義所謂的P(a | 
b)代表的是英文字母b出現後，下個字母為a 的機率（或是前一個字母為b，而目前字母為a 的機率）。由此定義，一個i階的馬可夫模式可表示如下：

    
上式說明當知道前面i個符號所獲得的資訊（所決定出的機率）相當於知道過去全部出現過的符號所獲得的資訊。其中可稱為狀態(states)。也就是說，前面所描述的機率模式，可視為一種0階的馬可夫模式，溫為每個字母符號是獨立的，以前出現過什麼符號並不會提供任何有利的資訊讓你知道下一個符號為何。
    
假設來源字母集合(source 
alphabet)中有j個符號，若使用i階的馬可夫模式，則此時就會有 個狀態。也就是說，當馬可夫模式的階數越高，狀態將越多，模式的運算過程也就越複雜，各通常我們只是用一階或是二階的馬可夫模式。一階馬可夫模式可表示為：

    
而二階馬可夫模式可表示為：

    
我們可以從下麵的說明中瞭解到0階與1階馬可夫模式的異同。設想若要編碼一段英文文章，必須先計算每一字母出現的機率。假設目前計算的是’x’這個字母出現的機率，若使用0階馬可夫模式統計文章後發現p(x)=0.02。但是若使用1 階馬可夫模式，而前一個字母是e，我們可以確定的是，x出現的機率（即p(x|e)）應該很大，因為許多單字是以ex所起頭的，此時x出現的機率可能高達0.6；但若是前一個字母是y，其機率可能極為渺小，因為但字以yx 
起頭的相當稀少，p(x|y)可能為0。由上面說明可明白，一階馬可夫模式有考量前一齣現字母對目前字母影響，各能得到比0階更正確的機率估計，因此也較易得到好的編碼壓縮效果。
  
混合模式(Mixed 
Model)：
    
多數資料是由數個訊號所混合而成，因此在許多的應用場合中，要使用單一模式來描述資料的特性並不容易。遇到這種情況，我們必須分析資料並將其分成數個訊號，依照其特性分別建立所需的模式，使用時再根據當時的資料處理情形，動態地選擇所需的模式，當然此模式所需的計算與儲存成本也就相對提高。
    

    
要發展一個高效率的無失真或是失真壓縮方法都不事件容易的是，必須先選擇一個適合自己需求的模式，在輔以一個適當的編碼方法。較重要且基本的無失真壓縮方法如：霍夫曼編碼法(Huffman coding)、算數編碼法(arithmetic coding 
method)和字典編碼法(dictionary coding method)。在此就不多深入的介紹，對其模式和編碼方式有興趣讀者可參考本篇的參考書目(1)。
GO 
BACK
 
Chapter 
Three  The technology of lossless Compression － Quantization：
    
下麵所要談到的是有關於失真壓縮方法的介紹。在講到其方法前，先要談到評估失真壓縮效能的度量標準。失真壓縮時，主要的考量除了較高的壓縮效率外，還需要考慮到訊號失真程度的大小。由於失真壓縮能達到比無失真壓縮高出數倍甚至數十倍的壓縮效率，目前影像與聲音訊號大都是採用失真壓縮法訪來編碼。
    
一般而言，要評估一個失真壓縮方法所產生的重建訊號之失真程度，可使用下麵三種方法：
一、由人類的經驗盼但。即由一群所謂的專家，來對原始的影像或語音訊號作深入分析，並評估出重建訊號和原始訊號的失真程度。
二、用一些數學模式連坐失真程度的評估，是較科學的作法。
三、綜合上面兩種方式，用數學模式來表示人類的之學，並將原始訊號及重建後的訊號轉換到此知覺空間上，並在知覺空間上評估訊號的誤差。例如，在人類視覺系統中，因為人類的眼睛對於高頻信號的變化不太敏感，而對低頻部分較為敏銳，故眼睛可唯一中空間中的低頻濾波器。
目前多使用數學式子來評估失真程度，其大小一般使用下麵四種方式來定義：
1.      
平均絕對值誤差（mean absolute error），e :
2.      
平均平方誤差（mean squared error，MSE），
3.      
訊號雜訊比（signal-to-noise ratio，SNR）：
4.      
尖峰信號雜訊比（peak-signal-to-noise ratio，PSNR）：
詳細的數學式子讀者可自行參考相關書籍，但要註意的是，雖然以數學式子可以表現出重建訊號和原始訊號間的誤差比例，但呈現在人類的感官卻就不一定如計算所示。因為人類的知覺系統有其特性，數學式子無法反映出人類知覺系統中的特性，因此一個壓縮方法的好壞，仍應取決於使用者的認知，而數學式子，可作為一評比的參考數據。
  
Quantization：
    
量化是一中簡單且被廣泛使用的失真壓縮技術。量化就是將一個包含很多可能值的集合用一個較少個值的集合來表示的過程。也就是說，原始資料的集合中可能包含很多甚至無限個不同的值，而用來量化並代表原始資料的新集合則通常只包含無限且少數個值。在大部分的失真壓縮相關應用中，如聲音和影像，我們經常需要將資料源的所有可能值用有限數目的字碼來表示，因此量化的動作勢必要且不可避免的。
    
譬如說，資料源的內容包含1~10間所有可能的數值，很明顯的，這是一個無限集合，因為1~10 
之間的可能小數共有無限多個。我們希望量化後的只有十個可能值，則可建立一個班含10個數的有限集合如{1,2,3,…,10}。在一般電腦的應用中，我們習慣使用二進制碼，故此集合可表示成{0001,0010,0011,…,1010}。將1 到 10 切分成十個區間，當輸入值是0到1的任何數時用字碼0001來代表；輸入值是2到3 間的任何數時用字碼0011來代表，依此類推，所有輸入值都能對應到這10個字碼中的一個，這個將無限多個數值對應到有限個數值的過程便稱之為量化。當然，我們無法從10個字馬來推導出原始資料的真正值，只能夠知道該值所在的區間，因此我們一定會遺失一些資訊，故量化使一種失真編碼(lossy coding)。
    
在量化的過程中，資料的輸入可能為數值（scalars）也可能是向量（vectors），當要量化的輸入資料為數值時，我們稱之為「數值量化」(scalar quantization)，反之，當要量化的輸入資料為向量時，我們就稱之為「向量量化」(vector quantization)。
    
負責執行數值量化動作的物件稱為數值量化器，一個完整的數值量化器包含兩個部分：實現編碼映對(encoding mapping)的數值量化編碼器與實現解碼映對(decoding 
mapping)的數值量化解碼器。 
    
數值量化編碼器(Encoder)的功用是將資料源所有可能的數值範圍(range)分割成數目有限的區間，並將每一區間用一個唯一的字碼來表示。每輸入一個要量化的數值，編碼器就會找出此數值被歸類的區間，並送出相對於此區間的字碼，如此一來便完成了數值量化的編碼工作。
    
量化時，若共要分割成個區間，則編碼這N個區間所需要字碼的位元數為「」，也就是說，編碼器會將每個輸入值用個位元的字碼來表示。一個普通的ADC轉換器(analog-to-digital 
converter)，可視為標準的數值量化編碼器。
    
數值量化解碼器(Decoder)的功用是針對每一個數值量化編碼器送來的字碼，產生相對應的重建值(reconstruction value)，也就說，產生一個最能表示原始輸入所在區間的數值，並將此值送出便完成了數量化解碼的動作。由於重建值並無法真正代表該區間的所有可能值，故解碼後無法得回真正輸入值，只能盡量將誤差減到最少，因此量化的過程一定會有失真產生。一個標準的DAC轉換器(digital-to-analog converter)，可視為標準的數值量化解碼器。
    
向量量化(vector 
quantization, VQ)是採用每輸入一個向量（一串的數值或是一群數值為一個向量），才量化一次的方式。它是一種有效且重要的壓縮技術，可達到極高的壓縮效率，也因此被廣泛地使用在許多不同的場合，如：多媒體系統、高畫質電視、電傳系統、影像資料庫管理(image data base management)..等。而向量量化編解碼的大致步驟如下：
  
向量量化編碼演算法：
    
假設輸入資料包含個向量且編碼簿包含個碼向量：
Step 1：將輸入資料分割成一個個的向量（每個向量由L個數值組成）並令i=1（代表正處理第一個輸入向量）。
Step 2：將輸入向量和系統編碼簿(codebook)中所有的碼向量(codevector)一一比較，找出最接近輸入向量的碼向量(the best-matched codevector)，其中。
Step 3：將碼向量的索引值(index)m當成量化結果送出。
Step 4：i = i+1；重複步驟二到三，直到所有的輸入向量都被處理完畢(即)才結束。  圖二是量化編碼過程的示意圖

圖二  
(1)
為區別個碼向量，索引直的位元數至少為「」位元。假使輸入向量個數值中，每個數值由B個位元所組成，則所謂向量量化就是將原先需要L×B個位元輸入資料量用「」個位元來表示，故其壓縮效率為：

  
向量量化解碼演算法：
Step1：依據索引值m找出編碼簿中相對應的碼向量（稱為查表動作），此時就是所謂量化後重建向量。要註意的是，為確保正確解碼。需要使用和編碼端一模一樣編碼簿。
Step：重複步驟一，直到所有索引值都被處理完畢，那些全部重建向量的集合就是量化重建結果。
    
有很多重要的影像壓縮技術( 
例如JPEG) 
都應用到VQ 
的基本觀念；VQ 
是學術界最廣被用來研究影像壓縮的重要格式。傳統VQ 的基本作法首先將壓縮的影像分割成許多大小相同的小方格。例如一張512 × 512 點的影像，我們通常會將它分割成128 
×128 個4 ×4 點的小方格。按著查詢事先完成的編碼書(Code book) 
，找出跟每一個影像方格最接近( 
即最相似) 
的編碼字(Code word) 
。然後，再利用這些最接近的編碼字之索引值，組成一張索引表，如此即完成影像的壓縮。這張索引表即是VQ 壓縮後的結果，因為索引表的體積通常會比原影像小方格的體積小很多，故VQ 能有很好的壓縮效果。以一本含有256 個編碼字的編碼書而言，VQ 的壓縮率通常是十六分之一( 約6%) 
。至於影像還原，由於VQ 
解碼器可以利用壓縮後的索引表找出每個影像小方格的最相似編碼字，故可還原出原始影像來。雖然還原的原始影像與真正的原始影像並非完全相同，但必定十分相似。一般而言，VQ 的影像品質決定於編碼書內編碼字的數量之多寡及代表性之優劣。
    
上述是基本的向量量化過程，但主要仍有兩個問題要解決，其一是如何產生適宜的編碼簿，再來是如何決定最接近的碼向量。這兩者都需要設計者的巧思和創意了，在此就不對其做更深入的介紹。
 
    
在介紹完基本的資料壓縮編碼方式後，下麵所要介紹的是現今主流的壓縮檔案格式，他們的規格和編碼都相當的複雜，因此下麵只就其特色和規格應用作一概略性的介紹。
GO 
BACK
Chapter 
four  影像壓縮格式概述：
    
目前影像壓縮的方法有很多種，這些方法基本上可以分為「無失真」及「有失真」兩類。例如我們常見的PCX 、GIF 、TIFF 、及TGA 等格式就是屬於無失真的影像壓縮格式。它們利用傳統檔案的壓縮原理及技術來處理影像壓縮，所以壓縮前的原始影像與壓縮後還原的結果絲毫不差。至於VQ(Vector Quantization) 及JPEG(Joint Photographic 
Coding Expert Group) 等則是屬於有失真的影像壓縮格式。影像資料如經VQ 
及JPEG 
等壓縮法處理過，還原後的影像資料會和原始影像十分接近，其間雖然會有少許的差距，但是這些差距都應在人類肉眼所接受的誤差範圍之內。 
  TIFF：
    
TIFF 是Tagged 
Image File Format 的縮寫，也是一個非常重要的影像壓縮格式。它的第一個版本是由 
Aldus Corporation 的Aldus Developers 於1986 年所公佈的。它利用標籤(Tag) 為其組成的基本架構，具有極大的擴充性。至今，它仍被大量而廣泛的應用在各個工作平臺上，例如MS Windows、Unix、OS/2等等，支援相當廣泛。而它也提供各式不同的壓縮策略，如藍波- 
立夫- 衛曲 編碼法、霍夫曼編碼法(Huffman's 
Encoding)及變動長度編碼法等，根據不同的需要，可自行選擇適當的編碼方式。此外，TIFF能夠處理的色彩相當廣泛，單色、灰階或是全彩的處理都相當傑出。但在要求更佳壓縮效率的條件下，TIFF格式顯得相對較為笨重，而被其他格式所取代。但無論如何，他在影像壓縮中仍佔有一席之地。
  GIF：
    
是1987年由Compu-serve 所提出的影像壓縮格式，所使用的壓縮方法是「藍波- 
立夫- 衛曲編碼法」，又可稱為「字串表(String Table) 
壓縮法」。其基本的原理是將原始影像資料中重複的字串編成一個表，然後再利用表上的索引值來取代原始影像資料中的字串，由於索引值的體積遠比原始影像中的字串體積來的小，故GIF 能影像有壓縮的效果。但GIF在處理影像的編輯方面，由於其編碼的限制，只能處理256 
色以下的影像，所以在使用上有其限制。如果是在網路上色彩數較少的圖片、logo等可利用GIF來壓縮影像，但是如果是屬於連續色彩的圖片的話，就無法適用於此項壓縮格式。
  JPEG (Joint 
Photographic Coding Expert Group)：
    
JPEG 由國際標準組織(International Organization for Standardization ，簡稱ISO) 和國際電話電報諮詢委員會(International 
Telegraph and Telephone Consultative Committee ，簡稱CCITT) 所建立的一個數位影像壓縮標準，主要是用於靜態影像壓縮方面。JPEC 採用可失真(Lossy) 編碼法的概念，利用數位餘弦轉換法(Discrete 
Cosine Transform，簡稱DCT) 將影像資料中較不重要的部份去除，僅保留重要的資訊，以達到高壓縮率的目的。雖然被JPEC 處理後的影像會有失真的現象，但由於JPEG 
的失真比例可以利用參數來加以控制；一般而言，當壓縮率在5% ∼15% 之間時，JPEC 依然能保証其適當的影像品質，這是一般無失真壓縮法所作不到的。
    
下麵藉由四張圖片的比較，讓我們進一步瞭解影像壓縮格式間的差異。首先原圖是一張未經壓縮的BMP圖形，大小高達1.12MB，但是經過JPE壓縮後，在不同的品質要求下，個別呈現不同的顯示成果與壓縮效率。但在我們一般可以接受的範圍內，圖片經由壓縮編碼後可縮小至一百KB左右，讓我們見識到JPEG壓縮編碼的強大效用。
 
原圖（BMP 1.12MB）        
            JPEG (100%)  347KB
 
JPEG 
(70%) 63.8KB         
              
 JPEG (10%) 14.9KB
GO 
BACK
Chapter 
five  視訊數位壓縮標準－MPEG家族：
    
動畫專家群(Moving 
Picture Expert Group，簡稱 MPEG)的首次會議於1988年五月所召開，當時出席此單獨一個會期的人員計有25人。時至今日，出席MPEG相關會議的人數以多達300人左右。MPEG的教父記催生者Leonardo Chiariglione認為，造成MPEG如此成功的因素固然不少，但最重要的是其出現的時機，所謂時勢造英雄。MPEG出現的時機，正好是音訊及視訊信號的編碼演算法性能已攀登至接近最高峰，此外，數位信號處理晶片的處理能裡也已達能夠應付複雜演算法所需之計算的地步。
    
時至今日，MPEG不但是國際性的標準，也一應用範疇的不同而發展出一個族系(Family)，意即我們所熟知的MPEG-1、MPEG-2、MPEG-4以及MPEG-7。例如：美國高等電視系統(ATV)的大聯盟(GA)所提出的新一代高畫質電視系統(High-definition television，簡稱做HDTV)標準中，其視訊壓縮即採用國際標準的MPEG-2，不過有意思的是，音訊信號的壓縮卻採用杜比實驗室(Dolby 
Labs)所發展的AC-3數位音訊壓縮技術，而非採用MPEG-2 Audio。
  
MPEG-1：
    
這是目前VCD光碟所採用的格式，每秒可傳送三十個圖框(Frame)。通常是一片650MB的光碟可儲存74分鐘長度的影片，解析度是352×240(NTSC模式)，傳送速度為1.5Mbps。MPEG-1可說是MPEG系列的長子，它的出現向世人證實以低至1.5Mbps左右的位元速率將動態影像與音訊同時儲存於今日的Compact 
Disc尚且達到相當於VHS的畫質是可能的。而它同時也是第一個將視訊與音訊整合在一起進行編碼的標準。VCD的市場在今日可算是相當的成功。
    
而另一方面，MPEG-的音訊部分，已經成為數位音訊廣播實現「CD品質的無線電廣播」的核心技術。而對於網際網路而言，MPEG-1標準的音訊第二層和第三層，也已經成為其播送音樂的標準形式。如時下流行的MP3，實際上就是MPEG-Layer3 的簡稱。它利用人類聽覺能力分辨的聲波有一定範圍的特性，高於或低於這個範圍，人耳便無法分辨，於是只取人耳可以接受的部分，以減少資料量。它可以將聲音資料壓縮至原來CD音樂檔案容量的十二分之一，傳送速度56~64Kbps，且保持人耳幾乎無法辨識的失真率，音質上相當接近於一般的CD，這也就是MP3之所以盛行的原因。
  
MPEG-2：
    
原本是專為有線電視和HDTV制訂的標準，也是當前DVD所採用的格式，其解析度可從352×288到1920×1152不等，但一般以720×486(DVD的解析度)為主，每秒可傳送60個圖框，傳送速度3~10Mbps。但是，MPEG-2的應用不局限於陸地播送、衛星播送或是有線電纜網路的播送而已。它的應用範疇同時涵蓋透過電信號網路的互動電視(Interactive Television) 等應用在內。
  
MPEG-4：
    
1999年制訂完成的MPEG-4是MPEG專家群針對電信、電腦和電視/影的整合，制訂出真會多媒體應用與多用途環境的音訊編碼標準。MPEG-4在一開始是朝向制訂極低位元率的視訊影像壓縮標準而努力，但是制訂完成後可向上支援到4 Mbits/sec。以每畫面176×144 像素的視訊資料而言，MPEG-4所產生的低位元率可以達到4800~64Kbits/sec。MPEG-4將使用在廣播、互動是與對話的環境，其傳輸方式可以是 
cable TV或Web。MPEG-4技術是建構在MPEG-1和MPEG-2固有的技術上，額外再加上以下幾個特點：
1.      
整合自然影像與合成物件，以物件(objects)的方式成陷於視訊資料中(object content 
information，OCI)。
2.      
 提供2D與3D的物件於視訊資料中。
3.      
提供數種互動式的模式。
4.      
提供壓縮率由極低位元率(2Kbits/sec for speech)到極高位元率的傳輸速率(5Mbits/sec for 
transparent quality for video)。
5.      
智慧財產的管理與保障（intellectual property management and protection ， IPMP）。
  而和MPEG-1 和 MPEG-2不同的是，除了沿用比對前後畫面差異的方式，另外還將畫面中的背景、物體、聲音等各個元素化分成一個個的物件，在依據各個物件不同的屬性採取不同的壓縮方式，如果固定不變的物件就只傳送一次。解碼時，Encoder先將收到的資料衣物見各個不同的屬性分開，按各自的格式解碼，再予以組合還原。
    
例如就物件的區分而言，但是聲音就可以細分為自然音、語音、合成音效等；影像又可細分成自然物、2D、3D影像、背景、人物面部表情等。區分這些不同的物件後，就可以根據物件特性選擇最佳的壓縮格式。像國外網站俗稱的”DivX”是將Video以MPEG-4格式壓縮，Audio部分則以MP3壓縮，組合而成AVI影片，目的是為了將DVD影片轉成一般電腦都可播放的AVI檔。
    
不過也正因為MPEG-4具有多重組合的靈活性，相對的也增加技術上的難度和複雜度，如果要達到低失真率、高壓縮比的壓縮效果，影音處理人員勢必要經過多方摸索和磨練，累積一定程度的經驗之後才能靈活運用。
GO 
BACK
Conclusion：
    
資料壓縮發展至今，涉及的層面早已不單單只是說找尋資料瘦身、壓縮的方法。在考慮科技與人類的視野下，壓縮的概念不斷並加入新的創意與技術；向人類的影音編碼壓縮，透過人類視覺與聽覺系統的研究，逐漸發展出人類所能接受的失真壓縮法，大幅提昇壓縮效率。或許訊號的雜訊比不佳，但別忘了，科技是為服務人類了創造的，只要人類能夠享受同價值的視聽效果，科學的比較也只是屬於參考價值。因此，未來透過進一步的人體相關知覺的研究，在處理資訊方面，尤其是多媒體科技，仍有可預見的遠景。
此外，在整個科技的架構下，資料壓縮在儲存、多媒體傳輸、多媒體通訊等人類生活的總總都有著資料壓縮的貢獻。它不僅僅是將資料縮小，更是一種溝通的介面模式。經由編碼系統的發展，量化概念的創新，如何追求品質和容量的平衡？是每個研究者所努力的目標。資料壓縮早已跳脫其所被賦予的任務，而建構起溝通科技與訊息的橋樑標準。而未來將是怎樣的標準主宰市場？沒有人能夠肯定地回答。編解碼技術的發展固然是因素之一，但消費者的接受程度，才是真正主導市場標準的依據。消費者的選擇，才是真正標準的主宰力量。
而資料壓縮在未來發展，仍是擁有多方面的探索領域，其方向不僅僅是追求更高效率的壓縮編碼技術，還有編解碼的速度及應用在網路多媒體傳輸時的種種問題。向當使用寬頻傳輸影像視訊等多媒體時，所考慮的不僅是壓縮的速率，更要設法使編解碼的速度能夠跟上視訊處理的需求，否則使用者仍然無法享受到立即的影音享受。當然這僅僅是其眾多領域中的一個，但在可見的未來，資料壓縮和網路多媒體的傳輸必然息息相關。
GO 
BACK 
Reference：
1.      
資料壓縮概論 陳培殷  滄海書局  2001年
2.      
視訊技術原理－視訊信號的數位處理  林常平 電子技術 1998年8月     pp 
256~261
3.      
視訊技術原理－視訊信號的數位處理  林常平 電子技術 1998年9月     pp 
249~253
4.      
數位音訊編解碼 謝勳璋  電腦與通訊 第三十期 1994.5 pp 2~12
5.      
數位影音壓縮技術ABC  徐偉翰  廣電人  pp 54~55
 































[SQL]斯斯有三種，SQL Server 上資料庫的「壓縮」也有三種喔 ! | 五餅二魚工作室 - 點部落






























五餅二魚工作室
James Fu 的技術學習之路










2014-02-23
   

[SQL]斯斯有三種，SQL Server 上資料庫的「壓縮」也有三種喔 !

25373


0

資料庫管理經驗分享


檢舉文章





[SQL]斯斯有三種，SQL Server 上資料庫的「壓縮」也有三種喔 !


之所以會想要寫這篇，主要是因為個人的工作主要是做技術服務，有些時候會跟一些客戶的 MIS 解釋和說明一些資料庫的問題，但時常會遇到大家所說的資料庫「壓縮」，都是代表的不同的意思，而造成雞同鴨講的狀況，因此想說用點時間，把 SQL Server 內所謂的「壓縮」給整理一下，避免有朋友因為誤會造成困擾。

 

基本上 「資料庫壓縮」( Shrink Database )、「備份壓縮」(Backup Compression) 和「資料壓縮」(Data Compression) 只是剛好中文翻譯上都有「壓縮」的字眼，也因此大家都時常都簡稱叫做壓縮，但這三種分別是不同的意思，也不是所有版本都可以支援的喔。


「Shrink Database」是用來釋放沒有儲存資料的資料檔或交易紀錄檔，比方說現在資料庫內有些 TABLE 內的資料我們不再需要使用，當我們使用 DELETE 或者是 TRUNCATE TABLE 將資料刪除之後，如果資料庫選項是採用預設的不自動壓縮的話，則原本資料所占用的空間並不會自動釋放出來，而會留著當後續資料庫內有需要使用這些資料 Page 的時候，就可以直接取用。但有時因為一些原因我們在大量的刪除資料之後，希望資料庫釋放未使用的空間，則可以配合 DBCC SHRINKDATABASE 或是 DBCC SHRINKFILE 來壓縮資料庫或檔案。







如上面的圖所示，您可以使用下指令或者是 GUI 介面上的操作來執行，而這樣的功能所有 SQL Server 的版本都有提供，不限制在哪個 SQL Server 的版本。

 


「Backup Compression」備份壓縮是用來縮減備份時所占用的空間，其最早是出現在 SQL Server 2008 Enterprise 的版本，但在 SQL Server 2008 Standard Service Pack 1 之後的版本也都開始支援備份壓縮。雖然 SQL Server Express 不支援備份壓縮，但在 Standard 或 Enterprise 版本上建立的備份壓縮，依然可以在 Express 版本上進行還原。由於備份壓縮是在資料庫進行備份的時候才會有影響，因此不論有沒有進行資料庫壓縮，對於一般資料庫上面的所有資料處理，都不會有任何的影響。而在備份的時候由於備份壓縮通常只需要比原本沒有設定壓縮時更少的 I/O 處理，因此可以大幅提升備份速度和減少儲存空間，但相對的是在進行時會大幅增加 CPU 使用量，這點要稍微註意一下。

 

在 SQL Server 2008/2012 的版本中，我們可以使用 SSMS 下更改「伺服器屬性」→「資料庫設定」→「壓縮備份」的設定值，決定當使用 Backup 指令的時候，預設情況下備份資料庫時是否要採用壓縮的方式來進行。



或者是在備份資料庫的時候才決定是否要採用備份壓縮。



 

至於要怎麼查看備份檔是否是採用備份壓縮呢 ? 這個部分可以透過 RESTORE HEADERONLY 的指令，就可以透過 Compressed 的欄位知道該備份檔是否有壓縮。




「Data Compression」資料壓縮主要是拿來壓縮資料存放時所占用的空間，是 SQL Server 2008 Enterprise 開始提供的，目前該功能只允許在 Enterprise 以上的版本才可以使用，SQL Server 支援資料表和索引的「資料列壓縮」與「頁面壓縮」兩種壓縮模式。 當我們在資料庫內採用資料壓縮時除了節省空間之外，資料壓縮也有助於改善 I/O 密集型工作負載的效能，因為資料會儲存在更少的頁面中，而且查詢需要從磁碟讀取的頁面也變少了。雖然設定好之後就可以使用，相關使用的 SQL 指令也不需要做任何的變更或調整，但與備份壓縮相同，資料在讀取和寫入的時候會耗用額外的 CPU 資源來進行壓縮和解壓縮資料，因此如果 SQL Server 主機的 CPU 原本就已經是瓶頸的狀況下，可能會對部分作業有所影響。

 

如果要設定資料壓縮，則可以使用 SSMS 或在資料表或索引上按下滑鼠右鍵，選擇「儲存體」→「管理壓縮」，透過壓縮精靈來選擇要使用 Row(資料列壓縮) 或 Page (頁面壓縮)





 

但在使用過程中要註意，當有表格或索引設定資料壓縮一次之後，則所有進入該物件內的資料都會自動採用壓縮的方式儲存，因此不需要利用 SQL Agent 定時去針對物件設定壓縮或者是重整；但由於資料壓縮是 Enterprise 以上版本才提供的功能，因此只要該資料庫內有任何一個表格或者是一個索引有設定壓縮，則該資料庫不論使用卸離或者是備份的方式，都不能再拿到其他較低的版本上來使用，除非先解除壓縮設定，這一點要特別註意一下。

 


以上是個人針對這三種常被混淆的壓縮做一些整理，如果想要對上述這三種壓縮能有更詳細的瞭解，則可以參考以下相關連結：

 

壓縮資料庫 http://msdn.microsoft.com/zh-tw/library/ms189035.aspx

備份壓縮 http://technet.microsoft.com/zh-tw/library/bb964719(v=sql.110).aspx

資料壓縮 http://technet.microsoft.com/zh-tw/library/cc280449.aspx




SQL 2012
Data Compression




迴首頁














 





系列文章






標籤雲






廣告 







贊助商連結





最新留言















Please enable JavaScript to view the comments powered by Disqus.











​MTK 最新的晶片可以為使用者節省時間和金錢，靠的是壓縮！


































































































Engadget CN


中文版







登入




















































    最新產業新聞文章  













                Intel 據報終結了穿戴裝置部門
              






  17 小時前

View












                HMD Global 毫無預兆地換掉了自己的 CEO
              






  2017 年 7 月 19 日

View












                Google 將透過雲端，將量子運算服務帶給有興趣的研究學者
              






  2017 年 7 月 18 日

View












                Netflix 用戶數超越 1 億大關，你是其中一員嗎？
              






  2017 年 7 月 18 日

View











Image credit: 













save








Save









































share









​MTK 最新的晶片可以為使用者節省時間和金錢，靠的是壓縮！













Eric Chan
, @erichankc

                        2014 年 9 月 18 日, 下午 01:01
        
          
 






578
分享次數











分享












分享












Twitter 發表












line












電郵













儲存































Join Us On
Facebook


























正當 Opera Max 還在慢條斯理地在各地上架之際，這間從事雲端資料壓縮的公司就宣佈正與一個相當有份量的夥伴合作。來自挪威的 Opera 宣佈把 Opera Max 嵌入聯發科（MediaTek）兩款支援 LTE 技術的 64-bit 晶片：八核心的 MT6752 和四核心的 MT6732 。這就意味著手機廠商能夠按意願把手機增添這功能（以我們的理解，這功能是可自行選擇開關的），而且為了縮短上市時間，這功能並不會另作測試。使用者最終得到的好處是更快地加載手機上的網頁、音樂和影片（不是像 Opera 瀏覽器般只會壓縮網頁上的數據）而對 Opera 伺服器的頻寬亦會節省「高達 50%」，當然經加密的資料並不會經過 Opera 伺服器。想知道更多有關 Opera Max 的讀者可以看看跳轉後的介紹影片。









































    9 月 5 日


















                    2016 年 9 月 5 日, 下午 03:49
        





                  魅族對商務機的理解就是「大」
              
 

6 吋螢幕加 4,100mAh 電池打造出一款魅藍 Max。 






 


作者: 
Sanji Feng,                   2016 年 9 月 5 日, 下午 03:49
        




save








儲存



 



































share
















    View
  













    8 月 20 日


















                    2015 年 8 月 20 日, 下午 04:30
        





                  ​國際版的小米裝置將會有 Opera 數據節省技術加持
              
 

在 Opera Max 正式對 YouTube 和 Netflix 作出支援後，該公司再公佈多有一個系統整合了他們的數據節省功能，這就是小米最新推出的 MIUI 7 了。根據小米的說法，這功能將會... 






 


作者: 
Eric Chan,                   2015 年 8 月 20 日, 下午 04:30
        




save








儲存



 



































share
















    View
  













    2 月 24 日


















                    2014 年 2 月 24 日, 凌晨 02:13
        





                  Opera 正式推出為 Android 手機而設的 Opera Max 數據壓縮程式
              
 

Opera 剛剛宣佈推出上圖這個 Opera Max 手機數據流量壓縮程式（Beta 版），它的重點是不單純可以壓縮手機版 Opera 瀏覽器上所用的網絡數據，更可以把其他程式的數據用量也壓縮，更... 






                  2014 年 2 月 24 日, 凌晨 02:13
        




save








儲存



 



































share
















    View
  









































​MTK 最新的晶片可以為使用者節省時間和金錢，靠的是壓縮！


































































































Engadget CN


中文版







登入




















































    最新產業新聞文章  













                Intel 據報終結了穿戴裝置部門
              






  17 小時前

View












                HMD Global 毫無預兆地換掉了自己的 CEO
              






  2017 年 7 月 19 日

View












                Google 將透過雲端，將量子運算服務帶給有興趣的研究學者
              






  2017 年 7 月 18 日

View












                Netflix 用戶數超越 1 億大關，你是其中一員嗎？
              






  2017 年 7 月 18 日

View











Image credit: 













save








Save









































share









​MTK 最新的晶片可以為使用者節省時間和金錢，靠的是壓縮！













Eric Chan
, @erichankc

                        2014 年 9 月 18 日, 下午 01:01
        
          
 






578
分享次數











分享












分享












Twitter 發表












line












電郵













儲存































Join Us On
Facebook


























正當 Opera Max 還在慢條斯理地在各地上架之際，這間從事雲端資料壓縮的公司就宣佈正與一個相當有份量的夥伴合作。來自挪威的 Opera 宣佈把 Opera Max 嵌入聯發科（MediaTek）兩款支援 LTE 技術的 64-bit 晶片：八核心的 MT6752 和四核心的 MT6732 。這就意味著手機廠商能夠按意願把手機增添這功能（以我們的理解，這功能是可自行選擇開關的），而且為了縮短上市時間，這功能並不會另作測試。使用者最終得到的好處是更快地加載手機上的網頁、音樂和影片（不是像 Opera 瀏覽器般只會壓縮網頁上的數據）而對 Opera 伺服器的頻寬亦會節省「高達 50%」，當然經加密的資料並不會經過 Opera 伺服器。想知道更多有關 Opera Max 的讀者可以看看跳轉後的介紹影片。









































    9 月 5 日


















                    2016 年 9 月 5 日, 下午 03:49
        





                  魅族對商務機的理解就是「大」
              
 

6 吋螢幕加 4,100mAh 電池打造出一款魅藍 Max。 






 


作者: 
Sanji Feng,                   2016 年 9 月 5 日, 下午 03:49
        




save








儲存



 



































share
















    View
  













    8 月 20 日


















                    2015 年 8 月 20 日, 下午 04:30
        





                  ​國際版的小米裝置將會有 Opera 數據節省技術加持
              
 

在 Opera Max 正式對 YouTube 和 Netflix 作出支援後，該公司再公佈多有一個系統整合了他們的數據節省功能，這就是小米最新推出的 MIUI 7 了。根據小米的說法，這功能將會... 






 


作者: 
Eric Chan,                   2015 年 8 月 20 日, 下午 04:30
        




save








儲存



 



































share
















    View
  













    2 月 24 日


















                    2014 年 2 月 24 日, 凌晨 02:13
        





                  Opera 正式推出為 Android 手機而設的 Opera Max 數據壓縮程式
              
 

Opera 剛剛宣佈推出上圖這個 Opera Max 手機數據流量壓縮程式（Beta 版），它的重點是不單純可以壓縮手機版 Opera 瀏覽器上所用的網絡數據，更可以把其他程式的數據用量也壓縮，更... 






                  2014 年 2 月 24 日, 凌晨 02:13
        




save








儲存



 



































share
















    View
  









































































資料壓縮 | Microsoft Docs



















資料壓縮Data Compression


2016-7-1
14 分鐘可讀完
參與者









本主題的適用對象：SQL Server (自 2016 起)Azure SQL DatabaseAzure SQL 資料倉儲平行處理資料倉儲THIS TOPIC APPLIES TO: SQL Server (starting with 2016)Azure SQL DatabaseAzure SQL Data Warehouse Parallel Data Warehouse 
 SQL Server 2016SQL Server 2016 和  Azure SQL DatabaseAzure SQL Database 支援資料列和頁面壓縮 (針對資料列存放區的資料表和索引)，亦支援資料行存放區和資料行存放區封存壓縮 (針對資料行存放區的資料表和索引)。 support row and page compression for rowstore tables and indexes, and supports columnstore and columnstore archival compression for columnstore tables and indexes. 
 如果是資料列存放區資料表和索引，使用資料壓縮功能有助於減少資料庫的大小。For rowstore tables and indexes, use the data compression feature to help reduce the size of the database. 除了節省空間之外，資料壓縮也有助於改善 I/O 密集型工作負載的效能，因為資料會儲存在更少的頁面中，而且查詢需要從磁碟讀取的頁面也變少了。In addition to saving space, data compression can help improve performance of I/O intensive workloads because the data is stored in fewer pages and queries need to read fewer pages from disk. 但是在與應用程式交換資料時，資料庫伺服器上需要額外的 CPU 資源來壓縮和解壓縮資料。However, extra CPU resources are required on the database server to compress and decompress the data, while data is exchanged with the application. 您可以針對下列資料庫物件來設定資料列和頁面壓縮：You can configure row and page compression on the following database objects: 

儲存為堆積的整個資料表。A whole table that is stored as a heap. 

儲存為叢集索引的整個資料表。A whole table that is stored as a clustered index. 

整個非叢集索引。A whole nonclustered index. 

整個索引檢視。A whole indexed view. 

如果是分割資料表和索引，您可以針對每個資料分割設定壓縮選項，而物件的不同資料分割則不必擁有相同的壓縮設定。For partitioned tables and indexes, you can configure the compression option for each partition, and the various partitions of an object do not have to have the same compression setting. 
如果是資料行存放區資料表和索引，所有資料行存放區資料表和索引一律都使用資料行存放區壓縮，而且使用者無法進行設定。For columnstore tables and indexes, all columnstore tables and indexes always use columnstore compression and this is not user configurable. 當您可負擔額外的時間和 CPU 資源來儲存及擷取資料時，使用資料行存放區封存壓縮會進一步減少資料大小。Use columnstore archival compression to further reduce the data size for situations when you can afford extra time and CPU resources to store and retrieve the data. 您可以針對下列資料庫物件來設定資料行存放區封存壓縮：You can configure columnstore archival compression on the following database objects: 

整個資料行存放區資料表或整個叢集資料行存放區索引。A whole columnstore table or a whole clustered columnstore index. 因為資料行存放區資料表會儲存成叢集資料行存放區索引，所以兩種方法有相同的結果。Since a columnstore table is stored as a clustered columnstore index, both approaches have the same results. 

整個非叢集資料行存放區索引。A whole nonclustered columnstore index. 

如果是分割資料行存放區資料表和資料行存放區索引，您可以針對每個資料分割設定封存壓縮選項，而不同資料分割則不必擁有相同的封存壓縮設定。For partitioned columnstore tables and columnstore indexes, you can configure the archival compression option for each partition, and the various partitions do not have to have the same archival compression setting. 


註意 資料也可以使用 GZIP 演算法格式進行壓縮。Data can also be compressed using the GZIP algorithm format. 這是額外的步驟，最適合在封存舊資料進行長期儲存時壓縮部分資料。This is an additional step and is most suitable for compressing portions of the data when archiving old data for long term storage. 使用 COMPRESS 函數壓縮的資料無法編製索引。Data compressed using the COMPRESS function cannot be indexed. 如需詳細資訊，請參閱 COMPRESS (Transact-SQL)。For more information, see COMPRESS (Transact-SQL). 

使用資料列和頁面壓縮時的考量Considerations for When You Use Row and Page Compression
 當您使用資料列和頁面壓縮時，請註意以下考量事項：When you use row and page compression, be aware the following considerations: 

Service Pack 或後續版本中的資料壓縮詳細資料可能會變更，恕不另行通知。The details of data compression are subject to change without notice in service packs or subsequent releases.

壓縮適用於  Azure SQL DatabaseAzure SQL DatabaseCompression is available in  Azure SQL DatabaseAzure SQL Database 

每一個  SQL ServerSQL Server版本中都無法使用壓縮。Compression is not available in every edition of  SQL ServerSQL Server. 如需詳細資訊，請參閱 SQL Server 2016 版本支援的功能。For more information, see Features Supported by the Editions of SQL Server 2016. 

壓縮不適用於系統資料表。Compression is not available for system tables. 

壓縮可讓更多的資料列儲存在頁面上，但是不會變更資料表或索引的資料列大小上限。Compression can allow more rows to be stored on a page, but does not change the maximum row size of a table or index. 

當資料列大小上限加上壓縮負擔超過 8060 個位元組的資料列大小上限時，資料表將無法啟用壓縮。A table cannot be enabled for compression when the maximum row size plus the compression overhead exceeds the maximum row size of 8060 bytes. 例如，因為有額外的壓縮負荷，所以無法壓縮具有資料行 c1char(8000) 及 c2char(53) 的資料表。For example, a table that has the columns c1char(8000) and c2char(53) cannot be compressed because of the additional compression overhead. 當使用 Vardecimal 儲存格式時，將會在啟用此格式時執行資料列大小檢查。When the vardecimal storage format is used, the row-size check is performed when the format is enabled. 對於資料列和頁面壓縮而言，最初壓縮物件時會執行資料列大小檢查，然後在插入或修改每一個資料列時加以檢查。For row and page compression, the row-size check is performed when the object is initially compressed, and then checked as each row is inserted or modified. 壓縮會強制執行下列兩個規則：Compression enforces the following two rules: 

固定長度類型的更新一定要成功。An update to a fixed-length type must always succeed. 

停用資料壓縮一定要成功。Disabling data compression must always succeed. 即使壓縮的資料列適合頁面大小，這表示它小於 8060 個位元組；如果它未壓縮，  SQL ServerSQL Server 會防止不適合資料列大小的更新。Even if the compressed row fits on the page, which means that it is less than 8060 bytes;  SQL ServerSQL Server prevents updates that would not fit on the row when it is uncompressed. 



當指定了資料分割清單時，壓縮類型可以在個別資料分割上設定為 ROW、PAGE 或 NONE。When a list of partitions is specified, the compression type can be set to ROW, PAGE, or NONE on individual partitions. 如果未指定資料分割的清單，將會設定所有資料分割，並包含陳述式中所指定的資料壓縮屬性。If the list of partitions is not specified, all partitions are set with the data compression property that is specified in the statement. 在建立資料表或索引時，除非另外指定，否則資料壓縮會設定為 NONE。When a table or index is created, data compression is set to NONE unless otherwise specified. 在修改資料表時，除非另外指定，否則會保留現有的壓縮。When a table is modified, the existing compression is preserved unless otherwise specified. 

如果您指定資料分割清單或超出範圍的資料分割，將會產生錯誤。If you specify a list of partitions or a partition that is out of range, an error will be generated. 

非叢集索引不會繼承資料表的壓縮屬性。Nonclustered indexes do not inherit the compression property of the table. 若要壓縮索引，您必須明確設定索引的壓縮屬性。To compress indexes, you must explicitly set the compression property of the indexes. 根據預設，當建立索引時，索引的壓縮設定將會設定為 NONE。By default, the compression setting for indexes will set to NONE when the index is created. 

在堆積上建立叢集索引時，此叢集索引會繼承堆積的壓縮狀態，除非指定了替代的壓縮狀態。When a clustered index is created on a heap, the clustered index inherits the compression state of the heap unless an alternative compression state is specified. 

當堆積設定了頁面層級壓縮時，頁面只會以下列方式接收頁面層級壓縮：When a heap is configured for page-level compression, pages receive page-level compression only in the following ways: 

資料會在啟用大量最佳化的情況下大量匯入。Data is bulk imported with bulk optimizations enabled. 

使用 INSERT INTO ...WITH (TABLOCK) 語法與資料表沒有非叢集索引。Data is inserted using INSERT INTO ... WITH (TABLOCK) syntax and the table does not have a nonclustered index. 

執行 ALTER TABLE ...REBUILD 陳述式並指定 PAGE 壓縮選項來重建資料表。A table is rebuilt by executing the ALTER TABLE ... REBUILD statement with the PAGE compression option. 



重建堆積之前，配置在堆積中成為 DML 作業一部分的新頁面將不會使用 PAGE 壓縮。New pages allocated in a heap as part of DML operations will not use PAGE compression until the heap is rebuilt. 您可以透過移除並重新套用壓縮，或建立並移除叢集索引，重建堆積。Rebuild the heap by removing and reapplying compression, or by creating and removing a clustered index. 

變更堆積的壓縮設定需要重建資料表上的所有非叢集索引，好讓它們擁有指向堆積內新資料列位置的指標。Changing the compression setting of a heap requires all nonclustered indexes on the table to be rebuilt so that they have pointers to the new row locations in the heap. 

您可以在線上或離線時啟用或停用 ROW 或 PAGE 壓縮。You can enable or disable ROW or PAGE compression online or offline. 在堆積上啟用壓縮對於線上作業而言是單一執行緒的作業。Enabling compression on a heap is single threaded for an online operation. 

啟用或停用資料列或頁面壓縮的磁碟空間需求與建立或重建索引的需求相同。The disk space requirements for enabling or disabling row or page compression are the same as for creating or rebuilding an index. 對於分割的資料而言，您可以一次啟用或停用一個資料分割的壓縮來減少所需的空間。For partitioned data, you can reduce the space that is required by enabling or disabling compression for one partition at a time. 

若要決定資料分割資料表中資料分割的壓縮狀態，請查詢 sys.partitions 目錄檢視的 data_compression 資料行。To determine the compression state of partitions in a partitioned table, query the data_compression column of the sys.partitions catalog view. 

當您壓縮索引時，可以在壓縮資料列和頁面的情況下壓縮分葉層級頁面。When you are compressing indexes, leaf-level pages can be compressed with both row and page compression. 非分葉層級頁面不會收到頁面壓縮。Non–leaf-level pages do not receive page compression. 

由於大數值資料類型的大小之緣故，這些類型有時會單獨儲存在特殊用途的頁面上，與一般資料列的資料分開。Because of their size, large-value data types are sometimes stored separately from the normal row data on special purpose pages. 資料壓縮不適用於個別儲存的資料。Data compression is not available for the data that is stored separately. 

在  SQL Server 2005SQL Server 2005 中實作 Vardecimal 儲存格式的資料表將會在升級時保留此設定。Tables which implemented the vardecimal storage format in  SQL Server 2005SQL Server 2005 will retain that setting when upgraded. 您可以將資料列壓縮套用到具有 Vardecimal 儲存格式的資料表。You can apply row compression to a table that has the vardecimal storage format. 但是，由於資料列壓縮是 Vardecimal 儲存格式的超集，所以沒有理由保留 Vardecimal 儲存格式。However, because row compression is a superset of the vardecimal storage format, there is no reason to retain the vardecimal storage format. 當您將 Vardecimal 儲存格式結合資料列壓縮時，十進位值不會取得額外的壓縮。Decimal values gain no additional compression when you combine the vardecimal storage format with row compression. 您可以將頁面壓縮套用到具有 Vardecimal 儲存格式的資料表；但是，Vardecimal 儲存格式資料行可能不會封存其他壓縮。You can apply page compression to a table that has the vardecimal storage format; however, the vardecimal storage format columns probably will not achieve additional compression. 
註意 SQL Server 2016SQL Server 2016 支援 Vardecimal 儲存格式；但是，由於資料列層級的壓縮會達成相同的目標，所以 Vardecimal 儲存格式已被取代。 supports the vardecimal storage format; however, because row-level compression achieves the same goals, the vardecimal storage format is deprecated. 未來的 Microsoft SQL Server 版本將移除這項功能。This feature will be removed in a future version of Microsoft SQL Server. 請避免在新的開發工作中使用這項功能，並規劃修改目前使用這項功能的應用程式。Avoid using this feature in new development work, and plan to modify applications that currently use this feature. 



使用資料行存放區和資料行存放區封存壓縮Using Columnstore and Columnstore Archive Compression
|||-||適用於：  SQL ServerSQL Server ( SQL Server 2014SQL Server 2014 至 目前版本)、  Azure SQL DatabaseAzure SQL Database。Applies to:  SQL ServerSQL Server ( SQL Server 2014SQL Server 2014 through current version),  Azure SQL DatabaseAzure SQL Database.|  
基本概念Basics
 資料行存放區資料表和索引永遠都會以資料行存放區壓縮形式來儲存。Columnstore tables and indexes are always stored with columnstore compression. 您可以進一步減少資料行存放區資料的大小，只要設定稱為封存壓縮的額外壓縮即可。You can further reduce the size of columnstore data by configuring an additional compression called archival compression. 為了執行封存壓縮，  SQL ServerSQL Server 會針對資料執行 Microsoft XPRESS 壓縮演算法。To perform archival compression,  SQL ServerSQL Server runs the Microsoft XPRESS compression algorithm on the data. 您可以使用下列資料壓縮類型來新增或移除封存壓縮：Add or remove archival compression by using the following data compression types: 

使用 COLUMNSTORE_ARCHIVE 資料壓縮，以封存壓縮來壓縮資料行存放區的資料。Use COLUMNSTORE_ARCHIVE data compression to compress columnstore data with archival compression. 

使用 COLUMNSTORE 資料壓縮，將封存壓縮解壓縮。Use COLUMNSTORE data compression to decompress archival compression. 這樣產生的資料將會持續以資料行存放區壓縮形式壓縮。This resulting data will continue to be compressed with columnstore compression. 
若要新增封存壓縮，請使用 ALTER TABLE (Transact-SQL) 或 ALTER INDEX (Transact-SQL) 搭配 REBUILD 選項和 DATA COMPRESSION = COLUMNSTORE。To add archival compression, use ALTER TABLE (Transact-SQL) or ALTER INDEX (Transact-SQL) with the REBUILD option and DATA COMPRESSION = COLUMNSTORE. 
範例:Examples: 


ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = 1 WITH (DATA_COMPRESSION =  COLUMNSTORE_ARCHIVE) ;  

ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = ALL WITH (DATA_COMPRESSION =  COLUMNSTORE_ARCHIVE) ;  

ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = ALL WITH (DATA_COMPRESSION =  COLUMNSTORE_ARCHIVE ON PARTITIONS (2,4)) ;  
 若要移除封存壓縮並將資料還原成資料行存放區壓縮，請使用 ALTER TABLE (Transact-SQL) 或 ALTER INDEX (Transact-SQL) 搭配 REBUILD 選項和 DATA COMPRESSION = COLUMNSTORE。To remove archival compression and restore the data to columnstore compression, use ALTER TABLE (Transact-SQL) or ALTER INDEX (Transact-SQL) with the REBUILD option and DATA COMPRESSION = COLUMNSTORE. 
 範例:Examples: 
ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = 1 WITH (DATA_COMPRESSION =  COLUMNSTORE) ;  

ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = ALL WITH (DATA_COMPRESSION =  COLUMNSTORE) ;  

ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = ALL WITH (DATA_COMPRESSION =  COLUMNSTORE ON PARTITIONS (2,4) ) ;  
 下一個範例會在某些資料分割上將資料壓縮設定為資料行存放區，以及在其他資料分割上設定為資料行存放區封存。This next example sets the data compression to columnstore on some partitions, and to columnstore archival on other partitions. 
ALTER TABLE ColumnstoreTable1   
REBUILD PARTITION = ALL WITH (  
    DATA_COMPRESSION =  COLUMNSTORE ON PARTITIONS (4,5),  
    DATA COMPRESSION = COLUMNSTORE_ARCHIVE ON PARTITIONS (1,2,3)  
) ;  
效能Performance
 以封存壓縮壓縮資料行存放區索引將會造成該索引的效能比沒有封存壓縮的資料行存放區索引還要慢。Compressing columnstore indexes with archival compression will cause the index to perform slower than columnstore indexes that do not have the archival compression. 只有當您可以負擔使用額外時間和 CPU 資源來壓縮及擷取資料時，才使用封存壓縮。Use archival compression only when you can afford to use extra time and CPU resources to compress and retrieve the data. 
 效能減緩的好處就是減少儲存體，這對於不常存取的資料很實用。The benefit of slower performance is reduced storage which is useful for data that is not frequently accessed. 例如，如果您每個月的資料都有一個資料分割，而您的大多數活動發生在最近的月份，您可以封存較舊的月份來減少儲存需求。For example, if you have a partition for each month of data, and most of your activity is for the most recent months, you could archive older months to reduce the storage requirements. 
中繼資料Metadata
 下列系統檢視表包含叢集索引之資料壓縮的相關資訊：The following system views contain information about data compression for clustered indexes: 

sys.indexes (Transact-SQL) - type 及 type_desc 資料行包含 CLUSTERED COLUMNSTORE 和 NONCLUSTERED COLUMNSTORE。sys.indexes (Transact-SQL) - The type and type_desc columns include CLUSTERED COLUMNSTORE and NONCLUSTERED COLUMNSTORE. 

sys.partitions (Transact-SQL) – data_compression 及 data_compression_desc 資料行包含 COLUMNSTORE 和 COLUMNSTORE_ARCHIVE。sys.partitions (Transact-SQL) – The data_compression and data_compression_desc columns include COLUMNSTORE and COLUMNSTORE_ARCHIVE. 
sp_estimate_data_compression_savings (Transact-SQL) 程序不適用於資料行存放區索引。The procedure sp_estimate_data_compression_savings (Transact-SQL) does not apply to columnstore indexes. 


壓縮對分割資料表和索引有何影響How Compression Affects Partitioned Tables and Indexes
 當您搭配分割資料表和索引使用資料壓縮時，請註意以下考量事項：When you use data compression with partitioned tables and indexes, be aware of the following considerations: 

當使用 ALTER PARTITION 陳述式分割資料分割時，兩個資料分割都會繼承原始資料分割的資料壓縮屬性。When partitions are split by using the ALTER PARTITION statement, both partitions inherit the data compression attribute of the original partition. 

當合併兩個資料分割時，所產生的資料分割會繼承目標資料分割的資料壓縮屬性。When two partitions are merged, the resultant partition inherits the data compression attribute of the destination partition. 

若要切換資料分割，此資料分割的資料壓縮屬性必須符合資料表的壓縮屬性。To switch a partition, the data compression property of the partition must match the compression property of the table. 

您可以使用兩種語法變化來修改分割資料表或索引的壓縮：There are two syntax variations that you can use to modify the compression of a partitioned table or index: 

下列語法只會重建參考的資料分割：The following syntax rebuilds only the referenced partition: 
ALTER TABLE <table_name>   
REBUILD PARTITION = 1 WITH (DATA_COMPRESSION =  <option>)  

下列語法會將現有的壓縮設定用於任何未參考的資料分割，藉以重建整個資料表：The following syntax rebuilds the whole table by using the existing compression setting for any partitions that are not referenced: 
ALTER TABLE <table_name>   
REBUILD PARTITION = ALL   
WITH (DATA_COMPRESSION = PAGE ON PARTITIONS(<range>),  
... )  
分割索引會遵循使用 ALTER INDEX 的相同原則。Partitioned indexes follow the same principle using ALTER INDEX. 



當卸除叢集索引時，除非修改了資料分割配置，否則對應的堆積資料分割會保留其資料壓縮設定。When a clustered index is dropped, the corresponding heap partitions retain their data compression setting unless the partitioning scheme is modified. 如果資料分割配置有所變更，所有資料分割都會重建為未壓縮的狀態。If the partitioning scheme is changed, all partitions are rebuilt to an uncompressed state. 若要卸除叢集索引及變更資料分割配置，您需要執行以下步驟：To drop a clustered index and change the partitioning scheme requires the following steps: 

卸除叢集索引。Drop the clustered index. 

使用指定壓縮選項的 ALTER TABLE ...REBUILD ... 選項來修改資料表。Modify the table by using the ALTER TABLE ... REBUILD ... option that specifies the compression option. 
在線上卸除叢集索引將會是非常快速的作業，因為只會移除叢集索引的上層。To drop a clustered index OFFLINE is a very fast operation, because only the upper levels of clustered indexes are removed. 在線上卸除叢集索引時，  SQL ServerSQL Server 必須重建堆積兩次，一次在步驟 1，另一次在步驟 2。When a clustered index is dropped ONLINE,  SQL ServerSQL Server must rebuild the heap two times, once for step 1 and once for step 2. 




壓縮將如何影響複寫How Compression Affects Replication
|||-||適用於：  SQL ServerSQL Server ( SQL Server 2014SQL Server 2014 至 目前版本)。Applies to:  SQL ServerSQL Server ( SQL Server 2014SQL Server 2014 through current version).| 當您搭配複寫使用資料壓縮時，請註意以下考量事項：When you are using data compression with replication, be aware of the following considerations: 

當快照集代理程式產生最初的結構描述指令碼時，新的結構描述會將相同的壓縮設定用於資料表和它的索引。When the Snapshot Agent generates the initial schema script, the new schema will use the same compression settings for both the table and its indexes. 不能只在資料表上啟用壓縮，而不在索引上啟用壓縮。Compression cannot be enabled on just the table and not the index. 

如果是異動複寫，發行項結構描述選項會判斷哪些相依的物件和屬性必須編寫指令碼。For transactional replication the article schema option determines what dependent objects and properties have to be scripted. 如需詳細資訊，請參閱 sp_addarticle。For more information, see sp_addarticle. 
 散發代理程式在套用指令碼時，不會檢查是否有下層的訂閱者。The Distribution Agent does not check for down-level Subscribers when it applies scripts. 如果選取了壓縮的複寫，在下層訂閱者上建立資料表將會失敗。If the replication of compression is selected, creating the table on down-level Subscribers will fail. 如果是混合拓撲，請勿啟用壓縮的複寫。In the case of a mixed topology, do not enable the replication of compression. 

如果是合併式複寫，發行集相容性層級會覆寫結構描述選項，並判斷將要編寫指令碼的結構描述物件。For merge replication, publication compatibility level overrides the schema options and determines the schema objects that will be scripted. 
 在混合拓撲的情況下，如果它不必支援新的壓縮選項，則發行集相容性層級應該設定為下層的訂閱者版本。In the case of a mixed topology, if it is not required to support the new compression options, the publication compatibility level should be set to the down-level Subscriber version. 如果需要的話，請於建立資料表之後在訂閱者上壓縮資料表。If it is required, compress tables on the Subscriber after they have been created. 
下表顯示在複寫期間控制壓縮的複寫設定。The following table shows replication settings that control compression during replication. 





使用者意圖User intent
複寫資料表或索引的資料分割配置Replicate partition scheme for a table or index
複寫壓縮設定Replicate compression settings
指令碼行為Scripting behavior




複寫資料分割配置，以及在資料分割的訂閱者上啟用壓縮。To replicate the partition scheme and enable compression on the Subscriber on the partition.
TrueTrue
TrueTrue
同時針對資料分割配置和壓縮設定編寫指令碼。Scripts both the partition scheme and the compression settings.


複寫資料分割配置，但是不壓縮訂閱者上的資料。To replicate the partition scheme but not compress the data on the Subscriber.
TrueTrue
FalseFalse
針對資料分割配置編寫指令碼，但是不針對資料分割的壓縮設定編寫指令碼。Scripts out the partition scheme but not the compression settings for the partition.


不複寫資料分割配置，而且不壓縮訂閱者上的資料。To not replicate the partition scheme and not compress the data on the Subscriber.
FalseFalse
FalseFalse
不針對資料分割或壓縮設定編寫指令碼。Does not script partition or compression settings.


如果所有資料分割都在發行者上壓縮，則壓縮訂閱者上的資料表，但是不複寫資料分割配置。To compress the table on the Subscriber if all the partitions are compressed on the Publisher, but not replicate the partition scheme.
FalseFalse
TrueTrue
檢查所有資料分割是否啟用壓縮。Checks if all the partitions are enabled for compression. 針對資料表層級上的壓縮編寫指令碼。Scripts out compression at the table level.



壓縮對於其他 SQL Server 元件有何影響How Compression Affects Other SQL Server Components
|||-||適用於：  SQL ServerSQL Server ( SQL Server 2014SQL Server 2014 至 目前版本)。Applies to:  SQL ServerSQL Server ( SQL Server 2014SQL Server 2014 through current version).|
 壓縮會發生在儲存引擎中，而且資料會以非壓縮狀態呈現給  SQL ServerSQL Server 中的大多數其他元件。Compression occurs in the storage engine and the data is presented to most of the other components of  SQL ServerSQL Server in an uncompressed state. 這樣會將壓縮對其他元件的影響限制為以下情況：This limits the effects of compression on the other components to the following: 

大量匯入及匯出作業Bulk import and export operations 
 當匯出資料時 (即使是原生格式)，資料為非壓縮資料列格式的輸出。When data is exported, even in native format, the data is output in the uncompressed row format. 這可能會造成匯出的資料檔大小比來源資料大出許多。This can cause the size of exported data file to be significantly larger than the source data. 
 當匯入資料時，如果目標資料表已啟用壓縮，則儲存引擎會將資料轉換成壓縮的資料列格式。When data is imported, if the target table has been enabled for compression, the data is converted by the storage engine into compressed row format. 這樣可能會造成 CPU 使用量增加 (相較於資料匯入未壓縮的資料表時)。This can cause increased CPU usage compared to when data is imported into an uncompressed table. 
 將資料大量匯入具有頁面壓縮的堆積內時，大量匯入作業會在插入具有頁面壓縮的資料時，嘗試壓縮這些資料。When data is bulk imported into a heap with page compression, the bulk import operation will try to compress the data with page compression when the data is inserted. 

壓縮不會影響備份和還原。Compression does not affect backup and restore. 

壓縮不會影響記錄傳送。Compression does not affect log shipping. 

資料壓縮與疏鬆資料行不相容。Data compression is incompatible with sparse columns. 因此，包含疏鬆資料行的資料表無法加以壓縮，也無法將疏鬆資料行加入至壓縮的資料表。Therefore, tables containing sparse columns cannot be compressed nor can sparse columns be added to a compressed table. 

啟用壓縮可能會造成查詢計畫變更，因為系統會使用不同的頁數以及每頁不同的資料列數來儲存資料。Enabling compression can cause query plans to change because the data is stored using a different number of pages and number of rows per page. 


另請參閱See Also
 資料列壓縮實作 Row Compression Implementation  頁面壓縮實作  Page Compression Implementation  Unicode 壓縮實作  Unicode Compression Implementation  CREATE PARTITION SCHEME (Transact-SQL)  CREATE PARTITION SCHEME (Transact-SQL)  CREATE PARTITION FUNCTION (Transact-SQL)  CREATE PARTITION FUNCTION (Transact-SQL)  CREATE TABLE (Transact-SQL)  CREATE TABLE (Transact-SQL)  ALTER TABLE (Transact-SQL)  ALTER TABLE (Transact-SQL)  CREATE INDEX (Transact-SQL)  CREATE INDEX (Transact-SQL)  ALTER INDEX (Transact-SQL) ALTER INDEX (Transact-SQL) 










編輯										


共用

Twitter
Facebook


|

佈景主題


淺色
深色


































旗標學校服務網：資料壓縮



















請選擇分類 　
計算機概論
作業系統
網路概論與技術
程式設計
資料結構與演算法
資料庫
系統程式
系統分析
商業套裝軟體
多媒體導論與技術
影像編修與繪圖
電腦動畫
影片剪輯
網頁設計
網頁程式設計
電子商務
管理資訊系統
資訊安全
資訊法律
數位訊號處理
硬體與自動控制
運動
電腦輔助設計

電腦輔助設計_工程圖學
數學
個人電腦實作
檢定考試用書
認證考試用書


 
 
 






  












 

 
 旗標科技
            l 旗標學校服務網
            l 學校書目錄
            l 教師服務
            l 購書服務
            l 特別企畫
            l 研討活動
            l 更正下載
            l Eleconce
            l 旗訊













旗標知識網>>好書能增進知識!提高學習效率! 卓越的品質是我們的信念與堅持

















•

突破傳統、領先潮流的資訊基礎教科書



•

學習網路, 除了理論, 也要實務、更要最新技術！



•

打造整合式的雲端服務頁面



•

最受歡迎的數位攝影教科書



•

遊戲廠推薦, 範例最豐富、多元的 Unity3D 入門書



•

超圖解、簡明易學的資料結構教科書



•

大量圖解+豐富案例 + 反覆練習的程式設計教科書



•

用創新案例來教電子商務和網路行銷






旗標知識網>>好書能增進知識!提高學習效率! 卓越的品質是我們的信念與堅持


























書籍單品頁








資料壓縮

作者：戴顯權 編著
書號：F7895

ISBN：9789574425174
定價：650  元
      


附件：附1片光碟片


 教學資源：

習題•投影片•
 


內容介紹　　　　      l 內容介紹 l 本書特色
l 附件內容 l 適用科目 l 本書大綱 l 教學推薦 l

 

在這本書推出之前，資料壓縮課程並沒有非常合適的教科書。雖然市面上有許多書是專門探討資料壓縮這個領域，但是它們或者太過於偏頗在某些特殊方法上，或者資料太過老舊，因此都算不上很好的教科書。在這樣的情況下，最好的選擇就是同時使用幾本書，去蕪存菁合成上課的教材。為了改善上述的問題，作者訂下目標，希望這本書能夠單獨地成為資料壓縮課程的教科書，因此它所涵蓋的內容必須包括資訊理論、無失真資料壓縮法、及失真資料壓縮法。同時作者也希望這本書能夠單獨地成為一本很好的參考書及工具書，於是它也附上了本書所介紹之各種資料壓縮法的實作程式，且這些程式都是實際上能壓縮、解壓縮的程式，而不是模擬程式。





 
本書特色

 
簡單地說，本書有兩大特色：一、條理清晰、主題完整而明確，極適合做為資料壓縮課程的教科書。二、整合各種資料壓縮方法、並提示各相關的參考來源，是一本非常詳細的參考書及工具書。





 
附件內容
根據經驗，資料壓縮的程式設計人員通常都在第一個程式上花最多的時間，因此作者將大部分這本書中所介紹過的資料壓縮演算法撰寫成C語言程式，附在書後的光碟的DISK1目錄中；每一個程式都附有詳細解說，有興趣的讀者可以從這些解說中進一步瞭解整個程式的設計。希望讀者能從這些程式中獲得一些經驗，並且利用這些程式再發展出更佳的程式。所有的程式都是實際上可以做壓縮、解壓縮的實作程式，而不是模擬程式，因此讀者可以用這些程式來壓縮自己的檔案。而書中所有的測試資料都存放在書附光碟中的DISK2目錄內，讀者可以用前面所提的壓縮程式做壓縮、解壓縮。





 
適用科目
資料壓縮





 
本書大綱
第一部份 介紹　第一章 介紹第二部份 理論基礎　第二章 資訊理論之觀念　第三章 熵之估計與無失真資料壓縮　第四章 資料率—失真理論與失真資料壓縮	第三部份 無失真壓縮　第五章 統計模式　第六章 字典基礎模式第四部份 失真壓縮　第七章 預測編碼　第八章 非累贅取樣編碼　第九章 方塊截短編碼　第十章 轉換編碼　第十一章 向量量化編碼　第十二章 分頻編碼法　第十三章  小波編碼　第十四章 影像碎形壓縮　第十五章 階級式編碼　第十六章 選擇一個失真壓縮技術　第十七章 彩色影像之壓縮　第十八章 視訊編碼第五部份 程式範例　第十九章 程式範例






教學推薦




數位訊號處理








 



  








旗 標 科 技 股 份 有 限 公 司   100 臺北市中正區杭州南路一段15-1號19樓
            TEL: 02-2396-3257
            Copyright © 2005 Flag Publishing Co.,Ltd. All Rights Reserved   
            版權所有 •聯絡我們
            •合作提案•隱私權政策






 






壓縮及修復資料庫檔案 - Access










































































試用 Microsoft Edge
專為 Windows 10 設計、快速且安全的瀏覽器


不，謝謝
開始使用















Microsoft



Office









 無結果




0
 個項目在購物車中




登入








Office


購買 Office 365














支援







應用程式



Access
Excel
OneDrive
OneNote
Outlook
PowerPoint
SharePoint
商務用 Skype
Visio
Word



安裝


帳戶


訓練


系統管理










壓縮及修復資料庫檔案




適用對象: 
Access 2016
Access 2013
更多...
更少




 

 
於網路共用的 Access 桌面資料庫檔案有時會損毀。若發生此事，通常會影響其設計而非資料。不過，若真的遺失資料，通常也限於單一使用者的最後一個動作。當 Access 桌面資料庫檔案損毀時，可能可以利用 [壓縮及修復] 程序修好一部分。壓縮作業並不是壓縮您的資料；它只是刪除未使用的空間，以縮減資料庫檔案大小。[壓縮及修復資料庫] 命令也有助於改善資料庫效能。


附註: 本文內容不適用於 Access Web App - 此為使用 Access 設計及線上發佈的資料庫類型。如需詳細資訊，請參閱建立 Access 應用程式。

當您嘗試開啟損毀的資料庫檔案時，Access 會提示您進行自動檔案修復程序；若此程序僅有部分成功，Access 會將未修復的物件登記於 MSysCompactErrors 資料表。若您擁有一份資料庫未損毀前的備份，可利用 MSysCompactErrors 資料表來決定要將哪些物件匯入您修復的資料庫。

分割資料庫有助預防資料庫檔案損毀，且因資料儲存於使用者不會直接存取的檔案，所以也能限制資料遺失的程度。


附註: 若您將之前發佈的 Access 網頁資料庫壓縮及修復，在壓縮及修復程序完成之後，請記得要同步處理資料庫。

如需詳細資訊，請參閱如何使用備份與還原程序來保護資料。


執行壓縮及修復程序之前


備份資料庫：


按一下 [檔案] 索引標籤上的 [儲存檔案]。


在 [檔案類型] 底下，按一下 [將資料庫儲存為]。


在 [進階] 按一下 [備份資料庫]。


附註: 若有多位使用者，請通知其他使用者勿在執行壓縮及修復期間使用資料庫。




取得執行壓縮及修復作業的權限：    如果您使用舊版資料庫檔案並且屬於工作群組的一部分，您可能無法自行壓縮及修復資料庫。如果您的權限不足卻需要壓縮及修復資料庫，請洽工作群組管理員協助。



 

設定資料庫關閉時自動壓縮及修復
您也可以設定壓縮及修復程序自動在每次關閉資料庫時執行。多使用者的資料庫或許不應設定此選項，因為可能暫時中斷資料庫可用性。此程序僅影響目前開啟的資料庫。


附註:  此選項不適用於 Access Web App。



按一下 [檔案] 索引標籤上的 [選項]。


按一下 [Access 選項] 方塊中的 [目前資料庫]。


按一下 [應用程式選項] 底下的 [關閉資料庫時壓縮]。



 

手動壓縮並修復已開啟的資料庫


重要: 執行壓縮及修復程序之前，請確認沒有任何人在使用資料庫檔案。



在 [檔案] 索引標籤按一下 [資訊] > [壓縮及修復資料庫]。































									擴展您的技能
								
探索訓練



									優先取得新功能
								
加入 Office 測試人員


















這項資訊有幫助嗎？


是
否




太好了! 還有其他意見反應嗎?
我們應該如何改進?



傳送​​
不，謝謝




感謝您的意見反應!


感謝您的意見反應! 我們將協助您與其中一位 Office 支援專員連絡以深入瞭解您的意見。

連絡客戶支援





×


















 

 










使用壓縮及修復協助防止並修正資料庫檔案問題 - Access








































































試用 Microsoft Edge
專為 Windows 10 設計、快速且安全的瀏覽器


不，謝謝
開始使用















Microsoft



Office









 無結果




0
 個項目在購物車中




登入








Office


購買 Office 365














支援







應用程式



Access
Excel
OneDrive
OneNote
Outlook
PowerPoint
SharePoint
商務用 Skype
Visio
Word



安裝


帳戶


訓練


系統管理










使用壓縮及修復協助防止並修正資料庫檔案問題




適用對象: 
Access 2007
更多...
更少




 



重要: 
本文係由機器翻譯而成，請參閱免責聲明。本文的英文版本請見這裡，以供參考。


 
資料庫檔案可能會隨著您的使用而快速成長，有時會防礙效能；資料庫檔案也可能偶而會損毀或損壞。您可以使用 Microsoft Office Access 中的 [壓縮及修復資料庫] 命令，以防止或修正這些問題。
本文內容不說明如何備份或還原資料庫，如需詳細資訊，請瀏覽 [請參閱] 一節中的連結。


本文內容
 



為何壓縮及修復資料庫




在您開始之前




壓縮及修復資料庫




 

為何壓縮及修復資料庫
本總覽說明使用 [壓縮及修復資料庫] 命令如何協助防止並修正下列有時會影響資料庫的問題：檔案隨著使用而成長變得越來越大，以及檔案損毀。

資料庫檔案隨著使用而成長
隨著您加入及更新資料並變更其設計，資料庫檔案變得越來越大，這種成長中有些是來自新資料，但是有些來自其他來源：


Access 會建立隱藏的暫存物件，以完成各種不同的工作。有時候當 Access 不再需要這些暫存物件之後，它們還是會留在您的資料庫中。


當您刪除資料庫物件時，該物件所佔用的磁碟空間並不會自動進行回收 - 即使刪除物件之後，資料庫檔案仍然使用該磁碟空間。


當您的資料庫檔案中塞滿殘留的暫存檔及已刪除的物件時，其效能可能會降低。物件開啟可能會更緩慢，查詢可能要耗費比一般更長的時間才能執行，而且一般來說經常執行的作業似乎都要花費更多時間。


附註: 壓縮作業並不是壓縮您的資料 - 它是消除未使用的空間，以縮減資料庫檔案大小。



資料庫檔案可能會損毀
在特定環境下，資料庫檔案可能會損毀。如果資料庫檔案是透過網路進行共用，而同時有多個使用者直接使用檔案，檔案損毀的風險很小；但是如果使用者經常在備忘欄位中編輯資料，損毀的風險就會加大，風險也會隨著時間而增加。您可以使用 [壓縮及修復資料庫] 命令來降低風險。
通常這種損毀產生的 Visual Basic for Applications (VBA) 模組問題，也不會造成資料遺失的風險。不過，這種損毀會造成風險的資料庫設計損毀，例如遺失的 VBA 程式碼或無法使用的表單。
資料庫檔案的損毀很少造成資料遺失，這種損失經常侷限於一個使用者的最後動作，也就是說，單一的資料變更。當使用者開始變更資料而變更遭到中斷時 - 例如，由於喪失網路服務 - Access 會將資料庫檔案標示為已損毀。檔案可以修復，但其中有些資料可能會在修復完成之後遺失。


提示: 分割資料庫可以協助防止資料庫檔案損壞，並將資料分別保存在使用者不會直接存取的另外一個檔案中，限制資料的遺失。


Access 提示您修復已損毀的資料庫檔案
當您嘗試開啟己損毀的資料庫檔案時，系統會提示您讓 Access 自動修復檔案。您也可以手動使用 [壓縮及修復資料庫] 命令來修復及開啟已損毀的資料庫檔案。
如果 Access 完全修復了損毀的檔案，就會顯示訊息，表明已成功修復檔案，您應該檢查資料庫內容，以確認一切都已回復正常。
如果 Access 只是部分修復成功，就會追蹤記錄無法修復的資料庫物件，以便讓您決定必須從備份復原的部分。


附註: 您可以設定資料庫選項，讓 [壓縮及修復] 功能在您每一次關閉特定資料庫時自動執行。如果您是資料庫的唯一使用者，就應該設定此選項；在多使用者資料庫中，您可能不要設定此選項，因為可能會暫時中斷資料庫的可用性。


頁面頂端​




 

在您開始之前
請考慮採取下列動作，再開始壓縮及修復作業：



一定要進行備份    在修復程序中，Access 可能會截斷已損壞資料表中的一些資料，而這些資料有時可能可以從備份中復原。除了定期備份的策略以外，還應該在您使用 [壓縮及修復資料庫] 命令之前進行備份。您可以使用 [備份資料庫] 命令製作備份：


按一下 [Microsoft Office 按鈕]
 
，指向 [管理]，然後在 [管理此資料庫] 底下，按一下 [備份資料庫]。





自動壓縮及修復    除非您在網路上與其他使用者共用單一資料庫檔案，否則就應該設定資料庫自動壓縮及修復。



記下系統復原錯誤表    當 Access 無法修復已損毀資料庫檔案中所有物件時，任何無法復原的物件都會記錄在 MSysCompactErrors 表中。如果有錯誤，Access 就會在資料工作表檢視中開啟 MSysCompactErrors 表。
如果您擁有在資料庫損毀之前的資料庫備份，就可以使用 MSysCompactErrors 表，決定要從資料庫備份匯入已修復資料庫中的物件。



取得資料庫的獨佔式存取權，以使用 [壓縮及修復資料庫] 命令    如果您是使用資料庫的唯一使用者，您可以略過本節中的其餘內容，直接跳到壓縮及修復資料庫。
壓縮及修復作業需要資料庫檔案的獨佔式存取權，因為此作業可能會中斷其他使用者的作業。當您計劃執行壓縮及修復作業時，應該通知其他使用者，以便讓他們在壓縮及修復期間避免使用該資料庫。
告知其他使用者，有多久時間必須避免使用該資料庫。如果定期執行壓縮及修復作業，請保存所耗費時間的記錄，您就可以作出更精準的估計，以便指引其他使用者，該避免使用資料庫多久時間。



取得足夠的權限，以執行壓縮及修復作業    如果使用較舊版本的資料庫檔案，而此檔案屬於工作群組的一部分，您可能就無法自行壓縮及修復資料庫。如果您沒有足夠的使用權限，而必須壓縮及修復資料庫，請連絡您的工作群組系統管理員，取得協助。



頁面頂端​


 

壓縮及修復資料庫
 



在資料庫關閉時自動壓縮及修復




手動壓縮及修復資料庫




 

在資料庫關閉時自動壓縮及修復
如果要在資料庫關閉時自動壓縮及修復，可以選取 [關閉資料庫時壓縮] 資料庫選項。


附註: 設定此選項隻影響目前已開啟的資料庫。您必須為要自動壓縮及修復的每一個資料庫，分別設定此選項。



按一下 [Microsoft Office 按鈕]  
 
，然後按一下 [Access 選項]。


在 [Access 選項] 對話方塊中，按一下 [目前資料庫]。


在 [應用程式選項] 下麵，選取 [關閉資料庫時壓縮] 核取方塊。



頁面頂端​


 

手動壓縮及修復資料庫
除了使用 [關閉資料庫時壓縮] 資料庫選項以外，或者不使用該選項，也可以手動執行 [壓縮及修復資料庫] 命令。您可以在已開啟資料庫時執行此命令，也可以在不開啟資料庫時執行此命令，還可以建立桌面捷徑，對特定資料庫檔案執行 [壓縮及修復資料庫] 命令。
 

壓縮及修復已開啟的資料庫


附註: 如果其他使用者目前也在使用資料庫檔案，您就不能執行壓縮及修復作業。



按一下 [ Microsoft Office 按鈕]
 
，指向 [管理]，然後在 [管理此資料庫，請按一下 [壓縮及修復資料庫。



 

壓縮及修復未開啟的資料庫


附註: 如果其他使用者目前在使用資料庫檔案，您就不能執行壓縮及修復作業。在您執行壓縮及修復作業的同時，沒有任何人能夠使用該資料庫檔案。



啟動 Access，但是不要開啟資料庫。


按一下 [ Microsoft Office 按鈕]
 
，指向 [管理]，然後在 [管理此資料庫，請按一下 [壓縮及修復資料庫。


在 [資料庫壓縮的來源] 對話方塊中，瀏覽至您要壓縮及修復的資料庫，然後按兩下。



 

建立桌面捷徑，對特定資料庫執行壓縮及修復
您可以在桌面上建立捷徑，用來壓縮及修復特定資料庫。
開始作業以前，請確認 Msaccess.exe 檔案在電腦上的位置，Msaccess.exe 檔案一般都是位於下列資料夾中：
C:\Program Files\Microsoft Office\Office12
如果在該位置找不到 Msaccess.exe 檔案，請搜尋該檔案並記下完整路徑。

建立桌面捷徑   


以滑鼠右鍵按一下桌面，指向 [新增]，然後按一下快顯功能表上的 [捷徑]。


第一頁的 [建立捷徑精靈] 中輸入項目的位置] 方塊中，輸入雙引號 (") Msaccess.exe 檔案 （包括檔案名稱），輸入完整的路徑，然後輸入另一個雙引號。（或者，按一下 [瀏覽] ，找出並選取檔案。在此例中括住會自動加入。）
例如，輸入："C:\Program Files\Microsoft Office\Office12\msaccess.exe"


在右雙引號之後輸入一個空格，然後輸入所要壓縮及修復資料庫的完整路徑。如果路徑包含空格，請以引號將路徑括住，再輸入另一個空格，然後輸入「/compact」。
例如，輸入："C:\My Folder\My Database.accdb" /compact


按 [下一步]。


在 [輸入這個捷徑的名稱] 方塊中，輸入捷徑的名稱，然後按一下 [完成]。
精靈便會建立捷徑並放置於您的桌面上。


您想壓縮及修復資料庫時，只要按兩下該捷徑即可。


提示: 若要將桌面捷徑新增到 [開始] 功能表中，請以滑鼠右鍵按一下捷徑，然後按一下快顯功能表上的 [固定至 [開始] 功能表]。




頁面頂端​



 



附註: 機器翻譯免責聲明︰本文係以電腦系統翻譯而成，未經人為介入。Microsoft 提供此等機器翻譯旨在協助非英語系使用者輕鬆閱讀 Microsoft 產品、服務及技術相關內容。基於本文乃由機器翻譯而成，因此文中可能出現詞辭、語法、文法上之錯誤。































									擴展您的技能
								
探索訓練



									優先取得新功能
								
加入 Office 測試人員


















這項資訊有幫助嗎？


是
否




太好了! 還有其他意見反應嗎?
我們應該如何改進?



傳送​​
不，謝謝




感謝您的意見反應!


感謝您的意見反應! 我們將協助您與其中一位 Office 支援專員連絡以深入瞭解您的意見。

連絡客戶支援





×


















 

 








﻿
演算法筆記 - Compression

Compression

濃縮資料

如何簡明扼要的記載資料、傳述訊息呢？

縮短資料長度，減少交流時間，減少儲存空間，好處多多。
Compress / Decompress
「壓縮」是濃縮資料，「解壓縮」是回復資料。觀念類似先前提及的「編碼」與「解碼」。

              compress
Thank you! -------------> 3Q!
            兩億鎂
              
文字、聲音、圖像、動作、感受，通通可以壓縮。
資料先壓縮、再解壓縮，如果還是跟原本資料一模一樣，就叫做「無失真壓縮lossless compression」；如果不一樣就叫做「失真壓縮lossy compression」。
用電腦處理資料，首重精準無誤。以下僅介紹無失真壓縮。
二元碼壓縮
二元碼（二進位字串）縮短成另一個二元碼。

                              compress   
001100111100101010100001   ------------->   10110101
                           
文字壓縮
例如Doctor縮寫成Dr.、公共汽車簡稱為公車。

vs.      versus
lol      laugh out loudly
RTFM     read the fucking manual
afaik    as far as I known
¥        Japanese Yen

文字壓縮得視作二元碼壓縮！文字儲存於電腦當中，本質上就是ASCII或UTF-8二元碼。
語言壓縮
長話短說的壓縮，一般認為是文學的範疇。

原文　　　　　　　｜壓縮　　　　　｜失真壓縮｜言簡意賅
如果你沒勇氣陪我到｜若你畏懼陪我到｜不愛我　｜再見
明天的明天的明天　｜大後天　　　　｜　　　　｜
倒不如就忘了就斷了｜不如忘盡　　　｜就忘了我｜
寂寞的昨天的昨天　｜寂寞的前天　　｜　　　　｜

資訊壓縮
古代人將壓縮和編碼視為相同，一般認為是文字學的範疇。
資訊壓縮是把抽象的資訊信息變成實際的碼。設立一種編碼方式，讓碼的長度越短越好，以三言兩語詮釋大千世界。
打個比方，白話文是不太理想的壓縮、文言文是更理想的壓縮；北京話是不太理想的壓縮、山東話是更理想的壓縮。

北京話　　　　　　｜台灣話　　　　｜閩南話　　　｜四川話　　｜山東話
甲：是誰在樓下啊？｜甲：誰在下麵？｜甲：啥咪郎？｜甲：喇國？｜甲：誰？
乙：是我在這兒唄！｜乙：我在這裡！｜乙：喜哇啦！｜乙：使握！｜乙：俺！
甲：你在做什麼咧？｜甲：你在幹嘛？｜甲：衝啥悔？｜甲：昨傻？｜甲：啥？
乙：我在這小便吶！｜乙：我在小便！｜乙：棒溜啦！｜乙：潦瞭！｜乙：尿！

除了文字可以當作碼，圖示、手語、表情也都可以當作碼。
Symbol / Code
資料通常很長。大家習慣逐段處理，符合電腦運作特性。
一段資料構成一個「符號」，再進一步變成簡短的「碼」。常見段落設定成符號，相同的符號對應相同的碼，有利於辨認。

制定符號：尚無最佳演算法，仍有研究空間。經典演算法是Lempel-Ziv Compression。
制定碼：已有最佳演算法，讓碼的總長度達到最小值！經典演算法是Arithmetic Compression、Huffman Compression。
兩者相互配合，產生了各式各樣的演算法：DEFLATE、gzip、bzip2、zopfli、brotli。有興趣的讀者請自行學習。
編碼與壓縮的差別：編碼時，符碼是公定的，符號長度是一個字元，碼長度是整數個byte；壓縮時，符碼是自訂的，長度不定。
【註：因為逐段處理，所以沒有活用到文字先後順序。】
何謂好的壓縮？
預先計算符碼，才能順利壓縮。符碼資訊，必須連同壓縮結果一併儲存，才能順利解壓縮。
所謂好的壓縮，就是讓「壓縮後長度」加「符碼資訊長度」少於「壓縮前長度」。

順帶一提，由於必須額外儲存符碼資訊，即便使用世上最好的壓縮演算法，檔案也可能越壓越大！比方說，已經壓縮過的資料再壓縮一遍，很容易產生這種情形。


Dictionary Compression

Dictionary Compression
用於制定符號。
常見單字、常見字根，當作符號。其餘部分則是一種字元當作一種符號。宛如查字典，通常以Trie作為字典的資料結構。時間複雜度O(N)。

text   | symbol
------ | ------
the    |   0
that   |   1
ing    |   2
is     |   3
ness   |   4
ion    |   5
less   |   6
ed     |   7
a      |   8
b      |   9
c      |   10
:      :   :



text       | symbol       int main() {
---------- | ------           int n = 1 + 1;
int        |   i              return 0;
main()     |   m          }
{          |   {                 ↓
           |   s          ims{
           |   t          tine1p1;
 +         |   p          tr
 =         |   a          }
return 0;  |   r                ↓
}          |   }          ims{⤶tine1p1;⤶tr⤶}
⤶          |   ⤶          
:          :   :

Antidictionary Compression
http://www.stringology.org/DataCompression/dca/index_en.html

Lempel-Ziv Compression

Lempel-Ziv Compression
用於制定符號。有多種變形，共同精神是：
依序讀取字元。遇到生字，就加入字典，然後從零開始加長單字；遇到熟字，就繼續加長單字。
這個演算法基本上沒有什麼道理，但是效果卻不錯。也許裡面有什麼神奇的數學性質，不過我不清楚。
LZ77 / LZ78 / LZW
http://my.stust.edu.tw/sys/read_attach.php?id=58496
LZMA
http://en.wikipedia.org/wiki/LZMA
LZO
http://en.wikipedia.org/wiki/Lempel–Ziv–Oberhumer

Run-length Compression

Run-length Compression
用於制定符號。

aaaabbcabcbbbaaaa ---> a4b2c1a1b1c1b3a4

連續重複符號，精簡成兩個符號。時間複雜度O(N)。
先實施「Burrows-Wheeler Transform」讓相同符號盡量靠在一起，再實施Run-length Compression，可以提升壓縮效果。
UVa 11541 12547 ICPC 3867

Arithmetic Compression（Under Construction!）

Arithmetic Compression（Range Coding）
用於制定碼。
Compress
預先統計符號出現次數，才能順利地壓縮。
依序讀取符號，不斷切割區間，最後得到一個分數。分數換成二進位表示法，小數部分就是碼。

區間寬度設定為1。浮點數運算，遭遇精確度問題。

區間寬度設定為大數。大數運算，遭遇效率問題，況且我們無法預測數字需要多大。

區間寬度設定成整數。整數運算，沒有問題。概念上是從大數取一小段高位數來計算。除不盡就算了，不補零不再除。當位數幾乎用罄、無法分辨符號，才替換下一段高位數。

因為計算過程不夠精準，所以壓縮效果稍微差了一點，不過無傷大雅。時間複雜度O(N)。
Decompress
碼和符號出現次數必須一併儲存，才能順利地解壓縮。
依序讀碼，判斷位於哪個區間。時間複雜度O(N)。

符號長度固定為一個字元的版本。

http://www.drdobbs.com/cpp/data-compression-with-arithmetic-encodin/240169251

不輸出二元碼、而是輸出可見符號的版本。

const char symbol[] = " !#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~";
int id[128];					// symbol to number
const int B = strlen(symbol);	// 93
const int W = 9;
const long long R = 520411082988487293LL;	// 93⁹

char s[100000];	// text
char t[100000];	// code

int cdf[128], rnk[128], cnt[128];

void encode(char s[], int cnt[])
{
	for (int i=0; s[i]; i++) cnt[s[i]]++;
	for (int i=1; i<128; i++) cdf[i] = cdf[i-1] + cnt[i-1];
	for (int i=1; i<128; i++) rnk[i] = rnk[i-1] + !!cnt[i];
	int A = rnk[128-1];					// symbol type
	int N = cdf[128-1] + cnt[128-1];	// symbol count

	long long x = 0, r = R;
	for (int i=0; s[i]; i++)
	{
		int c = s[i];
		if (r >= N)
		{
			r /= N;
			x += cdf[c] * r;
			r *= cnt[c];
		}
		else if (r >= A)
		{
			x += rnk[c] - 1;
			r  = 1;
		}

		if (r < A)
		{
			output(x);
			x = 0;
			r = R;
		}
	}

	if (r != R || A == 1) output(x);
}

int ti = 0;
void output(long long x)
{
	int b[W];
	for (int i=W-1; i>=0; i--) {b[i] = x % B; x /= B;}
	for (int i=0; i= A && si++ < N)
		{
			int c;
			if (r >= N)
			{
				r /= N;
				long long v = x / r;
				for (c=1; c<128 && cdf[c]<=v; c++) ;
				c--;
				x -= cdf[c] * r;
				r *= cnt[c];
			}
			else
			{
				for (c=1; c<128 && rnk[c]-1!=x; c++) ;
				r = 0;
			}
			cout << (char)c;
		}
	}
}

void range_coding()
{
	encode(s, cnt);
	decode(t, cnt);
}

Information
照理來說應該要為大家介紹什麼是「訊息」，不過還是算了。
想讓「壓縮後長度」最短：符號出現次數越多，壓縮後訊息越少，令兩者成反比。訊息套用二進位表示法，即得二元碼。

consider symbol sequence: abaacadb

　 min P(abaacadb)                             P() is information
=> min P(a) ⋅ P(b) ⋅ ... ⋅ P(d) ⋅ P(b)         independent events
=> min log₂(P(a) ⋅ P(b) ⋅ ... ⋅ P(d) ⋅ P(b))   binary code length

objective is minimum when P(a) : P(b) : ... = 1/#(a) : 1/#(b) : ...

由於只知道訊息比例，不知道訊息確切大小，取巧的方式是利用符號出現次數比例，取其小數做為二元碼。
符號出現次數越多，比例越大，小數位數越少，碼長越短。

symbol  count  ratio  binary  code  length  info ratio
------  -----  -----  ------  ----  ------  ----------
a       4      4/8    0.1     1     1       8/4
b       2      2/8    0.01    01    2       8/2
c       1      1/8    0.001   001   3       8/1
d       1      1/8    0.001   001   3       8/1

為了避免碼重複，比例求前綴和。

symbol  count  ratio  total  binary  code
------  -----  -----  -----  ------  ----
a       4      4/8    4/8    0.1     1   
b       2      2/8    6/8    0.11    11  
c       1      1/8    7/8    0.111   111 
d       1      1/8    8/8    1.0     0   

最後一個前綴和是1，二元碼是0，順序不漂亮。因此讓第一個前綴和是0。

symbol  count  ratio  total  binary  code
------  -----  -----  -----  ------  ----
a       4      4/8    0/8    0.0     0   
b       2      2/8    4/8    0.1     1   
c       1      1/8    6/8    0.11    11  
d       1      1/8    7/8    0.111   111 

比例可能除不盡。解法是保留足夠位數，足以分辨符號即可。

symbol  count  ratio  total  binary       code
------  -----  -----  -----  -----------  ----
a       1      1/6    0/6    0.0          0   
b       1      1/6    1/6    0.001010...  001 
c       2      2/6    2/6    0.01010...   01  
d       2      2/6    4/6    0.1010...    1   

最後講個八卦。此演算法是最好的壓縮演算法，然而此演算法最初是IBM公司的專利，大眾不得使用，造成許多遺憾。比如演算法課本，不得已改為介紹Huffman Compression。比如JPEG圖片、MPEG影片的標準規格，不得已改為採用Huffman Compression。
一旦習以為常，就難以回頭了。儘管現在專利已經過期，人人都能使用Arithmetic Compression；然而Huffman Compression卻依然荼毒著大家，成為歷史共業。
Timus 1307

Adaptive Arithmetic Compression

Adaptive Arithmetic Compression
adaptive是隨時視情況調整。dynamic是隨時改變過去輸入資料。online是隨時處理當前輸入資料。不要混淆囉。
壓縮、解壓縮的過程當中，不預先計算符號數量，而是即時更新符號數量。因此壓縮效果不如原始的Arithmetic Compression來得好。使用「Sequence」資料結構，時間複雜度O(NlogN)。
External Memory Algorithm。適合I/O速度很慢、資料量很大的情況。例如網路傳輸，一邊等待下載、一邊解壓縮，爭取時效。

Huffman Compression

Huffman Compression
用於制定碼。
Code Table
符號與碼的對應表，稱作「碼表」。

symbol  | code  | code length
------- | ----- | -----------
a       | 011   | 3
b       | 0011  | 4
c       | 11111 | 5

考慮abbacacc
a出現3次、b出現2次、c出現3次
壓縮後長度：3⋅3 + 4⋅2 + 5⋅3 = 9 + 8 + 15 = 32
碼表長度：3 + 4 + 5 = 12

替每種符號制定獨一無二的碼，碼長皆是整數，資料壓縮後可以明確區分符碼。
先前碼長是分數，此處碼長是整數。關係宛如Fractional Knapsack Problem和0/1 Knapsack Problem。因此壓縮效果不如Arithmetic Compression來得好。
現在要讓「壓縮後長度」與「碼表長度」都盡量短。
Code Tree
碼表的所有碼，存入Trie資料結構，得到「碼樹」。
二元碼的情況下，碼樹是二元樹：左樹枝是0、右樹枝是1。符號位於節點上；從樹根往符號的路線是其二元碼。

在二元樹上面安排各個符號的位置，就能產生一組二元碼，並且保證每個碼都相異。
一個碼千萬不能是另一個碼的開頭，以免解壓縮產生歧義。放到Code Tree上面來看就是：一個節點千萬不能是另一個節點的祖先。想解決這個問題，只要讓符號全部集中於樹葉！

Code Tree的樹葉深度總和，就是「碼表長度」。
碼長即樹葉深度。減少碼長即減少樹葉深度。碼長不斷減少，符號不斷挪往樹根，又要避免成為其他符號的祖先，最後符號都在樹葉，Code Tree形成滿二元樹。

調整滿二元樹的形狀，可以改變碼表長度。Code Tree長得越像完美二元樹，碼表長度就越短。

滿二元樹（full binary tree）：
每個節點只有零個或兩個小孩的二元樹。

完美二元樹（perfect binary tree）：
每片樹葉深度都一致的二元樹。亦是滿二元樹。

UVa 283 644
Code Tree的權重，刻意定義為「壓縮後長度」。
符號出現次數填入樹葉，做為權重。樹葉深度乘上權重，然後加總，定義為Code Tree的權重。

計算Code Tree的權重（Incremental Method）
深度相同的樹葉，可以一併累計權重，再一併乘上深度。逐層累計權重，就得到整棵樹的權重。

計算Code Tree的權重（Recursive Method）
滿二元樹每個內部節點都有兩個小孩。滿二元樹的最深的樹葉，一定有兩片樹葉互為兄弟。

刪除最深、互為兄弟的兩片樹葉，遞迴縮小問題。兩片樹葉權重相加，作為新樹葉的權重，進一步得到遞迴公式：

遞迴式：
原樹權重 = 新樹權重 + 左樹葉權重 + 右樹葉權重

化作一般式：
原樹權重 = 第一次刪除的左樹葉權重 + 第一次刪除的右樹葉權重 +
　　　　   第二次刪除的左樹葉權重 + 第二次刪除的右樹葉權重 +
　　　　　　　　　　　　　　　　　⋮
　　　　   第N-1次刪除的左樹葉權重 + 第N-1次刪除的右樹葉權重

Optimal Code Tree：降低壓縮後長度
Code Tree是哪一種形狀，權重才會最小呢？
根據方纔的公式，Code Tree的權重取決於每次刪除的那兩片樹葉。每次刪除的那兩片樹葉權重越小，Code Tree權重就越小。

換句話說，優先聚合權重最小的兩個節點，最小的相加之後還是最小的，如此遞推下去，Code Tree權重就達到最小值，得到Optimal Code Tree。

以Priority Queue存放節點，就能迅速找出權重最小的兩個節點。總共2N-1個push，2N-2個pop，時間複雜度O(NlogN)。N是一開始的樹葉數目，也就是符號數目。

int freq[8] = {4, 2, 1, 2, 3, 1, 2, 1};	// 符號出現次數

void optimal_code_tree()
{
	// STL預設是Max Heap，比較函式必須相反，採用greater。
	priority_queue, greater > pq;

	// 所有樹葉丟進Priority Queue
	for (int i=0; i<8; ++i)
		pq.push(freq[i]);

	// 聚合N-1次就得到樹根了
	int c = 0;	// Optimal Code Tree的權重
	for (int i=0; i<8-1; ++i)
	{
		// 聚合兩個權重最小的節點
		int a = pq.top(); pq.pop();
		int b = pq.top(); pq.pop();
		pq.push(a + b);	// 新節點丟進Priority Queue
		c += a + b;		// 計算Optimal Code Tree的權重
	}

	cout << "最小的壓縮後長度是" << c;
}

Optimal Code Tree：降低碼表長度
優先聚合碼長總和最小的兩個節點。


int freq[8] = {4, 2, 1, 2, 3, 1, 2, 1};	// 符號出現次數

struct Node
{
	int freq;	// 符號出現次數
	int leaf;	// 各節點涵蓋的樹葉數量
	int length;	// 各節點涵蓋的碼長總和
};

bool operator n2.freq
	return n1.length > n2.length;
}

void optimal_code_tree()
{
	priority_queue pq;

	for (int i=0; i<8; ++i)
		pq.push((Node){freq[i], 1, 0});

	int c = 0;
	for (int i=0; i<8-1; ++i)
	{
		Node a = pq.top(); pq.pop();
		Node b = pq.top(); pq.pop();
		pq.push((Node){
			a.freq + b.freq,
			a.leaf + b.leaf,
			a.length + b.length + a.leaf + b.leaf,
		});
		c += a.freq + b.freq;
	}

	cout << "最小的壓縮後長度是" << c;
	cout << "此時，最小的碼表長度是" <<  pq.top().length;
}

Compress
預先統計符號出現次數，預先建立碼表，才能順利地壓縮。
依序掃描符號，查碼表，將符號換成碼。時間複雜度O(N)。


int freq[256*2-1];		// 符號出現次數
int parent[256*2-1];	// optimal code tree
int left[256*2-1];		// optimal code tree
int right[256*2-1];		// optimal code tree
int bit[256*2-1];		// optimal code tree
int leaf[256*2-1];		// 各節點涵蓋的樹葉數量
int length[256*2-1];	// 各節點涵蓋的碼長總和
vector code[256];	// 碼表，但是code頭尾顛倒

struct cmp
{
	bool operator()(const int& i, const int& j)
	{
		if (freq[i] != freq[j])
			return freq[i] > freq[j];
		return length[i] > length[j];
	}
};

void optimal_code_tree()
{
	for (int i=0; i<256*2-1; ++i) freq[i] = 0;
	for (int i=0; s[i]; ++i) freq[s[i]]++;

	priority_queue, cmp> pq;

	for (int i=0; i<256; ++i)
	{
		leaf[i] = 1;
		length[i] = 0;
		pq.push(i);
	}

	for (int i=256; i<256*2-1; ++i)
	{
		int a = pq.top(); pq.pop();
		int b = pq.top(); pq.pop();
		freq[i] = freq[a] + freq[b];
		parent[a] = parent[b] = i;
		left[i] = a; right[i] = b;
		bit[a] = 0; bit[b] = 1;
		leaf[i] = leaf[a] + leaf[b];
		length[i] = length[a] + length[b] + leaf[i];
		pq.push(i);
	}

	// 從樹葉往樹根走訪，建立碼表。
	for (int i=0; i<256; ++i)
	{
		code[i].clear();
		for (int j=i; j!=256*2-2; j=parent[j])
			code[i].push_back(bit[j]);
	}
}

// 符號長度固定為1個字元。
// 正確的壓縮結果，要讓0與1成為位元。
// 此處便宜行事，直接輸出0/1字串。
void compress(unsigned char* s)
{
	optimal_code_tree(s);

	for ( ; *s; s++)
		for (int i=code[*s].size()-1; i>=0; ++i)
			cout << code[*s][i];
}

Decompress
碼和碼表必須一併儲存，才能順利地解壓縮。
依序掃碼，同時從樹根開始往下走訪Code Tree。一旦走到樹葉，就將碼換成符號、回到樹根。時間複雜度O(N)。


// 符號長度固定為1個字元。
// 正確的壓縮結果，要讓0與1成為位元。
// 此處便宜行事，直接輸入0/1字串。
void decompress(unsigned char* s)
{
	int p = 256*2-2;
	for ( ; *s; s++)
	{
		p = (*s == '0') ? left[p] : right[p];
		if (p < 256)
		{
			cout << (unsigned char)p;
			p = 256*2-2;
		}
	}
}

UVa 240 10954 ICPC 5179 4122

Adaptive Huffman Compression

Adaptive Huffman Compression
不預先建立Optimal Code Tree。即時調整Code Tree的形狀，維持是Optimal Code Tree。
讀入一個符號，符號出現次數加一，Optimal Code Tree對應的樹葉權重加一，該樹葉的祖先們權重也都要跟著加一。
當有需要重新調整Optimal Code Tree的形狀，也就是指其中有一個節點權重加一之後，權重剛好超越了另一個節點的權重（換句話說，這些節點本來權重相同），導致另一個節點必須先聚合，權重加一的節點必須晚一點才能聚合，改變了Optimal Code Tree的形狀。
Code Tree排序所有樹葉
深度相同的樹葉互相對調，Code Tree權重不變。
權重小、位置淺的樹葉，權重大、位置深的樹葉，兩者對調，可讓Code Tree權重變小。

換句話說，權重小的樹葉儘量挪往深處，權重大的樹葉儘量挪往淺處，可讓Code Tree權重變小。
進一步來說，所有樹葉依照權重由小到大排序之後，依序由深到淺安排位置、同一層則隨意安排位置（或者是刻意由左到右安排位置），可讓Code Tree權重達到區域極小值。
Optimal Code Tree排序所有節點

Optimal Code Tree則是全部節點都能如此排序。建立Optimal Code Tree時，每次都是聚合權重最小的兩個節點，因而造就了排序的性質。
節點依照權重排序之後，就很容易搜尋了，能夠快速找到權重相同的節點們。
調整Optimal Code Tree
http://www.stringology.org/DataCompression/fgk/index_en.html
http://www.stringology.org/DataCompression/ahv/index_en.html
節點權重要加一之前，就先與權重相同的節點交換位置，盡量換到最上層、最右端的位置，也就是盡量換到最靠近次大權重值的位置；這個交換不會影響Optimal Code Tree的權重、仍是Optimal Code Tree。如此一來，權重加一之後，不需要改變Code Tree的形狀，仍是Optimal Code Tree；而且所有節點依然是排序好的。
別忘記該樹葉的祖先們，權重也都要加一。採用遞增法，一步一步處理：樹葉權重加一之後，再處理父親權重加一的問題。
我不清楚如何得到碼表長度最短的Optimal Code Tree。

Hu-Tucker Compression

Alphabetic Code Tree
符號必須由小到大、從左往右排列。

特色是：符號的大小順序，就是碼的大小順序。符號比大小，就是碼比大小──可以直接使用壓縮之後的資料比大小。
有一好就有一壞，壓縮效果比起Huffman Compression就遜色了一點。
Alphabetic Code Tree的權重
與Code Tree的權重定義相同。

計算Code Tree的權重（更玄的Recursive Method）
先前計算Code Tree的權重，是刪除深度相同、互為兄弟的兩片樹葉；關註節點之間的高度關係、父子關係。
其實還有另外一種計算方式，是改為刪除深度相同、但是不一定要互為兄弟的兩片樹葉；改為關註高度關係、無視父子關係。最後得到類似的遞迴公式：

遞迴式：
原節點集合 = 新節點集合 + 一片樹葉權重 + 另一片樹葉權重

化作一般式：
原樹權重 = 第一次刪除的樹葉權重 + 第一次刪除的另一片樹葉權重 +
　　　　   第二次刪除的樹葉權重 + 第二次刪除的另一片樹葉權重 +
　　　　　　　　　　　　　　　　　⋮
　　　　   第N-1次刪除的樹葉權重 + 第N-1次刪除的另一片樹葉權重


Optimal Alphabetic Code Tree
http://www.cs.rit.edu/~std3246/thesis/node10.html
http://cseweb.ucsd.edu/classes/wi06/cse202/notes-feb09.pdf
優先聚合權重最小的兩個節點，Alphabetic Code Tree的權重就會達到最小值，就和Optimal Code Tree一樣。
但是Alphabetic Code Tree限定了樹葉的左右順序，所以每次聚合的兩個節點，如果剛好都是樹葉的話，就只能是相鄰的樹葉──如此才能維持符號的左右順序。
只有樹葉必須擔心符號順序問題；樹葉一旦經過聚合之後，就不必再擔心順序問題，也不再隔開其他樹葉。

一、統計各個符號的出現次數。
二、一開始有N個樹葉（節點），權重設定成符號出現次數。
　　現在以bottom-up方式建立Optimal Alphabetic Code Tree：
　甲、兩個權重最小的節點（不能是被隔離的兩片樹葉），相加得到新節點的權重。
　　　此時確立了這兩個節點的深度相同（不見得互為兄弟），
　　　同時確立了新節點深度比它們淺一層（不見得是它們的父親）。
　乙、聚合N-1次就得到樹根了，不過只能確立所有節點的高度關係。
　　　得到Optimal Alphabetic Code Tree的權重。
　丙、以top-down方式，按照高度關係，確立所有節點的父子關係。
　　　即形成Optimal Alphabetic Code Tree。

時間複雜度為O(NlogN)。不過實作比較複雜。
【待補程式碼】
相似的樹
這三棵樹非常相似，都是「深度」乘上「符號出現次數」，令總和最小。

Optimal Binary Search Tree
所有節點都有符號出現次數，節點的位置必須按照大小排列順序。O(N²)。

Optimal Alphabetic Binary Code Tree
只有樹葉擁有符號出現次數，樹葉的位置必須按照大小排列順序。O(NlogN)。

Optimal Binary Code Tree
只有樹葉擁有符號出現次數，樹葉的位置順序隨意。O(NlogN)。

實務上，符號種類數目通常很少，亦可運用OBST的O(N²)演算法，求得OABT；程式碼結構簡單，執行時間也比較短。
UVa 12057 PKU 1738
延伸閱讀：Garcia-Wachs Algorithm
http://www.math.tau.ac.il/~haimk/seminar00/dana-MCBT.ppt
演算法簡單很多，但是證明也複雜很多。




































資料列壓縮實作 | Microsoft Docs



















資料列壓縮實作Row Compression Implementation


2016-6-30
8 分鐘可讀完
參與者









本主題的適用對象：SQL Server (自 2016 起)Azure SQL DatabaseAzure SQL 資料倉儲平行處理資料倉儲THIS TOPIC APPLIES TO: SQL Server (starting with 2016)Azure SQL DatabaseAzure SQL Data Warehouse Parallel Data Warehouse 
 本主題摘要說明  Database EngineDatabase Engine 如何實作資料列壓縮。This topic summarizes how  Database EngineDatabase Engine implements row compression. 這個摘要提供協助您計畫資料所需之儲存空間的基本資訊。This summary provides basic information to help you plan the storage space that you need for your data. 
 啟用壓縮僅會變更與資料類型 (但不與其語法或語意) 相關聯之資料的實體儲存格式。Enabling compression only changes the physical storage format of the data that is associated with a data type but not its syntax or semantics. 當啟用一或多個資料表的壓縮時，不需要變更應用程式。Application changes are not required when one or more tables are enabled for compression. 新的記錄儲存格式具有下列的主要變更：The new record storage format has the following main changes: 

降低與記錄相關聯的中繼資料負擔。It reduces the metadata overhead that is associated with the record. 此中繼資料是有關資料行、其長度和位移的資訊。This metadata is information about columns, their lengths and offsets. 在某些情況下，中繼資料負擔可能會比舊的儲存格式還大。In some cases, the metadata overhead might be larger than the old storage format. 

針對數值類型 (例如 integer、 decimal和 float) 以及依據數值的類型 (例如 datetime 和 money) 使用可變長度儲存格式。It uses variable-length storage format for numeric types (for example integer, decimal, and float) and the types that are based on numeric (for example datetime and money). 

使用可變長度格式 (不儲存空白字元) 而儲存固定字元字串。It stores fixed character strings by using variable-length format by not storing the blank characters. 


註意 所有資料類型的 NULL 和 0 值都經過最佳化而不使用任何位元組。NULL and 0 values across all data types are optimized and take no bytes. 

資料列壓縮如何影響儲存How Row Compression Affects Storage
 下表描述資料列壓縮如何影響  SQL ServerSQL Server 和  Azure SQL DatabaseAzure SQL Database中的現有類型。The following table describes how row compression affects the existing types in  SQL ServerSQL Server and  Azure SQL DatabaseAzure SQL Database. 此表格不包含可藉由使用頁面壓縮而達成的節省量。The table does not include the savings that can be achieved by using page compression. 



資料類型Data type
儲存是否受到影響？Is storage affected?
描述Description




tinyinttinyint
否No
所需的最小儲存區是 1 個位元組。1 byte is the minimum storage needed.


smallintsmallint
是Yes
如果 1 個位元組能容納此值，只會使用 1 個位元組。If the value fits in 1 byte, only 1 byte will be used.


intint
是Yes
僅使用所需的位元組。Uses only the bytes that are needed. 例如，如果值可以儲存在 1 個位元組內，則儲存只會使用 1 個位元組。For example, if a value can be stored in 1 byte, storage will take only 1 byte.


bigintbigint
是Yes
僅使用所需的位元組。Uses only the bytes that are needed. 例如，如果值可以儲存在 1 個位元組內，則儲存只會使用 1 個位元組。For example, if a value can be stored in 1 byte, storage will take only 1 byte.


decimaldecimal
是Yes
此儲存與 Vardecimal 儲存格式完全相同。This storage is exactly same as the vardecimal storage format.


numericnumeric
是Yes
此儲存與 Vardecimal 儲存格式完全相同。This storage is exactly same as the vardecimal storage format.


bitbit
是Yes
中繼資料負荷將此設為 4 個位元。The metadata overhead brings this to 4 bits.


smallmoneysmallmoney
是Yes
藉由使用 4 位元組整數來使用整數資料表示。Uses the integer data representation by using a 4-byte integer. 貨幣值會乘以 10000，再移除小數點之後的任何數字以儲存產生的整數值。Currency value is multiplied by 10000 and the resulting integer value is stored by removing any digits after the decimal point. 此類型的儲存最佳化與整數類型類似。This type has a storage optimization similar to that for integer types.


moneymoney
是Yes
藉由使用 8 位元組整數來使用整數資料表示。Uses the integer data representation by using an 8-byte integer. 貨幣值會乘以 10000，再移除小數點之後的任何數字以儲存產生的整數值。Currency value is multiplied by 10000 and the resulting integer value is stored by removing any digits after the decimal point. 此類型的範圍比 smallmoney大。This type has a larger range than smallmoney. 此類型的儲存最佳化與整數類型類似。This type has a storage optimization similar to that for integer types.


floatfloat
是Yes
將不會儲存最小顯著性位元組為零的項目。Least significant bytes with zeros are not stored. float 壓縮主要適用於尾數中的非小數值。float compression is applicable mostly for nonfractional values in mantissa.


realreal
是Yes
將不會儲存最小顯著性位元組為零的項目。Least significant bytes with zeros are not stored. real 壓縮主要適用於尾數中的非小數值。real compression is applicable mostly for nonfractional values in mantissa.


smalldatetimesmalldatetime
否No
藉由使用兩個 2 位元組整數來使用整數資料表示法。Uses the integer data representation by using two 2-byte integers. 日期會使用 2 個位元組，The date takes 2 bytes. 是 1901 年 1 月 1 日之後的日數。It is the number of days since 1/1/1901. 這需要 2 個位元組，從 1902 開始；This needs 2 bytes starting from 1902. 因此在該時間點後就無法進行節省。Therefore, there is no savings after that point. 時間是午夜之後的分鐘數。The time is the number of minutes since midnight. 稍微超過 4AM 的時間值會開始使用第二個位元組。Time values that are slightly past 4AM start to use the second byte. 如果 smalldatetime 只會用來表示日期 (常見的情況)，則時間是 0.0。If a smalldatetime is only used to represent a date (a common case), the time is 0.0. 壓縮會針對資料列壓縮以最大顯著性位元組格式儲存時間而節省 2 個位元組。Compression saves 2 bytes by storing the time in most significant byte format for row compression.


datetimedatetime
是Yes
藉由使用兩個 4 位元組整數來使用整數資料表示。Uses the integer data representation by using two 4-byte integers. 整數值代表日數，基底日期則是 1900 年 1 月 1 日。The integer value represents the number of days with base date of 1/1/1900. 第一個 2 位元組最多可代表到 2079 年。The first 2 bytes can represent up to the year 2079. 在該時間點之前，此處的壓縮一定可以節省 2 個位元組。Compression can always save 2 bytes here until that point. 每個整數值都代表 3.33 毫秒。Each integer value represents 3.33 milliseconds. 壓縮在第一個五分鐘內就會用盡第一個 2 個位元組，而需要在 4PM 之後使用第四個位元組。Compression exhausts the first 2 bytes in first five minutes and needs the fourth byte after 4PM. 因此，在 4PM 之後僅能節省 1 個位元組。Therefore, compression can save only 1 byte after 4PM. 當 datetime 像任何其他整數一樣進行壓縮時，壓縮可以在日期中節省 2 個位元組。When datetime is compressed like any other integer, compression saves 2 bytes in the date.


datedate
否No
藉由使用 3 個位元組來使用整數資料表示法。Uses the integer data representation by using 3 bytes. 這代表從 0001 年 1 月 1 日開始的日期。This represents the date from 1/1/0001. 對於現代的日期而言，資料列壓縮會使用所有 3 個位元組。For contemporary dates, row compression uses all 3 bytes. 如此不會達成任何節省量。This achieves no savings.


timetime
否No
藉由使用 3 到 6 個位元組來使用整數資料表示法。Uses the integer data representation by using 3 to 6 bytes. 有多個以 0 到 9 的有效位數可以使用 3 到 6 個位元組。There are various precisions that start with 0 to 9 that can take 3 to 6 bytes. 壓縮空間的用法如下所示：Compressed space is used as follows: Precision = 0。Bytes = 3。Precision = 0. Bytes = 3. 每個整數值都代表一秒。Each integer value represents a second. 壓縮可藉由使用 2 個位元組而最多代表到 6PM 的時間，因而可能節省 1 個位元組。Compression can represent time up to 6PM by using 2 bytes, potentially saving 1 byte. Precision = 1。Bytes = 3。Precision = 1. Bytes = 3. 每個整數值都代表 1/10 秒。Each integer value represents 1/10 seconds. 壓縮在 2AM 之前會使用第三個位元組。Compression uses the third byte before 2AM. 產生的節省量很少。Results in little savings. Precision = 2。Bytes = 3。Precision = 2. Bytes = 3. 與前例類似，不太可能達到節省量。Similar to the previous case, it is unlikely to achieve savings. Precision = 3。Bytes = 4。Precision = 3. Bytes = 4. 因為在 5AM 之前就會使用了第一個 3 位元組，所以節省的量很少。Because the first 3 bytes are taken by 5AM, achieves little savings. Precision = 4。Bytes = 4。Precision = 4. Bytes = 4. 在第一個 27 秒內就會使用第一個 3 位元組。The first 3 bytes are taken in the first 27 seconds. 不預期有任何節省量。No savings are expected. Precision = 5，Bytes = 5Precision = 5, Bytes = 5. 在中午 12 點之後會使用第五個位元組。Fifth byte will be used after 12-noon. Precision = 6 和 7，Bytes = 5。Precision = 6 and 7, Bytes = 5. 不會達到任何節省量。Achieves no savings. Precision = 8，Bytes = 6Precision = 8, Bytes = 6. 在 3AM 之後會使用第六個位元組。Sixth byte will be used after 3AM.  請註意，資料列壓縮的儲存沒有變更。Note that there is no change in storage for row compression. 整體而言，無法預期從壓縮 time 資料類型達到很大的節省量。Overall, not much savings can be expected from compressing the time data type.


datetime2datetime2
是Yes
藉由使用 6 到 9 個位元組來使用整數資料表示。Uses the integer data representation by using 6 to 9 bytes. 第一個 4 位元組代表日期。The first 4 bytes represent the date. 由時間所使用的位元組會依所指定時間的有效位數而定。The bytes taken by the time will depend on the precision of the time that is specified. 整數值代表自 0001 年 1 月 1 日開始的日數，上限則是 9999 年 12 月 31 日。The integer value represents the number of days since 1/1/0001 with an upper bound of 12/31/9999. 為了代表 2005 年中的日期，壓縮會使用 3 個位元組。To represent a date in year 2005, compression takes 3 bytes. 不會節省任何時間，因為它針對不同的時間有效位數而允許 2 到 4 個位元組。There is no savings on time because it allows for 2 to 4 bytes for various time precisions. 因此，對於一秒鐘的時間有效位數而言，壓縮會為時間使用 2 個位元組，而在 255 秒之後使用第二個位元組。Therefore, for one-second time precision, compression uses 2 bytes for time, which takes the second byte after 255 seconds.


datetimeoffsetdatetimeoffset
是Yes
類似 datetime2，但此格式 (HH:MM) 的時區有 2 個位元組。Resembles datetime2, except that there are 2 bytes of time zone of the format (HH:MM). 與 datetime2類似，壓縮可節省 2 個位元組。Like datetime2, compression can save 2 bytes. 對於時區值，MM 值在多數情況下可能是 0。For time zone values, MM value might be 0 for most cases. 因此，壓縮可能可以節省 1 個位元組。Therefore, compression can possibly save 1 byte. 資料列壓縮的儲存沒有變更。There are no changes in storage for row compression.


charchar
是Yes
會移除尾端填補字元。Trailing padding characters are removed. 請註意，不論使用的定序為何，  Database EngineDatabase Engine 都會插入相同的填補字元。Note that the  Database EngineDatabase Engine inserts the same padding character regardless of the collation that is used.


varcharvarchar
否No
沒有影響。No effect.


texttext
否No
沒有影響。No effect.


ncharnchar
是Yes
會移除尾端填補字元。Trailing padding characters are removed. 請註意，不論使用的定序為何，  Database EngineDatabase Engine 都會插入相同的填補字元。Note that the  Database EngineDatabase Engine inserts the same padding character regardless of the collation that is used.


nvarcharnvarchar
否No
沒有影響。No effect.


ntextntext
否No
沒有影響。No effect.


binarybinary
是Yes
會移除尾端的零。Trailing zeros are removed.


varbinaryvarbinary
否No
沒有影響。No effect.


imageimage
否No
沒有影響。No effect.


cursorcursor
否No
沒有影響。No effect.


timestamp / rowversiontimestamp / rowversion
是Yes
藉由 8 個位元組以使用整數資料表示法。Uses the integer data representation by using 8 bytes. 有針對每個資料庫維護時間戳記計數器，且其值從 0 開始。There is a timestamp counter that is maintained for each database, and its value starts from 0. 這可以像任何其他整數值一般進行壓縮。This can be compressed like any other integer value.


sql_variantsql_variant
否No
沒有影響。No effect.


uniqueidentifieruniqueidentifier
否No
沒有影響。No effect.


tabletable
否No
沒有影響。No effect.


xmlxml
否No
沒有影響。No effect.


使用者定義型別User-defined types
否No
這在內部表示為 varbinary。This is represented internally as varbinary.


FILESTREAMFILESTREAM
否No
這在內部表示為 varbinary。This is represented internally as varbinary.



另請參閱See Also
 資料壓縮 Data Compression  頁面壓縮實作 Page Compression Implementation 










編輯										


共用

Twitter
Facebook


|

佈景主題


淺色
深色































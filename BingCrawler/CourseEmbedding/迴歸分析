


迴歸分析 - 維基百科，自由的百科全書































 







迴歸分析

維基百科，自由的百科全書


					前往：					導覽，					搜尋












統計學系列條目


迴歸分析





模型




線性回歸
簡單迴歸（英語：Simple linear regression）
普通最小平方法（英語：Ordinary least squares）
多項式迴歸（英語：Polynomial regression）
一般線性模型






廣義線性模式
離散選擇（英語：Discrete choice）
邏輯迴歸
多項羅吉特（英語：Multinomial logit）
混合羅吉特
波比（英語：Probit model）
多項式波比（英語：Multinomial probit）
排序性模型（英語：Ordered logit）
有序波比（英語：Ordered probit）
泊松迴歸






等級線性模型
固定效應（英語：Fixed effects model）
隨機效應（英語：Random effects model）
混合模型（英語：Mixed model）






非線性迴歸（英語：Nonlinear regression）
非參數（英語：Nonparametric regression）
半參數（英語：Semiparametric regression）
穩健（英語：Robust regression）
分位數迴歸
保序迴歸
主成分（英語：Principal component regression）
最小角
局部（英語：Local regression）
分段（英語：Segmented regression）






含誤差變量（英語：Errors-in-variables models）




估計




最小平方法
普通最小平方法（英語：Ordinary least squares）
線性
偏最小平方迴歸
總體（英語：Total least squares）
廣義（英語：Generalized least squares）
加權
非線性（英語：Non-linear least squares）
非負（英語：Non-negative least squares）
重複再加權（英語：Iteratively reweighted least squares）
嶺迴歸（英語：Tikhonov regularization）
LASSO






最小絕對值導數法（英語：Least absolute deviations）
貝葉斯（英語：Bayesian linear regression）
貝葉斯多元（英語：Bayesian multivariate linear regression）




背景




迴歸模型檢驗（英語：Regression model validation）
平均響應和預測響應（英語：Mean and predicted response）
誤差和殘差
擬合優度（英語：Goodness of fit）
學生化殘差（英語：Studentized residual）
高斯－馬可夫定理






 機率與統計主題







閱
論
編









簡單線性迴歸分析的例子


迴歸分析（英語：Regression Analysis）是一種統計學上分析數據的方法，目的在於瞭解兩個或多個變數間是否相關、相關方向與強度，並建立數學模型以便觀察特定變數來預測研究者感興趣的變數。更具體的來說，迴歸分析可以幫助人們瞭解在只有一個自變量變化時因變量的變化量。一般來說，通過迴歸分析我們可以由給出的自變量估計因變量的條件期望。
迴歸分析是建立因變數



Y


{\displaystyle Y}

（或稱依變數，反應變數）與自變數



X


{\displaystyle X}

（或稱獨變數，解釋變數）之間關係的模型。簡單線性回歸使用一個自變量



X


{\displaystyle X}

，複迴歸使用超過一個自變量（




X

1


,

X

2


.
.
.

X

i




{\displaystyle X_{1},X_{2}...X_{i}}

）。



目錄


1 起源
2 迴歸分析原理

2.1 參數估計


3 迴歸模型
4 迴歸分析的種類

4.1 簡單線性回歸
4.2 複迴歸（或多變量迴歸）
4.3 對數線性迴歸
4.4 非線性迴歸
4.5 邏輯迴歸
4.6 偏迴歸
4.7 自迴歸

4.7.1 自迴歸滑動平均模型
4.7.2 差分自迴歸滑動平均模型
4.7.3 向量自迴歸模型




5 參閱
6 參考資料
7 外部連結



起源[編輯]
迴歸的最早形式是最小平方法，由1805年的勒壤得(Legendre)[1]，和1809年的高斯(Gauss)出版[2]。勒壤得和高斯都將該方法應用於從天文觀測中確定關於太陽的物體的軌道（主要是彗星，但後來是新發現的小行星）的問題。 高斯在1821年發表了最小平方理論的進一步發展[3]，包括高斯－馬可夫定理的一個版本。
「迴歸」（或作「回歸」）一詞最早由法蘭西斯·高爾頓（Francis Galton）所使用[4][5]。他曾對親子間的身高做研究，發現父母的身高雖然會遺傳給子女，但子女的身高卻有逐漸「迴歸到中等（即人的平均值）」的現象。不過當時的迴歸和現在的迴歸在意義上已不盡相同。
在1950年代和60年代，經濟學家使用機械電子桌面計算器來計算迴歸。在1970年之前，它有時需要長達24小時從一個迴歸接收結果[6]。
迴歸分析原理[編輯]

目的在於找出一條最能夠代表所有觀測資料的函數（迴歸估計式）。
用此函數代表因變數和自變數之間的關係。

參數估計[編輯]

矩估計（Method of Moment、MOM）
最小平方法（Ordinary Least Square Estimation, OLSE）
最大似然估計（Maximum Likelihood Estimation, MLE）

迴歸模型[編輯]
迴歸模型主要包括以下變量：

未知參數，記為β，可以代表一個純量或一個向量。
自變量，X。
因變量，Y。

迴歸模型將Y和一個關於X和β的函數關聯起來。





Y
≈
f
(

X

,

β

)


{\displaystyle Y\approx f(\mathbf {X} ,{\boldsymbol {\beta }})}



迴歸分析的種類[編輯]
簡單線性回歸[編輯]
簡單線性迴歸（英語：Simple linear regression）（英語：simple linear regression）

應用時機


以單一變數預測
判斷兩變數之間相關的方向和程度

複迴歸（或多變量迴歸）[編輯]
複迴歸分析（英語：multiple regression analysis）是簡單線性迴歸的一種延伸應用，用以瞭解一個依變項與兩組以上自變項的函數關係。
對數線性迴歸[編輯]
對數線性迴歸（英語：Log-linear model）（英語：Log-linear model），是將解釋變項（實驗設計中的自變項）和反應變項（實驗設計中的依變項）都取對數值之後再進行線性迴歸，所以依據解釋變項的數量，可能是對數簡單線性迴歸，也可能是對數複迴歸。
非線性迴歸[編輯]
邏輯迴歸[編輯]
主條目：邏輯迴歸
邏輯迴歸（英語：Logistic Regression）
偏迴歸[編輯]
偏迴歸（英語：Partial Regression）（英語：Partial Regression）
自迴歸[編輯]
主條目：自迴歸模型
自迴歸滑動平均模型[編輯]
主條目：ARMA模型
差分自迴歸滑動平均模型[編輯]
主條目：ARIMA模型
向量自迴歸模型[編輯]
主條目：向量自迴歸模型
參閱[編輯]


機率與統計主題




曲線擬合
估計理論
廣義線性模型
多元常態分佈
皮爾遜積矩相關係數
信號處理
相關分析
多變量統計


參考資料[編輯]


^ A.M. Legendre. Nouvelles méthodes pour la détermination des orbites des comètes, Firmin Didot, Paris, 1805. 「Sur la Méthode des moindres quarrés」 appears as an appendix.
^ C.F. Gauss. Theoria Motus Corporum Coelestium in Sectionibus Conicis Solem Ambientum. (1809)
^ C.F. Gauss. Theoria combinationis observationum erroribus minimis obnoxiae. (1821/1823)
^ Mogull, Robert G. Second-Semester Applied Statistics. Kendall/Hunt Publishing Company. 2004: 59. ISBN 0-7575-1181-3. 
^ Galton, Francis. Kinship and Correlation (reprinted 1989). Statistical Science (Institute of Mathematical Statistics). 1989, 4 (2): 80–86. JSTOR 2245330. doi:10.1214/ss/1177012581. 
^ Rodney Ramcharan. Regressions: Why Are Economists Obessessed with Them? March 2006. Accessed 2011-12-03.


外部連結[編輯]

解讀迴歸分析的原理及結構









閱
論
編


統計學






描述統計學





連續變數機率分佈






集中趨勢


平均數（平方 · 算術 · 幾何 · 調和 · 算術-幾何 · 幾何-調和 · 希羅|平均數不等式） · 中位數 · 眾數







離散程度


全距 · 標準差 · 變異係數 · 百分位數 · 四分差 · 四分位數 · 變異數 · 標準分數 · 切比雪夫不等式







分佈形態（英語：Shape of the distribution）


偏態 · 峰態










離散變數機率分佈


次數（英語：Count data） · 列聯表（英語：Contingency table）












推論統計學
和 假設檢定





推論統計學


置信區間 · 區間估計（英語：Interval estimation） · 顯著性差異 · 元分析 · 貝氏推論







實驗設計


統計總量 · 抽樣 · 重複（英語：Replication (statistics)） · 阻礙 · 特敏度 · 區集（英語：Blocking (statistics)）







樣本量（英語：Sample size）


統計功效 · 效應值 · 標準誤 · 虛無假設 · 對立假設（英語：Alternative hypothesis） · 第一型和第二型誤差 · 統計檢定力







常規估計


貝葉斯推論 · 區間估計（英語：Interval estimation） · 最大似然估計 · 最小距離估計（英語：Minimum distance estimation） · 矩量法 · 最大間距







特效檢驗


Z檢驗 · 學生t檢驗 · F檢驗 · 卡方檢驗 · Wald檢驗（英語：Wald test） · 曼-惠特尼檢驗（英語：Mann–Whitney U test） · 秩和檢驗







生存分析


生存函數 · 乘積極限估計量 · 對數秩和檢定 · 失效率 · 危險比例模式









相關及
迴歸分析





相關性


混淆變項（英語：Confounding） · 皮爾森積差相關係數 · 等級相關（英語：Rank correlation） (史匹曼等級相關係數 · 肯德等級相關係數（英語：Kendall tau rank correlation coefficient）)







線性迴歸


線性模式（英語：Linear model） · 一般線性模式 · 廣義線性模式 · 變異數分析 · 協變異數分析（英語：Analysis of covariance）







非線性迴歸（英語：Nonlinear regression）


非參數迴歸模型（英語：Nonparametric regression） · 半參數迴歸模型（英語：Semiparametric regression） · Logit模型









統計圖形

圓餅圖 · 長條圖 · 雙標圖 · 箱形圖 · 管制圖 · 森林圖（英語：Forest plot） · 直方圖 · QQ圖 · 趨勢圖 · 散佈圖（英語：Scatter plot） · 莖葉圖（英語：Stem-and-leaf display） · 雷達圖（英語：Radar chart） · 示意地圖









分類
主題
共享資源
專題













權威控制



GND: 4129903-6
NDL: 00564579












 
						取自 "https://zh.wikipedia.org/w/index.php?title=迴歸分析&oldid=43004164"					
4 個分類：回歸分析統計方法計量經濟學精算隱藏分類：包含規範控制信息的維基百科條目 



導覽選單


個人工具

沒有登入對話貢獻建立帳號登入 



命名空間

條目
討論




台灣正體



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






查看

閱讀
編輯
檢視歷史



更多







搜尋



 







導航


首頁分類索引特色內容新聞動態近期變更隨機條目 



說明


說明維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



其他專案


維基共享資源 



列印/匯出


下載成 PDF 



工具


連結至此的頁面相關變更上傳檔案特殊頁面可列印版靜態連結頁面資訊維基數據 項目引用此頁面 



其他語言


العربيةAzərbaycancaБългарскиCatalàČeštinaDanskDeutschΕλληνικάEnglishEsperantoEspañolEuskaraفارسیSuomiFrançaisGalegoMagyarBahasa IndonesiaÍslenskaItaliano日本語Basa Jawa한국어LatviešuNederlandsNorsk nynorskNorsk bokmålPolskiPortuguêsРусскийSimple EnglishBasa SundaSvenskaТоҷикӣTagalogTürkçeУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯連結 





 本頁面最後修訂於2017年1月30日 (週一) 12:59。
本站的全部文字在創用CC 姓名標示-相同方式分享 3.0 協議之條款下提供，附加條款亦可能應用（請參閱使用條款）。
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發人員
Cookie 聲明
手機版檢視



 

 










SPSS 多變項分析 多元迴歸分析快訣 詮釋篇 統雄-統計神掌 Statistics/SPSS Canon: Multiple Linear Regression_Interpretation, By Sean TX Wu

































統雄-統計神掌 多元迴歸 分析1


多元判定係數與標準化迴歸係數的詮釋
			Multiple Linear Regression, MLR Interpretation
















研究方法講義目錄
資訊管理講義目錄
數位文創/數位內容講義目錄
數位音樂講義目錄
產學合作-就業進修講義目錄
人文素養-人與社會講義目錄 
人類行為+資訊管理研究目錄
網路使用/電子商務研究目錄
網路教育研究目錄
數位音樂作品目錄








神掌打通任督二脈‧易筋經以簡馭繁 

 符號意義:統雄快訣 
延伸閱讀 
進階議題 
警示訊息

多變項-多因子分析常用模型簡介

多元迴歸分析特色

概念模型與分析方法摘要

多元迴歸統計模式

淨迴歸係數

未標準化迴歸係數

多元迴歸之變異數分析

多元判定係數

多元相關係數

標準化迴歸係數

前置標準化


b與β 的關係：變動vs.預測力

假設檢定

自變項篩選方法

多元迴歸的前提、限制、爭論與未來

多元迴歸分析: SPSS 應用




多元迴歸目的是以多個獨立自變項預測一個應變項，本文解說：迴歸係數與相關係數之不同，多元迴歸之變異數分析，假設檢定，多元判定係數，多元相關係數，未標準化迴歸係數，標準化迴歸係數，與自變項篩選方法。辨別b與β 的關係：變動vs.預測力。
下載SPSS範例實作，解說什麼是：迴歸方法的選擇、選擇變數(Selection 
Variable)、觀察值標記(Case 
Labels)、加權變項(WLS Weight)、選擇統計量、與報表詮釋。




多元迴歸分析特色

 多元迴歸的目的是以多個自變項預測一個應變項，分析各自變項對應變項「獨立影響」的程度；同時具備篩選自變項的能力，從而發展、檢定多個包含不同自變項的模式。

多元迴歸分析是由Pearson(1908)所提出，
在傳統古典統計學教科書上，都把這項觀念作為統計的最高技術，實務上，也是建構各種多變項模型的基礎、扮演最重要的技術角色。

 In statistics, linear regression is an approach to modeling the relationship 

between a scalar dependent variable y and one or more explanatory variables 

denoted X. The case of one explanatory variable is called simple regression. 

More than one explanatory variable is multiple regression. (This in turn 

should be distinguished from multivariate linear regression, where multiple 

correlated dependent variables are predicted, rather than a single scalar 

variable.)

 In linear regression, data is modeled using linear predictor functions, and 

unknown model parameters are estimated from the data. Such models are called 

linear models. Most commonly, linear regression refers to a model in which 

the conditional mean of y given the value of X is an affine function of X. 

Less commonly, linear regression could refer to a model in which the median, 

or some other quantile of the conditional distribution of y given X is 

expressed as a linear function of X. 



理論概念模型


分析方法與其說明




多因子相關理論

多元迴歸模型
因子間關係：彼此獨立



目的

各因子共同作用時，是否對應變項產生獨立影響，與其影響的程度。

差異/相關理論的概念模型完全相同，區別理論類型與統計工具的選擇方法如下。
SPSS 
工具
應變項：連續資料/自變項：連續資料
多元迴歸分析。
多個連續資料之自變項，個別對應變項預測力的分析。
因子獨立性
這項模型成立的前提是各因子之間具備獨立性。

但因子之間可能因具備「交互作用」或「共線性」或「中介作用」而不符獨立性，就必須作進一步分析，發展不同的模型。





 多元迴歸統計模式

 In MLR, the goal is to predict, knowing the measurements collected on N

subjects, the value of the dependent variable Y from a set of K independent 

variables {X1, . . . ,Xi, . . . ,Xk}. We denote by X 

the N × (K + 1) augmented matrix collecting the data for the independent 

variables (this matrix is called augmented because the first column is 

composed only of ones), and by y the N × 1 vector of observations for the 

dependent variable.

Multiple regression finds a set of partial regression coefficients bk 

such that the dependent variable could be approximated as well as possible 

by a linear combination of the independent variables (with the bi 

』s being the weights of the combination). Therefore, a predicted value, 

denoted Y , of the dependent variable is obtained as the following:

Y = b0 + b1X1 

+  b2X2 + 

... +  bkXk 

+ e

 對「第1類知識」而言，是肯定迴歸現象存在，而沒有真實誤差項 

e的多元一次方程式，如果觀察值並不完全符合迴歸方程式，是工具誤差、傳導誤差所造成的。

 對「第2類知識」的統計「逆向」思想而言，就必須考慮「看到的迴歸不是真的迴歸」，就母群而言包括真實誤差項e，這個誤差是理論不正確所造成的。

多元迴歸統計模式中的 b 若作 β，e 

作 
ε，表達不同的意義。有些文獻混淆不清，讀者必須特別註意提防。這些符號的正確意義與運用，以下再詳細說明。 

 每1個Xi 必須是彼此獨立的，幾何學上的意義就是必須是彼此兩兩正交(pairwise 

orthogonal)的。

淨迴歸係數 Partial Regression 

Coefficients

 以上的 bi，是不考慮誤差項 

e時，由偏微分的最小平方法(Least squares)計算而得，故可特稱為淨迴歸係數 Partial Regression Coefficients。表示每1個Xi ，單獨對Y 的影響方向與程度，屬微積分與幾何學上的意義。

 推算 bi所採用的最小平方法，還包括各種子途徑，如OLS, 

PLS…等，屬於演算的進階論題，在此不深敘。

 The partial regression coefficient is also called regression coefficient, 

regression weight, partial regression weight, slope coefficient or partial 

slope coefficient. It is used in the context of multiple linear regression 

(MLR) analysis and gives the amount by which the dependent variable (DV) 

increases when one independent variable (IV) is increased by one unit and 

all the other independent variables are held constant. This coefficient is 

called partial because its

value depends, in general, upon the other independent variables. 

Specifically, the value of the partial coefficient for one independent 

variable will vary, in general, depending upon the other independent 

variables included in the regression equation.

 未標準化迴歸係數 Unstandardized Coefficients

 根據以上程序產生的多元迴歸係數，具備彼此獨立性，也是迴歸方程式的係數值，表現的是幾何上的斜率概念。在統計思想中，特稱為未標準化迴歸係數。


 多元迴歸之變異數分析

 對統計思想而言，就必須考慮誤差項 e的作用，而進行變異數分析，以便進一步作迴歸係數 bi，是否顯著的假設檢定。

 SSR: SS of Regression

 SSE: SS of Error

 SST: SS of Total

 其中「迴歸」即為可預測部分，「隨機」即誤差部分，又是不同名詞，相同意義。



 多元判定係數 Multiple 

Determination Coefficient

 統計思想會考慮模式解釋力、預測力的問題，所以有以下衡量指標。

R2 稱為多元判定係數（multiple 

determination coefficient），相當於總變異中可被解釋之百分比。



 調整判定係數 Adjusted
R2 

 如果自變項的個數很多，就要用調整後的判定係數代替原始的判定係數，因為自變項愈多，R2 

會變大，調整以避免膨脹。

多元相關係數 Multiple 

Correlation Coefficient

 將判定係數開平方，就是多元相關係數 R 。
0 =< R =< 1 



     R < .3


相關性不重要




  .3 < R <.7


相關重要性中低，視個案而定。




   .7< R <.9


相關性具重要性




   .9 <R


相關性具高重要性





 標準化迴歸係數 Standardized Coefficients

 未標準化迴歸係數的單位，因各自變項不同而不同，所以無法彼此比較。

 而作多元迴歸的目的，通常是要比較各自變項之間的預測力，這時就要使用標準化迴歸係數。



 亦即：各未標準化迴歸係數，乘上：「自變項之標準差除以應變項之標準差」。

前置標準化

 有些研究分析程序，是在「資料整理」階段，就將資料集「標準化」，亦即將資料全部轉換為平均數為0，測量值為-1至1的資料。

 		   這是在電腦發明以前的可簡化計算的方式，以今日的電腦能力，已無如此處理必要。

 以標準化資料所計算的淨迴歸係數，就是標準化迴歸係數。

b與β 的關係：變動vs.預測力

註意：有些文獻，b與β不分。不僅弄昏讀者，更使未標準化與標準化迴歸係數混淆，造成嚴重觀念錯誤。

			有些文獻用 b 表示樣本迴歸係數，β表示母群迴歸係數；以類比以表示樣本平均數，以 
			μ 表示母群平均數，在溝通上也容易產生困擾。

在觀念正確、與名詞一致的考量上，應用 b 表示未標準化迴歸係數，β 表示標準化迴歸係數，SPSS報表也是遵循此準則。

b 表示的是幾何學上斜率、變動程度的意義，而 β 表示的是對樣本、對已發生事件解釋力、或對母群、對未來預期事件的預測力。

 

假設檢定

 多元迴歸之假設檢定，就是檢定各自變項對對應變項「獨立影響」的程度 β。 

 		    假設檢定的呈現法，包括總檢定與邊際檢定兩種。

 總檢定

 假設迴歸模式中的所有 β 係數是否全部為0。

當 β 係數不全為0時，Y與(X1,X2,…,XK)才具有對應變項的的函數關係與預測力。 

H0: β1= 

	β2= 

... = βk= 

0

H1: βj≠0，對某些j 
(j=1,2,…,K) 


 個別檢定 Marginal Tests（一般常用）

 假設個別自變項之 β 係數(j, j=1,2,…,K)是否為0，共要作K次檢定。

H0: βj=0 

(j=1,2,…,K) 

H1: βj≠0




Marginal Tests
					
Marginal Tests 中文常直譯為「邊際檢定」，頗不達意。統雄老師建議按照其
 H0 意義，譯為「個別檢定」。



個別檢定/自變項篩選方法

 個別檢定等同篩選掉迴歸方程式中，β﹦0的自變項。

 自變項篩選方法有4種，根據每一自變項預測力之大小決定刪去或留在模式中。

 強迫進入法(All-Possible-Regression Procedure)/ 輸入法(Enter)

 不由系統篩選，所有自變項的，均須計算報告。通常作為初步分析使用。

註意：SPSS 
		新版中文譯為「輸入」法，非常不能達意，愈譯愈差。

 
後退淘汰法(Backward Elimination Procedure)


先將所有的自變項放入迴歸方程式中，然後根據淘汰標準一一將不符合標準的自變項加以淘汰。

 
前進選擇法(Forward Selection Procedure)


第一個進入迴歸方程式的自變項是與應變項有最大相關的自變項，第一個自變項進入模型之後，再以對判定係數值大小的影響，檢查第二個自變項該誰進入，依此類推，直到沒有其他的自變項符合選取的標準為止。

 
逐步迴歸法(Stepwise Regression Procedure)


結合前進選擇法與反向淘汰法二種程序。首先採用順向選擇法，選進與應變項有最大相關的自變項，接下來以反向淘汰法檢查此自變項是否須加以排除。為了避免相同的自變項重複地被選進或排除，選進的標準(α值)必須小於淘汰的標準。

 在一般情況下，逐步迴歸法是最後建構理論時，較常用的方法。


多元迴歸的前提、限制、爭論與未來

在傳統古典統計學教科書上，都把多元迴歸分析作為統計的最高技術，實務上，也是建構各種多變項模型的基礎、扮演最重要的技術角色。

但多元迴歸之所以能夠分析，實有許多前提、限制、與爭論，如以下引文。然而這些即使以最科普的英文陳述，除非對統計非常有興趣的人，大概也很難懂。

統雄老師以教學的立場，白話詮釋如下：

The following are the major assumptions made by standard linear regression 
models with standard estimation techniques (e.g. ordinary least squares):

Weak exogeneity

自變項可具體測量，且為連續資料、或人為連續資料。

This essentially means that the predictor variables x can be treated as fixed 
values, rather than random variables. This means, for example, that the 
predictor variables are assumed to be error-free, that is they are not 
contaminated with measurement errors. Although not realistic in many settings, 
dropping this assumption leads to significantly more difficult 
errors-in-variables models.
Linearity. This means that the mean of the response variable is a linear 
combination of the parameters (regression coefficients) and the predictor 
variables. Note that this assumption is much less restrictive than it may at 
first seem. Because the predictor variables are treated as fixed values (see 
above), linearity is really only a restriction on the parameters. The predictor 
variables themselves can be arbitrarily transformed, and in fact multiple copies 
of the same underlying predictor variable can be added, each one transformed 
differently. This trick is used, for example, in polynomial regression, which 
uses linear regression to fit the response variable as an arbitrary polynomial 
function (up to a given rank) of a predictor variable. This makes linear 
regression an extremely powerful inference method. In fact, models such as 
polynomial regression are often "too powerful", in that they tend to overfit the 
data. As a result, some kind of regularization must typically be used to prevent 
unreasonable solutions coming out of the estimation process. Common examples are 
ridge regression and lasso regression. Bayesian linear regression can also be 
used, which by its nature is more or less immune to the problem of overfitting. 
(In fact, ridge regression and lasso regression can both be viewed as special 
cases of Bayesian linear regression, with particular types of prior 
distributions placed on the regression coefficients.)

Constant variance (aka homoscedasticity)

變項同質性，亦即變項應符常態分配，且具相同變異性。

This means that different response variables have the same variance in their 
errors, regardless of the values of the predictor variables. In practice this 
assumption is invalid (i.e. the errors are heteroscedastic) if the response 
variables can vary over a wide scale. In order to determine for heterogeneous 
error variance, or when a pattern of residuals violates model assumptions of 
homoscedasticity (error is equally variable around the 'best-fitting line' for 
all points of x), it is prudent to look for a "fanning effect" between residual 
error and predicted values. This is to say there will be a systematic change in 
the absolute or squared residuals when plotted against the predicting outcome. 
Error will not be evenly distributed across the regression line. 
Heteroscedasticity will result in the averaging over of distinguishable 
variances around the points to get a single variance that is inaccurately 
representing all the variances of the line. In effect, residuals appear 
clustered and spread apart on their predicted plots for larger and smaller 
values for points along the linear regression line, and the mean squared error 
for the model will be wrong. Typically, for example, a response variable whose 
mean is large will have a greater variance than one whose mean is small. For 
example, a given person whose income is predicted to be $100,000 may easily have 
an actual income of $80,000 or $120,000 (a standard deviation of around 
$20,000), while another person with a predicted income of $10,000 is unlikely to 
have the same $20,000 standard deviation, which would imply their actual income 
would vary anywhere between -$10,000 and $30,000. (In fact, as this shows, in 
many cases – often the same cases where the assumption of normally distributed 
errors fails – the variance or standard deviation should be predicted to be 
proportional to the mean, rather than constant.) Simple linear regression 
estimation methods give less precise parameter estimates and misleading 
inferential quantities such as standard errors when substantial 
heteroscedasticity is present. However, various estimation techniques (e.g. 
weighted least squares and heteroscedasticity-consistent standard errors) can 
handle heteroscedasticity in a quite general way. Bayesian linear regression 
techniques can also be used when the variance is assumed to be a function of the 
mean. It is also possible in some cases to fix the problem by applying a 
transformation to the response variable (e.g. fit the logarithm of the response 
variable using a linear regression model, which implies – as noted above – that 
the response variable has a log-normal distribution rather than a normal 
distribution).

Independence of errors

誤差獨立性，即誤差與變項無相關，且服從常態分配。

This assumes that the errors of the response variables are uncorrelated with 
each other. (Actual statistical independence is a stronger condition than mere 
lack of correlation and is often not needed, although it can be exploited if it 
is known to hold.) Some methods (e.g. generalized least squares) are capable of 
handling correlated errors, although they typically require significantly more 
data unless some sort of regularization is used to bias the model towards 
assuming uncorrelated errors. Bayesian linear regression is a general way of 
handling this issue. 

Lack of multicollinearity in the predictors

自變項具「非共線性」，即彼此獨立。幾何學上的意義，就是自變項必須是彼此兩兩正交(pairwise 

orthogonal)的。

For standard least squares estimation methods, the design matrix X must have 
full column rank p, i.e. be invertible; otherwise, we have a condition known as 
multicollinearity in the predictor variables. This can be triggered by having 
two or more perfectly correlated predictor variables (e.g. if the same predictor 
variable is mistakenly given twice, either without transforming one of the 
copies or by transforming one of the copies linearly). It can also happen if 
there is too little data available compared to the number of parameters to be 
estimated (e.g. fewer data points than regression coefficients). In the case of 
multicollinearity, the parameter vector β will be non-identifiable — it has no 
unique solution. At most we will be able to identify some of the parameters, 
i.e. narrow down its value to some linear subspace of Rp. See partial least 
squares regression. Methods for fitting linear models with multicollinearity 
have been developed; some require additional assumptions such as 「effect 
sparsity」 — that a large fraction of the effects are exactly zero. Note that the 
more computationally expensive iterated algorithms for parameter estimation, 
such as those used in generalized linear models, do not suffer from this problem 
— and in fact it's quite normal to when handling categorically-valued predictors 
to introduce a separate indicator variable predictor for each possible category, 
which inevitably introduces multicollinearity.

Sampling and design of experiments

研究方法的影響：抽樣方法、實驗設計…等等，均會產生影響。

Beyond these assumptions, several other statistical properties of the data 
strongly influence the performance of different estimation methods:

The statistical relationship between the error terms and the regressors plays an 
important role in determining whether an estimation procedure has desirable 
sampling properties such as being unbiased and consistent.
The arrangement, or probability distribution of the predictor variables x has a 
major influence on the precision of estimates of β. Sampling and design of 
experiments are highly-developed subfields of statistics that provide guidance 
for collecting data in such a way to achieve a precise estimate of β.

標準化迴歸係數的爭論

 標準化迴歸係數在計量上的應用與解釋，文獻有許多爭論與修正意見。

 統雄老師的建議：學習、反省、發展

 就行為研究而言，更有許多超越計量技術、牽涉基礎知識論的問題。

 大部分的行為研究，變項的測量與性質，與以上的前提與限制，牴觸是很嚴重的。如果沒有「反省」意識，很容易變成跑「垃圾進出(GIGO)」和作儀式。

 但在學習階段，統雄老師建議暫時放下這些爭論，先學習前人對發展多元迴歸、解決問題的思想方法，培養從微積分、到統計的計量技術能力。

 未來，可能不是修正，而是根本要放棄多元迴歸，探索、發展完全不同思想向面的解決方案。 




統雄數學樂學/統計神掌易經筋-問捲
 











		
		 


統雄數學神掌系列目錄

分享意見反映
統計教學的內涵與取向
高考統計考題的解析
微積分精華篇
微積分思想篇
微積分進階精華篇
統計/數學符號與其英語讀法
資料型態與視覺呈現
敘述統計
機率論與機率分配
推論統計學精華篇
t分配與 t檢定
推論統計‧理論建構
資料分析程序與SPSS基礎
SPSS 資料清理

SPSS 轉換:Recode 重新編碼

SPSS 轉換:Compute 建構新變項
SPSS 選擇觀察值_SPSS 
資料庫管理

樣本代表性檢定
單變項:類別_二元資料/詮釋
單變項:類別_二元資料/應用
單變項分析:連續資料

單變項連續資料視覺檢視與清理
卡方分析（雙向）
多向卡方分析
單向卡方分析
變異數分析（單因子）：詮釋
變異數分析（單因子）：應用
簡單迴歸/相關分析：詮釋
簡單迴歸/相關分析：應用
對數/邏輯相關分析

測量工具信度/效度分析

量表信度 檢定
量表效標關聯效度 檢定

探索式因素分析 (EFA)：詮釋與實作
探索式因素分析 (EFA)：應用進階

因素效度分析_CFA：詮釋

因素效度分析_CFA：應用
多變項分析精華篇
多元迴歸分析：詮釋
多元迴歸分析：應用
一般線性模型精華篇
廣義線性模型

雙因子/多因子變異數分析
調節模型與交互作用詮釋
調節模型分析與建構
SPSS 統計圖應用:調節模型檢定
共變數分析/詮釋
共變模型建構/應用
因果模型與因果邏輯
中介模型分析

因徑/SEM:模型詮釋與因果邏輯

因徑/SEM:探索式因徑模型建構

因徑/SEM:驗證式結構方程解析

多變項分析實例SEM篇

多變項分析實例SEM+調節篇

因徑/結構方程SEM：反省
無母數統計
統計研討篇
專題-卜豐投針實驗
專題-機率與統計悖論
第1類知識計量工具
第2類知識計量工具
第3類知識計量工具

非等機率知識體系建構
TX空時座標建構
一般取用測量
信仰取用測量

研究方法/民調市調系列















TX取用行為一般模式篇

TX取用行為進階模式篇
人類取用行為模式 應用系列
調查知識管理系統 應用系列
資訊系統與資訊管理 系列

多元學習‧獨立好問
教改與快樂學習
自主式學習成就評鑑方案
核心理念-全人教育
網路無邊界教室
國際化雙語互動
人格與群己教育
虛擬平等校園
孔子的杏壇六藝
亞理斯多德的學園漫步
腦半球的偽科學與真知識
教育與社經地位
知識創新與知識光譜
接龍實驗：創新就是與眾不同
Google排行榜實驗：科學創新就是一再與眾不同
學習的金字塔












  
  
 

 








 


















回歸分析預測法 - MBA智庫百科









 
 















回歸分析預測法

出自 MBA智庫百科(http://wiki.mbalib.com/)


回歸分析預測法(Regression Analysis Prediction Method)

目錄

1 什麼是回歸分析預測法？
2 回歸分析預測法的分類
3 回歸分析預測法的步驟
4 應用回歸預測法時應註意的問題
5 回歸分析預測法案例分析

5.1 案例一:回歸分析預測法預測新田公司銷售[1]


6 參考文獻


[編輯] 什麼是回歸分析預測法？ 
　　回歸分析預測法，是在分析市場現象自變數和因變數之間相關關係的基礎上，建立變數之間的回歸方程，並將回歸方程作為預測模型，根據自變數在預測期的數量變化來預測因變數關係大多表現為相關關係，因此，回歸分析預測法是一種重要的市場預測方法，當我們在對市場現象未來發展狀況和水平進行預測時，如果能將影響市場預測對象的主要因素找到，並且能夠取得其數量資料，就可以採用回歸分析預測法進行預測。它是一種具體的、行之有效的、實用價值很高的常用市場預測方法。

[編輯] 回歸分析預測法的分類 
　　回歸分析預測法有多種類型。依據相關關係中自變數的個數不同分類，可分為一元回歸分析預測法和多元回歸分析預測法。在一元回歸分析預測法中，自變數只有一個，而在多元回歸分析預測法中，自變數有兩個以上。依據自變數和因變數之間的相關關係不同，可分為線性回歸預測和非線性回歸預測。

[編輯] 回歸分析預測法的步驟 
　　1．根據預測目標，確定自變數和因變數
　　明確預測的具體目標，也就確定了因變數。如預測具體目標是下一年度的銷售量，那麼銷售量Y就是因變數。通過市場調查和查閱資料，尋找與預測目標的相關影響因素，即自變數，並從中選出主要的影響因素。
　　2．建立回歸預測模型
　　依據自變數和因變數的歷史統計資料進行計算，在此基礎上建立回歸分析方程，即回歸分析預測模型。
　　3．進行相關分析
　　回歸分析是對具有因果關係的影響因素（自變數）和預測對象（因變數）所進行的數理統計分析處理。只有當變數與因變數確實存在某種關係時，建立的回歸方程才有意義。因此，作為自變數的因素與作為因變數的預測對象是否有關，相關程度如何，以及判斷這種相關程度的把握性多大，就成為進行回歸分析必須要解決的問題。進行相關分析，一般要求出相關關係，以相關係數的大小來判斷自變數和因變數的相關的程度。
　　4．檢驗回歸預測模型，計算預測誤差
　　回歸預測模型是否可用於實際預測，取決於對回歸預測模型的檢驗和對預測誤差的計算。回歸方程只有通過各種檢驗，且預測誤差較小，才能將回歸方程作為預測模型進行預測。
　　5．計算並確定預測值
　　利用回歸預測模型計算預測值，並對預測值進行綜合分析，確定最後的預測值。

[編輯] 應用回歸預測法時應註意的問題 
　　應用回歸預測法時應首先確定變數之間是否存在相關關係。如果變數之間不存在相關關係，對這些變數應用回歸預測法就會得出錯誤的結果。
　　正確應用回歸分析預測時應註意：
　　①用定性分析判斷現象之間的依存關係；
　　②避免回歸預測的任意外推；
　　③應用合適的數據資料；

[編輯] 回歸分析預測法案例分析 
[編輯] 案例一:回歸分析預測法預測新田公司銷售[1] 
　　一、新田公司的發展現狀
　　新田公司全稱為新田摩托車製造有限公司，成立於1992年3月，當時的錫山市(那時還叫無錫縣)有兩個生產摩托車的鄉鎮企業：查橋鎮的捷達摩托車廠和洛社鎮的雅西摩托車廠。在9l、92年這兩家廠可以說是如日中天，但這兩家廠又各具特點：雅西摩托車廠完全是自主生產，除發動機外其餘配件都由本廠生產；捷達摩托車廠則是裝配型廠，配件由其他廠家生產，本廠只是組裝(後來也發展成了連發動機都生產的綜合型企業)。顧建新當時還只是一家村辦企業的供銷員，他就瞄準了摩托車行業的發展前景，於是想方設法和捷達廠取得了聯繫，從1992年3月起為捷達廠生產兩種型號的減震器，廠名是無錫減震器廠，由此開始了企業發展的道路。
　　減震器廠自成立以後，隨著捷達摩托車廠摩托車年產量的不斷增長而得到了迅速發展。到了1994年6月，顧建新終於有了一個極好的機會：捷達摩托車廠的銷售部門和捷達摩托車的銷售商產生了予盾，因此捷達摩托車的銷售商答應顧建新，若顧建新也能生產出和捷達差不多質量的摩托車，則他們會在相同條件下優先銷售顧建新生產的摩托車。有了這個承諾，顧建新於94年lO月就成立了新田摩托車製造有限公司，開始生產新田牌摩托車。
　　新田公司成立以後，在顧總和匡建中總工程師的領導下，開始了艱苦的創業過程，經過六年多的奮鬥，薪田公司終於從一個20多人的小廠發展成瞭如今的工人總數超過400人，日產摩托車超過200輛，年利潤超過2000萬的集團型企業，新田摩托車的配件包括發動機在內都由本企業自主生產。
　　新田公司如今已是一個企業集團，除公司本部(總裝廠)外，還有減震器廠、發動機廠、塑件廠、車架車間、油箱車間、噴塗車間等獨立部門，這些部門除滿足新田公司所需配件外，還可以對外供應。1999年底，由於摩托車市場競爭的日趨激烈，新田公司的銷售模式由代理制轉向了派員銷售制(由公司往各城市直接派出銷售人員，負責各城市的銷售工作)，以減少中間環節，確保公司產品在整個摩托車市場的競爭力。同時，由於銷售模式的轉變，也帶來了生產模式的變化：以前是根據各地代理商的訂貨量來組織生產，現在則必需根據銷售情況和對將來銷售情況的預期來組織生產，這給企業的生產組織帶來了極大的困難。
　　2.新田公司銷售的歷史數據及要解決的問題
　　新田公司自94年成立以來取得了飛躍性的發展，這可以從新田公司歷年的銷售數據中看出來。下麵所附的表就是新田公司主導產品的銷售數據。（參見下麵表1.2.3.4）
　　從表中的數據可以看出，新田公司的生產銷售形勢還是比較好的，從總體上來說是處於上升趨勢，但某些車型的銷售也有下降趨勢。同時，還有一些問題從銷售數據上是看不出來的。自從公司實行派員銷售制以來，由於銷售的預期值估計不准，常常出現工人加班加點仍趕不上交貨對間的情況和工人上了班卻無事可做的情況。顧建新總經理和其他公司領導也都發現了這個問題，也找到了原因所在，但由於技術上的原因而無法解決。因此，新田公司目前急需解決的問題就是如何來進行準確可行的銷售預測，以保證公司的正常運行。

　　新田公司2001年第一季度銷售數據



XT150-TXT150-HXT125-CXT125-WXT100-WXT100-GXT50-K總數


665897166015001529160893310372

　　新田公司2001年第二季度銷售數據



XT150-TXT150-HXT125-CXT125-WXT100-WXT100-GXT50-K總數


668350180815811542150316039862

　　新田公司XT50-M在無錫的銷售數據



第一季度第二季度第三季度第四季度


1996年150170172180


1997年201230233245


1998年258292284298


1999年283255209199


2000年17516012290



　　二、回歸分析預測法分析
　　回歸分析預測法是通過研究分析一個應變數對一個或多個自變數的依賴關係，從而通過自變數的已知或設定值來估計和預測應變數均值的一種預測方法。
　　回歸分析預測法又可分成線性回歸分析法、非線性回歸分析法、虛擬變數回歸預測法三種。這三種預測方法在新田公司銷售預測中都可以運用。
　　(一)線性回歸分析法的運用
　　線性回歸預測法是指一個或一個以上自變數和應變數之間具有線性關係(一個自變數時為一元線性回歸，一個以上自變數時為多元線性回歸)，配合線性回歸模型，根據自變數的變動來預測應變數平均發展趨勢的方法。
　　線性回歸預測法在銷售預測中用得比較多，根據新田公司銷售數據的散點圈分析，作者發現新田公司的XTl50～T、XTl25～C XTl25一W三種車型的銷售可以用一元線性回歸預測法進行預測，由於銷售數據是時間性序列，多元線性回歸在此不適用。
　　1.預測模型
　　由於新田公司銷售預測中只用到一元線性回歸預測法，而一元線性回歸又是一種廣泛應用並且比較簡單的預測方法，因此，只需對一元線性回歸模型作簡單介紹。
　　設X為自變數，Y為應變數，Y與X之間存在某種線性關係，一元線性回歸模型為：
　　yi = a + bxi + εi　　  (1)
　　式中ε為各種隨機因素y的影響總和，ε − (0,σ2)；y-N(a+bx,σ2)。則可設無法解析 (PNG 轉換失敗; 請檢查是否正確安裝了 latex, dvips, gs 和 convert): \widehat{y}i=a+b x_i
　　(2)
　　對此，可以通過最小二乘法來估計模型的回歸繫數。根據最小平方原理，必須符合以下條件：
　　=最小值　　(3)
　　無法解析 (PNG 轉換失敗; 請檢查是否正確安裝了 latex, dvips, gs 和 convert): \sum(yi-\widehat{y}i)=0
　　(4)
　　根據最小二乘法要求，記
　　根據極值原理，為使Q具有最小值，可分別對a、b求偏導數，並令其等於零，即
　　無法解析 (PNG 轉換失敗; 請檢查是否正確安裝了 latex, dvips, gs 和 convert): \frac{\partial Q}{\partial a}=-2\sum(yi-a-b x_i)=0

　　
　　整理的：
　　　　　　
　　對上兩式聯立求解，即可得到回歸繫數的估計值：
　　　　(5)
　　　　(6)
　　相關係數R可根據最小二乘原理及平均數的數學性質得到：
　　　　(7)
　　相關係數R的絕對值的大小表示相關程度的高低。
　　①當R=0時，說明是零相關，所求回歸繫數無效。
　　②當時，說明是完全相關，自變數X與應變數Y之間的關係為函數系。
　　⑧當時，說明是部分相關，淵值越大相關程度越高。
　　另外，估計標準差Sy，和預測區間公式參見《預測與決策技術》。
　　估計標準差：　　(8)
　　預測區間：　　(9)
　　在上式中，a為顯著水平，n-2為自由度，為y在xo的估計值。
　　2.預測計算
　　根據上面介紹的預測模型，下麵就先計算XTl50-T在2001年第一季度的預測銷售量。
　　根據XTl50-T的銷售數據有：(X為時間，Y為銷售量)。
　　n=16；；；；；
　　根據公式(5)、(6)、(7)、(8)、(9)有：
　　
　　
　　　　(xi = 17)
　　
　　
　　
　　i0.025(14) = 2.145
　　以上是XT150-T的銷售預測計算，同理可計算XT125-C、XT150-W的預測結果，這裡不再給出計算過程而直接寫出結果：
　　①XTl25-C的預測結果：
　　　；　；　；R=0.99　；Sy = 16.56
　　預測區間為：(1641，1723)  (i0.025(20) = 2.086)
　　②XTl25-W的預測結果：
　　　；　；　；R=0.99　；
　　Sy = 29.35
　　預測區間為：(1450，1596)  (i0.025(20) = 2.086)
　　3.預測結果分析
　　從上面的預測結果來看，有一點非常奇怪，那就是三種車型的預測中，相關係數R都非常接近於“1”，也就是說，這三種車型的銷售量和時間基本上是線性關係，相關程度非常之高。對於這個結果，作者感到很驚訝，為此，特意找到了新田公司，詢問這三種車型的銷售狀況，這才找到了原因。原來，這三種車型是新田公司的形象產品，基本上沒有利潤，和其他品牌的同類車型相比具有較大的的競爭力，因而這三種車型的銷售情況一直很好。公司為了其形象，對這三種車型採取計劃供應的方式，按逐年遞增的方式供應市場，以使這三種車型一直保持供不應求。由於以上原因，相關係數接近於“1”也就不奇怪了。
　　另外，作者把通過公式計算得到的各期銷售數和實際銷售量比較發現，這三種車型有一個共同特點，那就是：第一季度的預測值一般要比實際值大，而第二季度則相反。第三、四季度則預測值和實際值相近。仔細分析原因，可能是因為這三種車型價格都比較高，受年終分配影響，第一季度銷量自然較大，隨後的第二季度銷量就自然偏小。
　　對比2001年第一季度的預測值和實際值，以及上面說到的兩個特點可以發現，XT150-T的預測結果比較正常，而XTl25-C、XTl25-W的預測值卻出現了反而比實際值大的反常情況。通過各期預測值和實際值比較發現，原來XTl25-W從99年第二季度開始就出現預測值大於實際值的情況，根據作者對摩托車市場的瞭解，認為可能是因為這種車型的銷路已經出現問題，不能保持供不應求了。
　　XTl25-C可能也是這種情況，只不過該車型的滯銷出現得稍稍晚而已。通過和新田公司銷售部門的聯繫發現，作者的判斷是正確的。
　　(二)非線性回歸預測法的運用
　　非線性回歸預測法是指自變數與因變數之間的關係不是線性的，而是某種非線性關係時的回歸預測法。非線性回歸預測法的回歸模型常見的有以下幾種：雙曲線模型、二次曲線模型、對數模型、三角函數模型、指數模型、冪函數模型、羅吉斯曲線模型、修正指數增長模型。
　　通過對新田公司銷售數據的散點圖分析發現，XT100-W和XT50-K這兩種車型的圖形接近於拋物線形狀，因此可用非線性回歸的二次曲線模型來預測。
　　1.預測模型
　　非線性回歸二次曲線模型為：　　(10)
　　令,則模型變化為：　　(11)
　　上式的矩陣形式為：Y = XB + ε　　(12)
　　用最小二乘法作參數估計，可設觀察值與模型估計值的殘差為E，則
　　，
　　根據小二乘法要求有：
　　=最小值，　　(13)
　　即：=最小值
　　由極值原理，根據矩陣求導法，對B求導，並令其等於零，得：
　　
　　
　　整理得回歸繫數向量B的估計值為：　　(14)
　　二次曲線回歸中最常用的檢驗是R檢驗和F檢驗，公式如下：
　　　　(15)
　　　　(16)
　　在實際工作中，R的計算可用以下簡捷公式：
　　　　(17)
　　估計標準誤差為：
　　　　(18)
　　預測區間為：
　　·S  (n<30)　　(19)
　　·S  (n>30)　　(20)
　　2.預測計算
　　根據上面介紹的預測模型，下麵就先進行XT100-W的預測計算。
　　根據XTl00-W的銷售數據及(11)、(14)、(17)、(18)、(19)有(xi為時間變數)：
　　
　　。
　　
　　　(x_i=25)
　　；；；
　　
　　
　　(n-3)·　　(i0.025(21) = 2.080)
　　下麵再計算XT50-K的預測結果。
　　根據XT50-K的銷售數據及公式(11) 、(14)、(17)、(18)、(19)有：
　　。
　　
　　
　　
　　
　　；；；
　　
　　　　(t0.025(21) = 2.080)
　　下麵再計算XT50—K的預測結果。
　　根據XT50---K的銷售數據及公式(11)、(14)、(17)、(18)、(19)有：
　　
　　
　　　　
　　　　(xi = 25)
　　;;;
　　
　　
　　　　t0.025(21) = 2.080
　　3.預測結果分析
　　從2001年第一季度的預測結果和實際值的比較來看，預測還算是可行的，XTl00—W和XT50—K的實際銷售量均在預測範圍之內，回歸繫數也都接近於1，說明這兩種車型選取非線性回歸的二次曲線模型還是比較合適的。但是，還應該看到，兩種車型的預測結果中估計標準差S都比較大，說明回歸曲線和實際銷售數據的擬合情況並不太好，而S數值的偏大同時也帶來了預測範圍較大的後果。因此，預測精度較差。
　　當然了，實際工作中不可能會有真正符合某條曲線的數據存在，只能是從散點圖來看大致符合某種曲線，就用該種曲線來進行擬合，以求大致的預測結果。因此，對於XTl00—W和XT50—K的預測還是可行的。
　　再進一步考慮，XTl00—W的預測值比實際值大了66，說明實際下降趨勢比預測的要小，而XT50—K的情況則剛好相反。如果排除偶然因素的話，有可能XTlOO—w銷售量的下降趨勢在減緩，而XT50—K則相反，下降趨勢在加劇。聯繫實際情況，作者認為是50車型的銷量因競爭的日益加劇和政策的影響而加速下滑，而100車型則可能是由於公司的努力而減低了銷量下降的速度。作者的這個想法在後來和新田公司總工程師匡建中的交流中得到了驗證。
　　(三)虛擬變數回歸預測法的運用
　　在回歸模型分析中，有時還要考慮諸如性別、文化程度、宗教、戰爭、災難、季節以及政府經濟政策變化等品質變數的影響。這時，可在建立回歸模型時將品質變數引入線性回歸模型中，這種回歸預測法就是虛擬變數回歸預測法。
　　常見的帶虛擬變數的回歸模型有以下三種形式：
　　(1)反映政府政策變化或某種因素髮生重大變異的跳躍、間斷式模型。
　　(2)具有轉折點的系統趨勢變化模型。
　　(3)含有多個虛擬變數的線性回歸模型。
　　虛擬變數回歸預測法的適用性一般在散點圖上明確看出。在表(1.1)中的數據都不適用。不過，作者發現新田公司的XT50—M在無錫的銷售倒是適合用具有轉折點的系統趨勢變化模型來進行預測。
　　1.預測模型
　　由於只有XT50—M在無錫的銷售適合用具有轉折點的系統趨勢變化模型來
進行預測(見是表4)下麵僅介紹具有轉折點的系統趨勢變化模型。
　　具有轉折點的系統趨勢變化模型為：
　　yi = β1 + β2xi + β3(xi − x0)Di + εi　　(21)
　　式中Di為虛擬變數，Di的取值為
　　io為發生轉折點的時間，xo為io時間xi的觀察值。(21)可變形為：
　　
　　根據(21)，可令,，則該虛擬變數回歸轉化為二元線性回歸，可用二元線性回歸的計算方法計算。
　　2)預測計算
　　經過對散點圖觀察發現，1998年第四季度為轉折點，即i0 = 12，由表(4)的數據及(14)、(17)、(18)、(19)、(21)可得：
　　
　　　　
　　
　　
　　　　xi = 21
　　；；；
　　
　　
　　　　(t0.025(18) = 2.101)
　　3.預測結果分析
　　新田公司的XT50—M2001年第一季度在無錫的實際銷售量為55輛，和預測結果相比，可以說還在預測範圍內，說明該車型在無錫的銷售用虛擬變數回歸預測法預測還是比較成功的。而之所以會在98年第四季度出現轉折點，作者還是瞭解的，原因就在於98年第四季度無錫市公佈了50車型不允許上助力車牌照的規定，從而引起了50車型在無錫的銷售量逐步減少。當然了，這種情況銷售預測中出現得不多，因此使用也不是很廣。
　　三、回歸分析法總結
　　回歸分析預測法是一類比較經典，也比較實用的預測方法。正是由於它經典，因此也就成熟，再加上比較容易理解，運用也就比較廣泛。相比之下，其中的線性回歸預測法和非線性回歸預測法的運用更廣些。在實際使用過程中，如果在選擇具體的方法和模型時能對數據作較為詳細的分析，對散點圖的觀察分析也能仔細一點的話，預測結果也就會比較令人滿意的。當然了回歸分析最大的特點就是在偶然中發現必然，而實際情況卻常常是千變萬化的，有時偶然因素的影響也會超過必然，這時預測結果也就不能很如意，這就要求在預測工作中不能機械，要會靈活運用，要註意瞭解會影響預測結果的偶然情況，以便對預測結果進行適當修正，這樣才能使預測結果更接近實際，也才能使預測能更好地為經濟建設服務。從新田公司的回歸分析預測結果來看，用線性回歸預測法來預測XTl50-T、XTl25—C和XTl25一W都得到了比較滿意的結果，而且各項指標也比較好，用虛擬變數回歸預測法預測XT50—M也得到了滿意的結果。因此可以基本上確定，用上述的預測方法來預測新田公司的這幾種車型是可行的。(參見下麵二圖)。
　　
　　

[編輯] 參考文獻 

↑ 錢曉星.新田公司摩托車銷售預測研究[D].2002



取自"http://wiki.mbalib.com/zh-tw/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E6%B3%95"

本條目對我有幫助280  分享到：














   如果您認為本條目還有待完善，需要補充新內容或修改錯誤內容，請編輯條目。

本條目相關文檔
 回歸分析預測法 15頁 第十二章 回歸分析預測法 51頁更多相關文檔
本條目由以下用戶參與貢獻
sky,funwmy,Zfj3000,Angle Roh,Vulture,Dan,Jiangyingrong,Ljf0516,Yixi,Zxe,Boomtown,Landscape,Arran,林巧玲,Mis銘. 頁面分類: 決策預測 





評論(共31條)提示:評論內容為網友針對條目"回歸分析預測法"展開的討論，與本站觀點立場無關。

 222.168.55.*  在 2009年12月15日 11:13 發表    


真是好文章


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 125.71.200.*  在 2009年12月24日 09:59 發表    


說的比較詳細


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Lymaster (討論 | 貢獻) 在 2009年12月27日 13:47 發表    


非常好的預測模型選定和應用的例子。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 159.226.20.*  在 2009年12月30日 10:17 發表    


很好，支持LZ，好東西


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 116.228.229.*  在 2010年3月2日 11:12 發表    


很好很好，可是自己感覺學過的東西都還給老師了...汗


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 219.243.90.*  在 2010年4月22日 20:34 發表    


很好，用minitab 和e-views 都可以很快得出結果。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 58.255.160.*  在 2010年5月22日 12:59 發表    


還是不明白，這些是大學里學的嗎？


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 113.250.152.*  在 2010年5月29日 18:55 發表    


謝謝！


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 210.21.124.*  在 2010年6月12日 13:41 發表    


很詳細,謝謝!


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 119.114.243.*  在 2010年6月30日 20:53 發表    


為什麼不用股市數據做背景！


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 61.152.251.*  在 2010年8月24日 22:09 發表    


額。。。看的懂例子，看不懂數據。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Deren1984 (討論 | 貢獻) 在 2010年8月27日 19:50 發表    


是很好的文章，但是在一些小細節上有錯誤。比如在對XT-150T分析時，前後兩次的R式就不一樣


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Dan (討論 | 貢獻) 在 2010年9月3日 19:45 發表    


 Deren1984 (討論 | 貢獻) 在 2010年8月27日 19:50 發表

是很好的文章，但是在一些小細節上有錯誤。比如在對XT-150T分析時，前後兩次的R式就不一樣





已做了部分修改，希望對你有所幫助～～
MBA智庫百科是可以自由參與編輯和修改的百科，如有發現錯誤和不足，您也可以進行修改哦~


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 221.137.62.*  在 2010年9月15日 13:02 發表    


謝謝。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 180.110.77.*  在 2010年10月1日 11:23 發表    


很好的，希望能和你切磋，QQ1041015393


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 222.43.55.*  在 2011年1月7日 11:10 發表    


以前在書本上看過關於回歸分析法的講解，但從來沒想過怎麼用，原來這種方法運用的這麼廣，雖然計算過程還是沒看明白，但大體意思懂了，謝謝。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Helentanht (討論 | 貢獻) 在 2011年1月18日 13:01 發表    


謝謝作者這麼詳盡的講解，但是數學都還給老師了，現在回歸分析是否有現成的工具或軟體進行？


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 58.214.9.*  在 2011年3月22日 14:19 發表    


已經暈了


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 118.232.182.*  在 2011年4月27日 00:11 發表    


利害!!!


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 61.161.147.*  在 2011年6月3日 14:33 發表    


我還是不會阿.學習這個怎麼學呢? Q 406098080 求高手好人給予知道


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 60.0.78.*  在 2011年6月6日 09:27 發表    


看得懂例子，看不懂公式.....


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 123.53.24.*  在 2011年7月24日 10:16 發表    


文章對於本人的數學建模學習很有用，呵呵，謝了，很經典。。。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 112.97.24.*  在 2012年6月19日 10:15 發表    


 61.152.251.*  在 2010年8月24日 22:09 發表

額。。。看的懂例子，看不懂數據。





股市的相關係數太多了，不合適做教學。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 218.29.102.*  在 2012年12月14日 16:55 發表    


過程很詳細，適合大家學習參考。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 171.109.150.*  在 2013年3月24日 22:06 發表    


某次調查活動涉及的調查對象總體包括公務員5萬人，企業管理人員10萬人和教育人士7萬人，擬採用分層比例抽樣法從總體中抽取2000人作為調查樣本，公務員，企業管理人員和教育界人士和各應抽取多少人？


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 24.252.22.*  在 2013年4月5日 19:27 發表    


在國外的商科孩子準備畢業考試。。可是這些完全看不懂啊，要暈了。。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 220.168.209.*  在 2013年9月1日 15:01 發表    


可惜沒有數據  不然可以自己試驗下  效果會好些


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 221.232.147.*  在 2013年11月14日 16:05 發表    


用什麼軟體可以計算出預測值呢，誰能告知一下


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 111.126.166.*  在 2014年4月8日 09:26 發表    


求弄一下呼倫貝爾市物流業的需求預測唄。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 210.42.32.*  在 2014年8月11日 10:22 發表    


不錯


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 60.221.18.*  在 2015年5月5日 20:28 發表    


 58.255.160.*  在 2010年5月22日 12:59 發表

還是不明白，這些是大學里學的嗎？





是呀，寫論文要用到


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 



發表評論﻿請文明上網，理性發言並遵守有關規定。




 




導航


首頁
文檔
百科
商學院
資訊
培訓
幫幫




個人工具


用戶登錄創建新帳號 









搜索



 
 

全球最大的中文經管百科，由121,994位網友共同編寫而成，共計414,214個條目








 
首頁
 
管理
 
營銷
 
經濟
 
金融
 
人力資源
 
咨詢
 
財務
 
品牌
 
證券
 
物流
 
貿易
 
商學院
 
法律
 
人物
 
分類索引
 




查看

條目討論編輯簡體中文繁體中文 


工具▼


鏈入頁面
鏈出更改
上載文件 特殊頁面 可列印版
永久鏈接 













導航


最新資訊
最新評論
最新推薦
熱門推薦
編輯實驗
使用幫助
創建條目
隨便看看












本周推薦
最多推薦



影響世界的100個經典管理定律產品定位五步法垃圾人定律MECE分析法巴納姆效應管理百科DISC個性測驗感性型人格約哈里窗戶PPP模式 

蘑菇管理定律猴子管理法則情緒ABC理論100個最流行的管理辭彙21天效應破窗效應懶螞蟻效應SWOT分析模型墨菲定律踢貓效應 

以上內容根據網友推薦自動排序生成









x



	   最後更改16:32, 2015年3月17日.	  
智庫首頁 - 
百科首頁 - 
關於百科 -
	   客戶端 -
	   人才招聘 -
	   廣告合作 - 
權利通知 -
	   聯繫我們 -
	   免責聲明
 - 友情鏈接

©2006-2017 MBAlib.com, All rights reserved. 


 














































迴歸分析-變項各自解釋力（一） @ 晨晰統計部落格新站（統計、SPSS、BIG DATA討論園地） :: 痞客邦 PIXNET ::




























































依據 Google 關鍵字搜尋結果








痞客邦 PIXNET


首頁


部落格


運動


PIXstyleMe


3C


電影


旅遊


親子


美食







進修深造


今日熱門


日文五十音(完整教學)104、105、106年大學指考考試入學越來越容易考好!! 主筆:陳順基多益900秘訣分享 / TOEIC 聽力閱讀準備 @愛莉莎莎聯成電腦學員學習心得 ─ 只為了：愛畫圖【韓文發音對照表】韓文基本字母表(含羅馬拼音) 



達人話題


【教學】Win10電腦還原 (重設此電腦)by 歐飛酒店甘苦談-經紀人和酒店小姐的信任by 臺北酒店經紀拿鐵《DMM》2016 年九月十大 AV 女優by RainDog新屋房屋二胎借款 八德二胎,京誠代書 0930...by 京誠代書藤小二電腦修配坊 筆電購買指南-2017年 推...by 藤小二電腦修配坊 



編輯力推


別再吵街景啦！看看臺南國華街的美食才是真的免找代購！超夯Excel眉筆、眼影盤台灣買得到了！貴婦奈奈：夫妻溝通，就是一起想想好辦法童年的回憶！植村秀揪瑪利兄弟一起推出聯名系列！各界強力介紹，板橋深夜隱藏版、超人氣涼麵 










×

找文章
找部落客





登入












晨晰統計部落格新站（統計、SPSS、BIG DATA討論園地）
跳到主文
一個討論統計的好地方
部落格全站分類：圖文創作


相簿
部落格

留言

名片





公告版位

晨晰統計顧問有限公司在板橋~~服務市話：02-29602817 手機：0918-276-622 聯絡信箱：raising.statistic@gmail.com。 網址：http://www.rai-stat.com.tw。
歡迎大家踴躍發問，問問題請用facebook問（http://tinyurl.com/raising100）會快速回覆喔，我們每週才會統一回一次部落格上的問題。








Nov 03 Mon 2014 09:38
迴歸分析-變項各自解釋力（一）




有關問捲調查的研究中，獨立樣本t檢定、單因子變異數分析、皮爾森相關、多元線性迴歸是推論統計常使用的分析方法，其中前三項都不致於有什麼太大的奇怪問題，但在迴歸分析裡，有些老闆會要求學生「列出每一個自變項對依變項的解釋力，好看出哪一個自變項的影響力或預測力最大」。
老闆的要求看起來似乎合理，不過通常他們認知各自變項的解釋力，和真正變項的解釋力不太相同，以下先介紹如何求出老闆要求的各自變項解釋力，在本文章採用的例子，自變項有3個（分別是X1、X2、X3），依變項名稱為Y。
若迴歸分析選取變項的方式為逐步法（stepwise），點選方式參考如下。(我也想要上統計課)
（1）點選「分析」→「迴歸」→「線性」
（2）將左邊的依變項Y丟入右邊的依變數欄位
（3）將左邊的自變項X1、X2、X3丟入右邊的自變數欄位
（4）方法選用「逐步迴歸分析法」
 
 

 
（5）點選「統計量」→「迴歸」→「線性」
（6）估計值與模式適合度預設已勾選，另外再勾選「R平方改變量」
 

 
（7）模式摘要顯示，最終模式R平方=.384，表示此3個變項的聯合解釋力達38.4%。
（8）由R平方改變量得知，增加X1時為模式增加30.6%的解釋力，增加X2時為模式增加6.9%的解釋力，增加X3時為模式增加0.9%的解釋力，30.6%+6.9%+0.9%又剛好為38.4%，因此很容易讓人認定此三筆數值剛好就是該變項的各自解釋力，而一般老闆要求研究生求的也是這個。

 
若迴歸分析選取變項的方式為全部進入法（Enter），點選方式參考如下。
（1）點選「分析」→「迴歸」→「線性」
（2）將左邊的依變項Y丟入右邊的依變數欄位
（3）先將左邊的自變項X1丟入右邊的自變數欄位
（4）方法選用「輸入」
（5）點選「下一個」
 
 
 

 
（6）此時會來到區塊2的部分，且發現自變數欄位被清空，這時再把左邊的自變項X2丟入右邊的自變數欄位
（7）方法一樣選用「輸入」
（8）點選「下一個」
 
 

 
（9）此時會來到區塊3的部分，且發現自變數欄位被清空，這時再把左邊的自變項X3丟入右邊的自變數欄位
（10）方法一樣選用「輸入」
（11）點選「統計量」
（12）估計值與模式適合度預設已勾選，另外再勾選「R平方改變量」
 
 

 
 
（13）模式摘要顯示，最終模式R平方=.384，表示此3個變項的聯合解釋力達38.4%。
（14）此處配合論文向度的一致性，變項順序按照X1、X2、X3一一放入，由R平方改變量得知，增加X1時為模式增加30.6%的解釋力，增加X2時為模式增加6.9%的解釋力，增加X3時為模式增加0.9%的解釋力，所以結論是X1的影響最大，其次為X2，而X3的影響力最小。
（15）再來我們調動一下自變項的順序，改為X3、X2、X1，模式摘要顯示，最終模式R平方=.384，表示此3個變項的聯合解釋力仍是38.4%。
（16）再來看R平方改變量，此處似乎和剛剛的結果不同，增加X3時為模式增加24.6%的解釋力，增加X2時為模式增加6.5%的解釋力，增加X3時為模式增加7.3%的解釋力，所以結論是X3的影響最大，其次為X1，而X2的影響力最小。
  
 
根據結果得知，R平方改變時並不能視為自變項各自的解釋力，這是因為在計算R平方改變量時，已經控制先前自變項對依變項的影響了，以（14）為例，X1的解釋力30.6%，並未控制任何其他的自變項，因為是第一個順位被選進到模式的變項，因此通常有最高的解釋力；X2的解釋力6.9%，已經控制了X1對依變項的影響，因此解釋力就不會那麼高了；X3的解釋力0.9%，已經控制了X1與X2對依變項的影響，因此解釋力又會再更嚴格。
因此在大部分的情況，先放到模式的解釋力通常都比較高，而越後面放到模式的解釋力則會越低。

創作者介紹




晨晰部落格新站







晨晰統計部落格新站（統計、SPSS、BIG DATA討論園地）




 

		    晨晰部落格新站 發表在 痞客邦 PIXNET 留言(8) 人氣()
 

E-mail轉寄
 




 








 


全站分類：進修深造 個人分類：迴歸與SEM 此分類上一篇： 中介調節分析的SPSS Macro彙整
此分類下一篇： 迴歸分析-變項各自解釋力（二）
上一篇： 投稿期刊時要註意的事－時間議題（time issue）Part 2 ~林星帆顧問整理
下一篇： 迴歸分析-變項各自解釋力（二）


歷史上的今天

2010: 會員心得分享--恭喜桃園李小姐順利畢業！！
2009: IRT如何入門最好？---張世諭顧問學習心得分享
2008: 資料分析前的預備動作，資料清理與編碼要項整理（林星帆顧問整理）


▲top
 


 



 留言列表 (8)
發表留言



 
#1
 小乖 於 2016/12/08 14:57


 


                                老師 請問一下如果執行乾擾效果，X加入乾擾變數後，R平方提升，但加入XY交互作用後，R平方卻不變，應如何解釋呢?謝謝                            

              您好：XY交互作用顯著與否跟新增R平方的量，這之間沒有必然的關係喔。              晨晰部落格新站 於 2016/12/09 13:50 回覆              



 
#2
 hsuya 於 2016/12/09 13:34


 


                                如果只有兩個變數，那要怎麼決定X1X2順序呢?


              您好：順序不影響結果喔。              晨晰部落格新站 於 2016/12/09 13:50 回覆              



 
#3
 訪客 於 2017/02/13 16:13


 


                                你好請問如果Y是0和1 是不是要用logit迴歸 那要從哪裡判別解釋力呢?謝謝                            

              您好：Y是0和1，建議使用logit迴歸。有「pseudo R-squared」，例如SPSS有Cox & Snell R Square以及Nagelkerke R Square兩種。              晨晰部落格新站 於 2017/02/17 15:04 回覆              



                            悄悄話                            


 





 
#5
 小ˋ豬 於 2017/03/08 15:26


 


                                請問該如使用 SPSS 計算 cox proportional hazards model 的 R square or concordance index 以比較不同 models 對於 survival 預測的效果何者為優。                            

              您好: 請參考以下連結
http://www-01.ibm.com/support/docview.wss?uid=swg21478383 晨晰部落格新站 於 2017/03/13 12:31 回覆              



 
#6
 moon 於 2017/05/27 23:05


 


                                如果只有5個變數，那要怎麼決定X1-5順序呢?                            

              您好: 可以考慮使用stepwise (逐步) 法。              晨晰部落格新站 於 2017/05/31 18:24 回覆              



 
#7
 roy 於 2017/06/05 21:27


 


                                請教這是多元迴歸還是階層迴歸呢                            

              您好：這是多元線性迴歸。              晨晰部落格新站 於 2017/06/06 09:21 回覆              



 
#8
 kay 於 2017/06/27 19:40


 


                                想請問，如果是同樣應變數和7個字變數的資料，但是用逐步回歸跑不出來，但是用輸入法就可以分析，想說是應變數的問題嗎？


              您好：可能是7個自變數都與應變數沒有相關性，所以逐步法選不進變項。              晨晰部落格新站 於 2017/07/04 15:47 回覆              

 


 
 

 
 

















            晨晰主打星    	    


（1）SPSS～1日速成班：1日速成班        
（2）加入晨晰的FB粉絲團吧，一起瘋狂聊統計：粉絲團
（3）林星帆顧問的新書：醫護投稿實務一本通
（4）論文自動化分析系統：極速分析系統 
 


	個人資訊	    





暱稱：晨晰部落格新站
分類：圖文創作
好友：共0位 (看全部)
地區：
新北市
公司/組織：
未填寫






            熱門文章    	    





 


            文章分類    	    





晰視 (6)數據話視頻 (13)SAS教學 (46)統計應用專題 (74)研究方法 (50)會員心得分享 (10)Excel與統計軟體 (23)晨晰的宣傳與服務專案 (61)新聞類 (68)論文寫作 (6)統計分析新趨勢 (11)問捲知識 (26)生物醫學統計 (56)迴歸與SEM (42)其他類統計知識 (101)我們的故事 (82)

 


            最新文章    	    


應用Excel進行LSD事後比較
使用G-power計算RCT介入研究所需樣本數
數據話第14集~建立戰情室綜觀全局？用SmartBI就對了
SAS lag指令的應用
極速分析系統（六）：卡方分析


 


            最新留言    	    



 


            文章精選    	    


文章精選
2017 七月 (3)
2017 六月 (4)
2017 五月 (3)
2017 四月 (3)
2017 三月 (5)
2017 二月 (3)
2017 一月 (4)
2016 十二月 (4)
2016 十一月 (5)
2016 十月 (4)
2016 九月 (4)
2016 八月 (5)
2016 七月 (4)
2016 六月 (4)
2016 五月 (4)
2016 四月 (5)
2016 三月 (5)
2016 二月 (4)
2016 一月 (5)
2015 十二月 (4)
2015 十一月 (5)
2015 十月 (4)
2015 九月 (4)
2015 八月 (4)
2015 七月 (4)
2015 六月 (5)
2015 五月 (4)
2015 四月 (3)
2015 三月 (5)
2015 二月 (3)
2015 一月 (4)
2014 十二月 (5)
2014 十一月 (4)
2014 十月 (4)
2014 九月 (5)
2014 八月 (4)
2014 七月 (4)
2014 六月 (5)
2014 五月 (4)
2014 四月 (4)
2014 三月 (5)
2014 二月 (3)
2014 一月 (4)
2013 十二月 (6)
2013 十一月 (4)
2013 十月 (5)
2013 九月 (5)
2013 八月 (4)
2013 七月 (5)
2013 六月 (4)
2013 五月 (4)
2013 四月 (6)
2013 三月 (4)
2013 二月 (4)
2013 一月 (6)
2012 十二月 (4)
2012 十一月 (5)
2012 十月 (6)
2012 九月 (4)
2012 八月 (4)
2012 七月 (9)
2012 六月 (4)
2012 五月 (5)
2012 四月 (4)
2012 三月 (4)
2012 二月 (4)
2012 一月 (5)
2011 十二月 (4)
2011 十一月 (6)
2011 十月 (4)
2011 九月 (5)
2011 八月 (5)
2011 七月 (4)
2011 六月 (4)
2011 五月 (5)
2011 四月 (4)
2011 三月 (5)
2011 二月 (3)
2011 一月 (4)
2010 十二月 (5)
2010 十一月 (5)
2010 十月 (4)
2010 九月 (5)
2010 八月 (5)
2010 七月 (5)
2010 六月 (5)
2010 五月 (4)
2010 四月 (5)
2010 三月 (6)
2010 二月 (5)
2010 一月 (6)
2009 十二月 (5)
2009 十一月 (5)
2009 十月 (7)
2009 九月 (5)
2009 八月 (8)
2009 七月 (7)
2009 六月 (6)
2009 五月 (4)
2009 四月 (6)
2009 三月 (4)
2009 二月 (6)
2009 一月 (4)
2008 十二月 (9)
2008 十一月 (9)
2008 十月 (9)
2008 九月 (11)
2008 八月 (12)
2008 七月 (10)
2008 六月 (13)
2008 五月 (13)
2008 四月 (10)
2008 三月 (12)
2008 二月 (10)
2008 一月 (11)
2007 十二月 (13)
2007 十一月 (12)
2007 十月 (14)
2007 九月 (10)
2007 八月 (10)
2007 七月 (7)
2007 六月 (7)


所有文章列表


 


            文章搜尋    	    









 


            新聞交換(RSS)    	    




 


            誰來我家    	    



 


            參觀人氣    	    


本日人氣：
累積人氣：



 


            QR Code    	    





 


            POWERED BY    	    



(登入)


 


            twcount    	    

 
 
 






{{ article.user_name }}
{{ article.timestamp * 1000 | date:'MMM.dd.y.hh.mm' }}
{{ article.title }}
{{ article.content }}









我要留言                





 



 
 



回到頁首
回到主文
免費註冊
客服中心
痞客邦首頁
          © 2003 - 2017 PIXNET             
 
 




 




 




 



















關閉視窗












    找更多相關文章與討論



















PIXNET


Facebook


Yahoo!


Google


MSN










{{ guestName }}
(登出)






您尚未登入，將以訪客身份留言。亦可以上方服務帳號登入留言


請輸入暱稱 ( 最多顯示 6 個中文字元 )



請輸入標題 ( 最多顯示 9 個中文字元 )



請輸入內容 ( 最多 140 個中文字元 )







請輸入左方認證碼：

看不懂,換張圖

請輸入驗證碼


送出留言



















執行迴歸分析 - Excel









































































試用 Microsoft Edge
專為 Windows 10 設計、快速且安全的瀏覽器


不，謝謝
開始使用















Microsoft



Office









 無結果




0
 個項目在購物車中




登入








Office


購買 Office 365














支援







應用程式



Access
Excel
OneDrive
OneNote
Outlook
PowerPoint
SharePoint
商務用 Skype
Visio
Word



安裝


帳戶


訓練


系統管理










執行迴歸分析




適用對象: 
Excel Online
更多...
更少




 



重要: 
本文係由機器翻譯而成，請參閱免責聲明。本文的英文版本請見這裡，以供參考。


在 Excel Online 中，您可以檢視迴歸分析 (統計學中預測及預測趨勢的方式) 的結果，但由於迴歸分析工具尚無法使用，所以您無法建立結果。
您也無法使用統計的工作表函數 (例如 LINEST) 進行有意義的分析，因為其需要您將它輸入為陣列公式，這在 Excel Online 中尚不支援。
 
如果您有 Excel 桌面應用程式，您可以使用 [在 Excel 中開啟] 按鈕來開啟活頁簿，並使用分析工具箱的迴歸分析工具或統計函數來執行迴歸分析。
按一下 [在 Excel 中開啟] 並執行迴歸分析。



如需取得最新 Excel Online 更新的消息，請造訪 Microsoft Excel 部落格。
如需取得 Office 應用程式與服務的完整套件，請在 Office.com 上試用或購買。

 



附註: 機器翻譯免責聲明︰本文係以電腦系統翻譯而成，未經人為介入。Microsoft 提供此等機器翻譯旨在協助非英語系使用者輕鬆閱讀 Microsoft 產品、服務及技術相關內容。基於本文乃由機器翻譯而成，因此文中可能出現詞辭、語法、文法上之錯誤。































									擴展您的技能
								
探索訓練



									優先取得新功能
								
加入 Office 測試人員


















這項資訊有幫助嗎？


是
否




太好了! 還有其他意見反應嗎?
我們應該如何改進?



傳送​​
不，謝謝




感謝您的意見反應!


感謝您的意見反應! 我們將協助您與其中一位 Office 支援專員連絡以深入瞭解您的意見。

連絡客戶支援





×


















 

 









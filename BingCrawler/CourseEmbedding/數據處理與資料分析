

	科技大觀園 -- 大數據與巨量資料分析


















































:::
						｜
						網站導覽
						｜
						科國司
						｜
						科技部
						｜
						行動版


一般大眾 
						|
						國中小生





























  單元  



新知報
新知專欄 (956)電磁波知多少 (5)科技新知 (999)專題報導 (541)人物專訪 (86)科普點子王 (33)行動與無線通..(3)產學小聯盟 (32)科普人談科普 (32)創業第一桶金 (16)


文章
科普知識 (793)精選專題 (1121)文章導覽 (9)突破的故事 (94)女科技人 (28)獎聲響起 (82)台灣新發現 (274)科技與社會 (114)科技瞭望 (67)


演講
「展望」系列..(182)「週日閱讀科..(167)「週末 Le..(146)「FUN科學..(58)經典譯註『人..(24)人文大師下午..(2)「網際網路素..(53)健康與醫藥科..(27)科學講古 (74)週末學術科普..(34)生活化與科技..(16)中研院「知識..(20)其它演講 (195)


影視
來點ㄦ科學 (100)牛頓馬戲團 (80)科學大解碼 (201)科技萬花筒 (34)發現 (129)神秘的史前踏..(5)科學再發現 (113)流言真與假 (118)有趣化學實驗..(38)百秒說科學 (23)二分鐘發現科..(37)ㄐㄧㄤˋ吃就..(26)科普一傳十 (40)其它影視 (2)


廣播
科學180 (67)生活才科學 (112)來自海洋的聲..(103)今天科學了沒..(50)科學三分鐘 (148)啟動科學腦 (52)似是而非 (54)




  訊息  

佈告欄 (16)電子報 (51)演講活動 (466)科普活動 (372)

  認證  

公務人員學習教師研習

  科學迴廊    資源  

活動成果 (45)假日科學廣場 (45)科普資源資料庫 (11720)國研院年度成果 (1)全國科學探究競賽－這樣教我就懂 (2)

  出版品  

科學發展 (67)東亞科技與社會國際期刊 (13)



























:::
首頁 > 
			單元 > 文章 > 科普知識 > 大數據與巨量資料分析



				科普知識
			





	
		 
		
    


















大數據與巨量資料分析
 


2016/08/05
曾龍 | 崑山科技大學資訊工程系／雲端大數據分析暨資通安全研發中心
















 

在2012年10月發行的《哈佛商業評論》中，戴文波特‧湯姆斯（Thomas H. Davenport）及帕蒂爾（D.J. Patil）發表了一篇文章，描述「21世紀最性感的職業—資料科學家（Data Scientist: The Sexiest Job of the 21st Century）」。同年美國歐巴馬政府更投資了近兩億美元推行「大數據的研究與發展計畫（The Big Data Research and Development Initiative）」，希望藉著提升從大型複雜的資料中提取知識的能力，能加快科學和工程的開發並保障國家安全。

2015年2月19日，白宮正式任命帕蒂爾為首位首席資料科學家。當天他在聖荷西（San Jose）的Strata + Hadoop 2015會議做了一場主題演講，講題是「資料科學：我們將邁向何方？（Data Science: Where are We Going）」，美國總統歐巴馬還特地錄製短片祝賀大會順利舉行。影片中歐巴馬呼籲：「我們需要你—資料科學家—來幫助國民建立更好的數位服務，幫助我們揭開更新的創意……幫助我們改善這個國家和全世界。」

資料科學與大數據

在這個大數據時代，資料科學的狂潮不斷地推動著這個世界。2015年4月，美國國家標準技術研究所（National Institute of Standards and Technology, NIST）發表了共包括7冊資料的「大數據互用性架構草案」。在第一冊定義篇中，資料科學被譽為新興的第四個科學典範（理論科學、實驗科學、計算科學與資料科學）：「資料科學是一透過完整資料生命周期流程，所產生的自原始資料到具行動力的知識的實驗性綜合體。」

資料科學，這第四個科學典範是2007年由格雷‧吉姆（Jim Gray）所命名，它代表直接由資料本身所產生的知識。NIST所定義的資料科學典範是「直接由資料，並透過一系列發現、假設與假設檢定的流程，萃取出具行動力的知識」。

所謂「Big Data」坊間有許多翻譯，包括大數據、巨量資料、海量資料等。NIST則定義為：由具有龐大資料量、高速度、多樣性（多重異質資料格式）、變異性等特徵的資料集所組成，它需要可擴延的架構來進行有效儲存、處理與分析。

巨量資料的特徵

今日可說是個大數據的時代！自從進入21世紀後，全球資料量呈現大爆炸式的增長，資料量從PB級躍升至ZB級。根據國際資料公司（IDC）發布的2012年研究報告，從2011年全球創建和複製的資料總量是1.8 ZB，並以每兩年增加一倍的速度快速增長。預計到2020年，全球產生的資料總量將超過 40 ZB，這是地球上所有海灘上沙粒數量的57倍。

谷歌（Google）公司每天處理超過24 PB的資料，每個月則超過400 PB。淘寶網有5億多名會員，線上商品超過10億件，每天交易平均金額高達新台幣6億元以上，每日所產生的資料量也超過 50 TB以上，然而這只是全球資料量的一小部分。

大數據時代產生的資料有許多特徵，這些特徵也引領資料科學在這些新興資料型態的分析上有著重大發展。巨量資料的最大特徵當然就是龐大的資料量，如一般桌上型電腦的記憶體是以GB為計量單位，硬碟的容量則是以TB為主。電腦運算須把資料載入到記憶體上，因此要處理龐大的PB或EB資料，就必須有新的儲存模式及計算模式，這也是資料科學的重要研發領域。

巨量資料的第二大特徵就是速度。高速有兩層涵義，第一層是資料產生的速度，每天社交網路Facebook、Twitter及通訊軟體Line所產生的資料就是一例。IDC指出，到2020年，全球所有資訊部門擁有伺服器的總量將較目前多出10倍，管理的資料也比現在多出50倍，全球將總共有35ZB的資料量。另一層則是處理的速度要求，以中國大陸淘寶網在每年11月11日光棍節的電子商務活動為例，淘寶網須針對交易資料即時呈現活動的交易現況，這是巨量資料分析的一大挑戰。

巨量資料通常有時效性，一旦傳送到運算伺服器，就要能即時取得分析結果才能發揮其最大價值。巨量資料的即時分析需要飛秒級的速度，甚至1秒內完成億萬級資料的處理和分析，這也是巨量資料分析的挑戰課題。

資料多樣性是巨量資料的第三大特徵。一般商業交易所使用的資料大抵是以結構化資料為主，透過預先定義好的資料欄位進行儲存與運算。但除了結構化資料外，巨量資料還包含許多半結構化或非結構化資料。這些資料包括各類型生產機台所產生的日誌檔案、各式網路設備與伺服器產生的網路日誌檔、聲音、影片、圖片、地理位置資訊等，這類型資料的儲存與運算都需要新的運算架構。

上述所指的巨量資料主要以龐大的資料量（volume）、速度（velocity）與資料多樣性（variety）三大特徵為主，這就是大數據所謂的3V特徵。後續也有許多學研單位指出其他特徵包括真實性、價值與視覺化，這也凸顯了巨量資料的多面向觀點。

挑戰性課題與解決方案

龐大、高度異質性與非結構化資料的第一個挑戰就是資料儲存架構。現今資料庫技術主要是1970年卡德（E.F. Codd）所提出的關聯式資料庫，不管是開放原始碼的Postgresql、MySQL或商業版的Oracle、IBM DB2與微軟MSSQL資料庫，都是以關聯式資料庫的理論架構為主。這些資料庫在面對新興的高度異質性與非結構化資料都面臨了極大的挑戰，因此有許多新興的資料庫技術被提出，這些不同的資料庫技術都通稱為NoSQL（Not Only SQL）。

NoSQL與傳統式資料庫有相當多的不同，後者以定義良好的資料庫綱要來組織與儲存資料，並利用高階的SQL查詢語法存取資料。但前者無固定綱要模式，且NoSQL也不使用一般認知的SQL查詢語法。這些不同資料庫設計都有其目的與使用場景，最主要的設計考量包括可擴展性資料儲存功能的需求。

NoSQL資料庫是現今資料庫技術研發的重要領域之一。在超過上百個NoSQL資料庫中，大致可區分為五大類型，分別是鍵—值儲存資料庫、圖形資料庫、文件儲存資料庫、記憶體資料庫與欄儲存資料庫。這些針對資料多樣性與可擴展性所設計的資料庫技術，是資訊領域必須掌握的新技術。

針對龐大資料量進行運算，最常見與直覺的做法便是利用多台電腦（電腦叢集）來運算，這是分散式運算著重的主題。要進行電腦叢集的運算，通常需要有分散式檔案系統來儲存計算過程中的資料，以方便不同電腦快速且一致地存取資料。另外，不同台電腦運算所得的結果可能出錯，部分電腦也有當機的風險，因此要讓計算結果無誤，便需要新的容錯架構來處理。巨量資料的資料匯入、資料預先處理、資料分析與資料探勘都是巨量資料分析平臺必須深入考量的課題。

面對龐大資料量的分析，必須特別註重穩定性與系統平臺的可擴延性。現今巨量資料分析有許多架構，從最早廣受喜愛的Hadoop生態體繫到新進的Apache Spark、Storm都有不同的擁護者。Hadoop是Apache軟體基金會眾多開放原始碼的專案之一，也是現今使用度最高的巨量資料分析平臺，它主要特色在於分散式運算和分散式檔案系統，整合了許多軟體及元件共同組成了一個Hadoop生態體系，具有高可用性、高擴充性、高效率、高容錯性等優點，因此廣受喜愛。

2003年當谷歌發表GFS分散式檔案系統的核心技術論文後，次年卡丁‧道格（Doug Cutting）根據這理論撰寫出HDFS分散式檔案系統，同年谷歌再發表Map Reduce核心運算模式，而卡丁‧道格與同事也立即實作出運算架構。

由於卡丁等人曾聽見小孩為小象玩具取名為Hadoop，索性就把Hadoop做為專案名稱。Hadoop在2008年成為Apache頂級專案，這專案主要核心技術可分為3個子項目，即Hadoop Distributed File System（HDFS）分散式檔案系統和MapReduce分散式運算架構及資源調度子模組Yet Another Resource Negotiator（YARN）。

HDFS分散式檔案系統把分散的儲存資源整合成一個具有高容錯性、高擴充性、高吞吐率等優點，且允許使用者把Hadoop建置在低廉的硬體上的檔案系統。HDFS是主從架構，它由兩種角色組成：命名節點及資料節點。命名節點負責檔案系統中各個檔案屬性權限等資訊的管理及儲存，資料節點則擔任運算的任務。

一個龐大的資料檔案會被切割成數個較小的區塊，儲存在不同的資料節點上，每一個區塊還會有數份副本存放在不同節點，因此當其中一個節點損壞時，檔案系統中的資料還能保存無缺。命名節點還需要記錄每一份檔案存放的位置，當有存取檔案的需求時，要協調資料節點來負責回應。當有節點損壞時，命名節點也會自動進行資料的搬遷和複製。

Hadoop的分散式運算是建立在MapReduce計算模式，其主架構是把龐大資料切割成許多部分資料，然後交給多台電腦先進行Map運算後，再做Reduce運算來進行巨量資料的平行化快速處理。在Hadoop中是以Java編寫程式，其以Java開發的MapReduce模式稱為native mode（原生模式），若要以不同程式如Python或R進行分析，也可利用Hadoop Streaming模式開發。

Hadoop隨著發展推出第2代的Yarn資源調度與管理的新框架。Yarn把負責運算工作分配與追蹤的任務分開來，它使用資源管理者負責管理分配全局資源，並使用應用程式主導者負責管理任務的整個生命周期內的所有事宜，任務執行的追蹤與管理則使用節點管理者。整體運作架構是由應用程式主導者與資源管理者溝通協商如何分配資源，和節點管理者協同執行並監測應用程式的執行情況。

Hadoop生態體系除了上述三大核心外，也包括了下列子平臺。其中HBase是用於Hadoop檔案系統上的資料庫系統，採取Column-Oriented 資料庫設計。Hive則是建置在HDFS上的一套分散式資料倉儲系統，可用SQL語法存取Hadoop資料，另可讓使用者以慣用的SQL語法存取Hadoop檔案中的大型資料集。

ZooKeeper則是監控和協調Hadoop分散式運作的集中式服務，可提供各個伺服器的配置和運作狀態資訊，用於提供不同Hadoop系統角色之間的工作協調。Pig則利用更接近使用者的介面，封裝了HDFS和MapReduce中低層的程式設計介面，使用者使用一些敘述就能完成工作，而不需撰寫較為複雜的Map Reduce框架程式，這就降低了使用者開發的難度，也為系統自動進行最佳化。

Sqoop主要是協助傳統關聯式資料庫與 Hadoop之間進行高效率的大規模資料交換，透過 Sqoop可以輕鬆地在指令模式下把資料導入到Hadoop與其相關系統（如HBase、Hive）。Mahout則提供具高度可擴充性的機器學習演算法，它包括群集、分類，以及協同過濾的核心演算法。

近年興起的Storm是Twitter公司在2011年7月收購的BackType社交媒體資料分析公司，其首席工程師馬茲‧內森（Nathan Marz）與其團隊於同年9月17日推出的第一個作品Storm，是一個分散式串流資料處理系統，其強大的分散式管理、可靠性高、高容錯保障，在性能和功能方面大幅彌補Hadoop所欠缺的即時運算需求，使得很多公司紛紛加入使用。

Clojure是Storm主要的開發語言，它是基於Lisp所設計的函數型語言，並且增加了多執行緒等特性，使得Storm在底層有著高效率的通信和非同步處理能力。另一個著名的巨量資料分析平臺是Spark，2009年由扎哈里亞‧馬泰（Matei Zaharia）在加州大學柏克萊分校AMP Lab所開發，2010年以Scala語言開發完成，並於同年透過BSD授權條款開源釋出。2013年該專案捐贈給Apache軟體基金會，並切換授權條款至Apache2.0。

2014年2月Cloudera宣稱加入Spark，2014年4月MapR也投入Spark陣營。另Apache Mahout也放棄MapReduce模式，將改用Spark為計算引擎。2014年11月Databricks團隊使用Spark刷新資料排序的世界紀錄而引起全球註目。

Spark使用了記憶體內運算技術，能在資料尚未寫入硬碟時，就在記憶體內分析運算，甚至透過Spark的串流處理套件即時處理串流資料。根據Apache Spark官方的說明，Spark在記憶體內執行程式的運算速度，可以比Hadoop MapReduce的運算速度還快上100倍，即便是在硬碟執行時，Spark也有達到10倍的速度。

面對巨量資料時代的作為

我國及全球已經有許多巨量資料分析的應用領域與成功案例。以半導體產業為例，各種先進製程控制的資料分析至為關鍵，一旦製程良率出問題，如何在最短的時間內找出所有相關因素，甚至事先就能預知並且杜絕問題發生，一直是高科技製造業最大的挑戰。面對各種機台產生的大數據，巨量資料分析就扮演著重要角色。

另外在全球興起的物聯網、車聯網及智慧城市，再加上各國政府力推的開放政府與開放資料，都會產生許多龐大的資料，這些資料如何產生有價值的訊息、如何有效管理與利用，更是現今資料治理的重大議題。

各行各業對於大數據的濃厚興趣，也直接反映在大數據人才的豐厚薪資中。McKinsey Global Institute在 2013 年的報告指出，僅美國而言，到 2018 年就缺少 14 萬到 19 萬名的大數據分析師。在美國芝加哥獵人頭公司Linda Burtch 2014年的薪資報告中，也發現資料科學家的平均年薪資已優於醫師和律師，而美國人力資源網站 SimplyHires.com與Linkedin上則約有 24,000～36,000個資料科學職務求才名額。這些報導都不斷強調嚴重欠缺的資料科學家或大數據資料分析師將是各國爭相搶奪的人才。

資料科學家或大數據資料分析師都是近三年才冒出頭的職務，學術界尚未培育出足夠業界所需的人力，因此現在大多是以其他領域的人來從事資料分析工作。譬如雅虎的資料分析工作是由天體物理學、應用數學背景的人擔任；行動付款公司Square則僱用認知心理學家來研究消費者的付款行為模式。

大數據時代的到來及巨量資料分析的龐大需求，不管是大資料城市治理，還是智慧聯網的各種應用，都宣示著需要更多的人才投入。這也是現今台灣朝向加值創新智慧島之路邁進時，須及早準備的議題。
 瀏覽人次：6,078    大數據(29)  來源：《科學發展》2016年8月，524期，66 ~ 71頁 




已有 1 個人按~讚~


 

熱門標籤  

 


物種滅絕(13)電洞(21)聖嬰現象(14)擴增實境(19)輻射(27)基因工程(6)電波(41)臺灣山毛櫸(3)災害(42)3D列印(29)枯草桿菌(4)再生能源(27)稀有物種滅絕(2)肥胖(48)大數據(29)機器人(51)衛星遙測(32)演化(85)穿戴裝置(7)地震(106)


 


 返回列表 


 





颱風來時要幹嘛？–親臨...
自然語言理解–人工智慧...
手機的奇幻漂流(二)：...
大數據專題報導（一）：...
大數據專題報導（二）：...





















單元
新知報
文章
演講
影視
廣播


訊息
佈告欄
電子報
演講活動
科普活動


認證
公務人員學習
教師研習


科學迴廊


資源
活動成果
假日科學廣場
科普資源資料庫
國研院年度成果
全國科學探究競賽－這樣教我就懂


出版品
科學發展
東亞科技與社會國際期刊














關於我們 | 著作權聲明 | 隱私權及資訊安全宣告 | 服務條款 | 聯絡我們

				瀏覽本站建議使用 IE10 以上、MS Edge、Firefox、Chrome 或 Safari 等瀏覽器，1,280 x 720 以上解析度  
				    
				網站瀏覽人次：15,184,158
			

















實驗數據的處理與分析


實驗數據的處理與分析


物理是個實驗科學，免不了要從事測量。很多同學常常疑惑的是
不知道如何正確的分析與處理實驗的數據。
希望本單元能對你（妳）有所幫助！
為了減少本網頁篇幅，歡迎繼續參考 物理實驗
相關網頁。


誤差 = 測量值 - 真值

談實驗數據往往會先談到 誤差的定義。於是出現了上面的式子。
誤差 就是 所測得的數值 與 被測量物理量 真正數值之間的差別。
好像很有道理，又好像在講廢話！
先想一想，為什麼我們要從事測量？（才能有測量值！）
如果 我已經知道 想測量的物理量的真值，我為什麼還要去測它？
難道就為了要 知道測量的誤差嗎？
就是因為不知道 物理量的真值才要測量。
那！ 誤差的定義 又有什麼用呢？
實驗數據的處理與分析 便是想運用統計的方法，
讓我們從多次的測量數據中，估算出 最接近 真值 的數據。
也就是我們所想要的測量結果。並藉由 誤差的分析，讓我們瞭解
我們所做的估算，可信度有多高！並探討實驗誤差的可能來源。
拿一杯開(茶)水或咖啡，以下可有好一陣子讓妳（你）想一想的！


誤差的種類：（依照來源）
一般而言，可以分為 系統誤差(systematic error)與 隨機誤差(random
error)。
1. 『系統誤差』：
所謂測量，乃是大家事先公定有一測量 單位（標準），例如 公尺。
然後依據製造出含刻度的測量工具（例如 尺），
將測量工具 和待測物相互比較，而判得 測量值。
如果測量工具本身所顯示的刻度，因為
校正時疏忽，造成不正確。
或因為 環境的因素（例如溫度 壓力等），使得數值產生變化。
或因 人為不正確（或不熟練）操作或 觀測方法錯誤。
都是可能產生 系統誤差的來源。
對於某些非 直接測量的物理量，依據某 原理或方法設計出來的實驗。
也有可能因為 實驗時 無法充分滿足 原理所假設的狀況，
或根本設計原理有失誤，而造成系統誤差。（這也是很多人常忽略的）
通常 『系統誤差』會使得所有測量值 都過高或過低的偏差，
偏差量大致相同，不含機率分佈的因素。

2. 『隨機誤差』：
實驗的基本方法，往往是希望能 控制變因，
以找出 物理量受 個別變因的影響。
因此 總是希望 控制所有影響的變因，一次只讓一種變因變化。
實驗的設計便是盡量能達到上述的目的。
而且為了實驗簡便，往往也忽略對實驗影響較微小的因素。（也比較實際）
但實際操作時，不見得盡如人意。
這些不易控制（有時候無法控制）的小變因，
便會使測量值產生隨機分佈的誤差。
也就是說 有些測量值會過高，有些則會稍低。


降低 『系統誤差』的方法，當然只有靠 正確分析誤差來源：

儀器造成的 → 設法改良儀器。
環境造成的 → 設法控制實驗環境。
操作不良的→ 只好 加強訓練自己了喔！
理論上 或許可能將儀器誤差完全消除，
但是 前兩項的改善，並不需要做到 最完美的情形！
？？？
奇怪！ 不是儀器越精良，環境越穩定 實驗結果越好嗎？
因為 這些改善的要求，牽涉到 對測量值 所要求的『精密度』
與實際環境與經費等的考量 。
而且改善時 應該以所有誤差來源 所造成測量誤差的比例，
能以約略相同的比例 減少才有效。
例如：把所有經費大部份都買最精密（也最昂貴）的儀器，
環境因素卻因為能力不夠改善（或已經改善至最好境界），
但仍然造成較大比例誤差，則精密的儀器不過是 花冤枉錢 吧了！
碳的 電阻係數（resistivity) 的溫度係數 = -0.0005 （於 20oC
)
也就是說 碳的 電阻值 當溫度升高 1 Co時，電阻值會減少 萬分之五。
若是使用 6位有效位數的電表（數萬元）來測量實驗過程中的電阻值，
但實驗過程中並未註意（或控制）溫度變化，而使得 碳電阻器的溫度
有好幾度的變化，則 效果和只用 3-4位有效位數的電表（數千元）一樣。

降低『隨機誤差』的方法，則是我們以下所要探討的：
藉由 統計的方法，提供我們如何（藉由增加測量次數）
最有效率的改善『隨機誤差』。

準確度與精密度：
精密度：當多次重複測量時，不同測量值彼此間偏差量的大小。如果多次測量時，
彼此間結果皆很接近，則稱為精密度較高。

準確度：準確度的定義是 測量值與 真值（或公認值）
的偏差程度。
公認值通常指 使用已知較準確且精密度高的實驗儀器，
在優良訓練的實驗人員重複操作下，所得出精密度相當高的 實驗結果。
但實驗時 不見得有所謂公認值存在。
問題： 你認為 精密度與準確度之間有直接的關係嗎？
精密度高的結果，準確度一定高嗎？
準確度高的結果（平均值），精密度一定高嗎？


測量本身必然造成誤差。（抬槓篇）
當去測量 待測物時，需要去觀測它，也就因此改變了待測物。
例如：用溫度計去測量物體溫度，則溫度計溫度因而改變至與待測物相同，
溫度計所變化的溫度是 兩者能量交流的結果。
也因此待測物 測後溫度已經不同於 測量前了。
問題：難道 用尺去測量長度也會影響待測物長度嗎？
當然這種影響很小（但還是存在 --抬槓嘛！）
當你要用尺去測量物體時，會要求兩者之間無相對運動，
（相對運動也可以，但一樣會牽涉到時間與其他的問題）
則必然要對他們施力，於是造成 通常很微弱的形變。
再不行，我還有最後法寶 --- 測不準原理。
（有學問的名詞吧！抬槓，可別太介意！）

當然 測量的方法，也有所謂的 非破壞性測量。
也就是說不主動去乾擾 待測物，而只是測量 待測物所 產生的訊號。
例如：利用物體的黑體輻射測量其溫度，
但物體會輻射也就表示 其物理量（溫度）在變動。該回主題了！



統計分析方法
母分佈：
每一個待測物理量，我們可以假想 存在一個『真值』（只是不知道）。
假設只有隨機誤差而完全前沒有系統誤差的情況下，
如果我們對同一物理量，測量次數一直增加。
則隨機誤差的影響 使得 測量值大於真值與小於真值的機率分佈一樣，
則 所有測量值的平均值，將隨著測量次數得增加而越接近 真值。
當 測量次數等於 無窮多次 時，測量值的分佈 稱為 母分佈。
（橫軸為測量不同數值，縱軸為每個測量值被測到的次數）
無窮多次：什麼意思嘛！怎樣才算？
由於我們不可能 無窮多次 的測量，所測得有限次的測量屬於
母分佈的部份樣本 --> 就稱為『樣本分佈』好嗎？
於是 有限次數的 算數平均值 是我們對於
真值 所能給（猜）的最好的估計值。
算數平均值(mean) ：

偏差（deviation)：
為了想瞭解測量數據與平均值的偏離程度，於是定義
每一個數據與平均值的差值，稱為偏差。


但偏差量有正有負，且所有偏差量的總和必為零。

為了想 量化 實驗數據的精密度，且解決偏差量總和必為零的情形。
我們可以將 偏差量平方後相加，而定義出
方差（Variance)：
為 偏差平方的平均值。
當然將偏差量取絕對值後相加，也可以顯示實驗的精密度，但是數學計算上
採用方差 ，比較方便。

方差計算時 可簡化為 平方的平均值 減去 平均值的平方。
比直接用公式計算，簡單多了！



標準偏差(Standard Deviation)：
對於母分佈而言（n→∞）時，取方差的平方根（與測量量相同單位）
定義 母分佈的 標準偏差（代表實驗數據分佈的精密度）***註:下圖中d23應該修正為d22

為 偏差平方的平均值 的根號，稱為『方均根』。
方均根英文為 root（根）mean（均）square（方）.
如果直接利用上面的定義來 處理 有限次數的 測量數據時，
會發生矛盾的情形？
例如：如果對於某一物理待測量，只有測量一個數據，
則 平均值等於唯一測量值，因此偏差為零。
當然 偏差的方均根值必為零。也就是有最良好的精密度。
那豈不是所有測量皆測一次就夠了！？
問題出在哪兒呢？
因為計算 n 個數據的個別偏差時，需先計算 平均值。
當有平均值時，只要有 n-1 個數據便可以算出所有的偏差量。
也就是 計算方差（偏差量平方的平均值）時，
數據中的獨立變數僅有 n-1 個，因此計算平均值時
分母若改為 n-1 較為合理。
因此 樣本分佈（有限次數）數據的 標準差定義為

如此一來只測量一次時，上式中分子分母皆為零，
也就是 無法確定 標準差（合理吧！）
當（n→∞）時則分母為 n 或 n-1 已經沒有差別了。
*** 工程用 計算機上有 σn 與 σn-1 差別便在於分母。
以上定義的 標準差代表 所有測量數據與 平均值之間
平均的 偏差量（也就是每一測量數據的精密度的平均值）。
可是通常我們也關心所計算出 平均值的可信度是多少？
也就是 實驗結果的 精密度有多高？
平均值的精密度 應該要高於 個別測量數據的精密度。
我們先寫下 依據統計理論所得出的結果。
平均值 的標準差（standard
error of the mean)

（想知道知為何如此，先再去泡杯茶，休息一下，再繼續看下去...)
多次實驗測量結果 寫為

也就是 測量（平均）量 加上 所對應的標準差（俗稱 不準量 ：uncertainty）。
註： 實驗結果不見得一定都是 平均值，例如 測量 電阻的溫度係數，
溫度一直再改變，測量不同溫度時 電阻值的變化量。
可以用 最小方差計算法 計算出斜率（變化率）。
並利用『誤差傳遞』方法計算其 標準差。


標準偏差所代表的意義與運用：
通常當 測量次數多時，測量數據的 隨機分佈 滿足
常態分佈 (normal or gaussian distribution):

P 是測量值 為 x 的機率。(次數少時為二項式分佈）。
如下圖為平均值為 50, 標準差為 10. 的常態分佈，

測量值 出現在
範圍內的機率為
68.3%。(2:1)
範圍內的機率為
95.4%。(20:1)
範圍內的機率為
99.7%。(350:1)
範圍內的機率為
99.994%。(15000:1)
當從事多次測量時，有時候會某些數據與平均值相差的較多，
懷疑是因為測量時不小心 觀測錯誤或 ... ，怎樣判斷該不該
捨去那些數據呢？
例如：測量某物體長度100次，計算出 平均值與標準差（非 平均值的標準差）後，
發現 有 3 組數據 落在 3 倍標準差外，4 組 落在 2倍與3倍之間，
其餘皆在 平均值與 標準差之間。
若採用常態分佈， 由於數據 落在2 倍標準內的機率有 4.6%。
因此 那四組數據是合理的。
但是數據 落在 3 倍標準差外的機率應 小於 千分之三。
因此 應該重新檢討 那三組數據，（除非肯定數據沒問題）通常可以捨去
那三組數據捨去後，重新計算 平均值 與 標準差 。再檢視都沒有問題後，
並計算平均值的標準差後，寫出 測量結果。


平均值的標準差的意義：
每次(組）多次實驗所得平均值都不會相同。這些平均值也會形成一種分佈。
平均值的標準差便是 代表這些不同的平均值的可能差異性（精密度）。
綜合說來：
實驗數據的 標準差(standard deviation)
顯示單一個測量值與平均值間可能偏差的程度。
重複（增加實驗次數）並不會減少其數值。（單一測量的精密度）
平均值的標準差(standard error of the mean): 則
顯示 所得平均值的可重覆性程度，（結果的精密度）。
如果多組重覆測量 所計算出平均值 的 標準差。
其數值可以藉由 增加測量次數而減少，與 成反比。
因此 10000 次測量平均值的標準差為 100 次測量 的 1/10.
為了增加一位有效位數，次數由 100 增加到 10000. 可真是不容易。


誤差傳遞：
經常一個物理量 是經由測量 數個 物理量，再藉由 關係式 計算而得出。
例如：動量是由測量值 質量與速度相乘而得（速度又由位移與時間測量值得出）。
當測量時，質量、位移與時間的個別誤差 將影響最後結果的誤差。
假設 X 代表某一個物理量，由 等測量值所決定。
即 
而以 分別代表等分量
樣本分佈的平均值。
則 平均值 
對於某一組測量樣本數據，可以表示為 則

測量值的方差

其中
，，
而 稱為
協方差（corvarance）。
如果 u 和 v （測量物理量）彼此不相關，則
協方差為零。
（通常 測量時的個別參數間是互不相干的）
於是 方差可以簡化為 


當測量物體密度時，質量與體積的測量通常不相干，因此可用上式
計算 質量與體積的誤差所造成 密度測量的誤差。
但是體積測量誤差的計算，若體積是由 長、寬、高等測量值相乘而得。
當 長、寬、高 都是用同一量具同樣方式測量時，往往彼此間的誤差是相關的。
尤其當量具 的系統誤差 大於隨機誤差時，
由於 校正所造成誤差將造成長、寬、高的系統誤差。
則體積的百分誤差 將直接等於 長、寬、高 百分誤差之和。
（而非 長、寬、高 百分誤差平方之和 開根號）。
當使用誤差傳遞時 要辨別測量值間是否彼此相關。


讓我們運用上式 計算 平均值的
標準差。

平均值 是由 各測量值 取平均而得到（視為 以各測量值為獨立變數的函數）。



若 各測量值的標準差皆相同時，上式可以簡化為

於是平均值的 標準差 


讓我們再做幾個例題：
1. 


例如： (3.1257 ± 0.0138) - ( 1.892 ± 0.0095)
= (3.1257 - 1.892) ± (0.01382 + 0.00952)1/2
= 1.234 ± 0.017
註意： 誤差並非 0.0138 + 0.0095 ? 為什麼呢？
3.1257 ± 0.0138 表示 測量值在 3.1257-0.0138
與 3.1257+0.0138之間，
多次測量時應該越接近 3.1257 的數值越多，離開越遠的機率越少
（滿足常態分佈）。因為隨機分佈的關係，大於平均與小於平均的機率皆相等。
當兩測量值相加時，兩者偏差皆為最大正偏差或皆為最大負偏差的機率，
應該很小，經統計分析以 平方相加開根號為較適當。
2. 


若 協方差為零時，則 結果的百分誤差的平方
等於個別參數的百分誤差的平方和。
參數間為相除的情形時，也有相同結果，請你自以試一試。
3. 換人做做看！該你練習了喔！

分別練習計算 以上三種函數的標準差。

以上皆討論 獨立變數間的誤差皆互不相干，彼此不受影響。
若是討論包含系統誤差的情形，或是 變數間相互影像時，就必須考慮 協方差。
例如： 體積是由三個測量值 長，寬，高 相乘而得，
假使測量的尺因為溫度的變化而收縮。
用同一把尺測量，則 長寬高 誤差皆會有相同趨勢（同時過大或過小）。
則百分誤差不再是 平方後相加再開根號，而是直接相加。


有效位數的說明：
當使用測量工具從事測量時，工具的最小刻度限制了測量值的有效位數。
通常我們以儀器最小能讀到的刻度值 外加一位估計值 作為記錄的結果。
但是 由於科技的進步，現代很多儀表顯示時都已經 數位化（直接顯示數值），
在正常的情形下，最後一位顯示的數值，已經包含了儀器幫你估計的成分。
（事實上，你也無從估計！）
但是：並非數位化的儀器所顯示的數值，完全都是必須記錄的。
儀器顯示的最小刻度值，應該要配合儀器的精密度。
但是儀器商生產不同精密度的儀器時，為了成本問題很可能使用相同的顯示元件。
因此某些儀器顯示的數值，可能多於實際的精密度。
另外一種情形是，儀器也的確夠精密，但是你所測量的環境本身造成的影響，
超過儀器精密度的範圍。
例如：使用 6位半的精密電表去量 溫度沒有適當控制環境下的電阻。
結果數值後幾位連續不斷的跳動。（也就是選用太過精密的儀器）
多記了後面一直變動的數值，有用嗎？
（這也是一般學生常犯的毛病，所有數值皆記下來）
基本原則：實驗記錄所顯示的最小刻度值，也應該要配合測量的精密度。
否則只是增加自己計算的負擔而已！可能只是增加記錄的負擔而已，
數據處理時...
反正用計算機在計算，可能計算完畢，還多了好多位 有效位數呢！
用 10 位顯示的計算機， 實驗結果變成 10 位有效位數。
如果用 12 位顯示的計算機， 實驗結果變成 12 位有效位數。
好像 實驗的精密度 取決於計算機的功能！？？？
這不是笑話！這是現代很多學生的毛病，甚至在 科學展覽的會場都會見到。
這已經變成一種習慣，不是說一說就改的過來！要一直的提醒自己！
（其實在 正式的刊物，偶而也會見到類似的錯誤）
在過去要用 手算 的時代，就不容易出現這樣的問題！（科技帶來的影響）
舉一個實例：如下表
 


測量序號
長度 L (cm)
寬度 W (cm)


1
10.78
8.21


2
10.80
8.20


3
10.75
8.22


4
10.73
8.21


5
10.78
8.22


平均值 
標準差
平均值的標準差
結果
10.77 
±0.02
±0.01
10.77±0.01
8.212 
±0.008
±0.004
8.212±0.004


從以上的例子，是否看出該怎樣選取 記錄的有效位數。
和 試驗數據的標準差， 有怎樣的關係呢？
決定好有效位數後 多出來的位數， 便利用
四捨 六入 五成雙的原則。
四捨 六入 大概你得很清楚，可是什麼是 五成雙呢？
嚴格一點說：應該是 捨去的第一位如果大於 5 則 進位。
但如果恰好等於 5 則依照數據最後一位來決定，
奇數則進位，偶數則捨去。
主要是 我想是為了 數據常要除以 獨立變數等運算，
如果每次遇 5 皆進位，有可能經過數次運算後 連續進位好幾次。
而用上法 來試圖抵銷。
例如：

 


（取有效位數）處理前
（取有效位數）處理後


3.154
3.15


3.151
3.16


3.155
3.16


3.145
3.14




可是 如果最後的結果 是利用好幾層的關係式 計算而得到的，
是否每計算一次 就要將數據 取至適當的有效位數，再繼續算下去。
還是 反正用計算機一直算，最後在取有效位數。
我提供的原則是：
當數據計算時，運算的數目來源是 由於數學推導的常數或物理常數，
則最後 再取有效位數便可。（視常數完全有效）
但是若遇到 測量值，則必須運算完後，馬上取 至適當的有效位數。
例如：面積等於常乘寬，算出後馬上要決定 適當的有效位數，
再繼續運算下去。你認為這樣的原則合理嗎？

好像還有問題耶！ 9.8×1.28 該取幾位有效位數？
12.54 還是 12.5 還是 13.
雖然通常 加，減，乘，除等運算時 有效位數以最不準確的因子的 有效位數為基準。
但是 上面的運算 取 13. 就似乎不太合理。
事實上，當處理數據時，你可以用 數據的標準差 作為最適當的判斷依據。
附記：當使用游標尺時，有沒有
所謂的估計值呢？


補充說明：
1. 有限次數的平均值 是我們對於真值
所能給（猜）的最好的估計值
由於方差代表著 數據的偏差量，對於一組數據而言，
若是此偏差量越小越好。問題改換成：
採用 怎樣的平均值計算方式 會有 較小的方差？
取 方差對平均值（偏）微分等於零的結果如下：

所以採用 算數平均值 的計算方式時，方差有最小值。
（不信的話，你也可以自己試一試 幾何平均值，看看結果如何）
2. 最小平方作圖法：
實驗時，我們常會需要測量 某物理量（應變數）隨 物理參數（自變數）變化時，
彼此間的關係。例如：電阻（縱軸）隨溫度（橫軸）的變化。
最小平方曲線作圖法 便是在 所繪出 數據圖中（電阻--溫度圖），
描繪出一條曲線，使的所有數據點到曲線距離平方總和（方差）為最小。
用 f(xi,yi) 表示數據點，
我們希望找出（最小方差曲線），使得
有最小值。
以上假設 自變量 沒有誤差（或相對很小）：


以下我們以常見的線性關係為例，希望找出
a, b
使得 有極小值。
也就是找出 最能代表 測量數據線性關係的直線。
欲 使方差有 最小值 ==>


聯立解 上兩個方程式，可得到

上式中 a 為直線斜率，b 為其截距。


經常 所測量物理量之間的關係式並非如 如此簡單的關係，
可以仿造上面計算最小方差的方式，找出各係數的值。
但是大多數情況，皆可以利用 變數變換的方式，將關係式轉換成
簡單線性關係。
例如：電容放電時，電容電壓隨時間變化的關係
Vc(t) = Vo e-t/RC
實驗時測得 電壓 V 隨時間 t 變化的數值，欲求得 Vo 以及 放電時間
RC值。
可將所測得 電壓取對數
lnVc(t) = lnVo - t/RC
令 y =Vc(t)，x = t 則 有 y = a x + b 的關係。
利用上面最小平方法 求得
斜率 a = -1./RC，截距 b = lnVo


接下來的問題是：
1. 這樣計算出來的直線，用來代表原有數據的關係 好不好呢？
提示： 當然 方差 越小越好喔！
可是如何判斷呢？（你應該知道為何除以 n-2 了吧！）
2. 所計算出來的 直線斜率 a 和 截距 b 的誤差又是多少呢？
提示： 利用 誤差傳遞 的計算法 去計算。
將 a,b 視為 xi 以及 yi 的函數，但是上面的計算中皆假設
xi 沒有誤差。
因此 只需要 計算由於 yi的誤差所傳遞給
a,b 係數的誤差。


令 (Δ
≦ 0. 對嗎？）
則 且 
於是得到


若是 所有測量數據 標準差相同 ，
我們又可將原點平移（任選原點）使得
於是上面結果可以簡化為

 

對於任何數據我們皆可以 代入上面最小平方法找出一條直線 
可是 數據 x,y 之間，是否真的適合用 線性關係描述呢？
我們用這樣的想法來評斷：若 兩者之間真的滿足 y = a x + b
則 若是我們改用 x' = a' y + b' 去描述，應該也可以得到適當的曲線。
理想情況應當滿足 
於是我們可以檢驗用 以上兩種直線方式所得出之斜率相乘積越接近於 1
表示 x,y 間越相關，於是定義 (linear-correlation coefficient)

若是 γ值越接近於 1.0 則表示 x-y 數據間 越適合用上述 線性關係描述。

你的頭腦還清醒嗎？ 總算可以休息了！
為了減少本網頁的篇幅，請繼續參考 物理實驗
網頁。

參考資料：
1. 國立台灣師範大學物理系 普通物理實驗手冊
2. 國際奧林匹亞物理競賽 國家代表隊 選訓時，林明瑞
教授 講授
『實驗數據的處理』的講義。
3. "Data Reduction and Error Analysis for the Physical Sciences", Philip
R. Bevington
如有 疏漏之處，請批評指教！或有相關問題仍不明瞭，歡迎來信一起討論。(97/9/21)


歡迎批評指教！電子郵件 ： 請按 hwang@phy03.phy.ntnu.edu.tw
作者：國立台灣師範大學物理系
黃福坤
最後修訂時間： 













數據分析 - MBA智庫百科









 
 















數據分析

出自 MBA智庫百科(http://wiki.mbalib.com/)


數據分析（Data Analysis）

目錄

1 數據分析的概念[1]
2 數據分析的目的與意義
3 數據分析的功能
4 數據分析的類型
5 數據分析步驟
6 問捲數據分析方法[2]
7 數據分析案例分析

7.1 案例一：數據分析在郵政報刊中的應用模式研究[3]
7.2 案例二：數據分析在企業運營管理中的應用[4]


8 相關條目
9 參考文獻


[編輯] 數據分析的概念[1] 
　　數據分析是指通過建立審計分析模型對數據進行核對、檢查、復算、判斷等操作，將被審計單位數據的現實狀態與理想狀態進行比較，從而發現審計線索，搜集審計證據的過程。

[編輯] 數據分析的目的與意義 
　　數據分析的目的是把隱沒在一大批看來雜亂無章的數據中的信息集中、萃取和提煉出來，以找出所研究對象的內在規律。
　　在實用中，數據分析可幫助人們作出判斷，以便採取適當行動。數據分析是組織有目的地收集數據、分析數據，使之成為信息的過程。這一過程是質量管理體系的支持過程。在產品的整個壽命周期，包括從市場調研到售後服務和最終處置的各個過程都需要適當運用數據分析過程，以提升有效性。例如J.開普勒通過分析行星角位置的觀測數據，找出了行星運動規律。又如，一個企業的領導人要通過市場調查，分析所得數據以判定市場動向，從而制定合適的生產及銷售計劃。因此數據分析有極廣泛的應用範圍。

[編輯] 數據分析的功能 
    數據分析主要包含下麵幾個功能：
　　1. 簡單數學運算（Simple Math）
　　2. 統計（Statistics）
　　3. 快速傅里葉變換（FFT）
　　4. 平滑和濾波（Smoothing and Filtering）
　　5. 基線和峰值分析(Baseline and Peak Analysis)

[編輯] 數據分析的類型 
　　在統計學領域，有些人將數據分析劃分為描述性統計分析、探索性數據分析以及驗證性數據分析；其中，探索性數據分析側重於在數據之中發現新的特征，而驗證性數據分析則側重於已有假設的證實或證偽。

 探索性數據分析：是指為了形成值得假設的檢驗而對數據進行分析的一種方法，是對傳統統計學假設檢驗手段的補充。該方法由美國著名統計學家約翰·圖基(John Tukey)命名。

 定性數據分析：又稱為“定性資料分析”、“定性研究”或者“質性研究資料分析”，是指對諸如詞語、照片、觀察結果之類的非數值型數據（或者說資料）的分析。

[編輯] 數據分析步驟 
數據分析有極廣泛的應用範圍。典型的數據分析可能包含以下三個步：

1、探索性數據分析，當數據剛取得時，可能雜亂無章，看不出規律，通過作圖、造表、用各種形式的方程擬合，計算某些特征量等手段探索規律性的可能形式，即往什麼方向和用何種方式去尋找和揭示隱含在數據中的規律性。
2、模型選定分析，在探索性分析的基礎上提出一類或幾類可能的模型，然後通過進一步的分析從中挑選一定的模型。
3、推斷分析，通常使用數理統計方法對所定模型或估計的可靠程度和精確程度作出推斷。

數據分析過程實施
　　數據分析過程的主要活動由識別信息需求、收集數據、分析數據、評價並改進數據分析的有效性組成。
　　一、識別信息需求
　　識別信息需求是確保數據分析過程有效性的首要條件，可以為收集數據、分析數據提供清晰的目標。識別信息需求是管理者的職責管理者應根據決策和過程式控制制的需求，提出對信息的需求。就過程式控制制而言，管理者應識別需求要利用那些信息支持評審過程輸入、過程輸出、資源配置的合理性、過程活動的優化方案和過程異常變異的發現。
　　二、收集數據
　　有目的的收集數據，是確保數據分析過程有效的基礎。組織需要對收集數據的內容、渠道、方法進行策劃。策劃時應考慮：

①將識別的需求轉化為具體的要求，如評價供方時，需要收集的數據可能包括其過程能力、測量系統不確定度等相關數據；
②明確由誰在何時何處，通過何種渠道和方法收集數據；
③記錄表應便於使用；
④採取有效措施，防止數據丟失和虛假數據對系統的乾擾。

　　三、分析數據
　　分析數據是將收集的數據通過加工、整理和分析、使其轉化為信息，通常用方法有：

老七種工具，即排列圖、因果圖、分層法、調查表、散步圖、直方圖、控製圖；
新七種工具，即關聯圖、系統圖、矩陣圖、KJ法、計劃評審技術、PDPC法、矩陣數據圖；

　　四、數據分析過程的改進
　　數據分析是質量管理體系的基礎。組織的管理者應在適當時，通過對以下問題的分析，評估其有效性：

①提供決策的信息是否充分、可信，是否存在因信息不足、失準、滯後而導致決策失誤的問題；
②信息對持續改進質量管理體系、過程、產品所發揮的作用是否與期望值一致，是否在產品實現過程中有效運用數據分析；
③收集數據的目的是否明確，收集的數據是否真實和充分，信息渠道是否暢通；
④數據分析方法是否合理，是否將風險控制在可接受的範圍；
⑤數據分析所需資源是否得到保障。

[編輯]問捲數據分析方法[2]
　　採用的分析方法如下： 
　　1．描述性統計分析
　　包括樣本基本資料的描述，作各變數的次數分配及百分比分析，以瞭解樣本的分佈情況。此外，以平均數和標準差來描述市場導向、競爭優勢、組織績效等各個構面，以瞭解樣本企業的管理人員對這些相關變數的感知，並利用t檢驗及相關分析對背景變數所造成的影響做檢驗。
　　2．Cronbach’a信度繫數分析
　　信度是指測驗結果的一致性、穩定性及可靠性，一般多以內部一致性(consistency)來加以表示該測驗信度的高低。信度繫數愈高即表示該測驗的結果愈一致、穩定與可靠。針對各研究變數的衡量題項進行Cronbach’a信度分析，以瞭解衡量構面的內部一致性。一般來說，Cronbach’a僅大於0．7為高信度，低於0．35為低信度(Cuieford，1965)，0．5為最低可以接受的信度水準(Nunnally，1978)。
　　3．探索性因素分析(exploratory factor analysis)和驗訌性因素分析(confirmatory factor analysis)
　　用以測試各構面衡量題項的聚合效度(convergent validity)與區別效度(discriminant validity)。因為僅有信度是不夠的，可信度高的測量，可能是完全無效或是某些程度上無效。所以我們必須對效度進行檢驗。效度是指工具是否能測出在設計時想測出的結果。收斂效度的檢驗根據各個項目和所衡量的概念的因素的負荷量來決定；而區別效度的檢驗是根據檢驗性因素分析計算理論上相關概念的相關係數，檢定相關係數的95％信賴區間是否包含1．0，若不包含1．0，則可確認為具有區別效度(Anderson，1987)。
　　4．結構方程模型分析(structural equations modeling)
　　由於結構方程模型結合了因素分析(factor analysis)和路徑分析(path analysis)，並納入計量經濟學的聯立方程式，可同時處理多個因變數，容許自變數和因變數含測量誤差，可同時估計因數結構和因數關係。容許更大彈性的測量模型，可估計整個模型的擬合程度(Bollen和Long，1993)，因而適用於整體模型的因果關係。在模型參數的估計上，採用最大似然估計法(Maximum Likelihood，ML)；在模型的適合度檢驗上，以基本的擬合標準(preliminary fit criteria)、整體模型擬合優度(overall model fit)以及模型內在結構擬合優度(fit of internal structure of model)(Bagozzi和Yi，1988)三個方面的各項指標作為判定的標準。在評價整體模式適配標準方面，本研究採用x2(卡方)／df(自由度)值、擬合優度指數(goodness．of．f：iJt．in．dex，GFI)、平均殘差平方根(root—mean．square：residual，RMSR)、近似誤差均方根(root-mean—square-error-of-approximation，RMSEA)等指標；模型內在結構擬合優度則參考Bagozzi和Yi(1988)的標準，考察所估計的參數是否都到達顯著水平。

[編輯] 數據分析案例分析 
[編輯] 案例一：數據分析在郵政報刊中的應用模式研究[3] 
　　郵政報刊生產作業系統投入使用後，至今已經積累了豐富的數據。這些數據全面而真實地描述了郵政報刊發行的業務全流程，同時也沉澱了豐富的報刊客戶及訂閱信息，這些信息集中存儲在資料庫中，以報表為主進行展示。隨著數據分析方法的不斷進步，數據分析的應用模式已經不再局限於單純的報表方式，新的應用模式不斷涌現，先進的數據分析手段將使郵政報刊數據發揮出更大價值。

　　一、數據分析方法及郵政應用現狀

　　數據分析是為了提取有用信息和形成結論而對數據加以詳細研究和概括總結的過程。數據分析方法大致可以分為三張統計分析，以基礎的統計分析為主高級分析，以計量經濟建模理論為主；數據挖掘，以機器學習、數據倉庫等複合技術為主。對於郵政報刊全國集中的大數據量來說，數據挖掘方法更能夠發揮作用。有關數據挖掘方法及典型應用見表所示。

　　表數據挖掘方法及應用



種類功能演算法典型應用


分類預測分類決策樹、神經網路分類、區別分析、邏輯回歸、概率回歸風險分析、客戶輓留分析、欺詐探測


預測線性回歸、非線性回歸收益率分析，收入預測，信用價值預測，客戶潛在價值預測


聚類集群分析K-平均值，神經網路聚類客戶分割


關聯規則關聯分析統計學，集合理論交叉銷售。捆綁銷售


序列關聯分析統計學，集合理論交叉銷售


相似時間序列分析統計學，集合理論產品生命周期


預測時間序列預測統計時間序列模型、神經網路銷售預測、利率預測、損失預測


　　統計分析方法在郵政行業已有廣泛應用，在郵政業務系統中均有報表統計功能，如統計報刊業務量的同比、環比分析等。高級分析方法常常出現在向上級彙報的分析報告中，如時間序列分析中報刊業務量及收入隨著月份呈現季節性波動的曲線圖，相關分析中對於影響收入的重要指標的相關性分析等。數據挖掘方法目前在郵政的應用還處於起步階段。在郵政儲蓄行業數據挖掘方法正在以主題分析的形勢開展，如郵政儲蓄的VIP客戶分析、客戶進行流失分析等。在郵政報刊行業，數據挖掘方法的應用還處於探索階段。

　　二、數據分析在郵政報刊中的應用模式

　　以《中國郵政郵務類信息化規劃》中報刊業務需求作為研究的著手點，分營銷、經營、產品、渠道四個方面來進行數據分析應用模式的探索。

　　1、營銷類

　　營銷類數據分析主要圍繞市場營銷和客戶營銷兩方面來開展。一是報刊客戶細分。報刊客戶細分是以報刊訂閱客戶為對象，使用數據挖掘方法，根據客戶基本信息、興趣愛好、訂閱行為、客戶忠誠度等多個維度進行聚類分析，得出差異顯著的分群。以分群結果為基礎，總結歸納各個細分群的特征，發掘潛在的細分客戶的消費行為習慣，有針對性地對各個分群客戶開展營銷活動。二是“高碼洋”專題分析。“高洋碼”專題分析主要為滿足郵政報刊發行局發展高端客戶的需求而進行的多系統關聯分析。參照業務部門提供的“高碼洋”刊物進行重點研究，交叉關聯現有的郵政系統如簡訊系統、郵儲系統、“自由一族”、航空客票、中郵快購網站等系統的客戶數據，得出在這些系統中潛在的報刊客戶群。

　　2、經營類

　　經營類數據分析主要包括對郵政報刊業務涉及全流程以及經營模式等方面的分析，以及滿意度、投訴分析。一是報刊發行商業運營模式研究。報刊發行商業運營模式研究是根據規劃中“由傳統發行向數字化發行領域進軍”提出的，研究將引入市場調查手段，通過對報刊發行商業運營情況進行分析，發現郵政報刊發行的優勢與不足，為應對出版產業數字化的迅猛發展形勢，提出數字發行策略模式。二是報刊發行流程優化。在報刊現有的經營管理模式下對統一接辦、統一結算、統一運營和報刊社維護、集團大客戶開發、報刊訂閱網站運營、數字發行等各個業務模式進行梳理，綜合運用統計分析和數據挖掘方法，對相關環節中的數據進行分析，發現業務流程中存在的問題，提出相應的改善建議。

　　3、產品類

　　產品類數據分析主要指提供分析報告或數據服務，如報刊廣告價值報告、報刊要數服務等。一是報刊要數歷史數據分析。報刊要數歷史數據分析是對不j報刊歷年要數數據進行的監測分析處理。該分析能E刊社及時掌握髮行終端的詳實信息，尋找提高報刊有效發行量的途徑同時也為廣告商和廣告主提供同報刊發行情況的橫向對比分析。二是報刊廣告價分析。報刊廣告價值分析來源於郵政報刊訂閱及零；數據和郵政報刊客戶群體數據，從報刊發行和讀者讀兩方面的各項指標對比評價各地公開發行的主要曼刊的廣告價值，分析各報刊的競爭優勢，將分析結以報告的形式呈現給廣告發行商。

　　4、渠道類

　　渠道類數據分析指對報刊的渠道運作狀況進行分千，為郵政報刊合理安排資源、增加渠道效能提供參， 為探索發現新渠道提供幫助。一是報刊訂閱方式析。報刊訂閱方式分析是對讀者訂閱報刊的多種方如支局訂閱、網上訂閱、電話訂閱等進行分析，一亨面，比較各種訂閱方式優劣勢；另一方面，隨著讀訂閱習慣的變化，探索新的訂閱方式，吸引更多的戶訂閱報刊。二是郵政報刊發行渠道分析。隨著新出版業自辦發行的出現，及地鐵、機場、超市等新強勢終端對郵政零售業的衝擊，郵政報刊發行的主暮道地位受到了衝擊。通過對現有渠道的發行量、發亍特征進行歸納總結，一方面可以改善渠道建設中不符合實際情況的問題，另一方面也能從中探索出報刊發行新途徑。
　　綜上。郵政報刊順應市場導向，由計劃經營向市場化經營轉變所提出的變革需求還有很多，在上述四個方面的應用模式之外，還有很多數據分析的應用模式有待挖掘整理和探討。

　　三、應用案例——報刊產品與潛在客戶挖掘

　　1、背景及內容

　　該案例屬於營銷類應用模式，案例以報刊業務從傳統經驗型營銷向現代資料庫營銷轉變的需要作為切入點，基於簡訊系統和量收系統的數據，通過手機號碼將簡訊系統和量收系統中的報刊數據進行匹配整合，關聯報刊與簡訊的交叉用戶，採用聚類分析、相關性分析的數據分析方法，對客戶數據做多維度的分群，進行報刊產品與潛在客戶分析，實現巨集觀市場細分和微觀層面的產品營銷兩個基本內容。

　　2、分析過程

　　該分析選擇了具有地域代表性的某省報刊訂閱客戶數據。整個分析過程包括數據準備、模型構建及模型業務解讀三個階段。數據準備階段將量收報刊營銷系統與簡訊系統關聯取數，形成中間層數據5大類數據，最後載入形成寬表。模型構建階段應用聚類演算法將客戶數據按照偏好和訂閱習慣兩大類進行細分，最後將細分結果進行整合，得出最終的細分結果。模型業務解讀階段從業務角度對模型進行解讀，包括應用落地建議。

　　3、分析成果

　　在巨集觀市場層面，通過判斷客戶的訂閱年限、訂閱份數、訂閱種類、退訂份數、退訂種類將報刊現有客戶劃分為頻繁退訂人群、高價值人群、大眾訂閱人群和中端消費人群。以某省郵政報刊業務為例，確定了四類人群。
　　通過將報刊用戶進行群體劃分，確定了不同類別人群的訂閱偏好。以上述該省報刊為例，高價值客戶偏好的前10名報刊品種有：揚子晚報、現代快報、參考消息、讀者、環球時報、新華日報、：N．-T~J文摘、中國剪報、新民晚報、特別文摘(形象期刊)。其中，參考消息、讀者和環球時報是重點：N~IJ o此分析對於形成有針對性的訂閱目錄提供了依據。
　　在微觀產品營銷層面，確定如何向不同類型客戶，有針對性的推薦報刊產品的基本演算法。首先提取了簡訊用戶，然後通過手機號碼實現用戶關聯其次，總結出既是簡訊用戶又是報刊用戶的人群在訂閱報刊產品方面的顯著特點(與整體報刊用戶比較)，分析交叉關聯客戶在報刊訂閱偏好方面與總體報刊客戶的差異，得出簡訊客戶對報刊的偏好；最後，根據“顯著性”和“客戶規模”等指標進行篩選，確定適合向各類客戶推薦的報刊種類，支撐精準營銷。整個分析過程實現了有針對性地向不同類別潛在客戶推薦報刊產品。例如，通過分析得到向該省簡訊客戶推薦的報刊品種有：北方新報．新周末、興安廣播電視報、37°女人。該分析實現了“應該向什麼樣的客戶推薦哪些產品”的基本功能。

　　4、實際應用

　　以某省為例，針對《看天下》的客戶進行分析，為該刊物挖掘出訂閱其他刊物的客戶人群。以一年的訂閱《看天下》客戶為分析數據，通過對興趣偏好的分析，得出同時訂閱其他雜誌的情況。
　　在此基礎上對訂閱這幾種報刊的客戶進一步分析興趣偏好，得出訂閱《三聯生活周刊》《中國國家地理》《世界博覽》《特別關註》《青年文摘》《南方周末》的客戶對《看天下》的興趣更高，並向市場營銷部門建議對訂閱這幾種報刊的客戶推薦《看天下)。另外，對《看天下》的客戶前22大分類報刊的偏好進行分析，通過聚類與相關性分析《看天下》的客戶同時訂閱其他種類的報刊客戶的占比情況，發現排在前列的有養生保健、文學、電影電視、科普、投資理財五類興趣偏好，由此向市場營銷部門建議對偏好這些興趣的人群推薦《看天下》，並開展相關的營銷活動。

　　5、應用效果及意義

　　該案例通過對報刊數據的深層分析，為郵政報刊的高端客戶提供了良好的報刊推薦服務。另外，對報刊和簡訊數據的關聯分析，挖掘出潛在的報刊客戶群體，並有針對性的推薦相關產品。這些分析所產生的報刊產品將直接服務於報刊社和報刊市場，為郵政報刊產生良好的社會和經濟效益。

[編輯]案例二：數據分析在企業運營管理中的應用[4]
　　(一)數據改變企業的運營管理決策方式
　　運營管理分為四種：移動化、雲計算、大數據和全球化，作為4大力量中堅力量之一的大數據，正改變著企業的運營管理決策方式。由於數據處理分析和管理等相關技術的不斷成熟，企業內部的管理運作數據、業務運作數據，企業與客戶的關係及互動數據，客戶或潛在客戶在企業經營業務之外的生活方式、活動、情感、社交等大數據，正為企業所採集和分析，企業洞察客戶需求更深入、更全面，對業務運營管控更及時有力，因此大數據將完全改變企業管理者以往“拍腦袋”的決策方式，管理決策更依賴“用數據說話”，決策更趨科學性、理性，更具定量化和可評估性以及準確性和延續性。數據促進企業管理決策的能量不在於數據之大，也不在於數據本身，而在於企業根據大數據做出的更深入、更全面的客戶需求洞察，並以此支撐企業針對性運營管理決策的及時、科學、有效形成，促進企業運營管理的高效準確運行以及企業生產力發展。
　　(二)目前企業數據分析的可拓展方向
　　(1)社交網路分析模型。數據伴隨社交網路的風行而發展。社交網路發展促進了人們的數字化生存，讓人們生活和工作的有關信息數字化，而這些數字化信息一方面成為以單個個體為對象的形形色色、包羅萬象、細緻入微、支撐洞察個體興趣需求和喜好的數據：另一方面也將原來現實生活中不可獲得的人與人之間的關係信息搬上了網路。對於移動通信企業來說，客戶的社交網路分析即一個重要的數據分析方向。社交網路分析的內容為：通過測算識別客戶與客戶之間關係所形成的圈子以及圈子中各客戶角色的判定，形成企業對各個客戶影響力和價值的判斷，在此基礎上，利用對這些圈子、角色和影響力的認識，幫助企業實現相關營銷活動或產品套餐的推廣，提高企業營銷和運營管理的效率。
　　(2)客戶價值分析模型。隨著社交網路的發展，不僅使得客戶行為需求喜好信息更豐富，而且可獲得客戶之間關係的數據信息。如在捆綁套餐營銷活動中，活動在用戶群中的擴散呈鏈狀發展，發展過程中，客戶的圈子構成以及客戶對圈中其他用戶的影響力對活動推廣擴散有重要影響。如果能夠識別並藉助有足夠影響力的客戶幫助推廣活動，活動的營銷效率必然有很大程度的提高。可見，數據時代，當企業的客戶分析在原有以客戶為對象進行分析的基礎上，增加以客戶與客戶之間關係為對象的分析時，客戶的價值測算和分析也將隨之發生變化，客戶的價值不再僅是個體客戶消費體現的價值，還應增加個體客戶對所在群體內其他客戶的影響力指標。
　　(三)企業應用數據分析的必要性
　　(1)實時數據分析支撐的營銷運營管理應用。由於數據分析、數據挖掘手段的支撐，傳統數據時代，一些先進的企業已經基本實現洞察力驅動的精確營銷運營管理。數據時代，客戶數據更為豐富和細緻，企業對客戶需求洞察更為全面而準確，更重要的是，由於數據處理分析技術的成熟，企業實現客戶洞察的能力在數據存儲與數據處理和分析方面將更高效，甚至達到實時，所以支撐營銷運營管理全流程各環節決策的數據流可以與營銷運營管理的工作流達到同步，企業可以綜合客戶的歷史消費行為信息和客戶當前行為，實時做出針對個體客戶的個性化營銷策略，從而在提高營銷命中率的同時及時有效地識別並抓住稍瞬即逝的營銷機會，極大地提高營銷運營管理效率。
　　(2)數據分析促進智能管道運營應用的落實。對於企業來說，智能管道的核心能力在於，根據客戶行為，實時為客戶推薦並調配網路設備資源。傳統數據時代，很難滿足智能管道運營的要求，因為涉及的問題與前述客戶體驗的實時測算一樣，由於技術條件限制不可能達到：數據時代，對半結構化機器數據實時採集、處理和分析的技術逐漸成熟，將大大促進智能管道運營管理落實的進程。
　　其實現原理基本類似於客戶體驗管理，最大的差別僅在於，智能管道以對客戶產品使用行為測算的數據與提供產品的網路設備資源做對應，從而在保證客戶體驗達標的條件下，充分調配、切割、整合企業的設備網路資源，通過實現資源利用的最高效而達到資源配置的最優化。
　　(四)IT系統對數據支撐的體系規劃和趨勢
　　(1)梳理並整合業務部門對數據的需求，立足分析需求，做好數據IT體系架構的3步規劃。數據相關技術條件的成熟、數據分析能力以及分析應用經驗的積累等多方面因素，都是制約企業建設數據IT系統的條件，要充分抓住數據帶來的機會並避免“心急吃不得熱豆腐，反被熱豆腐傷害”的問題，建議企業建設數據IT系統分階段實現：第l階段，將原來支撐報表分析的EDW優化升級到支撐高級分析的BI系統；第2階段，逐步採集數據，將BI系統升級到支撐數據分析的IT系統：第3階段，打通數據分析的IT系統與企業運營管理系統，將數據分析功能嵌入業務流程。
　　(2)以職能部門提供整體IT支撐方式向嵌入業務流程實時數據的分散能力支撐方式轉變。這種轉變趨勢又稱IT支撐“消費化”趨勢。傳統數據時代，企業建立數據中心，集中企業層面所有數據，為企業運營管理決策集中提供數據報表、分析甚至挖掘支撐，是公認的高效IT支撐方式；數據時代，數據從支撐企業中高層運營管理決策普及到支撐企業的產品運營、市場運營、客戶服務，甚至在智能管道運營全流程中涉及從企業中高層運營管理人員到基層生產執行人員，很明顯，這種數據獲取和分析能力如果僅集中在IT職能部門，而不是全體人員均結合自身業務需求而具備的話，數據分析驅動的各項運營管理應用即成為不可能的任務。
　　所以，數據時代，數據要真正改變企業運營管理決策方式，使企業上下形成以數據驅動的企業文化為標誌性特征，每個人都要做好與數據打交道的能力和心理準備，而IT系統運營管理部門也將不得不面臨數據從數據採集、清洗、存儲、處理到分析、提供和管理的過程，在各業務運營管理流程、各部門、各類用戶間如何高效運行、高效交互、高效支撐的更複雜的IT系統支撐問題。

[編輯]相關條目
數據整理
資料庫管理系統
信息管理系統
數據倉庫
信息系統
資料庫技術

[編輯]參考文獻

↑ 李潔.審計理論與實務  中級[M].中國經濟出版社,2010.06.
↑ 張雪蘭著.基於競爭優勢的理論建構與實證檢驗.武漢大學出版社,2008.9.
↑ 林琴,胡蓉,張靜茹.數據分析在郵政報刊中的應用模式研究[J].《現代郵政》.2012年 第1期
↑ 葛姝娜.數據分析在企業運營管理中的作用[J].電子產業經濟,2013(15)



取自"http://wiki.mbalib.com/zh-tw/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"

本條目對我有幫助150  分享到：














   如果您認為本條目還有待完善，需要補充新內容或修改錯誤內容，請編輯條目。

本條目相關文檔
 數據分析 30頁 數據分析 1頁 數據分析 25頁 數據分析控製程序 3頁 商品部數據分析 35頁 數據分析 指數方法 62頁 賣場數據分析 24頁 數據分析管理程式 4頁 數據分析管理 1頁 定量數據分析方法 29頁更多相關文檔

本條目相關資訊
《福布斯》預測2017年7大科技趨勢 都有誰入選？ 2016年12月27日HR如何從事務型向業務型華麗變身！？ 2016年10月5日新媒體崛起後，SEM投放就完蛋了嗎？  2016年9月26日HR如何讓這些沉默的管理數據開口說話？ 2016年9月19日書摘：經營數據分析的39個問題 2016年9月4日想成為高薪厚職的財務人？  你得看過來... 2016年8月16日運營跟產品的五種“曖昧”關係，你經歷過嗎？  2016年1月8日少說話多做事 懂數據分析的HR才是好HR 2015年12月14日傳統HR的"舊船票"還能登上"新客船"嗎？ 2015年11月30日大數據技術助力人力資源管理 2015年9月23日
本條目由以下用戶參與貢獻
Oval,funwmy,Angle Roh,山林,Zfj3000,Dan,Cabbage,Yixi,Honghong16455,鱸魚,胡椒粉,jane409,連曉霧,KAER,泡芙小姐,y桑,Lin,Mis銘,寒曦,蘇青荇. 頁面分類: 信息管理術語 





評論(共19條)提示:評論內容為網友針對條目"數據分析"展開的討論，與本站觀點立場無關。

 59.39.177.*  在 2008年1月7日 18:22 發表    


不錯


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 221.15.69.*  在 2008年7月23日 17:39 發表    


很好 不錯


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 125.83.43.*  在 2009年3月28日 14:13 發表    


講得太籠統了


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Hnoju (討論 | 貢獻) 在 2009年3月28日 17:58 發表    


 125.83.43.*  在 2009年3月28日 14:13 發表

講得太籠統了





已對條目進行補充，智庫百科是可以自由編輯的，歡迎您參與貢獻


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 219.134.63.*  在 2009年4月1日 10:12 發表    


純理論，不實用，沒意義


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 222.240.189.*  在 2009年5月7日 13:35 發表    


我有一個疑問，那就是數據分析應不應該包括收集數據的過程？
[quote]數據分析是指用適當的統計方法對收集來的大量第一手資料和第二手資料進行分析，以求最大化地開發數據資料的功能，發揮數據的作用。[/quote]
從這一段來看，數據分析只是收集來的資料進行分析，因而就不包括收集數據的過程。然而在下麵的文章內容中，又說數據分析的過程包含了有目的地收集數據。
這是何解呢？


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 203.95.110.*  在 2009年8月18日 14:57 發表    


很好，系統。對於瞭解數據分析基本方法很有幫助


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Xiaomenglong (討論 | 貢獻) 在 2009年10月28日 16:57 發表    


 222.240.189.*  在 2009年5月7日 13:35 發表

我有一個疑問，那就是數據分析應不應該包括收集數據的過程？
[quote]數據分析是指用適當的統計方法對收集來的大量第一手資料和第二手資料進行分析，以求最大化地開發數據資料的功能，發揮數據的作用。[/quote]
從這一段來看，數據分析只是收集來的資料進行分析，因而就不包括收集數據的過程。然而在下麵的文章內容中，又說數據分析的過程包含了有目的地收集數據。
這是何解呢？





我認為這是一個廣義和狹義的問題；
數據分析發揮作用的前提是數據的準確性和關聯性；
這就要求你的數據收集這個基礎要做好，也就是數據分析的前期工作；
如此看來，數據分析的廣義應該是從數據收集開始；而狹義的就是指其中的統計分析那個階段


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 124.234.190.*  在 2010年3月8日 14:52 發表    


 222.240.189.*  在 2009年5月7日 13:35 發表

我有一個疑問，那就是數據分析應不應該包括收集數據的過程？
[quote]數據分析是指用適當的統計方法對收集來的大量第一手資料和第二手資料進行分析，以求最大化地開發數據資料的功能，發揮數據的作用。[/quote]
從這一段來看，數據分析只是收集來的資料進行分析，因而就不包括收集數據的過程。然而在下麵的文章內容中，又說數據分析的過程包含了有目的地收集數據。
這是何解呢？





數據分析包括收集數據的過程？ [


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 113.108.130.*  在 2011年3月8日 13:01 發表    


不錯，有參考價值


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Lymgigi (討論 | 貢獻) 在 2012年1月19日 10:48 發表    


有具體的方法就更好了。。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Jane409 (討論 | 貢獻) 在 2012年1月19日 17:12 發表    


 Lymgigi (討論 | 貢獻) 在 2012年1月19日 10:48 發表

有具體的方法就更好了。。





已添加具體方法部分~
MBA智庫百科是可以自由參與的百科，如有發現錯誤和不足，您也可以參與修改編輯，點擊條目上方的編輯進入即可參與，期待您的加入！~


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 222.174.87.*  在 2012年4月27日 11:40 發表    


不好


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Yixi (討論 | 貢獻) 在 2012年4月27日 14:48 發表    


 222.174.87.*  在 2012年4月27日 11:40 發表

不好





添加了新的內容和案例，並附上參考文獻！


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 120.85.181.*  在 2012年6月20日 22:30 發表    


能提供一些參考書目嗎?


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 118.122.118.*  在 2012年8月21日 15:49 發表    


數據收集的實例方法版本為舊版本，在新的OFFICE中無法運用。可否提供新的方法？“分析”過程很快，但按現在各大企業的人為操作模式，數據的準確性除非經過幾方審核，在單一公司內部準確度估計只有60%多，光校正前期錯誤就會花費很長一段時間。而很多公司都不會投入多的人力成本進行前期數據校正檢查，真正集中到後期對數據分析的時候，就很痛苦了。何況後期往往只有一個人。最好能有方法是可以直接糾錯——多偏差數據進行提取分析的就好了。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 62.142.167.*  在 2013年5月16日 02:39 發表    


 Xiaomenglong (討論 | 貢獻) 在 2009年10月28日 16:57 發表

我認為這是一個廣義和狹義的問題；
數據分析發揮作用的前提是數據的準確性和關聯性；
這就要求你的數據收集這個基礎要做好，也就是數據分析的前期工作；
如此看來，數據分析的廣義應該是從數據收集開始；而狹義的就是指其中的統計分析那個階段





請查閱關鍵詞“採樣(sampling)”就明白你們所謂的數據收集的原理和方法了。從方法論上來說，無論數據的採獲還是分析，都是統計學的應用。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 112.104.219.*  在 2014年4月13日 10:17 發表    


實例不夠具體，讓人看了不知所云。


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 




 Procrastination (討論 | 貢獻) 在 2014年4月14日 14:55 發表    


 112.104.219.*  在 2014年4月13日 10:17 發表

實例不夠具體，讓人看了不知所云。





案例部分內容已做更新~
MBA智庫百科是可以自由參與的百科，如有發現錯誤和不足，您也可以參與修改編輯，只要通過網頁右上角創建新帳號，創建用戶名後即可參與，期待您的加入！~


 回複評論
 發表評論﻿請文明上網，理性發言並遵守有關規定。




 



發表評論﻿請文明上網，理性發言並遵守有關規定。




 




導航


首頁
文檔
百科
商學院
資訊
培訓
幫幫




個人工具


用戶登錄創建新帳號 









搜索



 
 

全球最大的中文經管百科，由121,994位網友共同編寫而成，共計414,047個條目








 
首頁
 
管理
 
營銷
 
經濟
 
金融
 
人力資源
 
咨詢
 
財務
 
品牌
 
證券
 
物流
 
貿易
 
商學院
 
法律
 
人物
 
分類索引
 




查看

條目討論編輯簡體中文繁體中文 


工具▼


鏈入頁面
鏈出更改
上載文件 特殊頁面 可列印版
永久鏈接 













導航


最新資訊
最新評論
最新推薦
熱門推薦
編輯實驗
使用幫助
創建條目
隨便看看












本周推薦
最多推薦



影響世界的100個經典管理定律垃圾人定律七層次領導力產品定位五步法樹立和提高威信法MECE分析法吳曉波裙擺指數PPP模式六項精進 

蘑菇管理定律猴子管理法則情緒ABC理論100個最流行的管理辭彙21天效應破窗效應懶螞蟻效應SWOT分析模型墨菲定律踢貓效應 

以上內容根據網友推薦自動排序生成









x



	   最後更改10:05, 2016年12月5日.	  
智庫首頁 - 
百科首頁 - 
關於百科 -
	   客戶端 -
	   人才招聘 -
	   廣告合作 - 
權利通知 -
	   聯繫我們 -
	   免責聲明
 - 友情鏈接

©2006-2017 MBAlib.com, All rights reserved. 


 






大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 









大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 









大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 









大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 









大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 









大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 









大數據 - 維基百科，自由的百科全書































 







大數據

維基百科，自由的百科全書


					跳轉至：					導航，					搜索















本條目可能包含原創研究或未查證內容。（2014年8月8日） 
請協助添加參考資料以改善這篇條目。詳細情況請參見討論頁。 


巨量資料（英語：Big data[1][2][3]），指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語[4][5]。在總資料量相同的情況下，與個別分析獨立的小型資料集（Data set）相比，將各個小型資料集合併後進行分析可得出許多額外的資訊和資料關聯性，可用來察覺商業趨勢、判定研究品質、避免疾病擴散、打擊犯罪或測定即時交通路況等；這樣的用途正是大型資料集盛行的原因[6][7][8]。
截至2012年 (2012-Missing required parameter 1=month!)[update]，技術上可在合理時間內分析處理的資料集大小單位為艾位元組（exabytes）[9]。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括氣象學、基因組學[10]、神經網路體學、複雜的物理模擬[11]，以及生物和環境研究[12]。這樣的限制也對網絡搜索、金融與經濟資訊學造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（遙感）、軟體記錄、相機、麥克風、無線射頻辨識（RFID）和無線感測網路。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍[13]；截至2012年 (2012-Missing required parameter 1=month!)[update]，全世界每天產生2.5艾位元組（2.5×1018字節）的資料[14]。
巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（計算機集群是其中一種常用方式）[15]。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百TB才會對他們造成困擾。」[16]
隨著大數據被越來越多的提及，有些人驚呼大數據時代已經到來了，2012年《紐約時報》的一篇專欄中寫到，“大數據”時代已經降臨，在商業、經濟及其他領域中，決策將日益基於數據和分析而作出，而並非基於經驗和直覺。但是並不是所有人都對大數據感興趣，有些人甚至認為這是商學院或咨詢公司用來嘩眾取寵的buzzword，看起來很新穎，但只是把傳統重新包裝，之前在學術研究或者政策決策中也有海量數據的支撐，大數據並不是一件新興事物。
大數據時代的來臨帶來無數的機遇，但是與此同時個人或機構的隱私權也極有可能受到衝擊，大數據包含各種個人信息數據，現有的隱私保護法律或政策無力解決這些新出現的問題。有人提出，大數據時代，個人是否擁有“被遺忘權”，被遺忘權即是否有權利要求數據商不保留自己的某些信息，大數據時代信息為某些互聯網巨頭所控制，但是數據商收集任何數據未必都獲得用戶的許可，其對數據的控制權不具有合法性。2014年5月13日歐盟法院就“被遺忘權”（right to be forgotten）一案作出裁定，判決谷歌應根據用戶請求刪除不完整的、無關緊要的、不相關的數據以保證數據不出現在搜索結果中。這說明在大數據時代，加強對用戶個人權利的尊重才是時勢所趨的潮流。




IBM對維基百科的編輯紀錄資料進行視覺化的呈現。維基百科上總計數兆位元組的文字和圖片正是大資料的例子之一






全球資訊儲存容量成長圖





目錄


1 定義
2 應用範例

2.1 巨大科學
2.2 科學研究
2.3 衛生學
2.4 公共部門
2.5 民間部門
2.6 社會學


3 市場
4 相關條目
5 註釋
6 參考文獻
7 延伸閱讀
8 外部連結



定義[編輯]
巨量資料由巨型數據集（英語：Data set）組成，這些數據集大小常超出人類在可接受時間下的收集（英語：data acquisition）、庋用（英語：data curation）、管理和處理能力[17]。巨量資料的大小經常改變，截至2012年 (2012-Missing required parameter 1=month!)[update]，單一資料集的大小從數太字節（TB）至數十兆億位元組（PB）不等。
在一份2001年的研究與相關的演講中[18]，麥塔集團（META Group，現為高德納）分析員道格·萊尼（Doug Laney）指出數據增長的挑戰和機遇有三個方向：量（Volume，數據大小）、速（Velocity，資料輸入輸出的速度）與多變（Variety，多樣性），合稱「3V」或「3Vs」。高德納與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據[19]。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理[原文 1][20]。」另外，有機構在3V之外定義第4個V：真實性（Veracity）為第四特點[21]。
巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。
資料探勘（data mining）則是在探討用以解析巨量資料的方法。
應用範例[編輯]
巨量資料的應用範例包括大科學、RFID、感測設備網路、天文學、大氣學、交通運輸、基因組學、生物學、大社會資料分析[22]、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的電子商務等[23]。




應用於運動界


巨大科學[編輯]
大型強子對撞機中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料[24][25][26]。
將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25拍位元組（PB），複製後為200拍位元組。
如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500艾位元組（EB）的資料量。這個數字代表每天實驗將產生相當於500垓（5×1020）位元組的資料，是全世界所有資料來源總和的200倍。
科學研究[編輯]
衛生學[編輯]
國際衛生學教授漢斯·羅斯林使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。
公共部門[編輯]
目前，發達國家的政府部門開始推廣大數據的應用。2012年奧巴馬政府投資近兩億美元開始推行《大數據的研究與發展計劃》，本計劃涉及美國國防部、美國衛生與公共服務部門等多個聯邦部門和機構，意在通過提高從大型複雜的的數據中提取知識的能力，進而加快科學和工程的開發，保障國家安全。
民間部門[編輯]

亞馬遜，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一[27]。
沃爾瑪可以在1小時內處理百萬以上顧客的消費處理。相當於美國議會圖書館所藏的書籍之167倍的情報量[6]。
Facebook，處理500億枚的使用者相片[28]。
全世界商業資料的數量，統計全部的企業全體、推計每1.2年會倍増[29]。
西雅圖文德米爾不動產（英語：Windermere Real Estate）分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值[30]。
軟銀，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度[31]。
企業對大數據技能需求大，吸引了許多大學諸如伯克利大學開專門提供受過大數據訓練的畢業者的大學部門。硅谷紐約為主《The Data Incubator》公司,2012年成立，焦點是數據科學與大數據企業培訓，提供國際大數據培訓服務。

社會學[編輯]
大資料產生的背景離不開Facebook、微博等社交網絡的興起，人們每天通過這種自媒體傳播信息或者溝通交流，由此產生的信息被網絡記錄下來，社會學家可以在這些數據的基礎上分析人類的行為模式、交往方式等。美國的塗爾乾計劃就是依據個人在社交網絡上的數據分析其自殺傾向，該計劃從美軍退役士兵中揀選受試者，透過Facebook的行動app收集資料，並將用戶的活動數據傳送到一個醫療資料庫。收集完成的數據會接受人工智能系統分析，接著利用預測程式來即時監視受測者是否出現一般認為具傷害性的行為。
市場[編輯]
巨量資料的出現提升了對資訊管理專家的需求，Software AG、甲骨文、IBM、微軟、SAP、易安信、惠普和戴爾已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍[6]。
經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路[6]。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過電信網路交換資訊的容量在1986年為281兆億位元組（PB），1993年為471兆億位元組，2000年時增長為2.2艾位元組（EB），在2007年則為65艾位元組[13]。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組[6]。
相關條目[編輯]


資訊科技主題




資料探勘
資料庫
對象數據庫
關係數據庫
統計學
商務智能
分佈式計算、分佈式數據庫、分散式檔案系統、分散式運算環境
超級計算機
運籌學
MapReduce
合成作戰中心


註釋[編輯]


^ 原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.


參考文獻[編輯]


^ White, Tom. Hadoop: The Definitive Guide. O'Reilly Media. 2012-05-10: 3. ISBN 978-1-4493-3877-0. 
^ MIKE2.0, Big Data Definition. 
^ 巨量資料與進階分析解決方案.  已忽略文本“ Microsoft Azure ” (幫助)
^ Kusnetzky, Dan. What is "Big Data?". ZDNet. （原始內容存檔於2010-02-21）. 
^ Vance, Ashley. Start-Up Goes After Big Data With Hadoop Helper. New York Times Blog. 2010-04-22. 
^ 6.0 6.1 6.2 6.3 6.4 Data, data everywhere. The Economist. 2010-02-25 [2012-12-09]. 
^ E-Discovery Special Report: The Rising Tide of Nonlinear Review. Hudson Global. [1 July 2012]. （原始內容存檔於3 七月 2012）.  請檢查|archive-date=中的日期值 (幫助) by Cat Casey and Alejandra Perez
^ What Technology-Assisted Electronic Discovery Teaches Us About The Role Of Humans In Technology — Re-Humanizing Technology-Assisted Review. Forbes. [1 July 2012]. （原始內容存檔於18 六月 2012）.  請檢查|archive-date=中的日期值 (幫助)
^ Francis, Matthew. Future telescope array drives development of exabyte processing. 2012-04-02 [2012-10-24]. 
^ Community cleverness required. Nature. 4 September 2008, 455 (7209): 1. doi:10.1038/455001a. 
^ Sandia sees data management challenges spiral. HPC Projects. 2009-08-04. （原始內容存檔於2011-05-11）. 
^ Reichman, O.J.; Jones, M.B.; Schildhauer, M.P. Challenges and Opportunities of Open Data in Ecology. Science. 2011, 331 (6018): 703–5. doi:10.1126/science.1197962. 
^ 13.0 13.1 Hilbert & López 2011
^ IBM What is big data? — Bringing big data to the enterprise. www.ibm.com. [2013-08-26]. 
^ Jacobs, A. The Pathologies of Big Data. ACMQueue. 6 July 2009. 
^ Magoulas, Roger; Lorica, Ben. Introduction to Big Data. Release 2.0 (Sebastopol CA: O'Reilly Media). 2009-02, (11). 
^ Snijders, C., Matzat, U., & Reips, U.-D. (2012). ‘Big Data’: Big gaps of knowledge in the field of Internet science. International Journal of Internet Science, 7, 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html
^ Douglas, Laney. 3D Data Management: Controlling Data Volume, Velocity and Variety (PDF). Gartner. [2001-02-06]. 
^ Beyer, Mark. Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data. Gartner. [2011-07-13]. （原始內容存檔於2011-07-10）. 
^ Douglas, Laney. The Importance of 'Big Data': A Definition. Gartner. [21 June 2012]. 
^ What is Big Data?. Villanova University. 
^ Erik Cambria; Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das. 13. Big social data analysis. Taylor & Francis. 2013.  引文使用過時參數coauthors (幫助)
^ Hogan, M. What is Big Data. 3 March 2013 [2013-06-20]. 
^ LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public.. CERN-Brochure-2010-006-Eng. LHC Brochure, English version. CERN. [20 January 2013]. 
^ LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers.. CERN-Brochure-2008-001-Eng. LHC Guide, English version. CERN. [20 January 2013]. 
^ Brumfiel, Geoff. High-energy physics: Down the petabyte highway. Nature 469. 19 January 2011: 282–83. doi:10.1038/469282a. 
^ Layton, Julia. Amazon Technology. Money.howstuffworks.com. [2013-03-05]. 
^ Scaling Facebook to 500 Million Users and Beyond. Facebook.com. [2013-07-21]. 
^ eBay Study: How to Build Trust and Improve the Shopping Experience. Knowwpcarey.com. 2012-05-08 [2013-03-05]. （原始內容存檔於2012-06-19）. 
^ Wingfield, Nick. Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com. Bits.blogs.nytimes.com. 2013-03-12 [2013-07-21]. 
^ 柴山和久. ビッグデータを利益に変える方法. 幻冬舎. 2014. ISBN 978-4344952393 （日語）. 


延伸閱讀[編輯]

Big Data for Good (PDF). ODBMS.org. 2012-06-05 [2013-11-12]. 
Hilbert, Martin; López, Priscila. The World's Technological Capacity to Store, Communicate, and Compute Information. Science. 2011, 332 (6025): 60–65. PMID 21310967. doi:10.1126/science.1200970. 
The Rise of Industrial Big Data. GE Intelligent Platforms. [2013-11-12]. 
ISBN 978-986-320-191-5 《大數據》
ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
IEEE Big Data Service. ODBMS.org. 2014-09-07 [2014-09-07]. 

外部連結[編輯]



維基共享資源中相關的多媒體資源：大數據





於維基詞典中查詢big data。



巨量資料的相關報導文章 （《Wired》中文網站）
處理巨量資料的挑戰（美國麻省理工學院線上課程）










查
論
編


電腦科學






數學基礎

數理邏輯 · 集合論 · 數論 · 圖論 · 類型論 · 範疇論 · 數值分析 · 信息論






計算理論

自動機 · 可計算性理論 · 計算複雜性理論 · 量子計算 · 數值計算方法






算法和數據結構

算法分析 · 算法設計 · 計算幾何






編程語言和編譯器

語法分析器 · 解釋器 · 編程範型（過程化編程 · 面向對象程序編程 · 函數式編程 · 邏輯編程等）






併發、並行和分佈式系統

多處理器 · 網格計算 · 併發控制






軟件工程

需求分析 · 軟件設計 · 程序設計 · 形式化方法 · 軟件測試 · 軟件開發過程






系統架構

電腦系統架構 · 微處理器體系結構 · 操作系統






電信與網絡

路由 · 網絡拓撲 · 密碼學






數據庫

數據庫管理系統 · 關係數據庫 · 結構化查詢語言 · NoSQL · 事務處理 · 數據庫索引 · 數據挖掘






人工智能

自動推理 · 計算語言學 · 計算機視覺 · 進化計算 · 專家系統 · 機器學習 · 自然語言處理 · 機器人學






計算機圖形學

可視化 · 計算機動畫 · 圖像處理






人機交互

計算機輔助功能 · 用戶界面 · 可穿戴計算機 · 普適計算 · 虛擬現實 · 聊天機器人






科學計算

人工生命 · 生物信息學 · 認知科學 · 計算化學 · 計算神經科學 · 計算物理學 · 數值算法 · 符號計算







註：計算機科學領域也可根據ACM-2012分類系統進行分類。










 
						取自“https://zh.wikipedia.org/w/index.php?title=大數據&oldid=44895418”					
分類：資訊科學數據庫數據挖掘電腦數據電腦架構計算機科學信息革命隱藏分類：含有未命名參數的引用的頁面引文格式1錯誤：日期含有過時參數的引用的頁面CS1日語來源 (ja)自2014年8月可能帶有原創研究的條目拒絕當選首頁新條目推薦欄目的條目含有英語的條目使用ISBN魔術鏈接的頁面 



導航菜單


個人工具

沒有登錄討論貢獻創建賬戶登錄 



命名空間

條目
討論




不轉換



不轉換
簡體
繁體
大陸簡體
香港繁體
澳門繁體
馬新簡體
台灣正體






視圖

閱讀
編輯
查看歷史



更多







搜索



 







導航


首頁分類索引特色內容新聞動態最近更改隨機條目 



幫助


幫助維基社群方針與指引互助客棧知識問答字詞轉換IRC即時聊天聯絡我們關於維基百科資助維基百科 



在其他項目中


維基共享資源 



打印/導出


下載為PDF 



工具


鏈入頁面相關更改上傳文件特殊頁面打印頁面固定鏈接頁面信息維基數據項引用本頁 



其他語言


العربيةAzərbaycancaБеларускаяBosanskiCatalàکوردیČeštinaDanskDeutschEnglishEspañolEuskaraفارسیSuomiFrançaisעבריתहिन्दीMagyarBahasa IndonesiaÍslenskaItaliano日本語한국어LietuviųLatviešuNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийසිංහලSimple EnglishСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTürkçeТатарча/tatarçaУкраїнськаOʻzbekcha/ўзбекчаTiếng Việt 
編輯鏈接 





 本頁面最後修訂於2017年6月23日 (星期五) 15:12。
本站的全部文字在知識共享 署名-相同方式共享 3.0協議之條款下提供，附加條款亦可能應用。（請參閱使用條款）
Wikipedia®和維基百科標誌是維基媒體基金會的註冊商標；維基™是維基媒體基金會的商標。
維基媒體基金會是在美國佛羅里達州登記的501(c)(3)免稅、非營利、慈善機構。


隱私政策
關於維基百科
免責聲明
開發者
Cookie聲明
手機版視圖



 

 






大數據分析-使用SparkR






















經濟部工業局製造業價值鏈資訊應用計畫



資策會•數位教育研究所•科技化服務（ITeS）中心


【資策會臺北課程】Big Data、物聯網系列課程
【Big Data課程】Big Data之處理與分析實務班
【Big Data課程】Big Data之處理與分析進階班
【Big Data課程】R軟體實作
【Big Data課程】R軟體與資料探勘
【Big Data課程】R軟體與資料視覺化
【Big Data課程】R軟體與網頁資料擷取應用
【Big Data課程】R軟體之金融大數據分析與應用
【Big Data課程】R軟體與Shiny Web應用程式設計
【Big Data課程】Python資料探勘實作
【Big Data課程】大數據分析-使用SparkR
【Big Data課程】Elasticsearch分散式系統實務班
【Big Data課程】Spark大數據分析實務班
【Big Data課程】網路爬蟲與Spark大數據流處理實務
【Big Data課程】文字資料探勘實作班
【Big Data課程】Big Data資料倉儲應用實務
【Big Data課程】整合Big Data與BI實戰班
【Big Data課程】大數據資料探勘與Weka分析
【Big Data課程】Cloud Computing 雲端運算國際認證班
【物聯網課程】物聯網規劃與應用實務班
【物聯網課程】物聯網營運與提案企劃實務班
【物聯網課程】物聯網工程師(EPCIE)國際認證班

							【主題館】資料科學家主題館

							【主題館】雲端運算課程主題館

							【主題館】服務科學主題館

 















 


　


《8/5 
								開課，7/28前報名即享補助40%優惠！》






 ◆ 課程介紹









　　
												當Hadoop技術問世後，大數據儲存及處理的問題便獲得瞭解答。但受限於Hadoop 
												MapReduce 
												框架的運算速度過於緩慢，讓使用者無法有效應用機器學習技術於大數據分析上，以致使用者即使擁有了資料金礦，卻抱著無法有效挖掘出價值的缺憾。所幸記憶體的價格日趨便宜，大眾對即時分析資料的需求日益增長，加州大學柏克萊分校的AMPLab 
												便使用記憶體內(In-Memory)運算技術開發出開源叢集運算框架Spark，彌補MapReduce 
												運算速度緩慢的缺點。
　　雖然Spark 
												的原生語言是Scala，但開發者也可以透過Java 及 
												Python 
												開發應用程式。而由於資料分析相關的開發者多數是以R語言做為主要分析工具，因此Spark 
												於1.4 版後，便支援SparkR，讓使用者可以透過R語言開發Spark 
												應用程式。有了SparkR，資料分析人員不但可妥善利用原本R語言所提供的資料分析與圖形化套件分析資料，更可透過Spark的分散式運算，有效解決大數據的運算問題。
　　
												為了滿足業界需求，資策會特規劃「大數據分析－使用SparkR」課程，本課程學員將學習到Spark 
												運算框架的優點及SparkR 
												的運作原理，藉由實作課程，讓學員可更加瞭解該如何使用SparkR，進行大數據的處理與分析。







◆ 課程目標











												　　本課程學員將學習到大數據運算框架的演進史及SparkR的運作流程。並透過實做課程，瞭解該如何從頭到尾架設起SparkR 
												開發環境。本課程將會提供實際分析案例，讓學員能在實際案例中學習到該如何使用SparkR分析大數據。 







◆ 課程特色










　　 
												本課程旨在使用SparkR進行大數據(Big 
												Data)的處理及分析，讓參訓學員能透過實際案例的操作，瞭解Spark運算框架的優點，以及學習到該如何將SparkR導入至企業內部。本教學會以體驗式教學為主，讓學員能經由指令剪貼的方式來體驗大數據分析流程，以從體驗中驗證課程所學。







◆ 招生對象










―    
												企業資料分析部門主管及相關人員

―    
												專案經理、系統架構師或系統網路管理人員

―    對於
												大數據(Big Data)處理、分析、應用有興趣者








◆ 預備知識









												具Python或Java等程式設計基礎為佳。 







◆ 課程日期








2017年 
												 
												 
												8/5(六)、8/6(日) ，每日 
												09:00~17:00上課，計14小時。







◆ 上課地點








資訊工業策進會數位教育研究所，臺北市信義路三段153號10樓。
                                                 上課地點位於捷運大安站1號出口左轉約20公尺。
                                               * 上課地點與教室之確認，以上課通知函為主。







◆ 課程大綱











 課程單元 
課程內容

													時數





													SparkR 

													概論

													(1)
													
													大數據分析平臺比較 
													- 比較 
													Spark 與 
													Hadoop
                                                   	(2)
													
													SparkR  

													簡介 

													2




													SparkR 

													安裝與設定

													(1)
													
													SparkR 

													安裝與開發環境建置
                                                   (2)
													
													SparkR 

													運作流程簡介 

													2




													SparkR 

													基礎操作

(1)
													

													SparkR DataFrame 
                                                   	(2) 

													建立 SparkR 
													Dataframe
                                                   	(3) 

													SparkR 

													基本操作


													3




													SparkR 

													進階操作

(1)
													

													使用SparkR
													操作 
													SQL 
                                                   	(2) 

													SparkR 

													應用開發實例
                                                   	(3) 

													SparkR 

													與資料視覺化

													3




													SparkR 

													與機器學習實作


													(1) 

													SparkR 

													與機器學習 
                                                   	(2) 

													運用 SparkR
													進行資料分類
                                                   	(3) 

													運用 SparkR
													進行資料分群

													4


* 課程執行單位保留調整課程內容與講師之權利之權利　 







◆ 報名方式









本課程採線上報名，請按右方【我要報名】進入報名系統(依據工業局人才培訓專案規範，接受補助之學員須完整填具學員基本資料表並於開課當天簽署一份「工業局個資告知同意書」，否則無法接受補助，結訓學員應配合經濟部工業局培訓後電訪調查。)

課程諮詢：(02)6631-6533 課程經理 
												黃小姐，E-mail：julie620@iii.org.tw
												報名確認：(02)6631-6535 孫小姐，E-mail：chelseasun@iii.org.tw
 










◆ 課程費用與繳費








1.
本課程原費用NT$10,000元，費用含課程、講義及午餐餐盒。


2.


 
									本課程由工業局負擔40%，凡於7月28日前完成報名與繳費者，可享優惠價NT$6,000元(含稅)。( 
						政府捐助(贈)財團法人、學校教職員工及非本國國籍者不在補助範圍內 )


3.

團報優惠：二人團報可打95折、四人團報可打9折優惠。


　






									●團報優惠與早鳥優惠可一併使用。


									●課程報名系統每個帳號僅提供一位學員報名，若為團報學員，每位皆必須完成線上報名，並於其他金額說明欄位註記「與XXX一起團報」，以利事後核對名單。


4.


						特殊身份優惠：如為「身心障礙者、原住民、低收入戶、中堅企業員工」等特殊身份學員，享有經濟部工業局負擔60%之優惠，前三者學員需提供政府機關核發之身份證明文件影本，中堅企業員工需提供在職證明文件正本，請參中堅企業名單與中堅企業躍升計畫介紹。




												5.

請以信用卡或即期支票支付—


　

● 以信用卡支付者：請務必將正確信用卡資料填寫於繳費方式資料表。
● 以即期支票支付者：抬頭為「財團法人資訊工業策進會」， 劃線並禁止背書轉讓
                                                 　
                                               ，以掛號寄至臺北市106信義路三段153號9樓之1 邱小姐 收。







◆ 報名確認與取消








1.
已完成報名與繳費之學員，課程主辦單位將於開課三天前以E-mail方式寄發上課通知函；若課程因故取消或延期，亦將以E-mail方式通知，如未收到任何通知，敬請來電確認。


2.
已完成繳費之學員如欲取消報名，請於實際上課日前以書面通知業務承辦人，主辦單位將退還90% 課程費用。


3.
學員於培訓期間如因個人因素無法繼續參與課程，將依課程退費規定辦理之︰上課未逾總時數三分之一，欲辦理退費，可退還
												所有課程費用二分之一；上課逾總時數三分之一，則不退費。


4.
課程執行單位保留是否接受報名之權利。







◆ 結業證書








　　依本會ISO品質系統之「教育訓練服務程序」規定，本課程為短期班，參訓學員缺課未 超過總時數五分之一者，結業時由本會核發結業證書。 （本計畫課程需參加並通過課程評量，才可取得結業證書。）








◆ 學習護照










資策會為人事行政局首批認證審定之民間學習機構，參加本課程之中小企業員工，亦可獲得「中小企業終身學習護照」認可之時數；此外，公務人員參加資策會課程，學習時數可登錄「公務人員終身學習護照」。








◆ 
										最低招生人數









 

												最低招生人數至少為12人，預計開班人數為25人。








◆ 
										相關課程









 

Big Data之處理與分析(Hadoop)實務班

Big Data之處理與分析(Hadoop)進階班

Big Data資料分析首部曲-R軟體實作

Big Data資料分析二部曲-R軟體與資料探勘

Big Data資料分析三部曲-R軟體與資料視覺化

R軟體與網頁資料擷取應用

R軟體之金融大數據分析與應用

R軟體與Shiny Web應用程式設計

Python資料探勘實作

大數據分析-使用SparkR

Elasticsearch分散式系統實務班

Spark大數據分析實務班

網路爬蟲與大數據流處理實務班

文字資料探勘實作班















 資訊工業策進會數位教育研究所  版權所有，禁止侵害，違者必究。
Copyright (c) 2013 III Digital Education Institute. All Rights
      Reserved







	R資料採礦與數據分析--以 GUI 套件 Rattle 結合程式語言實作
















































                                                                      






















 




 
               















	 
           
           


























             















加入會員
忘記密碼


修改基本資料
會員權益
















	 
           
           







































	 
           
























‧為企劃書製作索引



‧增強素描真實感的秘密武器



‧建造 Who's Off Bot 的對話體驗


















	 
           
























臺北: (02)2788-2408 






臺中: (04)2452-7051 

 



高雄: (07)384-7699 


 



















































R資料採礦與數據分析--以 GUI 套件 Rattle 結合程式語言實作 
                            
















作者：
                                                何宗武










書號：
AEM002000
   
                                            出版日：
2016/09/30



ISBN：
9789864760572
   
                                            EAN：
9789864760572



紙本書價格： 500
   
                                            附件： 
線上下載



電子書： 已出版















 試讀  






















  博客來    金石堂    天瓏     Google Play 圖書  團體購書




































         



















 
回頁首







臺中科技大學資訊工程系教授兼系主任 陳同孝 / 高雄第一科技大學財務金融學院院長 林楚雄 聯合推薦!!R語言的視窗化套件除了以統計分析為主的Commander，rattle是R社群所熟知的資料探勘視窗套件，它不僅具備資料探勘的功能，其視覺化功能也相當精彩。本書以實作出發，以個案導向介紹許多資料科學常用的分析方法。R裡面的ggplot2著重於許多主流媒體的主題版型和號稱優雅的配色技術，rattle的視覺化則是除了內建ggplot2和CairoDevice之外，還有一個很專業的獨立套件GGobi。如果你需要一本實用與視覺兼具的工具書，本書是您最佳的選擇。本書以GUI介面為主，程式語言為輔助，讓你充分掌握資料分析的關鍵，快速使用R語言的資料探勘工具，若你已接觸過R，則本書能擴大你應用的視野並提升專業資料分析能力。　　．步驟式教學使用 Rattle GUI視窗介面．資料的輸入與輸出．資料性質摘要和繪圖．視覺化．統計學習方法．機器學習之監督式與非監督式方法．多變量統計之資料降維方法．模型綜合評比．PMML方法整合．簡易大數據處理方法







回頁首














大數據分析Excel Power BI全方位應用 Excel 2016統計分析實務--市場調查與資料分析( 範例適用Excel 2016~2010，附...more 














 
回頁首









PART 1 資料分析與探勘ch01 資料分析原理ch02 機率原理ch03 R和 rattle裝置ch04 樣本性質分析ch05 資料性質檢定與轉換ch06 視覺化與探索性資料分析(本章為彩色印刷)PART 2 機器學習(1)-監督式學習ch07 線性模式與廣義線性模式ch08 分類方法ch09 強化式學習法PART 3 機器學習(2)-非監督式學習ch10 集群分析ch11 關聯分析PART 4 其他方法ch12 主成份分析法ch13 存活分析PART 5 綜合評估ch14 模型績效綜合評比ch15 案例資料與實作簡說ch16 R的簡易大數據介紹appA 時間序列分析入門









 
回頁首









請至http://books.gotop.com.tw/download/AEM002000下載相關檔案僅供合法持有本書的讀者使用，未經授權不得抄襲、轉載或任意散佈。



















僅提供已加入碁峰會員之教師申請任教科目之教師資源：教學投影片、習題解答、教學樣書、線上測驗系統…，若申請未任教科目之教學資源，碁峰保有核發與否之權利。






若您已是碁峰教師會員，請直接於左方 教師登入區 輸入帳號密碼。






若您尚未加入會員，請先 加入會員，即可享有多項教師專屬服務。













 
遍佈北中南，陣容堅強的碁峰業務團隊，都將竭誠的為您服務





請利用申請表單填寫欲申請之相關教學資源，將盡快為您處理 




授課電子樣書教學配件(教學投影片)













 










  
                                












 












關於碁峰│隱私權政策│聯絡我們    
                                檢視 : PC 版  手機版 






碁峰資訊股份有限公司 GOTOP INFORMATION INC. 
         臺北市南港區三重路66號7樓之6 / 7F.-6,No.66,Sanchong Rd.,Nangang District,Taipei 
         TEL:(02)2788-2408 FAX:(02)8192-4433 劃撥帳號:14244383 
         Copyright 2014© GOTOP   Information Inc, All Rights Reserved 請勿任意連結、轉載





﻿




















用Excel做商業資料分析，處理大數據資料，輕鬆低成本完成商業智慧分析




















成本最低的大數據分析工具
Excel
 面對日益嚴峻的全球性競爭，企業主下一步該往哪裡走？如何能精準預測未來？其實答案就在您手上擁有的資料數據中。
            所有企業都應學會如何讓資料主動告訴您，誰是企業的潛力客戶、客戶心中真正想要的是什麼，
            還要讓這些數據告訴你，如何提高企業營運績效及找出新的產品組合。 

 瞭解更多 











手上已有數據，卻不知如何分析？
現今資料數據分析面臨到一個困境，企業擁有的數據資料來源眾多，數量龐大，複雜性也日益提升，若不能將手上的數據及時進行分析，做出正確的決策，將會是非常大的遺憾。畢竟寶貴的資料已經在手上，卻不能透過有效的分析發現隱藏在其中的問題。 





隨手可得的超強分析工具Excel
別懷疑，您手邊就有一個很熟悉且有效的大數據分析工具，就是Excel！有超過一億的辦公室使用者正在使用Excel進行資料處理與分析，換句話說，絕大多數的企業使用者手上都有這個分析工具！您不需要增加商業智慧工具的採購成本，就能讓企業在極低的學習成本下，處理及分析資料數據。 












Excel商業數據分析王牌講師

吳翠鳳 Linda Wu


 


 個人與Excel已結緣20幾年，從Excel剛發表就與它熟識，一路走來看著Excel成為功能非常強大的數據分析工具，但能將它運用自如的人卻少之又少。有更多的人誤解Excel不過是個基本的Office軟體，隨便去坊間買本書便可將它擺平，事實卻不是這樣的。 
 恆逸因應大數據分析需求，開設一系列Excel課程，內容涵蓋Excel近90%的功能，別以為這些功能您用不到，實際狀況是您不知道有這些功能，時常事倍功半！我想要告訴大家，Excel的聰明絕對超乎您的想像！現在有了Power BI的加持，讓它在進行大數據分析領域上，更有如虎添翼的效果！ 
 恆逸Excel課程絕非坊間初階的Excel軟體教學，是能真正活用並替您完成數據分析與決策判斷的課程，讓您資料處理能力大躍升，成為企業大數據分析不可或缺的中流砥柱。




 認證：MCT、MCITP、MCTS、MCSE on Security、MCSE、MCSA on Security、MCSA on Messaging、MCSA、MCP、MCP+Internet、CCNA、TCSE、ITIL Foundation 


 專長：自助式商業智慧解決方案建置，Microsoft Office企業環境整合運用及建置、Internet及Intranet網路系統規劃與部署整合、系統分析與效能最佳化、趨勢科技全產品防毒規劃與管理、企業專案管理規劃及追蹤 











周錚瑋
每上完一段功能，就會讓學生馬上練習，完全沒有打瞌睡的機會




周錚瑋
吳翠鳳老師教學非常有自信，在三天的上課過程中非常緊湊，教學內容也非常豐富，她每上完一段功能，就會讓學生馬上練習，完全沒有打瞌睡的機會，三天的上課時間，讓我收獲滿滿的。課程中學了很多Excel之前不知道的的小技巧、上完課後，可以在工作時更快速的完成報表製作，EXCEL是很容易取得的軟體，可以很簡單也可以很複雜，從簡簡單單的加總、計數排列、圖表呈現，到很複雜的函數、樞鈕分析，都可以讓工作速度和品質加分不少。







施再聰
課程令人耳目一新，利用工具，將大量資料轉變為明確且有意義的報表或是圖表




施再聰
工作常需要作大量的資料比對、篩選，甚至是分析，但時常花費許多時間及精神去處理。這次的課程內容很令人驚喜，雖然時間僅短短幾天，但老師以零售商相關的業務數字進行資料採礦及分析的教學，除了基本的函數、vlookup、樞紐分析、圖表，且進階使用power pivot, power view等工具進行分析作業，令人耳目一新，利用這些分析工具，能快速將大量的資料轉變為明確且有意義的報表或是圖表，捨棄土法煉鋼式的報表，有效率的加速我的作業，產出的報表也很容易閱讀，可以提供長官更精確地去做決策。







張文華
上課後才發現上班天天會使用到的Excel，懂得利用原有功能，就可節省工作時間




張文華
課程老師提供的教材寫的很好淺顯易懂，日後留著又可當工具書，上課練習資料相當的充足。老師擁有豐富的教學經歷，腦中存有不少問與答題庫，學生容易遇到的問題都能輕易解答。上課後才發現原來平時上班天天會使用到的Excel，懂得多加利用工具原有的功能，可以節省掉不少工作時間！先前並不知道許多可用的函數，常常土法錬鋼花了許多時間達到目的，參加完課程後，可以快速方便處理資料。非常推薦有相同工作性質的人，一定能藉由課程累積實力增長見聞。







鄭佳怡
上完課程才知道Excel 2013擁有強大的大數據分析功能，可以輕鬆處理上億筆資料




鄭佳怡
吳翠鳳講師的授課非常精實，每一堂課講師傳授的內容大概是一般課程講師的1.5倍，講師實作的經驗豐富，且傳授非常多分析技術和數據解讀的技巧經驗，每一堂都必須聚精會神才能跟得上進度。上課前我對Excel的認知就是將數據資料用Excel作整理，製作樞紐分析、建置圖表這些基本功能。
上完這門課程才知道Excel 2013已經擁有強大的大數據分析功能，並且可以輕鬆處理上億筆以上的資料。從進行資料匯入→資料整理→建立關連性→進行樞紐分析→拖拉圖表，還有各項可以客製化的公式和數值、產生互動式數據及拖拉就能產生的簡報圖表，遠超過上課前我對Excel的認知。







蕭瑋翎
老師輕快與幽默的教學風格十分吸引人，特別是她常教授一些朗朗上口的實用口訣




蕭瑋翎
吳翠鳳老師輕快與略帶幽默的教學風格十分的吸引人，特別是老師常教授一些朗朗上口的實用口訣，比如「重覆的事情不要做」，只要操作Excel上遇到重覆的動作，就會想到老師的這句話，停下來想一下是否有更有效率的方法完成。上了課後才發現Excel學的好，加班就可少。另外「圖表製作要簡單易懂」，擺脫以往獃板製式的圖表樣式，讓寫文件的人以一種說故事的角度去繪出圖表，讓使用者一目瞭然，甚至不需要特別的解說也能讓人立即理解想要表達的情境，這點對常需要製作簡報的人是十分有幫助的。教材內容深入簡出，列出的都是十分實用的功能，是本不錯的工具書與教材。有些工具先前從來沒使用過，一直到上了這堂課，才發現原來有這麼多好用的工具等。













周錚瑋
吳翠鳳老師教學非常有自信，在三天的上課過程中非常緊湊，教學內容也非常豐富，她每上完一段功能，就會讓學生馬上練習，完全沒有打瞌睡的機會，三天的上課時間，讓我收獲滿滿的。課程中學了很多Excel之前不知道的的小技巧、上完課後，可以在工作時更快速的完成報表製作，EXCEL是很容易取得的軟體，可以很簡單也可以很複雜，從簡簡單單的加總、計數排列、圖表呈現，到很複雜的函數、樞鈕分析，都可以讓工作速度和品質加分不少。










施再聰
工作常需要作大量的資料比對、篩選，甚至是分析，但時常花費許多時間及精神去處理。這次的課程內容很令人驚喜，雖然時間僅短短幾天，但老師以零售商相關的業務數字進行資料採礦及分析的教學，除了基本的函數、vlookup、樞紐分析、圖表，且進階使用power pivot, power view等工具進行分析作業，令人耳目一新，利用這些分析工具，能快速將大量的資料轉變為明確且有意義的報表或是圖表，捨棄土法煉鋼式的報表，有效率的加速我的作業，產出的報表也很容易閱讀，可以提供長官更精確地去做決策。










張文華
課程老師提供的教材寫的很好淺顯易懂，日後留著又可當工具書，上課練習資料相當的充足。老師擁有豐富的教學經歷，腦中存有不少問與答題庫，學生容易遇到的問題都能輕易解答。上課後才發現原來平時上班天天會使用到的Excel，懂得多加利用工具原有的功能，可以節省掉不少工作時間！先前並不知道許多可用的函數，常常土法錬鋼花了許多時間達到目的，參加完課程後，可以快速方便處理資料。非常推薦有相同工作性質的人，一定能藉由課程累積實力增長見聞。










鄭佳怡
吳翠鳳講師的授課非常精實，每一堂課講師傳授的內容大概是一般課程講師的1.5倍，講師實作的經驗豐富，且傳授非常多分析技術和數據解讀的技巧經驗，每一堂都必須聚精會神才能跟得上進度。上課前我對Excel的認知就是將數據資料用Excel作整理，製作樞紐分析、建置圖表這些基本功能。上完這門課程才知道Excel 2013已經擁有強大的大數據分析功能，並且可以輕鬆處理上億筆以上的資料。從進行資料匯入→資料整理→建立關連性→進行樞紐分析→拖拉圖表，還有各項可以客製化的公式和數值、產生互動式數據及拖拉就能產生的簡報圖表，遠超過上課前我對Excel的認知。










鄭佳怡
吳翠鳳老師輕快與略帶幽默的教學風格十分的吸引人，特別是老師常教授一些朗朗上口的實用口訣，比如「重覆的事情不要做」，只要操作Excel上遇到重覆的動作，就會想到老師的這句話，停下來想一下是否有更有效率的方法完成。上了課後才發現Excel學的好，加班就可少。另外「圖表製作要簡單易懂」，擺脫以往獃板製式的圖表樣式，讓寫文件的人以一種說故事的角度去繪出圖表，讓使用者一目瞭然，甚至不需要特別的解說也能讓人立即理解想要表達的情境，這點對常需要製作簡報的人是十分有幫助的。教材內容深入簡出，列出的都是十分實用的功能，是本不錯的工具書與教材。有些工具先前從來沒使用過，一直到上了這堂課，才發現原來有這麼多好用的工具等。











Excel商業數據課程

BITCF商業數據分析-Excel資料處理及統計與函數應用
BITDS商業數據分析-Excel資料標準化及淨化突顯與模擬分析
BITPG商業數據分析-Excel 資料樞紐探勘與圖像視覺化溝通
BITPB商業數據分析-Excel Power BI 大數據挖掘與拆解分析
BITVB商業數據分析-Excel資料處理自動化






免費索取課程資料

限時合報優惠
            任選2科合報8折優惠，5科合報7折優惠
            每班優惠名額有限，請盡早報名
















臺北-臺北市復興北路99號14樓
02-25149191
02-25149292


新竹- 新竹市光復路二段295號3樓之2
03-5723322
03-5745738






臺中-臺中市西區臺灣大道二段309號2樓
04-23297722
04-23102000


高雄- 高雄市前鎮區中山二路2號25樓
07-5361199
07-5366161







本網站之內容屬於精誠資訊-恆逸教育訓練中心所有，非經書面同意禁止一切複製使用網站內其他授權公司與產品Logo，分屬其原公司所有
              
              服務條款與隱私權















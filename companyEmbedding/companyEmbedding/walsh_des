


Hadamard code - Wikipedia






















 






Hadamard code

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search



Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k


{\displaystyle k}




Rate




k

/


2

k




{\displaystyle k/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code





v
t
e







Punctured Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k
+
1


{\displaystyle k+1}




Rate




(
k
+
1
)

/


2

k




{\displaystyle (k+1)/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code





v
t
e









Matrix of the Punctured Hadamard code [32, 6, 16] for the Reed–Muller code (1, 5) of the NASA space probe Mariner 9






XOR operations
Here the white fields stand for 0
and the red fields for 1


The Hadamard code is an error-correcting code that is used for error detection and correction when transmitting messages over very noisy or unreliable channels. In 1971, the code was used to transmit photos of Mars back to Earth from the NASA space probe Mariner 9.[1] Because of its unique mathematical properties, the Hadamard code is not only used by engineers, but also intensely studied in coding theory, mathematics, and theoretical computer science. The Hadamard code is named after the French mathematician Jacques Hadamard. It is also known under the names Walsh code, Walsh family,[2] and Walsh–Hadamard code[3] in recognition of the American mathematician Joseph Leonard Walsh.
The Hadamard code is an example of a linear code over a binary alphabet that maps messages of length 



k


{\displaystyle k}

 to codewords of length 




2

k




{\displaystyle 2^{k}}

. It is unique in that each non-zero codeword has a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

, which implies that the distance of the code is also 




2

k
−
1




{\displaystyle 2^{k-1}}

. In standard coding theory notation for block codes, the Hadamard code is a 



[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code, that is, it is a linear code over a binary alphabet, has block length 




2

k




{\displaystyle 2^{k}}

, message length (or dimension) 



k


{\displaystyle k}

, and minimum distance 




2

k



/

2


{\displaystyle 2^{k}/2}

. The block length is very large compared to the message length, but on the other hand, errors can be corrected even in extremely noisy conditions. The punctured Hadamard code is a slightly improved version of the Hadamard code; it is a 



[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code and thus has a slightly better rate while maintaining the relative distance of 



1

/

2


{\displaystyle 1/2}

, and is thus preferred in practical applications. The punctured Hadamard code is the same as the first order Reed–Muller code over the binary alphabet.[4]
Normally, Hadamard codes are based on Sylvester's construction of Hadamard matrices, but the term “Hadamard code” is also used to refer to codes constructed from arbitrary Hadamard matrices, which are not necessarily of Sylvester type. In general, such a code is not linear. Such codes were first constructed by R. C. Bose and S. S. Shrikhande in 1959.[5] If n is the size of the Hadamard matrix, the code has parameters 



(
n
,
2
n
,
n

/

2

)

2




{\displaystyle (n,2n,n/2)_{2}}

, meaning it is a not-necessarily-linear binary code with 2n codewords of block length n and minimal distance n/2. The construction and decoding scheme described below apply for general n, but the property of linearity and the identification with Reed–Muller codes require that n be a power of 2 and that the Hadamard matrix be equivalent to the matrix constructed by Sylvester's method.
The Hadamard code is a locally decodable code, which provides a way to recover parts of the original message with high probability, while only looking at a small fraction of the received word. This gives rise to applications in computational complexity theory and particularly in the design of probabilistically checkable proofs. Since the relative distance of the Hadamard code is 1/2, normally one can only hope to recover from at most a 1/4 fraction of error. Using list decoding, however, it is possible to compute a short list of possible candidate messages as long as fewer than 





1
2


−
ϵ


{\displaystyle {\frac {1}{2}}-\epsilon }

 of the bits in the received word have been corrupted.
In code division multiple access (CDMA) communication, the Hadamard code is referred to as Walsh Code, and is used to define individual communication channels. It is usual in the CDMA literature to refer to codewords as “codes”. Each user will use a different codeword, or “code”, to modulate their signal. Because Walsh codewords are mathematically orthogonal, a Walsh-encoded signal appears as random noise to a CDMA capable mobile terminal, unless that terminal uses the same codeword as the one used to encode the incoming signal.[6]



Contents


1 History
2 Constructions

2.1 Construction using inner products
2.2 Construction using a generator matrix
2.3 Construction using general Hadamard matrices


3 Distance
4 Local decodability

4.1 Proof of lemma 1
4.2 Proof of theorem 1

4.2.1 Algorithm
4.2.2 Proof of correctness




5 Optimality
6 See also
7 Notes
8 References



History[edit]
Hadamard code is the name that is most commonly used for this code in the literature. However, in modern use these error correcting codes are referred to as Walsh–Hadamard codes.
There is a reason for this:
Jacques Hadamard did not invent the code himself, but he defined Hadamard matrices around 1893, long before the first error-correcting code, the Hamming code, was developed in the 1940s.
The Hadamard code is based on Hadamard matrices, and while there are many different Hadamard matrices that could be used here, normally only Sylvester's construction of Hadamard matrices is used to obtain the codewords of the Hadamard code.
James Joseph Sylvester developed his construction of Hadamard matrices in 1867, which actually predates Hadamard's work on Hadamard matrices. Hence the name Hadamard code is not undisputed and sometimes the code is called Walsh code, honoring the American mathematician Joseph Leonard Walsh.
A Hadamard code was used during the 1971 Mariner 9 mission to correct for picture transmission errors. The data words used during this mission were 6 bits long, which represented 64 grayscale values.
Because of limitations of the quality of the alignment of the transmitter at the time (due to Doppler Tracking Loop issues) the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used.
Errors of up to 7 bits per word could be corrected using this scheme. Compared to a 5-repetition code, the error correcting properties of this Hadamard code are much better, yet its rate is comparable. The efficient decoding algorithm was an important factor in the decision to use this code.
The circuitry used was called the "Green Machine". It employed the fast Fourier transform which can increase the decoding speed by a factor of three. Since the 1990s use of this code by space programs has more or less ceased, and the Deep Space Network does not support this error correction scheme for its dishes that are greater than 26 m.
Constructions[edit]
While all Hadamard codes are based on Hadamard matrices, the constructions differ in subtle ways for different scientific fields, authors, and uses. Engineers, who use the codes for data transmission, and coding theorists, who analyse extremal properties of codes, typically want the rate of the code to be as high as possible, even if this means that the construction becomes mathematically slightly less elegant.
On the other hand, for many applications of Hadamard codes in theoretical computer science it is not so important to achieve the optimal rate, and hence simpler constructions of Hadamard codes are preferred since they can be analyzed more elegantly.
Construction using inner products[edit]
When given a binary message 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 of length 



k


{\displaystyle k}

, the Hadamard code encodes the message into a codeword 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 using an encoding function 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

. This function makes use of the inner product 



⟨
x
,
y
⟩


{\displaystyle \langle x,y\rangle }

 of two vectors 



x
,
y
∈
{
0
,
1

}

k




{\displaystyle x,y\in \{0,1\}^{k}}

, which is defined as follows:





⟨
x
,
y
⟩
=

∑

i
=
1


k



x

i



y

i


 

mod

 


2

.


{\displaystyle \langle x,y\rangle =\sum _{i=1}^{k}x_{i}y_{i}\ {\bmod {\ }}2\,.}



Then the Hadamard encoding of 



x


{\displaystyle x}

 is defined as the sequence of all inner products with 



x


{\displaystyle x}

:






Had

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
0
,
1

}

k






{\displaystyle {\text{Had}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{0,1\}^{k}}}



As mentioned above, the punctured Hadamard code is used in practice since the Hadamard code itself is somewhat wasteful. This is because, if the first bit of 



y


{\displaystyle y}

 is zero, 




y

1


=
0


{\displaystyle y_{1}=0}

, then the inner product contains no information whatsoever about 




x

1




{\displaystyle x_{1}}

, and hence, it is impossible to fully decode 



x


{\displaystyle x}

 from those positions of the codeword alone. On the other hand, when the codeword is restricted to the positions where 




y

1


=
1


{\displaystyle y_{1}=1}

, it is still possible to fully decode 



x


{\displaystyle x}

. Hence it makes sense to restrict the Hadamard code to these positions, which gives rise to the punctured Hadamard encoding of 



x


{\displaystyle x}

; that is, 




pHad

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
1
}
×
{
0
,
1

}

k
−
1






{\displaystyle {\text{pHad}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{1\}\times \{0,1\}^{k-1}}}

.
Construction using a generator matrix[edit]
The Hadamard code is a linear code, and all linear codes can be generated by a generator matrix 



G


{\displaystyle G}

. This is a matrix such that 




Had

(
x
)
=
x
⋅
G


{\displaystyle {\text{Had}}(x)=x\cdot G}

 holds for all 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

, where the message 



x


{\displaystyle x}

 is viewed as a row vector and the vector-matrix product is understood in the vector space over the finite field 





F


2




{\displaystyle \mathbb {F} _{2}}

. In particular, an equivalent way to write the inner product definition for the Hadamard code arises by using the generator matrix whose columns consist of all strings 



y


{\displaystyle y}

 of length 



k


{\displaystyle k}

, that is,





G
=


(



↑


↑



↑





y

1





y

2




…



y


2

k








↓


↓



↓



)



.


{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\y_{1}&y_{2}&\dots &y_{2^{k}}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}\,.}



where 




y

i


∈
{
0
,
1

}

k




{\displaystyle y_{i}\in \{0,1\}^{k}}

 is the 



i


{\displaystyle i}

-th binary vector in lexicographical order. For example, the generator matrix for the Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:





G
=


[



0


0


0


0


1


1


1


1




0


0


1


1


0


0


1


1




0


1


0


1


0


1


0


1



]


.


{\displaystyle G={\begin{bmatrix}0&0&0&0&1&1&1&1\\0&0&1&1&0&0&1&1\\0&1&0&1&0&1&0&1\end{bmatrix}}.}



The matrix 



G


{\displaystyle G}

 is a 



(
k
×

2

k


)


{\displaystyle (k\times 2^{k})}

-matrix and gives rise to the linear operator 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

.
The generator matrix of the punctured Hadamard code is obtained by restricting the matrix 



G


{\displaystyle G}

 to the columns whose first entry is one. For example, the generator matrix for the punctured Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:






G
′

=


[



1


1


1


1




0


0


1


1




0


1


0


1



]


.


{\displaystyle G'={\begin{bmatrix}1&1&1&1\\0&0&1&1\\0&1&0&1\end{bmatrix}}.}



Then 




pHad

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k
−
1






{\displaystyle {\text{pHad}}:\{0,1\}^{k}\to \{0,1\}^{2^{k-1}}}

 is a linear mapping with 




pHad

(
x
)
=
x
⋅

G
′



{\displaystyle {\text{pHad}}(x)=x\cdot G'}

.
For general 



k


{\displaystyle k}

, the generator matrix of the punctured Hadamard code is a parity-check matrix for the extended Hamming code of length 




2

k
−
1




{\displaystyle 2^{k-1}}

 and dimension 




2

k
−
1


−
k


{\displaystyle 2^{k-1}-k}

, which makes the punctured Hadamard code the dual code of the extended Hamming code. Hence an alternative way to define the Hadamard code is in terms of its parity-check matrix: the parity-check matrix of the Hadamard code is equal to the generator matrix of the Hamming code.
Construction using general Hadamard matrices[edit]
Generalized Hadamard codes are obtained from an n-by-n Hadamard matrix H. In particular, the 2n codewords of the code are the rows of H and the rows of −H. To obtain a code over the alphabet {0,1}, the mapping −1 ↦ 1, 1 ↦ 0, or, equivalently, x ↦ (1 − x)/2, is applied to the matrix elements. That the minimum distance of the code is n/2 follows from the defining property of Hadamard matrices, namely that their rows are mutually orthogonal. This implies that two distinct rows of a Hadamard matrix differ in exactly n/2 positions, and, since negation of a row does not affect orthogonality, that any row of H differs from any row of −H in n/2 positions as well, except when the rows correspond, in which case they differ in n positions.
To get the punctured Hadamard code above with 



n
=

2

k
−
1




{\displaystyle n=2^{k-1}}

, the chosen Hadamard matrix H has to be of Sylvester type, which gives rise to a message length of 




log

2


⁡
(
2
n
)
=
k


{\displaystyle \log _{2}(2n)=k}

.
Distance[edit]
The distance of a code is the minimum Hamming distance between any two distinct codewords, i.e., the minimum number of positions at which two distinct codewords differ. Since the Walsh–Hadamard code is a linear code, the distance is equal to the minimum Hamming weight among all of its non-zero codewords. All non-zero codewords of the Walsh–Hadamard code have a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

 by the following argument.
Let 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 be a non-zero message. Then the following value is exactly equal to the fraction of positions in the codeword that are equal to one:






Pr

y
∈
{
0
,
1

}

k






[


(

Had

(
x
)

)

y


=
1


]


=

Pr

y
∈
{
0
,
1

}

k






[


⟨
x
,
y
⟩
=
1


]



.


{\displaystyle \Pr _{y\in \{0,1\}^{k}}{\big [}({\text{Had}}(x))_{y}=1{\big ]}=\Pr _{y\in \{0,1\}^{k}}{\big [}\langle x,y\rangle =1{\big ]}\,.}



The fact that the latter value is exactly 



1

/

2


{\displaystyle 1/2}

 is called the random subsum principle. To see that it is true, assume without loss of generality that 




x

1


=
1


{\displaystyle x_{1}=1}

. Then, when conditioned on the values of 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

, the event is equivalent to 




y

1


⋅

x

1


=
b


{\displaystyle y_{1}\cdot x_{1}=b}

 for some 



b
∈
{
0
,
1
}


{\displaystyle b\in \{0,1\}}

 depending on 




x

2


,
…
,

x

k




{\displaystyle x_{2},\dots ,x_{k}}

 and 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

. The probability that 




y

1


=
b


{\displaystyle y_{1}=b}

 happens is exactly 



1

/

2


{\displaystyle 1/2}

. Thus, in fact, all non-zero codewords of the Hadamard code have relative Hamming weight 



1

/

2


{\displaystyle 1/2}

, and thus, its relative distance is 



1

/

2


{\displaystyle 1/2}

.
The relative distance of the punctured Hadamard code is 



1

/

2


{\displaystyle 1/2}

 as well, but it no longer has the property that every non-zero codeword has weight exactly 



1

/

2


{\displaystyle 1/2}

 since the all 



1


{\displaystyle 1}

s vector 




1


2

k
−
1






{\displaystyle 1^{2^{k-1}}}

 is a codeword of the punctured Hadamard code. This is because the vector 



x
=

10

k
−
1




{\displaystyle x=10^{k-1}}

 encodes to 




pHad

(

10

k
−
1


)
=

1


2

k
−
1






{\displaystyle {\text{pHad}}(10^{k-1})=1^{2^{k-1}}}

. Furthermore, whenever 



x


{\displaystyle x}

 is non-zero and not the vector 




10

k
−
1




{\displaystyle 10^{k-1}}

, the random subsum principle applies again, and the relative weight of 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 is exactly 



1

/

2


{\displaystyle 1/2}

.
Local decodability[edit]
A locally decodable code is a code that allows a single bit of the original message to be recovered with high probability by only looking at a small portion of the received word.
A code is 



q


{\displaystyle q}

-query locally decodable if a message bit, 




x

i




{\displaystyle x_{i}}

, can be recovered by checking 



q


{\displaystyle q}

 bits of the received word. More formally, a code, 



C
:
{
0
,
1

}

k


→
{
0
,
1

}

n




{\displaystyle C:\{0,1\}^{k}\rightarrow \{0,1\}^{n}}

, is 



(
q
,
δ
≥
0
,
ϵ
≥
0
)


{\displaystyle (q,\delta \geq 0,\epsilon \geq 0)}

-locally decodable, if there exists a probabilistic decoder, 



D
:
{
0
,
1

}

n


→
{
0
,
1

}

k




{\displaystyle D:\{0,1\}^{n}\rightarrow \{0,1\}^{k}}

, such that (Note: 



Δ
(
x
,
y
)


{\displaystyle \Delta (x,y)}

 represents the Hamming distance between vectors 



x


{\displaystyle x}

 and 



y


{\displaystyle y}

):




∀
x
∈
{
0
,
1

}

k


,
∀
y
∈
{
0
,
1

}

n




{\displaystyle \forall x\in \{0,1\}^{k},\forall y\in \{0,1\}^{n}}

, 



Δ
(
y
,
C
(
x
)
)
≤
δ
n


{\displaystyle \Delta (y,C(x))\leq \delta n}

 implies that 



P
r
[
D
(
y

)

i


=

x

i


]
≥


1
2


+
ϵ
,
∀
i
∈
[
k
]


{\displaystyle Pr[D(y)_{i}=x_{i}]\geq {\frac {1}{2}}+\epsilon ,\forall i\in [k]}


Theorem 1: The Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

-locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Lemma 1: For all codewords, 



c


{\displaystyle c}

 in a Walsh–Hadamard code, 



C


{\displaystyle C}

, 




c

i


+

c

j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=c_{i+j}}

, where 




c

i


,

c

j




{\displaystyle c_{i},c_{j}}

 represent the bits in 



c


{\displaystyle c}

 in positions 



i


{\displaystyle i}

 and 



j


{\displaystyle j}

 respectively, and 




c

i
+
j




{\displaystyle c_{i+j}}

 represents the bit at position 



(
i
+
j
)


{\displaystyle (i+j)}

.
Proof of lemma 1[edit]

Let 



C
(
x
)
=
c
=
(

c

0


,
…
,

c


2

n


−
1


)


{\displaystyle C(x)=c=(c_{0},\dots ,c_{2^{n}-1})}

 be the codeword in 



C


{\displaystyle C}

 corresponding to message 



x


{\displaystyle x}

.
Let 



G
=


(



↑


↑



↑





g

0





g

1




…



g


2

n


−
1






↓


↓



↓



)




{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\g_{0}&g_{1}&\dots &g_{2^{n}-1}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}}

 be the generator matrix of 



C


{\displaystyle C}

.
By definition, 




c

i


=
x
⋅

g

i




{\displaystyle c_{i}=x\cdot g_{i}}

. From this, 




c

i


+

c

j


=
x
⋅

g

i


+
x
⋅

g

j


=
x
⋅
(

g

i


+

g

j


)


{\displaystyle c_{i}+c_{j}=x\cdot g_{i}+x\cdot g_{j}=x\cdot (g_{i}+g_{j})}

. By the construction of 



G


{\displaystyle G}

, 




g

i


+

g

j


=

g

i
+
j




{\displaystyle g_{i}+g_{j}=g_{i+j}}

. Therefore, by substitution, 




c

i


+

c

j


=
x
⋅

g

i
+
j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=x\cdot g_{i+j}=c_{i+j}}

.
Proof of theorem 1[edit]

To prove theorem 1 we will construct a decoding algorithm and prove its correctness.
Algorithm[edit]
Input: Received word 



y
=
(

y

0


,
…
,

y


2

n


−
1


)


{\displaystyle y=(y_{0},\dots ,y_{2^{n}-1})}


For each 



i
∈
{
1
,
…
,
n
}


{\displaystyle i\in \{1,\dots ,n\}}

:

Pick 



j
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle j\in \{0,\dots ,2^{n}-1\}}

 uniformly at random
Pick 



k
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle k\in \{0,\dots ,2^{n}-1\}}

 such that 



j
+
k
=

e

i




{\displaystyle j+k=e_{i}}

 where 



j
+
k


{\displaystyle j+k}

 is the bitwise xor of 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

.





x

i


←

y

j


+

y

k




{\displaystyle x_{i}\gets y_{j}+y_{k}}



Output: Message 



x
=
(

x

1


,
…
,

x

n


)


{\displaystyle x=(x_{1},\dots ,x_{n})}


Proof of correctness[edit]
For any message, 



x


{\displaystyle x}

, and received word 



y


{\displaystyle y}

 such that 



y


{\displaystyle y}

 differs from 



c
=
C
(
x
)


{\displaystyle c=C(x)}

 on at most 



δ


{\displaystyle \delta }

 fraction of bits, 




x

i




{\displaystyle x_{i}}

 can be decoded with probability at least 





1
2


+
(


1
2


−
2
δ
)


{\displaystyle {\frac {1}{2}}+({\frac {1}{2}}-2\delta )}

.
By lemma 1, 




c

j


+

c

k


=

c

j
+
k


=
x
⋅

g

j
+
k


=
x
⋅

e

i


=

x

i




{\displaystyle c_{j}+c_{k}=c_{j+k}=x\cdot g_{j+k}=x\cdot e_{i}=x_{i}}

. Since 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

 are picked uniformly, the probability that 




y

j


≠

c

j




{\displaystyle y_{j}\not =c_{j}}

 is at most 



δ


{\displaystyle \delta }

. Similarly, the probability that 




y

k


≠

c

k




{\displaystyle y_{k}\not =c_{k}}

 is at most 



δ


{\displaystyle \delta }

. By the union bound, the probability that either 




y

j




{\displaystyle y_{j}}

 or 




y

k




{\displaystyle y_{k}}

 do not match the corresponding bits in 



c


{\displaystyle c}

 is at most 



2
δ


{\displaystyle 2\delta }

. If both 




y

j




{\displaystyle y_{j}}

 and 




y

k




{\displaystyle y_{k}}

 correspond to 



c


{\displaystyle c}

, then lemma 1 will apply, and therefore, the proper value of 




x

i




{\displaystyle x_{i}}

 will be computed. Therefore, the probability 




x

i




{\displaystyle x_{i}}

 is decoded properly is at least 



1
−
2
δ


{\displaystyle 1-2\delta }

. Therefore, 



ϵ
=


1
2


−
2
δ


{\displaystyle \epsilon ={\frac {1}{2}}-2\delta }

 and for 



ϵ


{\displaystyle \epsilon }

 to be positive, 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Therefore, the Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

 locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}


Optimality[edit]
For k ≤ 7 the linear Hadamard codes have been proven optimal in the sense of minimum distance.[7]
See also[edit]

Zadoff–Chu sequence — improve over the Walsh–Hadamard codes

Notes[edit]



^ http://www.mcs.csueastbay.edu/~malek/TeX/Hadamard.pdf
^ See, e.g., Amadei, Manzoli & Merani (2002)
^ See, e.g., Arora & Barak (2009, Section 19.2.2).
^ See, e.g., Guruswami (2009, p. 3).
^ Bose, R.C.; Shrikhande, S.S. (1959). "A note on a result in the theory of code construction". Information and Control. 2 (2): 183–194. CiteSeerX 10.1.1.154.2879 . doi:10.1016/S0019-9958(59)90376-6. 
^ "CDMA Tutorial: Intuitive Guide to Principles of Communications" (PDF). Complex to Real. Retrieved 4 August 2011. 
^ Jaffe, David B.; Bouyukliev, Iliya, Optimal binary linear codes of dimension at most seven 



References[edit]

Amadei, M.; Manzoli, U.; Merani, M.L. (2002), "On the assignment of Walsh and quasi-orthogonal codes in a multicarrier DS-CDMA system with multiple classes of users", Global Telecommunications Conference, 2002. GLOBECOM'02. IEEE, 1, IEEE, pp. 841–5, ISBN 0-7803-7632-3, doi:10.1109/GLOCOM.2002.1188196 
Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4 
Guruswami, Venkatesan (2009), List decoding of binary codes (PDF) 
Rudra, Atri, "Hamming code and Hamming bound" (PDF), Lecture notes 







v
t
e


Consultative Committee for Space Data Systems



Data compression



Images

ICER
JPEG
JPEG 2000
122.0.B1


Data

Adaptive Entropy Coder







Error Correction



Current
Binary Golay code
Concatenated codes
Turbo codes
Proposed
LDPC codes





Telemetry command uplink



Command Loss Timer Reset
Proximity-1 Space Link Protocol





Telemetry downlink



Spacecraft Monitoring & Control
Beacon mode service





Telemetry general



Space Communications Protocol Specifications (SCPS): Performance Enhancing Proxy





Telemetry modulation systems



Current
BPSK
QPSK
OQPSK
Proposed
GMSK





Frequencies



X band
S band
Ku band
K band
Ka band





Networking, interoperability and monitoring



Service-oriented architecture (Message Abstraction Layer)










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Hadamard_code&oldid=783123479"					
Categories: Coding theoryError detection and correction 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


CatalàDeutsch日本語 
Edit links 





 This page was last edited on 31 May 2017, at 08:02.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 









Hadamard code - Wikipedia






















 






Hadamard code

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search



Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k


{\displaystyle k}




Rate




k

/


2

k




{\displaystyle k/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code





v
t
e







Punctured Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k
+
1


{\displaystyle k+1}




Rate




(
k
+
1
)

/


2

k




{\displaystyle (k+1)/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code





v
t
e









Matrix of the Punctured Hadamard code [32, 6, 16] for the Reed–Muller code (1, 5) of the NASA space probe Mariner 9






XOR operations
Here the white fields stand for 0
and the red fields for 1


The Hadamard code is an error-correcting code that is used for error detection and correction when transmitting messages over very noisy or unreliable channels. In 1971, the code was used to transmit photos of Mars back to Earth from the NASA space probe Mariner 9.[1] Because of its unique mathematical properties, the Hadamard code is not only used by engineers, but also intensely studied in coding theory, mathematics, and theoretical computer science. The Hadamard code is named after the French mathematician Jacques Hadamard. It is also known under the names Walsh code, Walsh family,[2] and Walsh–Hadamard code[3] in recognition of the American mathematician Joseph Leonard Walsh.
The Hadamard code is an example of a linear code over a binary alphabet that maps messages of length 



k


{\displaystyle k}

 to codewords of length 




2

k




{\displaystyle 2^{k}}

. It is unique in that each non-zero codeword has a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

, which implies that the distance of the code is also 




2

k
−
1




{\displaystyle 2^{k-1}}

. In standard coding theory notation for block codes, the Hadamard code is a 



[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code, that is, it is a linear code over a binary alphabet, has block length 




2

k




{\displaystyle 2^{k}}

, message length (or dimension) 



k


{\displaystyle k}

, and minimum distance 




2

k



/

2


{\displaystyle 2^{k}/2}

. The block length is very large compared to the message length, but on the other hand, errors can be corrected even in extremely noisy conditions. The punctured Hadamard code is a slightly improved version of the Hadamard code; it is a 



[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code and thus has a slightly better rate while maintaining the relative distance of 



1

/

2


{\displaystyle 1/2}

, and is thus preferred in practical applications. The punctured Hadamard code is the same as the first order Reed–Muller code over the binary alphabet.[4]
Normally, Hadamard codes are based on Sylvester's construction of Hadamard matrices, but the term “Hadamard code” is also used to refer to codes constructed from arbitrary Hadamard matrices, which are not necessarily of Sylvester type. In general, such a code is not linear. Such codes were first constructed by R. C. Bose and S. S. Shrikhande in 1959.[5] If n is the size of the Hadamard matrix, the code has parameters 



(
n
,
2
n
,
n

/

2

)

2




{\displaystyle (n,2n,n/2)_{2}}

, meaning it is a not-necessarily-linear binary code with 2n codewords of block length n and minimal distance n/2. The construction and decoding scheme described below apply for general n, but the property of linearity and the identification with Reed–Muller codes require that n be a power of 2 and that the Hadamard matrix be equivalent to the matrix constructed by Sylvester's method.
The Hadamard code is a locally decodable code, which provides a way to recover parts of the original message with high probability, while only looking at a small fraction of the received word. This gives rise to applications in computational complexity theory and particularly in the design of probabilistically checkable proofs. Since the relative distance of the Hadamard code is 1/2, normally one can only hope to recover from at most a 1/4 fraction of error. Using list decoding, however, it is possible to compute a short list of possible candidate messages as long as fewer than 





1
2


−
ϵ


{\displaystyle {\frac {1}{2}}-\epsilon }

 of the bits in the received word have been corrupted.
In code division multiple access (CDMA) communication, the Hadamard code is referred to as Walsh Code, and is used to define individual communication channels. It is usual in the CDMA literature to refer to codewords as “codes”. Each user will use a different codeword, or “code”, to modulate their signal. Because Walsh codewords are mathematically orthogonal, a Walsh-encoded signal appears as random noise to a CDMA capable mobile terminal, unless that terminal uses the same codeword as the one used to encode the incoming signal.[6]



Contents


1 History
2 Constructions

2.1 Construction using inner products
2.2 Construction using a generator matrix
2.3 Construction using general Hadamard matrices


3 Distance
4 Local decodability

4.1 Proof of lemma 1
4.2 Proof of theorem 1

4.2.1 Algorithm
4.2.2 Proof of correctness




5 Optimality
6 See also
7 Notes
8 References



History[edit]
Hadamard code is the name that is most commonly used for this code in the literature. However, in modern use these error correcting codes are referred to as Walsh–Hadamard codes.
There is a reason for this:
Jacques Hadamard did not invent the code himself, but he defined Hadamard matrices around 1893, long before the first error-correcting code, the Hamming code, was developed in the 1940s.
The Hadamard code is based on Hadamard matrices, and while there are many different Hadamard matrices that could be used here, normally only Sylvester's construction of Hadamard matrices is used to obtain the codewords of the Hadamard code.
James Joseph Sylvester developed his construction of Hadamard matrices in 1867, which actually predates Hadamard's work on Hadamard matrices. Hence the name Hadamard code is not undisputed and sometimes the code is called Walsh code, honoring the American mathematician Joseph Leonard Walsh.
A Hadamard code was used during the 1971 Mariner 9 mission to correct for picture transmission errors. The data words used during this mission were 6 bits long, which represented 64 grayscale values.
Because of limitations of the quality of the alignment of the transmitter at the time (due to Doppler Tracking Loop issues) the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used.
Errors of up to 7 bits per word could be corrected using this scheme. Compared to a 5-repetition code, the error correcting properties of this Hadamard code are much better, yet its rate is comparable. The efficient decoding algorithm was an important factor in the decision to use this code.
The circuitry used was called the "Green Machine". It employed the fast Fourier transform which can increase the decoding speed by a factor of three. Since the 1990s use of this code by space programs has more or less ceased, and the Deep Space Network does not support this error correction scheme for its dishes that are greater than 26 m.
Constructions[edit]
While all Hadamard codes are based on Hadamard matrices, the constructions differ in subtle ways for different scientific fields, authors, and uses. Engineers, who use the codes for data transmission, and coding theorists, who analyse extremal properties of codes, typically want the rate of the code to be as high as possible, even if this means that the construction becomes mathematically slightly less elegant.
On the other hand, for many applications of Hadamard codes in theoretical computer science it is not so important to achieve the optimal rate, and hence simpler constructions of Hadamard codes are preferred since they can be analyzed more elegantly.
Construction using inner products[edit]
When given a binary message 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 of length 



k


{\displaystyle k}

, the Hadamard code encodes the message into a codeword 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 using an encoding function 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

. This function makes use of the inner product 



⟨
x
,
y
⟩


{\displaystyle \langle x,y\rangle }

 of two vectors 



x
,
y
∈
{
0
,
1

}

k




{\displaystyle x,y\in \{0,1\}^{k}}

, which is defined as follows:





⟨
x
,
y
⟩
=

∑

i
=
1


k



x

i



y

i


 

mod

 


2

.


{\displaystyle \langle x,y\rangle =\sum _{i=1}^{k}x_{i}y_{i}\ {\bmod {\ }}2\,.}



Then the Hadamard encoding of 



x


{\displaystyle x}

 is defined as the sequence of all inner products with 



x


{\displaystyle x}

:






Had

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
0
,
1

}

k






{\displaystyle {\text{Had}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{0,1\}^{k}}}



As mentioned above, the punctured Hadamard code is used in practice since the Hadamard code itself is somewhat wasteful. This is because, if the first bit of 



y


{\displaystyle y}

 is zero, 




y

1


=
0


{\displaystyle y_{1}=0}

, then the inner product contains no information whatsoever about 




x

1




{\displaystyle x_{1}}

, and hence, it is impossible to fully decode 



x


{\displaystyle x}

 from those positions of the codeword alone. On the other hand, when the codeword is restricted to the positions where 




y

1


=
1


{\displaystyle y_{1}=1}

, it is still possible to fully decode 



x


{\displaystyle x}

. Hence it makes sense to restrict the Hadamard code to these positions, which gives rise to the punctured Hadamard encoding of 



x


{\displaystyle x}

; that is, 




pHad

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
1
}
×
{
0
,
1

}

k
−
1






{\displaystyle {\text{pHad}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{1\}\times \{0,1\}^{k-1}}}

.
Construction using a generator matrix[edit]
The Hadamard code is a linear code, and all linear codes can be generated by a generator matrix 



G


{\displaystyle G}

. This is a matrix such that 




Had

(
x
)
=
x
⋅
G


{\displaystyle {\text{Had}}(x)=x\cdot G}

 holds for all 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

, where the message 



x


{\displaystyle x}

 is viewed as a row vector and the vector-matrix product is understood in the vector space over the finite field 





F


2




{\displaystyle \mathbb {F} _{2}}

. In particular, an equivalent way to write the inner product definition for the Hadamard code arises by using the generator matrix whose columns consist of all strings 



y


{\displaystyle y}

 of length 



k


{\displaystyle k}

, that is,





G
=


(



↑


↑



↑





y

1





y

2




…



y


2

k








↓


↓



↓



)



.


{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\y_{1}&y_{2}&\dots &y_{2^{k}}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}\,.}



where 




y

i


∈
{
0
,
1

}

k




{\displaystyle y_{i}\in \{0,1\}^{k}}

 is the 



i


{\displaystyle i}

-th binary vector in lexicographical order. For example, the generator matrix for the Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:





G
=


[



0


0


0


0


1


1


1


1




0


0


1


1


0


0


1


1




0


1


0


1


0


1


0


1



]


.


{\displaystyle G={\begin{bmatrix}0&0&0&0&1&1&1&1\\0&0&1&1&0&0&1&1\\0&1&0&1&0&1&0&1\end{bmatrix}}.}



The matrix 



G


{\displaystyle G}

 is a 



(
k
×

2

k


)


{\displaystyle (k\times 2^{k})}

-matrix and gives rise to the linear operator 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

.
The generator matrix of the punctured Hadamard code is obtained by restricting the matrix 



G


{\displaystyle G}

 to the columns whose first entry is one. For example, the generator matrix for the punctured Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:






G
′

=


[



1


1


1


1




0


0


1


1




0


1


0


1



]


.


{\displaystyle G'={\begin{bmatrix}1&1&1&1\\0&0&1&1\\0&1&0&1\end{bmatrix}}.}



Then 




pHad

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k
−
1






{\displaystyle {\text{pHad}}:\{0,1\}^{k}\to \{0,1\}^{2^{k-1}}}

 is a linear mapping with 




pHad

(
x
)
=
x
⋅

G
′



{\displaystyle {\text{pHad}}(x)=x\cdot G'}

.
For general 



k


{\displaystyle k}

, the generator matrix of the punctured Hadamard code is a parity-check matrix for the extended Hamming code of length 




2

k
−
1




{\displaystyle 2^{k-1}}

 and dimension 




2

k
−
1


−
k


{\displaystyle 2^{k-1}-k}

, which makes the punctured Hadamard code the dual code of the extended Hamming code. Hence an alternative way to define the Hadamard code is in terms of its parity-check matrix: the parity-check matrix of the Hadamard code is equal to the generator matrix of the Hamming code.
Construction using general Hadamard matrices[edit]
Generalized Hadamard codes are obtained from an n-by-n Hadamard matrix H. In particular, the 2n codewords of the code are the rows of H and the rows of −H. To obtain a code over the alphabet {0,1}, the mapping −1 ↦ 1, 1 ↦ 0, or, equivalently, x ↦ (1 − x)/2, is applied to the matrix elements. That the minimum distance of the code is n/2 follows from the defining property of Hadamard matrices, namely that their rows are mutually orthogonal. This implies that two distinct rows of a Hadamard matrix differ in exactly n/2 positions, and, since negation of a row does not affect orthogonality, that any row of H differs from any row of −H in n/2 positions as well, except when the rows correspond, in which case they differ in n positions.
To get the punctured Hadamard code above with 



n
=

2

k
−
1




{\displaystyle n=2^{k-1}}

, the chosen Hadamard matrix H has to be of Sylvester type, which gives rise to a message length of 




log

2


⁡
(
2
n
)
=
k


{\displaystyle \log _{2}(2n)=k}

.
Distance[edit]
The distance of a code is the minimum Hamming distance between any two distinct codewords, i.e., the minimum number of positions at which two distinct codewords differ. Since the Walsh–Hadamard code is a linear code, the distance is equal to the minimum Hamming weight among all of its non-zero codewords. All non-zero codewords of the Walsh–Hadamard code have a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

 by the following argument.
Let 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 be a non-zero message. Then the following value is exactly equal to the fraction of positions in the codeword that are equal to one:






Pr

y
∈
{
0
,
1

}

k






[


(

Had

(
x
)

)

y


=
1


]


=

Pr

y
∈
{
0
,
1

}

k






[


⟨
x
,
y
⟩
=
1


]



.


{\displaystyle \Pr _{y\in \{0,1\}^{k}}{\big [}({\text{Had}}(x))_{y}=1{\big ]}=\Pr _{y\in \{0,1\}^{k}}{\big [}\langle x,y\rangle =1{\big ]}\,.}



The fact that the latter value is exactly 



1

/

2


{\displaystyle 1/2}

 is called the random subsum principle. To see that it is true, assume without loss of generality that 




x

1


=
1


{\displaystyle x_{1}=1}

. Then, when conditioned on the values of 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

, the event is equivalent to 




y

1


⋅

x

1


=
b


{\displaystyle y_{1}\cdot x_{1}=b}

 for some 



b
∈
{
0
,
1
}


{\displaystyle b\in \{0,1\}}

 depending on 




x

2


,
…
,

x

k




{\displaystyle x_{2},\dots ,x_{k}}

 and 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

. The probability that 




y

1


=
b


{\displaystyle y_{1}=b}

 happens is exactly 



1

/

2


{\displaystyle 1/2}

. Thus, in fact, all non-zero codewords of the Hadamard code have relative Hamming weight 



1

/

2


{\displaystyle 1/2}

, and thus, its relative distance is 



1

/

2


{\displaystyle 1/2}

.
The relative distance of the punctured Hadamard code is 



1

/

2


{\displaystyle 1/2}

 as well, but it no longer has the property that every non-zero codeword has weight exactly 



1

/

2


{\displaystyle 1/2}

 since the all 



1


{\displaystyle 1}

s vector 




1


2

k
−
1






{\displaystyle 1^{2^{k-1}}}

 is a codeword of the punctured Hadamard code. This is because the vector 



x
=

10

k
−
1




{\displaystyle x=10^{k-1}}

 encodes to 




pHad

(

10

k
−
1


)
=

1


2

k
−
1






{\displaystyle {\text{pHad}}(10^{k-1})=1^{2^{k-1}}}

. Furthermore, whenever 



x


{\displaystyle x}

 is non-zero and not the vector 




10

k
−
1




{\displaystyle 10^{k-1}}

, the random subsum principle applies again, and the relative weight of 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 is exactly 



1

/

2


{\displaystyle 1/2}

.
Local decodability[edit]
A locally decodable code is a code that allows a single bit of the original message to be recovered with high probability by only looking at a small portion of the received word.
A code is 



q


{\displaystyle q}

-query locally decodable if a message bit, 




x

i




{\displaystyle x_{i}}

, can be recovered by checking 



q


{\displaystyle q}

 bits of the received word. More formally, a code, 



C
:
{
0
,
1

}

k


→
{
0
,
1

}

n




{\displaystyle C:\{0,1\}^{k}\rightarrow \{0,1\}^{n}}

, is 



(
q
,
δ
≥
0
,
ϵ
≥
0
)


{\displaystyle (q,\delta \geq 0,\epsilon \geq 0)}

-locally decodable, if there exists a probabilistic decoder, 



D
:
{
0
,
1

}

n


→
{
0
,
1

}

k




{\displaystyle D:\{0,1\}^{n}\rightarrow \{0,1\}^{k}}

, such that (Note: 



Δ
(
x
,
y
)


{\displaystyle \Delta (x,y)}

 represents the Hamming distance between vectors 



x


{\displaystyle x}

 and 



y


{\displaystyle y}

):




∀
x
∈
{
0
,
1

}

k


,
∀
y
∈
{
0
,
1

}

n




{\displaystyle \forall x\in \{0,1\}^{k},\forall y\in \{0,1\}^{n}}

, 



Δ
(
y
,
C
(
x
)
)
≤
δ
n


{\displaystyle \Delta (y,C(x))\leq \delta n}

 implies that 



P
r
[
D
(
y

)

i


=

x

i


]
≥


1
2


+
ϵ
,
∀
i
∈
[
k
]


{\displaystyle Pr[D(y)_{i}=x_{i}]\geq {\frac {1}{2}}+\epsilon ,\forall i\in [k]}


Theorem 1: The Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

-locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Lemma 1: For all codewords, 



c


{\displaystyle c}

 in a Walsh–Hadamard code, 



C


{\displaystyle C}

, 




c

i


+

c

j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=c_{i+j}}

, where 




c

i


,

c

j




{\displaystyle c_{i},c_{j}}

 represent the bits in 



c


{\displaystyle c}

 in positions 



i


{\displaystyle i}

 and 



j


{\displaystyle j}

 respectively, and 




c

i
+
j




{\displaystyle c_{i+j}}

 represents the bit at position 



(
i
+
j
)


{\displaystyle (i+j)}

.
Proof of lemma 1[edit]

Let 



C
(
x
)
=
c
=
(

c

0


,
…
,

c


2

n


−
1


)


{\displaystyle C(x)=c=(c_{0},\dots ,c_{2^{n}-1})}

 be the codeword in 



C


{\displaystyle C}

 corresponding to message 



x


{\displaystyle x}

.
Let 



G
=


(



↑


↑



↑





g

0





g

1




…



g


2

n


−
1






↓


↓



↓



)




{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\g_{0}&g_{1}&\dots &g_{2^{n}-1}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}}

 be the generator matrix of 



C


{\displaystyle C}

.
By definition, 




c

i


=
x
⋅

g

i




{\displaystyle c_{i}=x\cdot g_{i}}

. From this, 




c

i


+

c

j


=
x
⋅

g

i


+
x
⋅

g

j


=
x
⋅
(

g

i


+

g

j


)


{\displaystyle c_{i}+c_{j}=x\cdot g_{i}+x\cdot g_{j}=x\cdot (g_{i}+g_{j})}

. By the construction of 



G


{\displaystyle G}

, 




g

i


+

g

j


=

g

i
+
j




{\displaystyle g_{i}+g_{j}=g_{i+j}}

. Therefore, by substitution, 




c

i


+

c

j


=
x
⋅

g

i
+
j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=x\cdot g_{i+j}=c_{i+j}}

.
Proof of theorem 1[edit]

To prove theorem 1 we will construct a decoding algorithm and prove its correctness.
Algorithm[edit]
Input: Received word 



y
=
(

y

0


,
…
,

y


2

n


−
1


)


{\displaystyle y=(y_{0},\dots ,y_{2^{n}-1})}


For each 



i
∈
{
1
,
…
,
n
}


{\displaystyle i\in \{1,\dots ,n\}}

:

Pick 



j
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle j\in \{0,\dots ,2^{n}-1\}}

 uniformly at random
Pick 



k
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle k\in \{0,\dots ,2^{n}-1\}}

 such that 



j
+
k
=

e

i




{\displaystyle j+k=e_{i}}

 where 



j
+
k


{\displaystyle j+k}

 is the bitwise xor of 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

.





x

i


←

y

j


+

y

k




{\displaystyle x_{i}\gets y_{j}+y_{k}}



Output: Message 



x
=
(

x

1


,
…
,

x

n


)


{\displaystyle x=(x_{1},\dots ,x_{n})}


Proof of correctness[edit]
For any message, 



x


{\displaystyle x}

, and received word 



y


{\displaystyle y}

 such that 



y


{\displaystyle y}

 differs from 



c
=
C
(
x
)


{\displaystyle c=C(x)}

 on at most 



δ


{\displaystyle \delta }

 fraction of bits, 




x

i




{\displaystyle x_{i}}

 can be decoded with probability at least 





1
2


+
(


1
2


−
2
δ
)


{\displaystyle {\frac {1}{2}}+({\frac {1}{2}}-2\delta )}

.
By lemma 1, 




c

j


+

c

k


=

c

j
+
k


=
x
⋅

g

j
+
k


=
x
⋅

e

i


=

x

i




{\displaystyle c_{j}+c_{k}=c_{j+k}=x\cdot g_{j+k}=x\cdot e_{i}=x_{i}}

. Since 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

 are picked uniformly, the probability that 




y

j


≠

c

j




{\displaystyle y_{j}\not =c_{j}}

 is at most 



δ


{\displaystyle \delta }

. Similarly, the probability that 




y

k


≠

c

k




{\displaystyle y_{k}\not =c_{k}}

 is at most 



δ


{\displaystyle \delta }

. By the union bound, the probability that either 




y

j




{\displaystyle y_{j}}

 or 




y

k




{\displaystyle y_{k}}

 do not match the corresponding bits in 



c


{\displaystyle c}

 is at most 



2
δ


{\displaystyle 2\delta }

. If both 




y

j




{\displaystyle y_{j}}

 and 




y

k




{\displaystyle y_{k}}

 correspond to 



c


{\displaystyle c}

, then lemma 1 will apply, and therefore, the proper value of 




x

i




{\displaystyle x_{i}}

 will be computed. Therefore, the probability 




x

i




{\displaystyle x_{i}}

 is decoded properly is at least 



1
−
2
δ


{\displaystyle 1-2\delta }

. Therefore, 



ϵ
=


1
2


−
2
δ


{\displaystyle \epsilon ={\frac {1}{2}}-2\delta }

 and for 



ϵ


{\displaystyle \epsilon }

 to be positive, 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Therefore, the Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

 locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}


Optimality[edit]
For k ≤ 7 the linear Hadamard codes have been proven optimal in the sense of minimum distance.[7]
See also[edit]

Zadoff–Chu sequence — improve over the Walsh–Hadamard codes

Notes[edit]



^ http://www.mcs.csueastbay.edu/~malek/TeX/Hadamard.pdf
^ See, e.g., Amadei, Manzoli & Merani (2002)
^ See, e.g., Arora & Barak (2009, Section 19.2.2).
^ See, e.g., Guruswami (2009, p. 3).
^ Bose, R.C.; Shrikhande, S.S. (1959). "A note on a result in the theory of code construction". Information and Control. 2 (2): 183–194. CiteSeerX 10.1.1.154.2879 . doi:10.1016/S0019-9958(59)90376-6. 
^ "CDMA Tutorial: Intuitive Guide to Principles of Communications" (PDF). Complex to Real. Retrieved 4 August 2011. 
^ Jaffe, David B.; Bouyukliev, Iliya, Optimal binary linear codes of dimension at most seven 



References[edit]

Amadei, M.; Manzoli, U.; Merani, M.L. (2002), "On the assignment of Walsh and quasi-orthogonal codes in a multicarrier DS-CDMA system with multiple classes of users", Global Telecommunications Conference, 2002. GLOBECOM'02. IEEE, 1, IEEE, pp. 841–5, ISBN 0-7803-7632-3, doi:10.1109/GLOCOM.2002.1188196 
Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4 
Guruswami, Venkatesan (2009), List decoding of binary codes (PDF) 
Rudra, Atri, "Hamming code and Hamming bound" (PDF), Lecture notes 







v
t
e


Consultative Committee for Space Data Systems



Data compression



Images

ICER
JPEG
JPEG 2000
122.0.B1


Data

Adaptive Entropy Coder







Error Correction



Current
Binary Golay code
Concatenated codes
Turbo codes
Proposed
LDPC codes





Telemetry command uplink



Command Loss Timer Reset
Proximity-1 Space Link Protocol





Telemetry downlink



Spacecraft Monitoring & Control
Beacon mode service





Telemetry general



Space Communications Protocol Specifications (SCPS): Performance Enhancing Proxy





Telemetry modulation systems



Current
BPSK
QPSK
OQPSK
Proposed
GMSK





Frequencies



X band
S band
Ku band
K band
Ka band





Networking, interoperability and monitoring



Service-oriented architecture (Message Abstraction Layer)










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Hadamard_code&oldid=783123479"					
Categories: Coding theoryError detection and correction 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


CatalàDeutsch日本語 
Edit links 





 This page was last edited on 31 May 2017, at 08:02.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 







Security Check Required





FacebookJoin or Log Into Facebook   Email or PhonePasswordForgot account?Log InDo you want to join Facebook?Sign UpSign UpSecurity CheckPlease enter the text belowCan't read the text above?Try another text or an audio captchaText in the box:What's this?Security CheckThis is a standard security test that we use to prevent spammers from creating fake accounts and spamming users.SubmitEnglish (US)EspañolFrançais (France)中文(简体)العربيةPortuguês (Brasil)Italiano한국어Deutschहिन्दी日本語MessengerFacebook LitePeoplePlacesGamesLocationsCelebritiesMarketplaceGroupsRecipesMomentsInstagramAboutCreate AdCreate PageDevelopersCareersPrivacyCookiesAd ChoicesTermsSettingsActivity Log Facebook © 2017


   Horse Halters for Sale | Walsh Products                                                                           Dealer Locator | News & Events |  Contact Us                   Cart is Empty                          Menu  Racing  Race Harness  USA Style Harness  International Style Harness    Bridles, Race Halters & Accessories  USA Bridles  International Bridles  Race Halters  Accessories    Harness Race Accessories  Buxtons & Breast Collars  Harness Pads  Girths & Backstraps  Lines & Handholds  Martingales & Tie Downs  Race Accessories    Hopples  Leg Protection  Front Tendon Boots  Hind Boots  Knee & Ankle Boots  Miscellaneous Leg Protection    Monté Race Equipment  Thoroughbred Race Equipment  Halters & Leads  Accessories  For the Driver  Private Label Products    Equestrian  Halters  Leads  Accessories  Training Equipment  Headstalls, Nosebands & Accessories  Martingales & Training Products  Lunging Equipment  Rider Accessories    Beris Bits  Leather & Foam Bits  Eggbutt Bits  Comfort Bar Bits  Port Bits  Butterfly Bits    Leg Protection  Front Tendon Boots  Hind Boots  Bell Boots, Quarter Boots & Miscellaneous Protection    Zandona Boots  Girths  For the Rider  Apparel  Riding Crops & Accessories    Private Label Products    Saddle Seat  Show Harness  Girths  Training Equipment  Training Products - Leg Action  Training Products - Rider Aids    Leg Protection  Tailsets & Accessories  For the Rider    Canine & Specialty  Canine Products  Specialty Products  Private Label Products    Apparel & Accessories  About Walsh  History  Sponsored Riders  Hawley Bennett  Scott Brash  Laura Kraut  Nick Skelton  Kent Farrington  Daniel Deusser  Lynn Symansky  Richie Moloney  Marilyn Little  Cian O'Connor  Lorenzo de Luca  Tiffany Foster  Taizo Sugitani  Darragh Kenny  Sergio Alvarez Moya  Dirk Demeersman  Mavis Spencer  Hannah Salazar    Sponsored Drivers  Tim Tetrick  Scott Zeron  Jody Jamieson  Johan Untersteiner  Ronnie Wrenn, Jr  Doug McNair  Tyler Smith  Marcus Melander  Marcus Miller  Trace Tetrick  Paula Pettersson    Affiliations  Contract Sewing/Private Label Products                      Halters  Walsh Products supplies the finest horse halters made from the highest quality leather available, selected for optimum weight, grain and firmness.        Home Equestrian Halters            Elegance & Luxury We start with the highest quality leather available, selected for optimum weight, grain and firmness. Using the finest materials is an excellent start but the ultimate quality of any Walsh leather product is also on craftsmanship. We don't take shortcuts in our manufacturing process of the finest horse halters in the world. Our goal is always to produce the best product on the market. Walsh makes the number one selling equestrian halters and are widely recognized. We want you to walk through the paddock and to the show pen with the best product in hand. We admire the care you dedicate to your horse therefore we honor you by taking the extra time and care when we manufacture our products. The finest English Bridle Leather and solid brass or stainless steel hardware are critical in achieving the level of luxury that you expect. View our full line of elegant and luxury horse halters for sale below.   Products   12    Sort By Product ↑Product ↓Price ↑Price ↓Default ↑Default ↓Sales ↑Sales ↓  Per Page 4 8 12 16 20 24 28 32 36 40 View All             Track Halter - 8700          <p>     $99.99 (€112.99)                                     Leather Grooming Halter - 4000          <p>     $62.99 (€71.18)                                     Grow With Me Foal Halter 7701          <p>     $48.99 (€55.36)                                     Equestrian Nylon Halter - 5600          <p>     $39.99 (€45.19)                                     Breakaway 1" Halter with Straight Chin - 65600          <p>     $49.99 (€56.49)                                     Breakaway 1" Halter with Adjustable Chin - 65700          <.>     $52.99 (€59.88)                                     Breakaway 3/4" Halter with Straight Chin - 63600          <p>     $37.99 (€42.93)                                     12    Sort By Product ↑Product ↓Price ↑Price ↓Default ↑Default ↓Sales ↑Sales ↓  Per Page 4 8 12 16 20 24 28 32 36 40 View All              Equestrian     Halters    Leads    Accessories     Training Equipment  Headstalls, Nosebands & Accessories  Martingales & Training Products  Lunging Equipment  Rider Accessories       Beris Bits  Leather & Foam Bits  Eggbutt Bits  Comfort Bar Bits  Port Bits  Butterfly Bits       Leg Protection  Front Tendon Boots  Hind Boots  Bell Boots, Quarter Boots & Miscellaneous Protection      Zandona Boots    Girths     For the Rider  Apparel  Riding Crops & Accessories      Private Label Products        Testimonials loading...               Contact Us   Contact Us & Map    800-558-5515   262-797-9888   262-797-9910     Customer Service Become a Dealer     Privacy Policy Terms of Use        Copyright © 2014-2017 Walsh Products, Inc.                                         


Hadamard code - Wikipedia






















 






Hadamard code

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search



Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k


{\displaystyle k}




Rate




k

/


2

k




{\displaystyle k/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code





v
t
e







Punctured Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k
+
1


{\displaystyle k+1}




Rate




(
k
+
1
)

/


2

k




{\displaystyle (k+1)/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code





v
t
e









Matrix of the Punctured Hadamard code [32, 6, 16] for the Reed–Muller code (1, 5) of the NASA space probe Mariner 9






XOR operations
Here the white fields stand for 0
and the red fields for 1


The Hadamard code is an error-correcting code that is used for error detection and correction when transmitting messages over very noisy or unreliable channels. In 1971, the code was used to transmit photos of Mars back to Earth from the NASA space probe Mariner 9.[1] Because of its unique mathematical properties, the Hadamard code is not only used by engineers, but also intensely studied in coding theory, mathematics, and theoretical computer science. The Hadamard code is named after the French mathematician Jacques Hadamard. It is also known under the names Walsh code, Walsh family,[2] and Walsh–Hadamard code[3] in recognition of the American mathematician Joseph Leonard Walsh.
The Hadamard code is an example of a linear code over a binary alphabet that maps messages of length 



k


{\displaystyle k}

 to codewords of length 




2

k




{\displaystyle 2^{k}}

. It is unique in that each non-zero codeword has a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

, which implies that the distance of the code is also 




2

k
−
1




{\displaystyle 2^{k-1}}

. In standard coding theory notation for block codes, the Hadamard code is a 



[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code, that is, it is a linear code over a binary alphabet, has block length 




2

k




{\displaystyle 2^{k}}

, message length (or dimension) 



k


{\displaystyle k}

, and minimum distance 




2

k



/

2


{\displaystyle 2^{k}/2}

. The block length is very large compared to the message length, but on the other hand, errors can be corrected even in extremely noisy conditions. The punctured Hadamard code is a slightly improved version of the Hadamard code; it is a 



[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code and thus has a slightly better rate while maintaining the relative distance of 



1

/

2


{\displaystyle 1/2}

, and is thus preferred in practical applications. The punctured Hadamard code is the same as the first order Reed–Muller code over the binary alphabet.[4]
Normally, Hadamard codes are based on Sylvester's construction of Hadamard matrices, but the term “Hadamard code” is also used to refer to codes constructed from arbitrary Hadamard matrices, which are not necessarily of Sylvester type. In general, such a code is not linear. Such codes were first constructed by R. C. Bose and S. S. Shrikhande in 1959.[5] If n is the size of the Hadamard matrix, the code has parameters 



(
n
,
2
n
,
n

/

2

)

2




{\displaystyle (n,2n,n/2)_{2}}

, meaning it is a not-necessarily-linear binary code with 2n codewords of block length n and minimal distance n/2. The construction and decoding scheme described below apply for general n, but the property of linearity and the identification with Reed–Muller codes require that n be a power of 2 and that the Hadamard matrix be equivalent to the matrix constructed by Sylvester's method.
The Hadamard code is a locally decodable code, which provides a way to recover parts of the original message with high probability, while only looking at a small fraction of the received word. This gives rise to applications in computational complexity theory and particularly in the design of probabilistically checkable proofs. Since the relative distance of the Hadamard code is 1/2, normally one can only hope to recover from at most a 1/4 fraction of error. Using list decoding, however, it is possible to compute a short list of possible candidate messages as long as fewer than 





1
2


−
ϵ


{\displaystyle {\frac {1}{2}}-\epsilon }

 of the bits in the received word have been corrupted.
In code division multiple access (CDMA) communication, the Hadamard code is referred to as Walsh Code, and is used to define individual communication channels. It is usual in the CDMA literature to refer to codewords as “codes”. Each user will use a different codeword, or “code”, to modulate their signal. Because Walsh codewords are mathematically orthogonal, a Walsh-encoded signal appears as random noise to a CDMA capable mobile terminal, unless that terminal uses the same codeword as the one used to encode the incoming signal.[6]



Contents


1 History
2 Constructions

2.1 Construction using inner products
2.2 Construction using a generator matrix
2.3 Construction using general Hadamard matrices


3 Distance
4 Local decodability

4.1 Proof of lemma 1
4.2 Proof of theorem 1

4.2.1 Algorithm
4.2.2 Proof of correctness




5 Optimality
6 See also
7 Notes
8 References



History[edit]
Hadamard code is the name that is most commonly used for this code in the literature. However, in modern use these error correcting codes are referred to as Walsh–Hadamard codes.
There is a reason for this:
Jacques Hadamard did not invent the code himself, but he defined Hadamard matrices around 1893, long before the first error-correcting code, the Hamming code, was developed in the 1940s.
The Hadamard code is based on Hadamard matrices, and while there are many different Hadamard matrices that could be used here, normally only Sylvester's construction of Hadamard matrices is used to obtain the codewords of the Hadamard code.
James Joseph Sylvester developed his construction of Hadamard matrices in 1867, which actually predates Hadamard's work on Hadamard matrices. Hence the name Hadamard code is not undisputed and sometimes the code is called Walsh code, honoring the American mathematician Joseph Leonard Walsh.
A Hadamard code was used during the 1971 Mariner 9 mission to correct for picture transmission errors. The data words used during this mission were 6 bits long, which represented 64 grayscale values.
Because of limitations of the quality of the alignment of the transmitter at the time (due to Doppler Tracking Loop issues) the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used.
Errors of up to 7 bits per word could be corrected using this scheme. Compared to a 5-repetition code, the error correcting properties of this Hadamard code are much better, yet its rate is comparable. The efficient decoding algorithm was an important factor in the decision to use this code.
The circuitry used was called the "Green Machine". It employed the fast Fourier transform which can increase the decoding speed by a factor of three. Since the 1990s use of this code by space programs has more or less ceased, and the Deep Space Network does not support this error correction scheme for its dishes that are greater than 26 m.
Constructions[edit]
While all Hadamard codes are based on Hadamard matrices, the constructions differ in subtle ways for different scientific fields, authors, and uses. Engineers, who use the codes for data transmission, and coding theorists, who analyse extremal properties of codes, typically want the rate of the code to be as high as possible, even if this means that the construction becomes mathematically slightly less elegant.
On the other hand, for many applications of Hadamard codes in theoretical computer science it is not so important to achieve the optimal rate, and hence simpler constructions of Hadamard codes are preferred since they can be analyzed more elegantly.
Construction using inner products[edit]
When given a binary message 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 of length 



k


{\displaystyle k}

, the Hadamard code encodes the message into a codeword 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 using an encoding function 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

. This function makes use of the inner product 



⟨
x
,
y
⟩


{\displaystyle \langle x,y\rangle }

 of two vectors 



x
,
y
∈
{
0
,
1

}

k




{\displaystyle x,y\in \{0,1\}^{k}}

, which is defined as follows:





⟨
x
,
y
⟩
=

∑

i
=
1


k



x

i



y

i


 

mod

 


2

.


{\displaystyle \langle x,y\rangle =\sum _{i=1}^{k}x_{i}y_{i}\ {\bmod {\ }}2\,.}



Then the Hadamard encoding of 



x


{\displaystyle x}

 is defined as the sequence of all inner products with 



x


{\displaystyle x}

:






Had

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
0
,
1

}

k






{\displaystyle {\text{Had}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{0,1\}^{k}}}



As mentioned above, the punctured Hadamard code is used in practice since the Hadamard code itself is somewhat wasteful. This is because, if the first bit of 



y


{\displaystyle y}

 is zero, 




y

1


=
0


{\displaystyle y_{1}=0}

, then the inner product contains no information whatsoever about 




x

1




{\displaystyle x_{1}}

, and hence, it is impossible to fully decode 



x


{\displaystyle x}

 from those positions of the codeword alone. On the other hand, when the codeword is restricted to the positions where 




y

1


=
1


{\displaystyle y_{1}=1}

, it is still possible to fully decode 



x


{\displaystyle x}

. Hence it makes sense to restrict the Hadamard code to these positions, which gives rise to the punctured Hadamard encoding of 



x


{\displaystyle x}

; that is, 




pHad

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
1
}
×
{
0
,
1

}

k
−
1






{\displaystyle {\text{pHad}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{1\}\times \{0,1\}^{k-1}}}

.
Construction using a generator matrix[edit]
The Hadamard code is a linear code, and all linear codes can be generated by a generator matrix 



G


{\displaystyle G}

. This is a matrix such that 




Had

(
x
)
=
x
⋅
G


{\displaystyle {\text{Had}}(x)=x\cdot G}

 holds for all 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

, where the message 



x


{\displaystyle x}

 is viewed as a row vector and the vector-matrix product is understood in the vector space over the finite field 





F


2




{\displaystyle \mathbb {F} _{2}}

. In particular, an equivalent way to write the inner product definition for the Hadamard code arises by using the generator matrix whose columns consist of all strings 



y


{\displaystyle y}

 of length 



k


{\displaystyle k}

, that is,





G
=


(



↑


↑



↑





y

1





y

2




…



y


2

k








↓


↓



↓



)



.


{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\y_{1}&y_{2}&\dots &y_{2^{k}}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}\,.}



where 




y

i


∈
{
0
,
1

}

k




{\displaystyle y_{i}\in \{0,1\}^{k}}

 is the 



i


{\displaystyle i}

-th binary vector in lexicographical order. For example, the generator matrix for the Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:





G
=


[



0


0


0


0


1


1


1


1




0


0


1


1


0


0


1


1




0


1


0


1


0


1


0


1



]


.


{\displaystyle G={\begin{bmatrix}0&0&0&0&1&1&1&1\\0&0&1&1&0&0&1&1\\0&1&0&1&0&1&0&1\end{bmatrix}}.}



The matrix 



G


{\displaystyle G}

 is a 



(
k
×

2

k


)


{\displaystyle (k\times 2^{k})}

-matrix and gives rise to the linear operator 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

.
The generator matrix of the punctured Hadamard code is obtained by restricting the matrix 



G


{\displaystyle G}

 to the columns whose first entry is one. For example, the generator matrix for the punctured Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:






G
′

=


[



1


1


1


1




0


0


1


1




0


1


0


1



]


.


{\displaystyle G'={\begin{bmatrix}1&1&1&1\\0&0&1&1\\0&1&0&1\end{bmatrix}}.}



Then 




pHad

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k
−
1






{\displaystyle {\text{pHad}}:\{0,1\}^{k}\to \{0,1\}^{2^{k-1}}}

 is a linear mapping with 




pHad

(
x
)
=
x
⋅

G
′



{\displaystyle {\text{pHad}}(x)=x\cdot G'}

.
For general 



k


{\displaystyle k}

, the generator matrix of the punctured Hadamard code is a parity-check matrix for the extended Hamming code of length 




2

k
−
1




{\displaystyle 2^{k-1}}

 and dimension 




2

k
−
1


−
k


{\displaystyle 2^{k-1}-k}

, which makes the punctured Hadamard code the dual code of the extended Hamming code. Hence an alternative way to define the Hadamard code is in terms of its parity-check matrix: the parity-check matrix of the Hadamard code is equal to the generator matrix of the Hamming code.
Construction using general Hadamard matrices[edit]
Generalized Hadamard codes are obtained from an n-by-n Hadamard matrix H. In particular, the 2n codewords of the code are the rows of H and the rows of −H. To obtain a code over the alphabet {0,1}, the mapping −1 ↦ 1, 1 ↦ 0, or, equivalently, x ↦ (1 − x)/2, is applied to the matrix elements. That the minimum distance of the code is n/2 follows from the defining property of Hadamard matrices, namely that their rows are mutually orthogonal. This implies that two distinct rows of a Hadamard matrix differ in exactly n/2 positions, and, since negation of a row does not affect orthogonality, that any row of H differs from any row of −H in n/2 positions as well, except when the rows correspond, in which case they differ in n positions.
To get the punctured Hadamard code above with 



n
=

2

k
−
1




{\displaystyle n=2^{k-1}}

, the chosen Hadamard matrix H has to be of Sylvester type, which gives rise to a message length of 




log

2


⁡
(
2
n
)
=
k


{\displaystyle \log _{2}(2n)=k}

.
Distance[edit]
The distance of a code is the minimum Hamming distance between any two distinct codewords, i.e., the minimum number of positions at which two distinct codewords differ. Since the Walsh–Hadamard code is a linear code, the distance is equal to the minimum Hamming weight among all of its non-zero codewords. All non-zero codewords of the Walsh–Hadamard code have a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

 by the following argument.
Let 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 be a non-zero message. Then the following value is exactly equal to the fraction of positions in the codeword that are equal to one:






Pr

y
∈
{
0
,
1

}

k






[


(

Had

(
x
)

)

y


=
1


]


=

Pr

y
∈
{
0
,
1

}

k






[


⟨
x
,
y
⟩
=
1


]



.


{\displaystyle \Pr _{y\in \{0,1\}^{k}}{\big [}({\text{Had}}(x))_{y}=1{\big ]}=\Pr _{y\in \{0,1\}^{k}}{\big [}\langle x,y\rangle =1{\big ]}\,.}



The fact that the latter value is exactly 



1

/

2


{\displaystyle 1/2}

 is called the random subsum principle. To see that it is true, assume without loss of generality that 




x

1


=
1


{\displaystyle x_{1}=1}

. Then, when conditioned on the values of 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

, the event is equivalent to 




y

1


⋅

x

1


=
b


{\displaystyle y_{1}\cdot x_{1}=b}

 for some 



b
∈
{
0
,
1
}


{\displaystyle b\in \{0,1\}}

 depending on 




x

2


,
…
,

x

k




{\displaystyle x_{2},\dots ,x_{k}}

 and 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

. The probability that 




y

1


=
b


{\displaystyle y_{1}=b}

 happens is exactly 



1

/

2


{\displaystyle 1/2}

. Thus, in fact, all non-zero codewords of the Hadamard code have relative Hamming weight 



1

/

2


{\displaystyle 1/2}

, and thus, its relative distance is 



1

/

2


{\displaystyle 1/2}

.
The relative distance of the punctured Hadamard code is 



1

/

2


{\displaystyle 1/2}

 as well, but it no longer has the property that every non-zero codeword has weight exactly 



1

/

2


{\displaystyle 1/2}

 since the all 



1


{\displaystyle 1}

s vector 




1


2

k
−
1






{\displaystyle 1^{2^{k-1}}}

 is a codeword of the punctured Hadamard code. This is because the vector 



x
=

10

k
−
1




{\displaystyle x=10^{k-1}}

 encodes to 




pHad

(

10

k
−
1


)
=

1


2

k
−
1






{\displaystyle {\text{pHad}}(10^{k-1})=1^{2^{k-1}}}

. Furthermore, whenever 



x


{\displaystyle x}

 is non-zero and not the vector 




10

k
−
1




{\displaystyle 10^{k-1}}

, the random subsum principle applies again, and the relative weight of 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 is exactly 



1

/

2


{\displaystyle 1/2}

.
Local decodability[edit]
A locally decodable code is a code that allows a single bit of the original message to be recovered with high probability by only looking at a small portion of the received word.
A code is 



q


{\displaystyle q}

-query locally decodable if a message bit, 




x

i




{\displaystyle x_{i}}

, can be recovered by checking 



q


{\displaystyle q}

 bits of the received word. More formally, a code, 



C
:
{
0
,
1

}

k


→
{
0
,
1

}

n




{\displaystyle C:\{0,1\}^{k}\rightarrow \{0,1\}^{n}}

, is 



(
q
,
δ
≥
0
,
ϵ
≥
0
)


{\displaystyle (q,\delta \geq 0,\epsilon \geq 0)}

-locally decodable, if there exists a probabilistic decoder, 



D
:
{
0
,
1

}

n


→
{
0
,
1

}

k




{\displaystyle D:\{0,1\}^{n}\rightarrow \{0,1\}^{k}}

, such that (Note: 



Δ
(
x
,
y
)


{\displaystyle \Delta (x,y)}

 represents the Hamming distance between vectors 



x


{\displaystyle x}

 and 



y


{\displaystyle y}

):




∀
x
∈
{
0
,
1

}

k


,
∀
y
∈
{
0
,
1

}

n




{\displaystyle \forall x\in \{0,1\}^{k},\forall y\in \{0,1\}^{n}}

, 



Δ
(
y
,
C
(
x
)
)
≤
δ
n


{\displaystyle \Delta (y,C(x))\leq \delta n}

 implies that 



P
r
[
D
(
y

)

i


=

x

i


]
≥


1
2


+
ϵ
,
∀
i
∈
[
k
]


{\displaystyle Pr[D(y)_{i}=x_{i}]\geq {\frac {1}{2}}+\epsilon ,\forall i\in [k]}


Theorem 1: The Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

-locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Lemma 1: For all codewords, 



c


{\displaystyle c}

 in a Walsh–Hadamard code, 



C


{\displaystyle C}

, 




c

i


+

c

j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=c_{i+j}}

, where 




c

i


,

c

j




{\displaystyle c_{i},c_{j}}

 represent the bits in 



c


{\displaystyle c}

 in positions 



i


{\displaystyle i}

 and 



j


{\displaystyle j}

 respectively, and 




c

i
+
j




{\displaystyle c_{i+j}}

 represents the bit at position 



(
i
+
j
)


{\displaystyle (i+j)}

.
Proof of lemma 1[edit]

Let 



C
(
x
)
=
c
=
(

c

0


,
…
,

c


2

n


−
1


)


{\displaystyle C(x)=c=(c_{0},\dots ,c_{2^{n}-1})}

 be the codeword in 



C


{\displaystyle C}

 corresponding to message 



x


{\displaystyle x}

.
Let 



G
=


(



↑


↑



↑





g

0





g

1




…



g


2

n


−
1






↓


↓



↓



)




{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\g_{0}&g_{1}&\dots &g_{2^{n}-1}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}}

 be the generator matrix of 



C


{\displaystyle C}

.
By definition, 




c

i


=
x
⋅

g

i




{\displaystyle c_{i}=x\cdot g_{i}}

. From this, 




c

i


+

c

j


=
x
⋅

g

i


+
x
⋅

g

j


=
x
⋅
(

g

i


+

g

j


)


{\displaystyle c_{i}+c_{j}=x\cdot g_{i}+x\cdot g_{j}=x\cdot (g_{i}+g_{j})}

. By the construction of 



G


{\displaystyle G}

, 




g

i


+

g

j


=

g

i
+
j




{\displaystyle g_{i}+g_{j}=g_{i+j}}

. Therefore, by substitution, 




c

i


+

c

j


=
x
⋅

g

i
+
j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=x\cdot g_{i+j}=c_{i+j}}

.
Proof of theorem 1[edit]

To prove theorem 1 we will construct a decoding algorithm and prove its correctness.
Algorithm[edit]
Input: Received word 



y
=
(

y

0


,
…
,

y


2

n


−
1


)


{\displaystyle y=(y_{0},\dots ,y_{2^{n}-1})}


For each 



i
∈
{
1
,
…
,
n
}


{\displaystyle i\in \{1,\dots ,n\}}

:

Pick 



j
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle j\in \{0,\dots ,2^{n}-1\}}

 uniformly at random
Pick 



k
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle k\in \{0,\dots ,2^{n}-1\}}

 such that 



j
+
k
=

e

i




{\displaystyle j+k=e_{i}}

 where 



j
+
k


{\displaystyle j+k}

 is the bitwise xor of 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

.





x

i


←

y

j


+

y

k




{\displaystyle x_{i}\gets y_{j}+y_{k}}



Output: Message 



x
=
(

x

1


,
…
,

x

n


)


{\displaystyle x=(x_{1},\dots ,x_{n})}


Proof of correctness[edit]
For any message, 



x


{\displaystyle x}

, and received word 



y


{\displaystyle y}

 such that 



y


{\displaystyle y}

 differs from 



c
=
C
(
x
)


{\displaystyle c=C(x)}

 on at most 



δ


{\displaystyle \delta }

 fraction of bits, 




x

i




{\displaystyle x_{i}}

 can be decoded with probability at least 





1
2


+
(


1
2


−
2
δ
)


{\displaystyle {\frac {1}{2}}+({\frac {1}{2}}-2\delta )}

.
By lemma 1, 




c

j


+

c

k


=

c

j
+
k


=
x
⋅

g

j
+
k


=
x
⋅

e

i


=

x

i




{\displaystyle c_{j}+c_{k}=c_{j+k}=x\cdot g_{j+k}=x\cdot e_{i}=x_{i}}

. Since 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

 are picked uniformly, the probability that 




y

j


≠

c

j




{\displaystyle y_{j}\not =c_{j}}

 is at most 



δ


{\displaystyle \delta }

. Similarly, the probability that 




y

k


≠

c

k




{\displaystyle y_{k}\not =c_{k}}

 is at most 



δ


{\displaystyle \delta }

. By the union bound, the probability that either 




y

j




{\displaystyle y_{j}}

 or 




y

k




{\displaystyle y_{k}}

 do not match the corresponding bits in 



c


{\displaystyle c}

 is at most 



2
δ


{\displaystyle 2\delta }

. If both 




y

j




{\displaystyle y_{j}}

 and 




y

k




{\displaystyle y_{k}}

 correspond to 



c


{\displaystyle c}

, then lemma 1 will apply, and therefore, the proper value of 




x

i




{\displaystyle x_{i}}

 will be computed. Therefore, the probability 




x

i




{\displaystyle x_{i}}

 is decoded properly is at least 



1
−
2
δ


{\displaystyle 1-2\delta }

. Therefore, 



ϵ
=


1
2


−
2
δ


{\displaystyle \epsilon ={\frac {1}{2}}-2\delta }

 and for 



ϵ


{\displaystyle \epsilon }

 to be positive, 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Therefore, the Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

 locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}


Optimality[edit]
For k ≤ 7 the linear Hadamard codes have been proven optimal in the sense of minimum distance.[7]
See also[edit]

Zadoff–Chu sequence — improve over the Walsh–Hadamard codes

Notes[edit]



^ http://www.mcs.csueastbay.edu/~malek/TeX/Hadamard.pdf
^ See, e.g., Amadei, Manzoli & Merani (2002)
^ See, e.g., Arora & Barak (2009, Section 19.2.2).
^ See, e.g., Guruswami (2009, p. 3).
^ Bose, R.C.; Shrikhande, S.S. (1959). "A note on a result in the theory of code construction". Information and Control. 2 (2): 183–194. CiteSeerX 10.1.1.154.2879 . doi:10.1016/S0019-9958(59)90376-6. 
^ "CDMA Tutorial: Intuitive Guide to Principles of Communications" (PDF). Complex to Real. Retrieved 4 August 2011. 
^ Jaffe, David B.; Bouyukliev, Iliya, Optimal binary linear codes of dimension at most seven 



References[edit]

Amadei, M.; Manzoli, U.; Merani, M.L. (2002), "On the assignment of Walsh and quasi-orthogonal codes in a multicarrier DS-CDMA system with multiple classes of users", Global Telecommunications Conference, 2002. GLOBECOM'02. IEEE, 1, IEEE, pp. 841–5, ISBN 0-7803-7632-3, doi:10.1109/GLOCOM.2002.1188196 
Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4 
Guruswami, Venkatesan (2009), List decoding of binary codes (PDF) 
Rudra, Atri, "Hamming code and Hamming bound" (PDF), Lecture notes 







v
t
e


Consultative Committee for Space Data Systems



Data compression



Images

ICER
JPEG
JPEG 2000
122.0.B1


Data

Adaptive Entropy Coder







Error Correction



Current
Binary Golay code
Concatenated codes
Turbo codes
Proposed
LDPC codes





Telemetry command uplink



Command Loss Timer Reset
Proximity-1 Space Link Protocol





Telemetry downlink



Spacecraft Monitoring & Control
Beacon mode service





Telemetry general



Space Communications Protocol Specifications (SCPS): Performance Enhancing Proxy





Telemetry modulation systems



Current
BPSK
QPSK
OQPSK
Proposed
GMSK





Frequencies



X band
S band
Ku band
K band
Ka band





Networking, interoperability and monitoring



Service-oriented architecture (Message Abstraction Layer)










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Hadamard_code&oldid=783123479"					
Categories: Coding theoryError detection and correction 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


CatalàDeutsch日本語 
Edit links 





 This page was last edited on 31 May 2017, at 08:02.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 









Hadamard code - Wikipedia






















 






Hadamard code

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search



Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k


{\displaystyle k}




Rate




k

/


2

k




{\displaystyle k/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code





v
t
e







Punctured Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k
+
1


{\displaystyle k+1}




Rate




(
k
+
1
)

/


2

k




{\displaystyle (k+1)/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code





v
t
e









Matrix of the Punctured Hadamard code [32, 6, 16] for the Reed–Muller code (1, 5) of the NASA space probe Mariner 9






XOR operations
Here the white fields stand for 0
and the red fields for 1


The Hadamard code is an error-correcting code that is used for error detection and correction when transmitting messages over very noisy or unreliable channels. In 1971, the code was used to transmit photos of Mars back to Earth from the NASA space probe Mariner 9.[1] Because of its unique mathematical properties, the Hadamard code is not only used by engineers, but also intensely studied in coding theory, mathematics, and theoretical computer science. The Hadamard code is named after the French mathematician Jacques Hadamard. It is also known under the names Walsh code, Walsh family,[2] and Walsh–Hadamard code[3] in recognition of the American mathematician Joseph Leonard Walsh.
The Hadamard code is an example of a linear code over a binary alphabet that maps messages of length 



k


{\displaystyle k}

 to codewords of length 




2

k




{\displaystyle 2^{k}}

. It is unique in that each non-zero codeword has a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

, which implies that the distance of the code is also 




2

k
−
1




{\displaystyle 2^{k-1}}

. In standard coding theory notation for block codes, the Hadamard code is a 



[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code, that is, it is a linear code over a binary alphabet, has block length 




2

k




{\displaystyle 2^{k}}

, message length (or dimension) 



k


{\displaystyle k}

, and minimum distance 




2

k



/

2


{\displaystyle 2^{k}/2}

. The block length is very large compared to the message length, but on the other hand, errors can be corrected even in extremely noisy conditions. The punctured Hadamard code is a slightly improved version of the Hadamard code; it is a 



[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code and thus has a slightly better rate while maintaining the relative distance of 



1

/

2


{\displaystyle 1/2}

, and is thus preferred in practical applications. The punctured Hadamard code is the same as the first order Reed–Muller code over the binary alphabet.[4]
Normally, Hadamard codes are based on Sylvester's construction of Hadamard matrices, but the term “Hadamard code” is also used to refer to codes constructed from arbitrary Hadamard matrices, which are not necessarily of Sylvester type. In general, such a code is not linear. Such codes were first constructed by R. C. Bose and S. S. Shrikhande in 1959.[5] If n is the size of the Hadamard matrix, the code has parameters 



(
n
,
2
n
,
n

/

2

)

2




{\displaystyle (n,2n,n/2)_{2}}

, meaning it is a not-necessarily-linear binary code with 2n codewords of block length n and minimal distance n/2. The construction and decoding scheme described below apply for general n, but the property of linearity and the identification with Reed–Muller codes require that n be a power of 2 and that the Hadamard matrix be equivalent to the matrix constructed by Sylvester's method.
The Hadamard code is a locally decodable code, which provides a way to recover parts of the original message with high probability, while only looking at a small fraction of the received word. This gives rise to applications in computational complexity theory and particularly in the design of probabilistically checkable proofs. Since the relative distance of the Hadamard code is 1/2, normally one can only hope to recover from at most a 1/4 fraction of error. Using list decoding, however, it is possible to compute a short list of possible candidate messages as long as fewer than 





1
2


−
ϵ


{\displaystyle {\frac {1}{2}}-\epsilon }

 of the bits in the received word have been corrupted.
In code division multiple access (CDMA) communication, the Hadamard code is referred to as Walsh Code, and is used to define individual communication channels. It is usual in the CDMA literature to refer to codewords as “codes”. Each user will use a different codeword, or “code”, to modulate their signal. Because Walsh codewords are mathematically orthogonal, a Walsh-encoded signal appears as random noise to a CDMA capable mobile terminal, unless that terminal uses the same codeword as the one used to encode the incoming signal.[6]



Contents


1 History
2 Constructions

2.1 Construction using inner products
2.2 Construction using a generator matrix
2.3 Construction using general Hadamard matrices


3 Distance
4 Local decodability

4.1 Proof of lemma 1
4.2 Proof of theorem 1

4.2.1 Algorithm
4.2.2 Proof of correctness




5 Optimality
6 See also
7 Notes
8 References



History[edit]
Hadamard code is the name that is most commonly used for this code in the literature. However, in modern use these error correcting codes are referred to as Walsh–Hadamard codes.
There is a reason for this:
Jacques Hadamard did not invent the code himself, but he defined Hadamard matrices around 1893, long before the first error-correcting code, the Hamming code, was developed in the 1940s.
The Hadamard code is based on Hadamard matrices, and while there are many different Hadamard matrices that could be used here, normally only Sylvester's construction of Hadamard matrices is used to obtain the codewords of the Hadamard code.
James Joseph Sylvester developed his construction of Hadamard matrices in 1867, which actually predates Hadamard's work on Hadamard matrices. Hence the name Hadamard code is not undisputed and sometimes the code is called Walsh code, honoring the American mathematician Joseph Leonard Walsh.
A Hadamard code was used during the 1971 Mariner 9 mission to correct for picture transmission errors. The data words used during this mission were 6 bits long, which represented 64 grayscale values.
Because of limitations of the quality of the alignment of the transmitter at the time (due to Doppler Tracking Loop issues) the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used.
Errors of up to 7 bits per word could be corrected using this scheme. Compared to a 5-repetition code, the error correcting properties of this Hadamard code are much better, yet its rate is comparable. The efficient decoding algorithm was an important factor in the decision to use this code.
The circuitry used was called the "Green Machine". It employed the fast Fourier transform which can increase the decoding speed by a factor of three. Since the 1990s use of this code by space programs has more or less ceased, and the Deep Space Network does not support this error correction scheme for its dishes that are greater than 26 m.
Constructions[edit]
While all Hadamard codes are based on Hadamard matrices, the constructions differ in subtle ways for different scientific fields, authors, and uses. Engineers, who use the codes for data transmission, and coding theorists, who analyse extremal properties of codes, typically want the rate of the code to be as high as possible, even if this means that the construction becomes mathematically slightly less elegant.
On the other hand, for many applications of Hadamard codes in theoretical computer science it is not so important to achieve the optimal rate, and hence simpler constructions of Hadamard codes are preferred since they can be analyzed more elegantly.
Construction using inner products[edit]
When given a binary message 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 of length 



k


{\displaystyle k}

, the Hadamard code encodes the message into a codeword 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 using an encoding function 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

. This function makes use of the inner product 



⟨
x
,
y
⟩


{\displaystyle \langle x,y\rangle }

 of two vectors 



x
,
y
∈
{
0
,
1

}

k




{\displaystyle x,y\in \{0,1\}^{k}}

, which is defined as follows:





⟨
x
,
y
⟩
=

∑

i
=
1


k



x

i



y

i


 

mod

 


2

.


{\displaystyle \langle x,y\rangle =\sum _{i=1}^{k}x_{i}y_{i}\ {\bmod {\ }}2\,.}



Then the Hadamard encoding of 



x


{\displaystyle x}

 is defined as the sequence of all inner products with 



x


{\displaystyle x}

:






Had

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
0
,
1

}

k






{\displaystyle {\text{Had}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{0,1\}^{k}}}



As mentioned above, the punctured Hadamard code is used in practice since the Hadamard code itself is somewhat wasteful. This is because, if the first bit of 



y


{\displaystyle y}

 is zero, 




y

1


=
0


{\displaystyle y_{1}=0}

, then the inner product contains no information whatsoever about 




x

1




{\displaystyle x_{1}}

, and hence, it is impossible to fully decode 



x


{\displaystyle x}

 from those positions of the codeword alone. On the other hand, when the codeword is restricted to the positions where 




y

1


=
1


{\displaystyle y_{1}=1}

, it is still possible to fully decode 



x


{\displaystyle x}

. Hence it makes sense to restrict the Hadamard code to these positions, which gives rise to the punctured Hadamard encoding of 



x


{\displaystyle x}

; that is, 




pHad

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
1
}
×
{
0
,
1

}

k
−
1






{\displaystyle {\text{pHad}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{1\}\times \{0,1\}^{k-1}}}

.
Construction using a generator matrix[edit]
The Hadamard code is a linear code, and all linear codes can be generated by a generator matrix 



G


{\displaystyle G}

. This is a matrix such that 




Had

(
x
)
=
x
⋅
G


{\displaystyle {\text{Had}}(x)=x\cdot G}

 holds for all 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

, where the message 



x


{\displaystyle x}

 is viewed as a row vector and the vector-matrix product is understood in the vector space over the finite field 





F


2




{\displaystyle \mathbb {F} _{2}}

. In particular, an equivalent way to write the inner product definition for the Hadamard code arises by using the generator matrix whose columns consist of all strings 



y


{\displaystyle y}

 of length 



k


{\displaystyle k}

, that is,





G
=


(



↑


↑



↑





y

1





y

2




…



y


2

k








↓


↓



↓



)



.


{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\y_{1}&y_{2}&\dots &y_{2^{k}}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}\,.}



where 




y

i


∈
{
0
,
1

}

k




{\displaystyle y_{i}\in \{0,1\}^{k}}

 is the 



i


{\displaystyle i}

-th binary vector in lexicographical order. For example, the generator matrix for the Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:





G
=


[



0


0


0


0


1


1


1


1




0


0


1


1


0


0


1


1




0


1


0


1


0


1


0


1



]


.


{\displaystyle G={\begin{bmatrix}0&0&0&0&1&1&1&1\\0&0&1&1&0&0&1&1\\0&1&0&1&0&1&0&1\end{bmatrix}}.}



The matrix 



G


{\displaystyle G}

 is a 



(
k
×

2

k


)


{\displaystyle (k\times 2^{k})}

-matrix and gives rise to the linear operator 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

.
The generator matrix of the punctured Hadamard code is obtained by restricting the matrix 



G


{\displaystyle G}

 to the columns whose first entry is one. For example, the generator matrix for the punctured Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:






G
′

=


[



1


1


1


1




0


0


1


1




0


1


0


1



]


.


{\displaystyle G'={\begin{bmatrix}1&1&1&1\\0&0&1&1\\0&1&0&1\end{bmatrix}}.}



Then 




pHad

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k
−
1






{\displaystyle {\text{pHad}}:\{0,1\}^{k}\to \{0,1\}^{2^{k-1}}}

 is a linear mapping with 




pHad

(
x
)
=
x
⋅

G
′



{\displaystyle {\text{pHad}}(x)=x\cdot G'}

.
For general 



k


{\displaystyle k}

, the generator matrix of the punctured Hadamard code is a parity-check matrix for the extended Hamming code of length 




2

k
−
1




{\displaystyle 2^{k-1}}

 and dimension 




2

k
−
1


−
k


{\displaystyle 2^{k-1}-k}

, which makes the punctured Hadamard code the dual code of the extended Hamming code. Hence an alternative way to define the Hadamard code is in terms of its parity-check matrix: the parity-check matrix of the Hadamard code is equal to the generator matrix of the Hamming code.
Construction using general Hadamard matrices[edit]
Generalized Hadamard codes are obtained from an n-by-n Hadamard matrix H. In particular, the 2n codewords of the code are the rows of H and the rows of −H. To obtain a code over the alphabet {0,1}, the mapping −1 ↦ 1, 1 ↦ 0, or, equivalently, x ↦ (1 − x)/2, is applied to the matrix elements. That the minimum distance of the code is n/2 follows from the defining property of Hadamard matrices, namely that their rows are mutually orthogonal. This implies that two distinct rows of a Hadamard matrix differ in exactly n/2 positions, and, since negation of a row does not affect orthogonality, that any row of H differs from any row of −H in n/2 positions as well, except when the rows correspond, in which case they differ in n positions.
To get the punctured Hadamard code above with 



n
=

2

k
−
1




{\displaystyle n=2^{k-1}}

, the chosen Hadamard matrix H has to be of Sylvester type, which gives rise to a message length of 




log

2


⁡
(
2
n
)
=
k


{\displaystyle \log _{2}(2n)=k}

.
Distance[edit]
The distance of a code is the minimum Hamming distance between any two distinct codewords, i.e., the minimum number of positions at which two distinct codewords differ. Since the Walsh–Hadamard code is a linear code, the distance is equal to the minimum Hamming weight among all of its non-zero codewords. All non-zero codewords of the Walsh–Hadamard code have a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

 by the following argument.
Let 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 be a non-zero message. Then the following value is exactly equal to the fraction of positions in the codeword that are equal to one:






Pr

y
∈
{
0
,
1

}

k






[


(

Had

(
x
)

)

y


=
1


]


=

Pr

y
∈
{
0
,
1

}

k






[


⟨
x
,
y
⟩
=
1


]



.


{\displaystyle \Pr _{y\in \{0,1\}^{k}}{\big [}({\text{Had}}(x))_{y}=1{\big ]}=\Pr _{y\in \{0,1\}^{k}}{\big [}\langle x,y\rangle =1{\big ]}\,.}



The fact that the latter value is exactly 



1

/

2


{\displaystyle 1/2}

 is called the random subsum principle. To see that it is true, assume without loss of generality that 




x

1


=
1


{\displaystyle x_{1}=1}

. Then, when conditioned on the values of 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

, the event is equivalent to 




y

1


⋅

x

1


=
b


{\displaystyle y_{1}\cdot x_{1}=b}

 for some 



b
∈
{
0
,
1
}


{\displaystyle b\in \{0,1\}}

 depending on 




x

2


,
…
,

x

k




{\displaystyle x_{2},\dots ,x_{k}}

 and 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

. The probability that 




y

1


=
b


{\displaystyle y_{1}=b}

 happens is exactly 



1

/

2


{\displaystyle 1/2}

. Thus, in fact, all non-zero codewords of the Hadamard code have relative Hamming weight 



1

/

2


{\displaystyle 1/2}

, and thus, its relative distance is 



1

/

2


{\displaystyle 1/2}

.
The relative distance of the punctured Hadamard code is 



1

/

2


{\displaystyle 1/2}

 as well, but it no longer has the property that every non-zero codeword has weight exactly 



1

/

2


{\displaystyle 1/2}

 since the all 



1


{\displaystyle 1}

s vector 




1


2

k
−
1






{\displaystyle 1^{2^{k-1}}}

 is a codeword of the punctured Hadamard code. This is because the vector 



x
=

10

k
−
1




{\displaystyle x=10^{k-1}}

 encodes to 




pHad

(

10

k
−
1


)
=

1


2

k
−
1






{\displaystyle {\text{pHad}}(10^{k-1})=1^{2^{k-1}}}

. Furthermore, whenever 



x


{\displaystyle x}

 is non-zero and not the vector 




10

k
−
1




{\displaystyle 10^{k-1}}

, the random subsum principle applies again, and the relative weight of 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 is exactly 



1

/

2


{\displaystyle 1/2}

.
Local decodability[edit]
A locally decodable code is a code that allows a single bit of the original message to be recovered with high probability by only looking at a small portion of the received word.
A code is 



q


{\displaystyle q}

-query locally decodable if a message bit, 




x

i




{\displaystyle x_{i}}

, can be recovered by checking 



q


{\displaystyle q}

 bits of the received word. More formally, a code, 



C
:
{
0
,
1

}

k


→
{
0
,
1

}

n




{\displaystyle C:\{0,1\}^{k}\rightarrow \{0,1\}^{n}}

, is 



(
q
,
δ
≥
0
,
ϵ
≥
0
)


{\displaystyle (q,\delta \geq 0,\epsilon \geq 0)}

-locally decodable, if there exists a probabilistic decoder, 



D
:
{
0
,
1

}

n


→
{
0
,
1

}

k




{\displaystyle D:\{0,1\}^{n}\rightarrow \{0,1\}^{k}}

, such that (Note: 



Δ
(
x
,
y
)


{\displaystyle \Delta (x,y)}

 represents the Hamming distance between vectors 



x


{\displaystyle x}

 and 



y


{\displaystyle y}

):




∀
x
∈
{
0
,
1

}

k


,
∀
y
∈
{
0
,
1

}

n




{\displaystyle \forall x\in \{0,1\}^{k},\forall y\in \{0,1\}^{n}}

, 



Δ
(
y
,
C
(
x
)
)
≤
δ
n


{\displaystyle \Delta (y,C(x))\leq \delta n}

 implies that 



P
r
[
D
(
y

)

i


=

x

i


]
≥


1
2


+
ϵ
,
∀
i
∈
[
k
]


{\displaystyle Pr[D(y)_{i}=x_{i}]\geq {\frac {1}{2}}+\epsilon ,\forall i\in [k]}


Theorem 1: The Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

-locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Lemma 1: For all codewords, 



c


{\displaystyle c}

 in a Walsh–Hadamard code, 



C


{\displaystyle C}

, 




c

i


+

c

j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=c_{i+j}}

, where 




c

i


,

c

j




{\displaystyle c_{i},c_{j}}

 represent the bits in 



c


{\displaystyle c}

 in positions 



i


{\displaystyle i}

 and 



j


{\displaystyle j}

 respectively, and 




c

i
+
j




{\displaystyle c_{i+j}}

 represents the bit at position 



(
i
+
j
)


{\displaystyle (i+j)}

.
Proof of lemma 1[edit]

Let 



C
(
x
)
=
c
=
(

c

0


,
…
,

c


2

n


−
1


)


{\displaystyle C(x)=c=(c_{0},\dots ,c_{2^{n}-1})}

 be the codeword in 



C


{\displaystyle C}

 corresponding to message 



x


{\displaystyle x}

.
Let 



G
=


(



↑


↑



↑





g

0





g

1




…



g


2

n


−
1






↓


↓



↓



)




{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\g_{0}&g_{1}&\dots &g_{2^{n}-1}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}}

 be the generator matrix of 



C


{\displaystyle C}

.
By definition, 




c

i


=
x
⋅

g

i




{\displaystyle c_{i}=x\cdot g_{i}}

. From this, 




c

i


+

c

j


=
x
⋅

g

i


+
x
⋅

g

j


=
x
⋅
(

g

i


+

g

j


)


{\displaystyle c_{i}+c_{j}=x\cdot g_{i}+x\cdot g_{j}=x\cdot (g_{i}+g_{j})}

. By the construction of 



G


{\displaystyle G}

, 




g

i


+

g

j


=

g

i
+
j




{\displaystyle g_{i}+g_{j}=g_{i+j}}

. Therefore, by substitution, 




c

i


+

c

j


=
x
⋅

g

i
+
j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=x\cdot g_{i+j}=c_{i+j}}

.
Proof of theorem 1[edit]

To prove theorem 1 we will construct a decoding algorithm and prove its correctness.
Algorithm[edit]
Input: Received word 



y
=
(

y

0


,
…
,

y


2

n


−
1


)


{\displaystyle y=(y_{0},\dots ,y_{2^{n}-1})}


For each 



i
∈
{
1
,
…
,
n
}


{\displaystyle i\in \{1,\dots ,n\}}

:

Pick 



j
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle j\in \{0,\dots ,2^{n}-1\}}

 uniformly at random
Pick 



k
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle k\in \{0,\dots ,2^{n}-1\}}

 such that 



j
+
k
=

e

i




{\displaystyle j+k=e_{i}}

 where 



j
+
k


{\displaystyle j+k}

 is the bitwise xor of 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

.





x

i


←

y

j


+

y

k




{\displaystyle x_{i}\gets y_{j}+y_{k}}



Output: Message 



x
=
(

x

1


,
…
,

x

n


)


{\displaystyle x=(x_{1},\dots ,x_{n})}


Proof of correctness[edit]
For any message, 



x


{\displaystyle x}

, and received word 



y


{\displaystyle y}

 such that 



y


{\displaystyle y}

 differs from 



c
=
C
(
x
)


{\displaystyle c=C(x)}

 on at most 



δ


{\displaystyle \delta }

 fraction of bits, 




x

i




{\displaystyle x_{i}}

 can be decoded with probability at least 





1
2


+
(


1
2


−
2
δ
)


{\displaystyle {\frac {1}{2}}+({\frac {1}{2}}-2\delta )}

.
By lemma 1, 




c

j


+

c

k


=

c

j
+
k


=
x
⋅

g

j
+
k


=
x
⋅

e

i


=

x

i




{\displaystyle c_{j}+c_{k}=c_{j+k}=x\cdot g_{j+k}=x\cdot e_{i}=x_{i}}

. Since 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

 are picked uniformly, the probability that 




y

j


≠

c

j




{\displaystyle y_{j}\not =c_{j}}

 is at most 



δ


{\displaystyle \delta }

. Similarly, the probability that 




y

k


≠

c

k




{\displaystyle y_{k}\not =c_{k}}

 is at most 



δ


{\displaystyle \delta }

. By the union bound, the probability that either 




y

j




{\displaystyle y_{j}}

 or 




y

k




{\displaystyle y_{k}}

 do not match the corresponding bits in 



c


{\displaystyle c}

 is at most 



2
δ


{\displaystyle 2\delta }

. If both 




y

j




{\displaystyle y_{j}}

 and 




y

k




{\displaystyle y_{k}}

 correspond to 



c


{\displaystyle c}

, then lemma 1 will apply, and therefore, the proper value of 




x

i




{\displaystyle x_{i}}

 will be computed. Therefore, the probability 




x

i




{\displaystyle x_{i}}

 is decoded properly is at least 



1
−
2
δ


{\displaystyle 1-2\delta }

. Therefore, 



ϵ
=


1
2


−
2
δ


{\displaystyle \epsilon ={\frac {1}{2}}-2\delta }

 and for 



ϵ


{\displaystyle \epsilon }

 to be positive, 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Therefore, the Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

 locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}


Optimality[edit]
For k ≤ 7 the linear Hadamard codes have been proven optimal in the sense of minimum distance.[7]
See also[edit]

Zadoff–Chu sequence — improve over the Walsh–Hadamard codes

Notes[edit]



^ http://www.mcs.csueastbay.edu/~malek/TeX/Hadamard.pdf
^ See, e.g., Amadei, Manzoli & Merani (2002)
^ See, e.g., Arora & Barak (2009, Section 19.2.2).
^ See, e.g., Guruswami (2009, p. 3).
^ Bose, R.C.; Shrikhande, S.S. (1959). "A note on a result in the theory of code construction". Information and Control. 2 (2): 183–194. CiteSeerX 10.1.1.154.2879 . doi:10.1016/S0019-9958(59)90376-6. 
^ "CDMA Tutorial: Intuitive Guide to Principles of Communications" (PDF). Complex to Real. Retrieved 4 August 2011. 
^ Jaffe, David B.; Bouyukliev, Iliya, Optimal binary linear codes of dimension at most seven 



References[edit]

Amadei, M.; Manzoli, U.; Merani, M.L. (2002), "On the assignment of Walsh and quasi-orthogonal codes in a multicarrier DS-CDMA system with multiple classes of users", Global Telecommunications Conference, 2002. GLOBECOM'02. IEEE, 1, IEEE, pp. 841–5, ISBN 0-7803-7632-3, doi:10.1109/GLOCOM.2002.1188196 
Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4 
Guruswami, Venkatesan (2009), List decoding of binary codes (PDF) 
Rudra, Atri, "Hamming code and Hamming bound" (PDF), Lecture notes 







v
t
e


Consultative Committee for Space Data Systems



Data compression



Images

ICER
JPEG
JPEG 2000
122.0.B1


Data

Adaptive Entropy Coder







Error Correction



Current
Binary Golay code
Concatenated codes
Turbo codes
Proposed
LDPC codes





Telemetry command uplink



Command Loss Timer Reset
Proximity-1 Space Link Protocol





Telemetry downlink



Spacecraft Monitoring & Control
Beacon mode service





Telemetry general



Space Communications Protocol Specifications (SCPS): Performance Enhancing Proxy





Telemetry modulation systems



Current
BPSK
QPSK
OQPSK
Proposed
GMSK





Frequencies



X band
S band
Ku band
K band
Ka band





Networking, interoperability and monitoring



Service-oriented architecture (Message Abstraction Layer)










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Hadamard_code&oldid=783123479"					
Categories: Coding theoryError detection and correction 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


CatalàDeutsch日本語 
Edit links 





 This page was last edited on 31 May 2017, at 08:02.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 









Hadamard code - Wikipedia






















 






Hadamard code

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search



Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k


{\displaystyle k}




Rate




k

/


2

k




{\displaystyle k/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code





v
t
e







Punctured Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k
+
1


{\displaystyle k+1}




Rate




(
k
+
1
)

/


2

k




{\displaystyle (k+1)/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code





v
t
e









Matrix of the Punctured Hadamard code [32, 6, 16] for the Reed–Muller code (1, 5) of the NASA space probe Mariner 9






XOR operations
Here the white fields stand for 0
and the red fields for 1


The Hadamard code is an error-correcting code that is used for error detection and correction when transmitting messages over very noisy or unreliable channels. In 1971, the code was used to transmit photos of Mars back to Earth from the NASA space probe Mariner 9.[1] Because of its unique mathematical properties, the Hadamard code is not only used by engineers, but also intensely studied in coding theory, mathematics, and theoretical computer science. The Hadamard code is named after the French mathematician Jacques Hadamard. It is also known under the names Walsh code, Walsh family,[2] and Walsh–Hadamard code[3] in recognition of the American mathematician Joseph Leonard Walsh.
The Hadamard code is an example of a linear code over a binary alphabet that maps messages of length 



k


{\displaystyle k}

 to codewords of length 




2

k




{\displaystyle 2^{k}}

. It is unique in that each non-zero codeword has a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

, which implies that the distance of the code is also 




2

k
−
1




{\displaystyle 2^{k-1}}

. In standard coding theory notation for block codes, the Hadamard code is a 



[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code, that is, it is a linear code over a binary alphabet, has block length 




2

k




{\displaystyle 2^{k}}

, message length (or dimension) 



k


{\displaystyle k}

, and minimum distance 




2

k



/

2


{\displaystyle 2^{k}/2}

. The block length is very large compared to the message length, but on the other hand, errors can be corrected even in extremely noisy conditions. The punctured Hadamard code is a slightly improved version of the Hadamard code; it is a 



[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code and thus has a slightly better rate while maintaining the relative distance of 



1

/

2


{\displaystyle 1/2}

, and is thus preferred in practical applications. The punctured Hadamard code is the same as the first order Reed–Muller code over the binary alphabet.[4]
Normally, Hadamard codes are based on Sylvester's construction of Hadamard matrices, but the term “Hadamard code” is also used to refer to codes constructed from arbitrary Hadamard matrices, which are not necessarily of Sylvester type. In general, such a code is not linear. Such codes were first constructed by R. C. Bose and S. S. Shrikhande in 1959.[5] If n is the size of the Hadamard matrix, the code has parameters 



(
n
,
2
n
,
n

/

2

)

2




{\displaystyle (n,2n,n/2)_{2}}

, meaning it is a not-necessarily-linear binary code with 2n codewords of block length n and minimal distance n/2. The construction and decoding scheme described below apply for general n, but the property of linearity and the identification with Reed–Muller codes require that n be a power of 2 and that the Hadamard matrix be equivalent to the matrix constructed by Sylvester's method.
The Hadamard code is a locally decodable code, which provides a way to recover parts of the original message with high probability, while only looking at a small fraction of the received word. This gives rise to applications in computational complexity theory and particularly in the design of probabilistically checkable proofs. Since the relative distance of the Hadamard code is 1/2, normally one can only hope to recover from at most a 1/4 fraction of error. Using list decoding, however, it is possible to compute a short list of possible candidate messages as long as fewer than 





1
2


−
ϵ


{\displaystyle {\frac {1}{2}}-\epsilon }

 of the bits in the received word have been corrupted.
In code division multiple access (CDMA) communication, the Hadamard code is referred to as Walsh Code, and is used to define individual communication channels. It is usual in the CDMA literature to refer to codewords as “codes”. Each user will use a different codeword, or “code”, to modulate their signal. Because Walsh codewords are mathematically orthogonal, a Walsh-encoded signal appears as random noise to a CDMA capable mobile terminal, unless that terminal uses the same codeword as the one used to encode the incoming signal.[6]



Contents


1 History
2 Constructions

2.1 Construction using inner products
2.2 Construction using a generator matrix
2.3 Construction using general Hadamard matrices


3 Distance
4 Local decodability

4.1 Proof of lemma 1
4.2 Proof of theorem 1

4.2.1 Algorithm
4.2.2 Proof of correctness




5 Optimality
6 See also
7 Notes
8 References



History[edit]
Hadamard code is the name that is most commonly used for this code in the literature. However, in modern use these error correcting codes are referred to as Walsh–Hadamard codes.
There is a reason for this:
Jacques Hadamard did not invent the code himself, but he defined Hadamard matrices around 1893, long before the first error-correcting code, the Hamming code, was developed in the 1940s.
The Hadamard code is based on Hadamard matrices, and while there are many different Hadamard matrices that could be used here, normally only Sylvester's construction of Hadamard matrices is used to obtain the codewords of the Hadamard code.
James Joseph Sylvester developed his construction of Hadamard matrices in 1867, which actually predates Hadamard's work on Hadamard matrices. Hence the name Hadamard code is not undisputed and sometimes the code is called Walsh code, honoring the American mathematician Joseph Leonard Walsh.
A Hadamard code was used during the 1971 Mariner 9 mission to correct for picture transmission errors. The data words used during this mission were 6 bits long, which represented 64 grayscale values.
Because of limitations of the quality of the alignment of the transmitter at the time (due to Doppler Tracking Loop issues) the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used.
Errors of up to 7 bits per word could be corrected using this scheme. Compared to a 5-repetition code, the error correcting properties of this Hadamard code are much better, yet its rate is comparable. The efficient decoding algorithm was an important factor in the decision to use this code.
The circuitry used was called the "Green Machine". It employed the fast Fourier transform which can increase the decoding speed by a factor of three. Since the 1990s use of this code by space programs has more or less ceased, and the Deep Space Network does not support this error correction scheme for its dishes that are greater than 26 m.
Constructions[edit]
While all Hadamard codes are based on Hadamard matrices, the constructions differ in subtle ways for different scientific fields, authors, and uses. Engineers, who use the codes for data transmission, and coding theorists, who analyse extremal properties of codes, typically want the rate of the code to be as high as possible, even if this means that the construction becomes mathematically slightly less elegant.
On the other hand, for many applications of Hadamard codes in theoretical computer science it is not so important to achieve the optimal rate, and hence simpler constructions of Hadamard codes are preferred since they can be analyzed more elegantly.
Construction using inner products[edit]
When given a binary message 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 of length 



k


{\displaystyle k}

, the Hadamard code encodes the message into a codeword 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 using an encoding function 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

. This function makes use of the inner product 



⟨
x
,
y
⟩


{\displaystyle \langle x,y\rangle }

 of two vectors 



x
,
y
∈
{
0
,
1

}

k




{\displaystyle x,y\in \{0,1\}^{k}}

, which is defined as follows:





⟨
x
,
y
⟩
=

∑

i
=
1


k



x

i



y

i


 

mod

 


2

.


{\displaystyle \langle x,y\rangle =\sum _{i=1}^{k}x_{i}y_{i}\ {\bmod {\ }}2\,.}



Then the Hadamard encoding of 



x


{\displaystyle x}

 is defined as the sequence of all inner products with 



x


{\displaystyle x}

:






Had

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
0
,
1

}

k






{\displaystyle {\text{Had}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{0,1\}^{k}}}



As mentioned above, the punctured Hadamard code is used in practice since the Hadamard code itself is somewhat wasteful. This is because, if the first bit of 



y


{\displaystyle y}

 is zero, 




y

1


=
0


{\displaystyle y_{1}=0}

, then the inner product contains no information whatsoever about 




x

1




{\displaystyle x_{1}}

, and hence, it is impossible to fully decode 



x


{\displaystyle x}

 from those positions of the codeword alone. On the other hand, when the codeword is restricted to the positions where 




y

1


=
1


{\displaystyle y_{1}=1}

, it is still possible to fully decode 



x


{\displaystyle x}

. Hence it makes sense to restrict the Hadamard code to these positions, which gives rise to the punctured Hadamard encoding of 



x


{\displaystyle x}

; that is, 




pHad

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
1
}
×
{
0
,
1

}

k
−
1






{\displaystyle {\text{pHad}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{1\}\times \{0,1\}^{k-1}}}

.
Construction using a generator matrix[edit]
The Hadamard code is a linear code, and all linear codes can be generated by a generator matrix 



G


{\displaystyle G}

. This is a matrix such that 




Had

(
x
)
=
x
⋅
G


{\displaystyle {\text{Had}}(x)=x\cdot G}

 holds for all 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

, where the message 



x


{\displaystyle x}

 is viewed as a row vector and the vector-matrix product is understood in the vector space over the finite field 





F


2




{\displaystyle \mathbb {F} _{2}}

. In particular, an equivalent way to write the inner product definition for the Hadamard code arises by using the generator matrix whose columns consist of all strings 



y


{\displaystyle y}

 of length 



k


{\displaystyle k}

, that is,





G
=


(



↑


↑



↑





y

1





y

2




…



y


2

k








↓


↓



↓



)



.


{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\y_{1}&y_{2}&\dots &y_{2^{k}}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}\,.}



where 




y

i


∈
{
0
,
1

}

k




{\displaystyle y_{i}\in \{0,1\}^{k}}

 is the 



i


{\displaystyle i}

-th binary vector in lexicographical order. For example, the generator matrix for the Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:





G
=


[



0


0


0


0


1


1


1


1




0


0


1


1


0


0


1


1




0


1


0


1


0


1


0


1



]


.


{\displaystyle G={\begin{bmatrix}0&0&0&0&1&1&1&1\\0&0&1&1&0&0&1&1\\0&1&0&1&0&1&0&1\end{bmatrix}}.}



The matrix 



G


{\displaystyle G}

 is a 



(
k
×

2

k


)


{\displaystyle (k\times 2^{k})}

-matrix and gives rise to the linear operator 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

.
The generator matrix of the punctured Hadamard code is obtained by restricting the matrix 



G


{\displaystyle G}

 to the columns whose first entry is one. For example, the generator matrix for the punctured Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:






G
′

=


[



1


1


1


1




0


0


1


1




0


1


0


1



]


.


{\displaystyle G'={\begin{bmatrix}1&1&1&1\\0&0&1&1\\0&1&0&1\end{bmatrix}}.}



Then 




pHad

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k
−
1






{\displaystyle {\text{pHad}}:\{0,1\}^{k}\to \{0,1\}^{2^{k-1}}}

 is a linear mapping with 




pHad

(
x
)
=
x
⋅

G
′



{\displaystyle {\text{pHad}}(x)=x\cdot G'}

.
For general 



k


{\displaystyle k}

, the generator matrix of the punctured Hadamard code is a parity-check matrix for the extended Hamming code of length 




2

k
−
1




{\displaystyle 2^{k-1}}

 and dimension 




2

k
−
1


−
k


{\displaystyle 2^{k-1}-k}

, which makes the punctured Hadamard code the dual code of the extended Hamming code. Hence an alternative way to define the Hadamard code is in terms of its parity-check matrix: the parity-check matrix of the Hadamard code is equal to the generator matrix of the Hamming code.
Construction using general Hadamard matrices[edit]
Generalized Hadamard codes are obtained from an n-by-n Hadamard matrix H. In particular, the 2n codewords of the code are the rows of H and the rows of −H. To obtain a code over the alphabet {0,1}, the mapping −1 ↦ 1, 1 ↦ 0, or, equivalently, x ↦ (1 − x)/2, is applied to the matrix elements. That the minimum distance of the code is n/2 follows from the defining property of Hadamard matrices, namely that their rows are mutually orthogonal. This implies that two distinct rows of a Hadamard matrix differ in exactly n/2 positions, and, since negation of a row does not affect orthogonality, that any row of H differs from any row of −H in n/2 positions as well, except when the rows correspond, in which case they differ in n positions.
To get the punctured Hadamard code above with 



n
=

2

k
−
1




{\displaystyle n=2^{k-1}}

, the chosen Hadamard matrix H has to be of Sylvester type, which gives rise to a message length of 




log

2


⁡
(
2
n
)
=
k


{\displaystyle \log _{2}(2n)=k}

.
Distance[edit]
The distance of a code is the minimum Hamming distance between any two distinct codewords, i.e., the minimum number of positions at which two distinct codewords differ. Since the Walsh–Hadamard code is a linear code, the distance is equal to the minimum Hamming weight among all of its non-zero codewords. All non-zero codewords of the Walsh–Hadamard code have a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

 by the following argument.
Let 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 be a non-zero message. Then the following value is exactly equal to the fraction of positions in the codeword that are equal to one:






Pr

y
∈
{
0
,
1

}

k






[


(

Had

(
x
)

)

y


=
1


]


=

Pr

y
∈
{
0
,
1

}

k






[


⟨
x
,
y
⟩
=
1


]



.


{\displaystyle \Pr _{y\in \{0,1\}^{k}}{\big [}({\text{Had}}(x))_{y}=1{\big ]}=\Pr _{y\in \{0,1\}^{k}}{\big [}\langle x,y\rangle =1{\big ]}\,.}



The fact that the latter value is exactly 



1

/

2


{\displaystyle 1/2}

 is called the random subsum principle. To see that it is true, assume without loss of generality that 




x

1


=
1


{\displaystyle x_{1}=1}

. Then, when conditioned on the values of 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

, the event is equivalent to 




y

1


⋅

x

1


=
b


{\displaystyle y_{1}\cdot x_{1}=b}

 for some 



b
∈
{
0
,
1
}


{\displaystyle b\in \{0,1\}}

 depending on 




x

2


,
…
,

x

k




{\displaystyle x_{2},\dots ,x_{k}}

 and 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

. The probability that 




y

1


=
b


{\displaystyle y_{1}=b}

 happens is exactly 



1

/

2


{\displaystyle 1/2}

. Thus, in fact, all non-zero codewords of the Hadamard code have relative Hamming weight 



1

/

2


{\displaystyle 1/2}

, and thus, its relative distance is 



1

/

2


{\displaystyle 1/2}

.
The relative distance of the punctured Hadamard code is 



1

/

2


{\displaystyle 1/2}

 as well, but it no longer has the property that every non-zero codeword has weight exactly 



1

/

2


{\displaystyle 1/2}

 since the all 



1


{\displaystyle 1}

s vector 




1


2

k
−
1






{\displaystyle 1^{2^{k-1}}}

 is a codeword of the punctured Hadamard code. This is because the vector 



x
=

10

k
−
1




{\displaystyle x=10^{k-1}}

 encodes to 




pHad

(

10

k
−
1


)
=

1


2

k
−
1






{\displaystyle {\text{pHad}}(10^{k-1})=1^{2^{k-1}}}

. Furthermore, whenever 



x


{\displaystyle x}

 is non-zero and not the vector 




10

k
−
1




{\displaystyle 10^{k-1}}

, the random subsum principle applies again, and the relative weight of 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 is exactly 



1

/

2


{\displaystyle 1/2}

.
Local decodability[edit]
A locally decodable code is a code that allows a single bit of the original message to be recovered with high probability by only looking at a small portion of the received word.
A code is 



q


{\displaystyle q}

-query locally decodable if a message bit, 




x

i




{\displaystyle x_{i}}

, can be recovered by checking 



q


{\displaystyle q}

 bits of the received word. More formally, a code, 



C
:
{
0
,
1

}

k


→
{
0
,
1

}

n




{\displaystyle C:\{0,1\}^{k}\rightarrow \{0,1\}^{n}}

, is 



(
q
,
δ
≥
0
,
ϵ
≥
0
)


{\displaystyle (q,\delta \geq 0,\epsilon \geq 0)}

-locally decodable, if there exists a probabilistic decoder, 



D
:
{
0
,
1

}

n


→
{
0
,
1

}

k




{\displaystyle D:\{0,1\}^{n}\rightarrow \{0,1\}^{k}}

, such that (Note: 



Δ
(
x
,
y
)


{\displaystyle \Delta (x,y)}

 represents the Hamming distance between vectors 



x


{\displaystyle x}

 and 



y


{\displaystyle y}

):




∀
x
∈
{
0
,
1

}

k


,
∀
y
∈
{
0
,
1

}

n




{\displaystyle \forall x\in \{0,1\}^{k},\forall y\in \{0,1\}^{n}}

, 



Δ
(
y
,
C
(
x
)
)
≤
δ
n


{\displaystyle \Delta (y,C(x))\leq \delta n}

 implies that 



P
r
[
D
(
y

)

i


=

x

i


]
≥


1
2


+
ϵ
,
∀
i
∈
[
k
]


{\displaystyle Pr[D(y)_{i}=x_{i}]\geq {\frac {1}{2}}+\epsilon ,\forall i\in [k]}


Theorem 1: The Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

-locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Lemma 1: For all codewords, 



c


{\displaystyle c}

 in a Walsh–Hadamard code, 



C


{\displaystyle C}

, 




c

i


+

c

j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=c_{i+j}}

, where 




c

i


,

c

j




{\displaystyle c_{i},c_{j}}

 represent the bits in 



c


{\displaystyle c}

 in positions 



i


{\displaystyle i}

 and 



j


{\displaystyle j}

 respectively, and 




c

i
+
j




{\displaystyle c_{i+j}}

 represents the bit at position 



(
i
+
j
)


{\displaystyle (i+j)}

.
Proof of lemma 1[edit]

Let 



C
(
x
)
=
c
=
(

c

0


,
…
,

c


2

n


−
1


)


{\displaystyle C(x)=c=(c_{0},\dots ,c_{2^{n}-1})}

 be the codeword in 



C


{\displaystyle C}

 corresponding to message 



x


{\displaystyle x}

.
Let 



G
=


(



↑


↑



↑





g

0





g

1




…



g


2

n


−
1






↓


↓



↓



)




{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\g_{0}&g_{1}&\dots &g_{2^{n}-1}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}}

 be the generator matrix of 



C


{\displaystyle C}

.
By definition, 




c

i


=
x
⋅

g

i




{\displaystyle c_{i}=x\cdot g_{i}}

. From this, 




c

i


+

c

j


=
x
⋅

g

i


+
x
⋅

g

j


=
x
⋅
(

g

i


+

g

j


)


{\displaystyle c_{i}+c_{j}=x\cdot g_{i}+x\cdot g_{j}=x\cdot (g_{i}+g_{j})}

. By the construction of 



G


{\displaystyle G}

, 




g

i


+

g

j


=

g

i
+
j




{\displaystyle g_{i}+g_{j}=g_{i+j}}

. Therefore, by substitution, 




c

i


+

c

j


=
x
⋅

g

i
+
j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=x\cdot g_{i+j}=c_{i+j}}

.
Proof of theorem 1[edit]

To prove theorem 1 we will construct a decoding algorithm and prove its correctness.
Algorithm[edit]
Input: Received word 



y
=
(

y

0


,
…
,

y


2

n


−
1


)


{\displaystyle y=(y_{0},\dots ,y_{2^{n}-1})}


For each 



i
∈
{
1
,
…
,
n
}


{\displaystyle i\in \{1,\dots ,n\}}

:

Pick 



j
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle j\in \{0,\dots ,2^{n}-1\}}

 uniformly at random
Pick 



k
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle k\in \{0,\dots ,2^{n}-1\}}

 such that 



j
+
k
=

e

i




{\displaystyle j+k=e_{i}}

 where 



j
+
k


{\displaystyle j+k}

 is the bitwise xor of 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

.





x

i


←

y

j


+

y

k




{\displaystyle x_{i}\gets y_{j}+y_{k}}



Output: Message 



x
=
(

x

1


,
…
,

x

n


)


{\displaystyle x=(x_{1},\dots ,x_{n})}


Proof of correctness[edit]
For any message, 



x


{\displaystyle x}

, and received word 



y


{\displaystyle y}

 such that 



y


{\displaystyle y}

 differs from 



c
=
C
(
x
)


{\displaystyle c=C(x)}

 on at most 



δ


{\displaystyle \delta }

 fraction of bits, 




x

i




{\displaystyle x_{i}}

 can be decoded with probability at least 





1
2


+
(


1
2


−
2
δ
)


{\displaystyle {\frac {1}{2}}+({\frac {1}{2}}-2\delta )}

.
By lemma 1, 




c

j


+

c

k


=

c

j
+
k


=
x
⋅

g

j
+
k


=
x
⋅

e

i


=

x

i




{\displaystyle c_{j}+c_{k}=c_{j+k}=x\cdot g_{j+k}=x\cdot e_{i}=x_{i}}

. Since 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

 are picked uniformly, the probability that 




y

j


≠

c

j




{\displaystyle y_{j}\not =c_{j}}

 is at most 



δ


{\displaystyle \delta }

. Similarly, the probability that 




y

k


≠

c

k




{\displaystyle y_{k}\not =c_{k}}

 is at most 



δ


{\displaystyle \delta }

. By the union bound, the probability that either 




y

j




{\displaystyle y_{j}}

 or 




y

k




{\displaystyle y_{k}}

 do not match the corresponding bits in 



c


{\displaystyle c}

 is at most 



2
δ


{\displaystyle 2\delta }

. If both 




y

j




{\displaystyle y_{j}}

 and 




y

k




{\displaystyle y_{k}}

 correspond to 



c


{\displaystyle c}

, then lemma 1 will apply, and therefore, the proper value of 




x

i




{\displaystyle x_{i}}

 will be computed. Therefore, the probability 




x

i




{\displaystyle x_{i}}

 is decoded properly is at least 



1
−
2
δ


{\displaystyle 1-2\delta }

. Therefore, 



ϵ
=


1
2


−
2
δ


{\displaystyle \epsilon ={\frac {1}{2}}-2\delta }

 and for 



ϵ


{\displaystyle \epsilon }

 to be positive, 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Therefore, the Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

 locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}


Optimality[edit]
For k ≤ 7 the linear Hadamard codes have been proven optimal in the sense of minimum distance.[7]
See also[edit]

Zadoff–Chu sequence — improve over the Walsh–Hadamard codes

Notes[edit]



^ http://www.mcs.csueastbay.edu/~malek/TeX/Hadamard.pdf
^ See, e.g., Amadei, Manzoli & Merani (2002)
^ See, e.g., Arora & Barak (2009, Section 19.2.2).
^ See, e.g., Guruswami (2009, p. 3).
^ Bose, R.C.; Shrikhande, S.S. (1959). "A note on a result in the theory of code construction". Information and Control. 2 (2): 183–194. CiteSeerX 10.1.1.154.2879 . doi:10.1016/S0019-9958(59)90376-6. 
^ "CDMA Tutorial: Intuitive Guide to Principles of Communications" (PDF). Complex to Real. Retrieved 4 August 2011. 
^ Jaffe, David B.; Bouyukliev, Iliya, Optimal binary linear codes of dimension at most seven 



References[edit]

Amadei, M.; Manzoli, U.; Merani, M.L. (2002), "On the assignment of Walsh and quasi-orthogonal codes in a multicarrier DS-CDMA system with multiple classes of users", Global Telecommunications Conference, 2002. GLOBECOM'02. IEEE, 1, IEEE, pp. 841–5, ISBN 0-7803-7632-3, doi:10.1109/GLOCOM.2002.1188196 
Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4 
Guruswami, Venkatesan (2009), List decoding of binary codes (PDF) 
Rudra, Atri, "Hamming code and Hamming bound" (PDF), Lecture notes 







v
t
e


Consultative Committee for Space Data Systems



Data compression



Images

ICER
JPEG
JPEG 2000
122.0.B1


Data

Adaptive Entropy Coder







Error Correction



Current
Binary Golay code
Concatenated codes
Turbo codes
Proposed
LDPC codes





Telemetry command uplink



Command Loss Timer Reset
Proximity-1 Space Link Protocol





Telemetry downlink



Spacecraft Monitoring & Control
Beacon mode service





Telemetry general



Space Communications Protocol Specifications (SCPS): Performance Enhancing Proxy





Telemetry modulation systems



Current
BPSK
QPSK
OQPSK
Proposed
GMSK





Frequencies



X band
S band
Ku band
K band
Ka band





Networking, interoperability and monitoring



Service-oriented architecture (Message Abstraction Layer)










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Hadamard_code&oldid=783123479"					
Categories: Coding theoryError detection and correction 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


CatalàDeutsch日本語 
Edit links 





 This page was last edited on 31 May 2017, at 08:02.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 









Hadamard code - Wikipedia






















 






Hadamard code

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search



Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k


{\displaystyle k}




Rate




k

/


2

k




{\displaystyle k/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code





v
t
e







Punctured Hadamard code


Named after
Jacques Hadamard


Classification


Type
Linear block code


Block length




n
=

2

k




{\displaystyle n=2^{k}}




Message length




k
+
1


{\displaystyle k+1}




Rate




(
k
+
1
)

/


2

k




{\displaystyle (k+1)/2^{k}}




Distance




d
=

2

k
−
1




{\displaystyle d=2^{k-1}}




Alphabet size




2


{\displaystyle 2}




Notation




[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code





v
t
e









Matrix of the Punctured Hadamard code [32, 6, 16] for the Reed–Muller code (1, 5) of the NASA space probe Mariner 9






XOR operations
Here the white fields stand for 0
and the red fields for 1


The Hadamard code is an error-correcting code that is used for error detection and correction when transmitting messages over very noisy or unreliable channels. In 1971, the code was used to transmit photos of Mars back to Earth from the NASA space probe Mariner 9.[1] Because of its unique mathematical properties, the Hadamard code is not only used by engineers, but also intensely studied in coding theory, mathematics, and theoretical computer science. The Hadamard code is named after the French mathematician Jacques Hadamard. It is also known under the names Walsh code, Walsh family,[2] and Walsh–Hadamard code[3] in recognition of the American mathematician Joseph Leonard Walsh.
The Hadamard code is an example of a linear code over a binary alphabet that maps messages of length 



k


{\displaystyle k}

 to codewords of length 




2

k




{\displaystyle 2^{k}}

. It is unique in that each non-zero codeword has a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

, which implies that the distance of the code is also 




2

k
−
1




{\displaystyle 2^{k-1}}

. In standard coding theory notation for block codes, the Hadamard code is a 



[

2

k


,
k
,

2

k
−
1



]

2




{\displaystyle [2^{k},k,2^{k-1}]_{2}}

-code, that is, it is a linear code over a binary alphabet, has block length 




2

k




{\displaystyle 2^{k}}

, message length (or dimension) 



k


{\displaystyle k}

, and minimum distance 




2

k



/

2


{\displaystyle 2^{k}/2}

. The block length is very large compared to the message length, but on the other hand, errors can be corrected even in extremely noisy conditions. The punctured Hadamard code is a slightly improved version of the Hadamard code; it is a 



[

2

k


,
k
+
1
,

2

k
−
1



]

2




{\displaystyle [2^{k},k+1,2^{k-1}]_{2}}

-code and thus has a slightly better rate while maintaining the relative distance of 



1

/

2


{\displaystyle 1/2}

, and is thus preferred in practical applications. The punctured Hadamard code is the same as the first order Reed–Muller code over the binary alphabet.[4]
Normally, Hadamard codes are based on Sylvester's construction of Hadamard matrices, but the term “Hadamard code” is also used to refer to codes constructed from arbitrary Hadamard matrices, which are not necessarily of Sylvester type. In general, such a code is not linear. Such codes were first constructed by R. C. Bose and S. S. Shrikhande in 1959.[5] If n is the size of the Hadamard matrix, the code has parameters 



(
n
,
2
n
,
n

/

2

)

2




{\displaystyle (n,2n,n/2)_{2}}

, meaning it is a not-necessarily-linear binary code with 2n codewords of block length n and minimal distance n/2. The construction and decoding scheme described below apply for general n, but the property of linearity and the identification with Reed–Muller codes require that n be a power of 2 and that the Hadamard matrix be equivalent to the matrix constructed by Sylvester's method.
The Hadamard code is a locally decodable code, which provides a way to recover parts of the original message with high probability, while only looking at a small fraction of the received word. This gives rise to applications in computational complexity theory and particularly in the design of probabilistically checkable proofs. Since the relative distance of the Hadamard code is 1/2, normally one can only hope to recover from at most a 1/4 fraction of error. Using list decoding, however, it is possible to compute a short list of possible candidate messages as long as fewer than 





1
2


−
ϵ


{\displaystyle {\frac {1}{2}}-\epsilon }

 of the bits in the received word have been corrupted.
In code division multiple access (CDMA) communication, the Hadamard code is referred to as Walsh Code, and is used to define individual communication channels. It is usual in the CDMA literature to refer to codewords as “codes”. Each user will use a different codeword, or “code”, to modulate their signal. Because Walsh codewords are mathematically orthogonal, a Walsh-encoded signal appears as random noise to a CDMA capable mobile terminal, unless that terminal uses the same codeword as the one used to encode the incoming signal.[6]



Contents


1 History
2 Constructions

2.1 Construction using inner products
2.2 Construction using a generator matrix
2.3 Construction using general Hadamard matrices


3 Distance
4 Local decodability

4.1 Proof of lemma 1
4.2 Proof of theorem 1

4.2.1 Algorithm
4.2.2 Proof of correctness




5 Optimality
6 See also
7 Notes
8 References



History[edit]
Hadamard code is the name that is most commonly used for this code in the literature. However, in modern use these error correcting codes are referred to as Walsh–Hadamard codes.
There is a reason for this:
Jacques Hadamard did not invent the code himself, but he defined Hadamard matrices around 1893, long before the first error-correcting code, the Hamming code, was developed in the 1940s.
The Hadamard code is based on Hadamard matrices, and while there are many different Hadamard matrices that could be used here, normally only Sylvester's construction of Hadamard matrices is used to obtain the codewords of the Hadamard code.
James Joseph Sylvester developed his construction of Hadamard matrices in 1867, which actually predates Hadamard's work on Hadamard matrices. Hence the name Hadamard code is not undisputed and sometimes the code is called Walsh code, honoring the American mathematician Joseph Leonard Walsh.
A Hadamard code was used during the 1971 Mariner 9 mission to correct for picture transmission errors. The data words used during this mission were 6 bits long, which represented 64 grayscale values.
Because of limitations of the quality of the alignment of the transmitter at the time (due to Doppler Tracking Loop issues) the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used.
Errors of up to 7 bits per word could be corrected using this scheme. Compared to a 5-repetition code, the error correcting properties of this Hadamard code are much better, yet its rate is comparable. The efficient decoding algorithm was an important factor in the decision to use this code.
The circuitry used was called the "Green Machine". It employed the fast Fourier transform which can increase the decoding speed by a factor of three. Since the 1990s use of this code by space programs has more or less ceased, and the Deep Space Network does not support this error correction scheme for its dishes that are greater than 26 m.
Constructions[edit]
While all Hadamard codes are based on Hadamard matrices, the constructions differ in subtle ways for different scientific fields, authors, and uses. Engineers, who use the codes for data transmission, and coding theorists, who analyse extremal properties of codes, typically want the rate of the code to be as high as possible, even if this means that the construction becomes mathematically slightly less elegant.
On the other hand, for many applications of Hadamard codes in theoretical computer science it is not so important to achieve the optimal rate, and hence simpler constructions of Hadamard codes are preferred since they can be analyzed more elegantly.
Construction using inner products[edit]
When given a binary message 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 of length 



k


{\displaystyle k}

, the Hadamard code encodes the message into a codeword 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 using an encoding function 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

. This function makes use of the inner product 



⟨
x
,
y
⟩


{\displaystyle \langle x,y\rangle }

 of two vectors 



x
,
y
∈
{
0
,
1

}

k




{\displaystyle x,y\in \{0,1\}^{k}}

, which is defined as follows:





⟨
x
,
y
⟩
=

∑

i
=
1


k



x

i



y

i


 

mod

 


2

.


{\displaystyle \langle x,y\rangle =\sum _{i=1}^{k}x_{i}y_{i}\ {\bmod {\ }}2\,.}



Then the Hadamard encoding of 



x


{\displaystyle x}

 is defined as the sequence of all inner products with 



x


{\displaystyle x}

:






Had

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
0
,
1

}

k






{\displaystyle {\text{Had}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{0,1\}^{k}}}



As mentioned above, the punctured Hadamard code is used in practice since the Hadamard code itself is somewhat wasteful. This is because, if the first bit of 



y


{\displaystyle y}

 is zero, 




y

1


=
0


{\displaystyle y_{1}=0}

, then the inner product contains no information whatsoever about 




x

1




{\displaystyle x_{1}}

, and hence, it is impossible to fully decode 



x


{\displaystyle x}

 from those positions of the codeword alone. On the other hand, when the codeword is restricted to the positions where 




y

1


=
1


{\displaystyle y_{1}=1}

, it is still possible to fully decode 



x


{\displaystyle x}

. Hence it makes sense to restrict the Hadamard code to these positions, which gives rise to the punctured Hadamard encoding of 



x


{\displaystyle x}

; that is, 




pHad

(
x
)
=


(


⟨
x
,
y
⟩



)



y
∈
{
1
}
×
{
0
,
1

}

k
−
1






{\displaystyle {\text{pHad}}(x)={\Big (}\langle x,y\rangle {\Big )}_{y\in \{1\}\times \{0,1\}^{k-1}}}

.
Construction using a generator matrix[edit]
The Hadamard code is a linear code, and all linear codes can be generated by a generator matrix 



G


{\displaystyle G}

. This is a matrix such that 




Had

(
x
)
=
x
⋅
G


{\displaystyle {\text{Had}}(x)=x\cdot G}

 holds for all 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

, where the message 



x


{\displaystyle x}

 is viewed as a row vector and the vector-matrix product is understood in the vector space over the finite field 





F


2




{\displaystyle \mathbb {F} _{2}}

. In particular, an equivalent way to write the inner product definition for the Hadamard code arises by using the generator matrix whose columns consist of all strings 



y


{\displaystyle y}

 of length 



k


{\displaystyle k}

, that is,





G
=


(



↑


↑



↑





y

1





y

2




…



y


2

k








↓


↓



↓



)



.


{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\y_{1}&y_{2}&\dots &y_{2^{k}}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}\,.}



where 




y

i


∈
{
0
,
1

}

k




{\displaystyle y_{i}\in \{0,1\}^{k}}

 is the 



i


{\displaystyle i}

-th binary vector in lexicographical order. For example, the generator matrix for the Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:





G
=


[



0


0


0


0


1


1


1


1




0


0


1


1


0


0


1


1




0


1


0


1


0


1


0


1



]


.


{\displaystyle G={\begin{bmatrix}0&0&0&0&1&1&1&1\\0&0&1&1&0&0&1&1\\0&1&0&1&0&1&0&1\end{bmatrix}}.}



The matrix 



G


{\displaystyle G}

 is a 



(
k
×

2

k


)


{\displaystyle (k\times 2^{k})}

-matrix and gives rise to the linear operator 




Had

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k






{\displaystyle {\text{Had}}:\{0,1\}^{k}\to \{0,1\}^{2^{k}}}

.
The generator matrix of the punctured Hadamard code is obtained by restricting the matrix 



G


{\displaystyle G}

 to the columns whose first entry is one. For example, the generator matrix for the punctured Hadamard code of dimension 



k
=
3


{\displaystyle k=3}

 is:






G
′

=


[



1


1


1


1




0


0


1


1




0


1


0


1



]


.


{\displaystyle G'={\begin{bmatrix}1&1&1&1\\0&0&1&1\\0&1&0&1\end{bmatrix}}.}



Then 




pHad

:
{
0
,
1

}

k


→
{
0
,
1

}


2

k
−
1






{\displaystyle {\text{pHad}}:\{0,1\}^{k}\to \{0,1\}^{2^{k-1}}}

 is a linear mapping with 




pHad

(
x
)
=
x
⋅

G
′



{\displaystyle {\text{pHad}}(x)=x\cdot G'}

.
For general 



k


{\displaystyle k}

, the generator matrix of the punctured Hadamard code is a parity-check matrix for the extended Hamming code of length 




2

k
−
1




{\displaystyle 2^{k-1}}

 and dimension 




2

k
−
1


−
k


{\displaystyle 2^{k-1}-k}

, which makes the punctured Hadamard code the dual code of the extended Hamming code. Hence an alternative way to define the Hadamard code is in terms of its parity-check matrix: the parity-check matrix of the Hadamard code is equal to the generator matrix of the Hamming code.
Construction using general Hadamard matrices[edit]
Generalized Hadamard codes are obtained from an n-by-n Hadamard matrix H. In particular, the 2n codewords of the code are the rows of H and the rows of −H. To obtain a code over the alphabet {0,1}, the mapping −1 ↦ 1, 1 ↦ 0, or, equivalently, x ↦ (1 − x)/2, is applied to the matrix elements. That the minimum distance of the code is n/2 follows from the defining property of Hadamard matrices, namely that their rows are mutually orthogonal. This implies that two distinct rows of a Hadamard matrix differ in exactly n/2 positions, and, since negation of a row does not affect orthogonality, that any row of H differs from any row of −H in n/2 positions as well, except when the rows correspond, in which case they differ in n positions.
To get the punctured Hadamard code above with 



n
=

2

k
−
1




{\displaystyle n=2^{k-1}}

, the chosen Hadamard matrix H has to be of Sylvester type, which gives rise to a message length of 




log

2


⁡
(
2
n
)
=
k


{\displaystyle \log _{2}(2n)=k}

.
Distance[edit]
The distance of a code is the minimum Hamming distance between any two distinct codewords, i.e., the minimum number of positions at which two distinct codewords differ. Since the Walsh–Hadamard code is a linear code, the distance is equal to the minimum Hamming weight among all of its non-zero codewords. All non-zero codewords of the Walsh–Hadamard code have a Hamming weight of exactly 




2

k
−
1




{\displaystyle 2^{k-1}}

 by the following argument.
Let 



x
∈
{
0
,
1

}

k




{\displaystyle x\in \{0,1\}^{k}}

 be a non-zero message. Then the following value is exactly equal to the fraction of positions in the codeword that are equal to one:






Pr

y
∈
{
0
,
1

}

k






[


(

Had

(
x
)

)

y


=
1


]


=

Pr

y
∈
{
0
,
1

}

k






[


⟨
x
,
y
⟩
=
1


]



.


{\displaystyle \Pr _{y\in \{0,1\}^{k}}{\big [}({\text{Had}}(x))_{y}=1{\big ]}=\Pr _{y\in \{0,1\}^{k}}{\big [}\langle x,y\rangle =1{\big ]}\,.}



The fact that the latter value is exactly 



1

/

2


{\displaystyle 1/2}

 is called the random subsum principle. To see that it is true, assume without loss of generality that 




x

1


=
1


{\displaystyle x_{1}=1}

. Then, when conditioned on the values of 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

, the event is equivalent to 




y

1


⋅

x

1


=
b


{\displaystyle y_{1}\cdot x_{1}=b}

 for some 



b
∈
{
0
,
1
}


{\displaystyle b\in \{0,1\}}

 depending on 




x

2


,
…
,

x

k




{\displaystyle x_{2},\dots ,x_{k}}

 and 




y

2


,
…
,

y

k




{\displaystyle y_{2},\dots ,y_{k}}

. The probability that 




y

1


=
b


{\displaystyle y_{1}=b}

 happens is exactly 



1

/

2


{\displaystyle 1/2}

. Thus, in fact, all non-zero codewords of the Hadamard code have relative Hamming weight 



1

/

2


{\displaystyle 1/2}

, and thus, its relative distance is 



1

/

2


{\displaystyle 1/2}

.
The relative distance of the punctured Hadamard code is 



1

/

2


{\displaystyle 1/2}

 as well, but it no longer has the property that every non-zero codeword has weight exactly 



1

/

2


{\displaystyle 1/2}

 since the all 



1


{\displaystyle 1}

s vector 




1


2

k
−
1






{\displaystyle 1^{2^{k-1}}}

 is a codeword of the punctured Hadamard code. This is because the vector 



x
=

10

k
−
1




{\displaystyle x=10^{k-1}}

 encodes to 




pHad

(

10

k
−
1


)
=

1


2

k
−
1






{\displaystyle {\text{pHad}}(10^{k-1})=1^{2^{k-1}}}

. Furthermore, whenever 



x


{\displaystyle x}

 is non-zero and not the vector 




10

k
−
1




{\displaystyle 10^{k-1}}

, the random subsum principle applies again, and the relative weight of 




Had

(
x
)


{\displaystyle {\text{Had}}(x)}

 is exactly 



1

/

2


{\displaystyle 1/2}

.
Local decodability[edit]
A locally decodable code is a code that allows a single bit of the original message to be recovered with high probability by only looking at a small portion of the received word.
A code is 



q


{\displaystyle q}

-query locally decodable if a message bit, 




x

i




{\displaystyle x_{i}}

, can be recovered by checking 



q


{\displaystyle q}

 bits of the received word. More formally, a code, 



C
:
{
0
,
1

}

k


→
{
0
,
1

}

n




{\displaystyle C:\{0,1\}^{k}\rightarrow \{0,1\}^{n}}

, is 



(
q
,
δ
≥
0
,
ϵ
≥
0
)


{\displaystyle (q,\delta \geq 0,\epsilon \geq 0)}

-locally decodable, if there exists a probabilistic decoder, 



D
:
{
0
,
1

}

n


→
{
0
,
1

}

k




{\displaystyle D:\{0,1\}^{n}\rightarrow \{0,1\}^{k}}

, such that (Note: 



Δ
(
x
,
y
)


{\displaystyle \Delta (x,y)}

 represents the Hamming distance between vectors 



x


{\displaystyle x}

 and 



y


{\displaystyle y}

):




∀
x
∈
{
0
,
1

}

k


,
∀
y
∈
{
0
,
1

}

n




{\displaystyle \forall x\in \{0,1\}^{k},\forall y\in \{0,1\}^{n}}

, 



Δ
(
y
,
C
(
x
)
)
≤
δ
n


{\displaystyle \Delta (y,C(x))\leq \delta n}

 implies that 



P
r
[
D
(
y

)

i


=

x

i


]
≥


1
2


+
ϵ
,
∀
i
∈
[
k
]


{\displaystyle Pr[D(y)_{i}=x_{i}]\geq {\frac {1}{2}}+\epsilon ,\forall i\in [k]}


Theorem 1: The Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

-locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Lemma 1: For all codewords, 



c


{\displaystyle c}

 in a Walsh–Hadamard code, 



C


{\displaystyle C}

, 




c

i


+

c

j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=c_{i+j}}

, where 




c

i


,

c

j




{\displaystyle c_{i},c_{j}}

 represent the bits in 



c


{\displaystyle c}

 in positions 



i


{\displaystyle i}

 and 



j


{\displaystyle j}

 respectively, and 




c

i
+
j




{\displaystyle c_{i+j}}

 represents the bit at position 



(
i
+
j
)


{\displaystyle (i+j)}

.
Proof of lemma 1[edit]

Let 



C
(
x
)
=
c
=
(

c

0


,
…
,

c


2

n


−
1


)


{\displaystyle C(x)=c=(c_{0},\dots ,c_{2^{n}-1})}

 be the codeword in 



C


{\displaystyle C}

 corresponding to message 



x


{\displaystyle x}

.
Let 



G
=


(



↑


↑



↑





g

0





g

1




…



g


2

n


−
1






↓


↓



↓



)




{\displaystyle G={\begin{pmatrix}\uparrow &\uparrow &&\uparrow \\g_{0}&g_{1}&\dots &g_{2^{n}-1}\\\downarrow &\downarrow &&\downarrow \end{pmatrix}}}

 be the generator matrix of 



C


{\displaystyle C}

.
By definition, 




c

i


=
x
⋅

g

i




{\displaystyle c_{i}=x\cdot g_{i}}

. From this, 




c

i


+

c

j


=
x
⋅

g

i


+
x
⋅

g

j


=
x
⋅
(

g

i


+

g

j


)


{\displaystyle c_{i}+c_{j}=x\cdot g_{i}+x\cdot g_{j}=x\cdot (g_{i}+g_{j})}

. By the construction of 



G


{\displaystyle G}

, 




g

i


+

g

j


=

g

i
+
j




{\displaystyle g_{i}+g_{j}=g_{i+j}}

. Therefore, by substitution, 




c

i


+

c

j


=
x
⋅

g

i
+
j


=

c

i
+
j




{\displaystyle c_{i}+c_{j}=x\cdot g_{i+j}=c_{i+j}}

.
Proof of theorem 1[edit]

To prove theorem 1 we will construct a decoding algorithm and prove its correctness.
Algorithm[edit]
Input: Received word 



y
=
(

y

0


,
…
,

y


2

n


−
1


)


{\displaystyle y=(y_{0},\dots ,y_{2^{n}-1})}


For each 



i
∈
{
1
,
…
,
n
}


{\displaystyle i\in \{1,\dots ,n\}}

:

Pick 



j
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle j\in \{0,\dots ,2^{n}-1\}}

 uniformly at random
Pick 



k
∈
{
0
,
…
,

2

n


−
1
}


{\displaystyle k\in \{0,\dots ,2^{n}-1\}}

 such that 



j
+
k
=

e

i




{\displaystyle j+k=e_{i}}

 where 



j
+
k


{\displaystyle j+k}

 is the bitwise xor of 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

.





x

i


←

y

j


+

y

k




{\displaystyle x_{i}\gets y_{j}+y_{k}}



Output: Message 



x
=
(

x

1


,
…
,

x

n


)


{\displaystyle x=(x_{1},\dots ,x_{n})}


Proof of correctness[edit]
For any message, 



x


{\displaystyle x}

, and received word 



y


{\displaystyle y}

 such that 



y


{\displaystyle y}

 differs from 



c
=
C
(
x
)


{\displaystyle c=C(x)}

 on at most 



δ


{\displaystyle \delta }

 fraction of bits, 




x

i




{\displaystyle x_{i}}

 can be decoded with probability at least 





1
2


+
(


1
2


−
2
δ
)


{\displaystyle {\frac {1}{2}}+({\frac {1}{2}}-2\delta )}

.
By lemma 1, 




c

j


+

c

k


=

c

j
+
k


=
x
⋅

g

j
+
k


=
x
⋅

e

i


=

x

i




{\displaystyle c_{j}+c_{k}=c_{j+k}=x\cdot g_{j+k}=x\cdot e_{i}=x_{i}}

. Since 



j


{\displaystyle j}

 and 



k


{\displaystyle k}

 are picked uniformly, the probability that 




y

j


≠

c

j




{\displaystyle y_{j}\not =c_{j}}

 is at most 



δ


{\displaystyle \delta }

. Similarly, the probability that 




y

k


≠

c

k




{\displaystyle y_{k}\not =c_{k}}

 is at most 



δ


{\displaystyle \delta }

. By the union bound, the probability that either 




y

j




{\displaystyle y_{j}}

 or 




y

k




{\displaystyle y_{k}}

 do not match the corresponding bits in 



c


{\displaystyle c}

 is at most 



2
δ


{\displaystyle 2\delta }

. If both 




y

j




{\displaystyle y_{j}}

 and 




y

k




{\displaystyle y_{k}}

 correspond to 



c


{\displaystyle c}

, then lemma 1 will apply, and therefore, the proper value of 




x

i




{\displaystyle x_{i}}

 will be computed. Therefore, the probability 




x

i




{\displaystyle x_{i}}

 is decoded properly is at least 



1
−
2
δ


{\displaystyle 1-2\delta }

. Therefore, 



ϵ
=


1
2


−
2
δ


{\displaystyle \epsilon ={\frac {1}{2}}-2\delta }

 and for 



ϵ


{\displaystyle \epsilon }

 to be positive, 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}

.
Therefore, the Walsh–Hadamard code is 



(
2
,
δ
,


1
2


−
2
δ
)


{\displaystyle (2,\delta ,{\frac {1}{2}}-2\delta )}

 locally decodable for 



0
≤
δ
≤


1
4




{\displaystyle 0\leq \delta \leq {\frac {1}{4}}}


Optimality[edit]
For k ≤ 7 the linear Hadamard codes have been proven optimal in the sense of minimum distance.[7]
See also[edit]

Zadoff–Chu sequence — improve over the Walsh–Hadamard codes

Notes[edit]



^ http://www.mcs.csueastbay.edu/~malek/TeX/Hadamard.pdf
^ See, e.g., Amadei, Manzoli & Merani (2002)
^ See, e.g., Arora & Barak (2009, Section 19.2.2).
^ See, e.g., Guruswami (2009, p. 3).
^ Bose, R.C.; Shrikhande, S.S. (1959). "A note on a result in the theory of code construction". Information and Control. 2 (2): 183–194. CiteSeerX 10.1.1.154.2879 . doi:10.1016/S0019-9958(59)90376-6. 
^ "CDMA Tutorial: Intuitive Guide to Principles of Communications" (PDF). Complex to Real. Retrieved 4 August 2011. 
^ Jaffe, David B.; Bouyukliev, Iliya, Optimal binary linear codes of dimension at most seven 



References[edit]

Amadei, M.; Manzoli, U.; Merani, M.L. (2002), "On the assignment of Walsh and quasi-orthogonal codes in a multicarrier DS-CDMA system with multiple classes of users", Global Telecommunications Conference, 2002. GLOBECOM'02. IEEE, 1, IEEE, pp. 841–5, ISBN 0-7803-7632-3, doi:10.1109/GLOCOM.2002.1188196 
Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4 
Guruswami, Venkatesan (2009), List decoding of binary codes (PDF) 
Rudra, Atri, "Hamming code and Hamming bound" (PDF), Lecture notes 







v
t
e


Consultative Committee for Space Data Systems



Data compression



Images

ICER
JPEG
JPEG 2000
122.0.B1


Data

Adaptive Entropy Coder







Error Correction



Current
Binary Golay code
Concatenated codes
Turbo codes
Proposed
LDPC codes





Telemetry command uplink



Command Loss Timer Reset
Proximity-1 Space Link Protocol





Telemetry downlink



Spacecraft Monitoring & Control
Beacon mode service





Telemetry general



Space Communications Protocol Specifications (SCPS): Performance Enhancing Proxy





Telemetry modulation systems



Current
BPSK
QPSK
OQPSK
Proposed
GMSK





Frequencies



X band
S band
Ku band
K band
Ka band





Networking, interoperability and monitoring



Service-oriented architecture (Message Abstraction Layer)










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Hadamard_code&oldid=783123479"					
Categories: Coding theoryError detection and correction 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


CatalàDeutsch日本語 
Edit links 





 This page was last edited on 31 May 2017, at 08:02.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 






   Equestrian Equipment | Walsh Products                                                                           Dealer Locator | News & Events |  Contact Us                   Cart is Empty                          Menu  Racing  Race Harness  USA Style Harness  International Style Harness    Bridles, Race Halters & Accessories  USA Bridles  International Bridles  Race Halters  Accessories    Harness Race Accessories  Buxtons & Breast Collars  Harness Pads  Girths & Backstraps  Lines & Handholds  Martingales & Tie Downs  Race Accessories    Hopples  Leg Protection  Front Tendon Boots  Hind Boots  Knee & Ankle Boots  Miscellaneous Leg Protection    Monté Race Equipment  Thoroughbred Race Equipment  Halters & Leads  Accessories  For the Driver  Private Label Products    Equestrian  Halters  Leads  Accessories  Training Equipment  Headstalls, Nosebands & Accessories  Martingales & Training Products  Lunging Equipment  Rider Accessories    Beris Bits  Leather & Foam Bits  Eggbutt Bits  Comfort Bar Bits  Port Bits  Butterfly Bits    Leg Protection  Front Tendon Boots  Hind Boots  Bell Boots, Quarter Boots & Miscellaneous Protection    Zandona Boots  Girths  For the Rider  Apparel  Riding Crops & Accessories    Private Label Products    Saddle Seat  Show Harness  Girths  Training Equipment  Training Products - Leg Action  Training Products - Rider Aids    Leg Protection  Tailsets & Accessories  For the Rider    Canine & Specialty  Canine Products  Specialty Products  Private Label Products    Apparel & Accessories  About Walsh  History  Sponsored Riders  Hawley Bennett  Scott Brash  Laura Kraut  Nick Skelton  Kent Farrington  Daniel Deusser  Lynn Symansky  Richie Moloney  Marilyn Little  Cian O'Connor  Lorenzo de Luca  Tiffany Foster  Taizo Sugitani  Darragh Kenny  Sergio Alvarez Moya  Dirk Demeersman  Mavis Spencer  Hannah Salazar    Sponsored Drivers  Tim Tetrick  Scott Zeron  Jody Jamieson  Johan Untersteiner  Ronnie Wrenn, Jr  Doug McNair  Tyler Smith  Marcus Melander  Marcus Miller  Trace Tetrick  Paula Pettersson    Affiliations  Contract Sewing/Private Label Products                      Equestrian        Home Equestrian            Equestrian Equipment Whether you are a Gold Medal Olympian or a first time exhibitor, the concept of teamwork is important to achieve a Winning Performance. Your team may simply include you and your horse or it may entail a team of trainers, veterinarians, stable managers and, of course, a slew of mentors. No matter the size or status of your team, Walsh wants to make sure we are there for you and your team. When you use Walsh equestrian equipment, we become part of your team, something we are very proud of. We will do everything we can to help you triumph in your winning performance, whatever that may be.      Halters    View      Leads    View      Accessories    View      Training Equipment    View      Beris Bits    View      Leg Protection    View      Zandona Boots    View      Girths    View      For the Rider    View      Private Label Products    View              Equestrian     Halters    Leads    Accessories     Training Equipment  Headstalls, Nosebands & Accessories  Martingales & Training Products  Lunging Equipment  Rider Accessories       Beris Bits  Leather & Foam Bits  Eggbutt Bits  Comfort Bar Bits  Port Bits  Butterfly Bits       Leg Protection  Front Tendon Boots  Hind Boots  Bell Boots, Quarter Boots & Miscellaneous Protection      Zandona Boots    Girths     For the Rider  Apparel  Riding Crops & Accessories      Private Label Products        Testimonials loading...               Contact Us   Contact Us & Map    800-558-5515   262-797-9888   262-797-9910     Customer Service Become a Dealer     Privacy Policy Terms of Use        Copyright © 2014-2017 Walsh Products, Inc.                                         

Walsh De Gogue - Equus Now!










































































  Loading... Please wait...













Sign In New Customers


Order Status








SHOPPING CART




Call us (740) 549-4959 or (877) 740-4959


Free shipping on most orders over $100







Home

For The Horse
 
For The Rider
 
For The Barn
 
Gifts
 
Consignment Shop
 
Sale
 
Our Retail Store
 
Contact















Categories


 Equus Now! Gear
 For the Horse
 For the Rider
 For the Barn
 Gifts
 Consignment Shop
 Sale
 Custom Items 







						Our Newsletter
					



Your First Name:

Your Email Address:
















































Click to enlarge









Walsh De Gogue


LIST PRICE:

$152.95



OUR PRICE:

$137.95
 (You save $15.00)



SKU:


                            WALSH SKU 8104
                        



Vendor:




Brand:

Walsh



Condition:




Weight:






Rating:


(
                            

                        )



Availability:




Shipping:

                        Free Shipping
                    


Minimum Purchase:

                         unit(s)
                    


Maximum Purchase:

                         unit(s)
                    


:






Gift Wrapping:















Quantity:



1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30






							Buy in bulk and save
						





































Product Description

An efficient training device that can be used for both lunging and riding. Designed to encourage your horse to lower their head in order to assist in strenthening their neck and back muscles. The degogue applies light pressure to develop a balanced, rounded horse while engaging from behind. Made of high quality Havana leather, soft chap leather padding, stainless steel hardware, as well as a strong and durable nylon rope. Available in Havana Only. 








Vendors Other Products





View All Products





write a review
Product Reviews







Write Your Own Review


How do you rate this product?


 
5 stars (best)
4 stars
3 stars (average)
2 stars
1 star (worst)


Write a headline for your review here:

Write your review here:

Enter your name: (optional)

Enter the code below:






						










		This product hasn't received any reviews yet. Be the first to review this product!
	






Related Products







Walsh Chambon


$157.95 $141.99












Walsh Double Stitched Replacement Crown


$28.00 $24.99












Walsh German Olympic Martingale


$208.00 $186.99












Walsh British Triple Stitched Leather Halter


$111.95 $100.99



















Shop our site

For The Horse
For The Rider
For The Barn


Gifts
Consignment Shop
Sale



Important Links

Retail Store
Shipping & Returns
Advertising Opportunities
Mobile Rig Travels
Newsletter Archive
Saddle Trade in Program


Ebay Store
Amazon Store
Sponsorship Program
Helmet Accident Policies
Saddle Fitting Service
Consign with Us


Stay Informed

 Facebook
 Twitter
 YouTube


 Pinterest
 Instagram
 Newsletter


Questions?
Call: (740) 549-4959 or
                        Toll Free: (877) 740-4959
















Microsoft personalized ad preferences




 













To opt out of personalized ads in this browser, your browser history must allow first-party and third-party cookies and you must have your browsing experience set to NOT delete browsing history on exit. Instructions for enabling cookies and configuring your browsing history may be available in your browsers settings, privacy, or help documentation.

















Sign in
















  Hold on… We’re sorry but this didn’t work.                  You can’t turn off personalized ads right now because your browser is currently blocking third-party cookies. We can help you fix this issue.                Let’s get started:  Depending on what browser you use, open Options or Settings.                  Make sure that third-party cookies are not blocked anymore. To find out how, search your browser’s Help.                                 Revisit http://choice.microsoft.com/opt-out, and then on the “Personalized ads in this browser” tile, click Off.                 ext74081 




  About Our Ads To create a more customized online experience, some of the ads you may receive on Microsoft websites and apps are tailored to your previous activities, searches and site visits. You're in control and here's where you can make the advertising choice that's right for you. ext74075 




  Where Can I Learn More about Advertising on Microsoft Websites and Apps? Microsoft partners with Oath, AppNexus and other third party service providers to help present customized content and display advertisements on MSN, Outlook.com and other websites and apps. Microsoft also delivers search ads to Bing and our search syndication partners. Learn more about Microsoft’s privacy practices here. You can learn more about interest-based ads from Oath and AppNexus in their privacy statements: Oath and AppNexus. What Choices Do I Have About Interest-Based Advertising? On this page, you can opt out of receiving interest based advertising from Microsoft. You can also opt out of receiving interest-based advertising from all self-regulatory members, including Microsoft, Oath, AppNexus and other third party ad networks, at the following sites:  In the US: Digital Advertising Alliance (DAA) In Europe: European Interactive Digital Advertising Alliance (EDAA) In Canada: Ad Choices: Digital Advertising Alliance of Canada (DAAC)  You can control interest-based advertising in Windows apps by turning off the advertising ID in Windows Settings.  More choices  Do you want personalized ads from other companies?  Questions? If you have a privacy question or a question for the Chief Privacy Officer of Microsoft, please contact us by using our web form. We will respond to questions within 30 days. ext74076 




       Personalized ads in this browser     OFF    Opt-out is currently unavailable, please try again later.  Control the "personalized ads" setting for this web browser.  Learn more           If you want Microsoft to show ads that might be relevant to you, click On. To show “generic” ads, click Off.          ext74078 




       Personalized ads wherever I use my Microsoft account     OFF   Sign in to change...    Opt-out is currently unavailable, please try again later.  Control the "personalized ads" setting that applies when you are signed in on any computer or device with your Microsoft account, including Windows, Windows phone, Xbox and other devices.  Learn more                    If you want Microsoft to show ads that might be relevant to you, click On. To show “generic” ads, click Off.         If you choose “generic” ads and use a browser, your choice applies to everyone when using that browser as long as you do not clear your cookies.          ext74079 




       Personalized ads in Windows         In your Windows Settings, you can turn off personalized ads that appear in apps on this device. You’ll still see ads, but they won’t be personalized anymore.     If you have Windows 8.1:            Access the charms by touching or moving your pointer to the right edge of the screen.                 Click or tap Settings, and then click or tap Change PC Settings.                 Click or tap Privacy, and then turn off Let apps use my advertising ID for experiences across apps.          If you have Windows 10:            Click or tap the Start button.                 Click or tap Settings.                 Click or tap Privacy, and then turn off Let apps use my advertising ID for experiences across apps.          If you have a Windows mobile device:            Go to Settings.                 Tap on Privacy.                 Tap on Advertising ID, and then turn off Let apps use my advertising ID for experiences across apps.                If you want to turn off personalized ads from Microsoft wherever you use your Microsoft account including apps on Windows, Windows Phone, Xbox and other devices, you can do so by selecting the Microsoft account option above.    ext74080 














Legal
Privacy & Cookies
© 2017 Microsoft









     Walsh Door & Hardware Inc - Des Moines, IA         














































                CMD Group is a ConstructConnect™ company. Learn more
















SBI home



Products



Companies


Specs














CompaniesView Product/ServicesContact InformationWalsh Door & Hardware Inc2600 Delaware AveDes Moines, IA  50317Phone: (515) 262-9822Fax: (515) 262-8315Website:www.walshdoor.com 



Regional Coverage 
Walsh Door & Hardware IncProduct Supplier / DistributorTo update this listing or get your company profile into SmartBuilding Index, Contact Us.Related keywords: 



Products/Services

Market Intelligence
Project Leads

Marketing Solutions
Terms of Service
Customer Testimonials



The Company

Why Choose Us
Press Releases
Partners
Executive Team
Careers
Contact Us



Resource Center

Building Codes
Project Leads by State
Project Leads by Type
Video library



News/Events

News
CEU Classes
Events
AEC Cares
RSS Feeds



Contact Us

Customer Support
Sales
Media/PR
General Questions
Content Approvals
Reprints
Payment Options
Request a Demo























































Des Walsh Home Page


















































+61 413089355




Facebook




Twitter




Google




RSS


 





Facebook




Twitter




Google




RSS



 

















Select Page


 




 
















 




Entrepreneurs! Too many options to weigh up? Need clarity to move ahead with confidence?
See what others like you have said about how just one session of my laser coaching has helped them break through: just click here.




 





 




 
 

Reclaiming My Passion for Blogging
by Des Walsh I’ve known for a while that not only was I not blogging so much but I’d actually mislaid or lost my earlier passion for blogging. In this post I talk about factors that turned what had been enjoyable into a chore, factors including too many “rules” for blogging. And how I decided to throw caution to the wind and post about whatever I wanted to post about and how I would do that.
read more


 
 

Do Your Business Values Include Having Fun?
by Des Walsh When I moved from working for government to being in business, I understood public service values and how important they are, but did not really focus on what business values I might want to subscribe to. I soon learned that business values are at least as important...
read more


 
 

Red Teaming and Other War Gaming for Business: Fred Aubin [Podcast]
by Des Walsh Lieutenant-Colonel (retd) Fred Aubin, CD, MCGI, is Founder and CEO of Strategic Red Team Consulting, and is based in Ottawa, Canada. A 34 year command-level combat veteran of the Canadian Forces, Fred leads a consultancy team with an extensive arsenal of expertise for...
read more


 
 

Diversity & Inclusivity Keys to New Leadership: Sunny Stout-Rostron [Podcast]
by Des Walsh From sunny California, via London and Paris, and with a formidable array of degrees ranging from Foothill College in Los Altos Hills, California, through the Universities of Portsmouth, Sussex and Middelsex (DProf, Executive Coaching from the last-mentioned), to South...
read more


 
 

No Ceiling, Just Sky™ Institute Founder, Donna Karlin [Podcast]
by Des Walsh Donna Karlin is a global leadership coach. She works with senior-level clients on six continents: N. America, S. America, Europe, Asia, Africa, and Australia. She is a coach and mentor to TED Fellows, a Founding Fellow at Harvard Institute of Coaching, McLean Medical...
read more


 
 

New Facebook Group for Real Conversation and Great Business Relationships
by Des Walsh I'm launching a new group on Facebook, the Coffee Break Network. Rationale and Group Concept First, why am I doing this? My Linking Business Professionals group on LinkedIn (originally the 30 Day LinkedIn Blitz Group) has passed its use-by date. I am increasingly...
read more


 
 

Leading Local Economic Development: Cr Hermann Vorster [Podcast]
by Des Walsh Councillor Hermann Vorster represents Division 11 on the City Council of the Gold Coast, Queensland, Australia. He also chairs the Council’s Economic Development and Major Events Committee.  He also serves on the City Planning and City Infrastructure committees....
read more


 
 

Transforming Careers, Guiding Business: Larry Cornett: [Podcast]
by Des Walsh Dr Larry Cornett is a business advisor and career consultant and Founder of Brilliant Forge. He helps people redefine their career, regain their freedom, and reclaim their life. Prior to founding Brilliant Forge, Larry was a product and design executive with over 18...
read more

 
 

 
 Stay Informed Get blog posts delivered to your email inbox
Get updates via RSS (What’s RSS?)

  

 Best Scheduling App 

 CategoriesCategories
Select Category
Blogging
Business
Coaching
Events
Facebook
General
Leadership
LinkedIn
Marketing
Podcast
Podcast Episodes
Podcasts
Resources
Social Business
Social Media


 Archives Archives

Select Month
 July 2017 
 June 2017 
 April 2017 
 March 2017 
 February 2017 
 December 2016 
 November 2016 
 October 2016 
 September 2016 
 August 2016 
 July 2016 
 June 2016 
 May 2016 
 April 2016 
 March 2016 
 February 2016 
 January 2016 
 December 2015 
 November 2015 
 October 2015 
 September 2015 
 August 2015 
 July 2015 
 June 2015 
 May 2015 
 March 2015 
 February 2015 
 January 2015 
 October 2014 
 September 2014 
 August 2014 
 July 2014 
 June 2014 
 May 2014 
 April 2014 
 March 2014 
 February 2014 
 January 2014 
 December 2013 
 November 2013 
 October 2013 
 September 2013 
 August 2013 
 July 2013 
 June 2013 
 May 2013 
 April 2013 
 March 2013 
 February 2013 
 January 2013 
 December 2012 
 November 2012 
 October 2012 
 September 2012 
 August 2012 
 July 2012 
 June 2012 
 May 2012 
 April 2012 
 March 2012 
 February 2012 
 January 2012 
 December 2011 
 October 2011 
 September 2011 
 August 2011 
 June 2011 
 May 2011 
 April 2011 
 March 2011 
 February 2011 
 January 2011 
 December 2010 
 November 2010 
 October 2010 
 September 2010 
 August 2010 
 July 2010 
 June 2010 
 May 2010 
 April 2010 
 March 2010 
 February 2010 
 January 2010 
 November 2009 
 October 2009 
 September 2009 
 August 2009 
 July 2009 
 June 2009 
 May 2009 
 April 2009 
 March 2009 
 February 2009 
 January 2009 
 December 2008 
 November 2008 
 October 2008 
 September 2008 
 August 2008 
 July 2008 
 June 2008 
 May 2008 
 April 2008 
 March 2008 
 February 2008 
 January 2008 
 December 2007 
 November 2007 
 October 2007 
 September 2007 
 August 2007 
 July 2007 
 June 2007 
 May 2007 
 April 2007 
 March 2007 
 January 2007 
 November 2006 
 October 2006 
 September 2006 
 August 2006 
 July 2006 
 June 2006 
 May 2006 
 February 2006 
 January 2006 
 November 2005 
 October 2005 
 September 2005 

 Des posts also at  
Recent Posts
How an Effective Leader Responds to a Negative Surprise 
What Leadership Skills are Needed for Merger Boom Time?
What to Do If You’re the Fair Weather Leader?
 
 
 
 
 



 
 
 




Hi, I’m Des Walsh. I support business owners and entrepreneurs by providing attentive, appreciative listening and fresh, strategic thinking about problems, challenges and opportunities.
I’ve been where you are. I've carried the responsibility for multimillion dollar projects. I've led teams working to immovable deadlines. And long ago I made the entrepreneurial jump to create my own consulting and coaching business. So I know solopreneur, microbusiness as well as the big picture stuff.
Now as a business coach, my specialty is being an independent, professional sounding board and strategic “thinking partner”. I'm also able to help with guidance on how to use social media effectively for your business.
If you're ready to change, ready to go beyond the lonely thinking of the "CEO internal monologue", I have programs to support that and I'm ready to help. Just grab a time in my schedule here and let's talk.

 
 



 
 
 





Click Here for more about Des and his work

 




It has been my pleasure to have Des as my business coach for the past 14 years. Des combines all the fundamentals of a good coach - expert knowledge; clear manner; guidance and suggestion rather than didactic instruction - with a leading edge knowledge of the way social media can improve my business. He is a trusted colleague and a key part of the continued success of my firm.
Kris Gale
Chairman, Michael Johnson Associates
 
 
 
 
 
 






Business Coaching
My focus as a business coach is on listening attentively to my clients. My mission is eliciting their greatness. I specialise in working with smart, interesting, well-balanced business owners and entrepreneurs in the professional services sector, combining my life and business experience with advanced coaching skills to be their objective, professional sounding board. [Read more ...]

					
 
 
 



Strategic Social Media
Too many business owners and entrepreneurs find social media overwhelming or just confusing. As a long term business user of social media and a certified social media strategist, I help my clients cut through the social media hype and align their social media activity with their strategic business objectives.[Read more ...]

					
 
 
 
 
 




Social Business Bites
Keep up with the latest social media developments, in bite-sized nuggets. My personally curated, best-of-the-week links, with brief comments.




Name



Email Address


Count me in!




 





Social Business Bites stands out because it's useful. Each article Des includes is there for a reason, and he always explains why it matters. His insight about business and technology and his depth of knowledge make all the difference. That's why I read every issue.
Becky McCray
Entrepreneur, Speaker, Author
 
 
 
 
 
 







Des Walsh is a driven and focused entrepreneur who stays in touch with the latest trends, resources, and technologies available to small business. These qualities, combined with years of experience in his field, make Des a superior coach and mentor.
In a single, thirty-minute conversation, Des redirected some concerns I had about my business model, introduced me to several valuable resources, and brought clarity to an issue that I’ve been struggling with for months. Yes, all of this in thirty-minutes!
I highly recommend that you consult with Des if you are a growth-minded entrepreneur who wishes to take your business far beyond its current state.
Marla Tabaka
Business Coach, Inc. Author, Small Business Strategist, MTabaka Enterprises Inc,
 
 
 
 
 
 
  
 
 
 
 
 































